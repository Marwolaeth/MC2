# Continuous change {#sec-continuous-change}

```{r child="../starter.Rmd"}
```

For our purposes, a good definition of calculus is  

> *The use of functions to model and explore continuous change*

In previous chapters we defined and studied functions. Now it is time to get at the core of calculus, the idea of "continuous change."


## Mathematics in motion

The questions that started it all had to do with motion of planets and marbles. In more technical language, "ballistics," the science of balls. There were words to describe speed: fast and slow. There were words to describe force: strong and weak, heavy and light. And there were words to describe location and distance: far and near, long and short, here and there. But what were the relationships among these things? And how did time fit in, an intangible quantity that had aspects of location (long and short) and speed (quick and slow)? 

Galileo (1564-1642) started the ball rolling.^[Galileo was not aware of Kepler's elliptical theory, even though they lived at the same time.] As the son of a musician and music theorist, he had a sense of musical time, a steady beat of intervals. When a student of medicine in Pisa, he noted that swinging pendulums kept reliable time, regardless of the amplitude of their swing. After unintentionally attending a geometry lecture, he turned to mathematics and natural philosophy. 

```{asis eval=knitr::is_html_output()}
::: {.column-margin}
<iframe width="140" height="79" src="https://www.youtube.com/embed/9BQKe9HT1OE?start=9" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

A re-enactment of Galileo's rolling-ball experiment. The frets on the ramp are at positions 2 cm, 8 cm, 18 cm, 32 cm, 50 cm, ..., that is, 2 cm times 1, 4, 9, 16, 25.
:::
```

```{r eval=knitr::is_latex_output(), echo=FALSE}
#| label: fig-galileo-reinactment
#| fig-cap: "A re-enactment of Galileo's rolling-ball experiment. The frets on the ramp are at positions 2 cm, 8 cm, 18 cm, 32 cm, 50 cm, ..., that is, 2 cm times 1, 4, 9, 16, 25. Link to video: <https://youtu.be/9BQKe9HT1OE?t=9>"
#| column: margin
knitr::include_graphics("www/galileo-reinactment.png")

```

Using his newly developed apparatus, the telescope, Galileo's observations put him on a collision course with the accepted classical truth about the nature of the planets. Seeking to understand gravity, he built an apparatus that enabled him accurately to measure the position in time of a ball rolling down a straight ramp. The belled gates he set up to mark the ball's passage were spaced evenly in musical time: 1, 2, 3, 4, .... To get this even spacing in time, Galileo found he had to position the gates unevenly. Defining as 1 the distance of the first gate from the ball's release point, the gates were at positions 1, 4, 9, 16, .... 

::: {#tbl-galileo-ball .column-margin}

$t$ | $x(t)$ | first increment | second increment
----|--------|-------|-------
0   | 0      | 1        | 2
1   | 1      | 3        | 2
2   | 4      | 5        | 2
3   | 9      | 7        | 
4   | 16     |          |

Galileo's observations and first & second increments. 

:::


Anyone familiar with the squares of the integers can see the pattern in 1, 4, 9, 16, .... To demonstrate the pattern even more clearly, Galileo took the difference between the successive positions, what we'll call the "first increment." 

$$\underbrace{1 - 0}_1 \ \ \ \ \ \underbrace{4 - 1}_3\ \ \ \ \ \underbrace{9 - 4}_{5}\ \ \ \ \ \underbrace{16-9}_7\ \ \ \underset{{\Large\strut}\text{first increment}}{\text{}}$$
Next, Galileo repeated the differencing process on the first increment to produce a "second increment."

$$\underbrace{3 - 1}_2 \ \ \ \ \ \underbrace{5 - 3}_2\ \ \ \ \ \underbrace{7 - 5}_{2}\ \ \ \underset{{\Large\strut}\text{second increment}}{\text{}}$$
::: {.column-margin} For more about Galileo's measurements, see 
Stillman Drake (1986) "Galileoâ€™s physical measurements" *American Journal of Physics* **54**, 302-305 <https://doi.org/10.1119/1.14634>
:::


The rule established by Galileo's observations for the motion of a ball rolling down the ramp:

> The second increment of position is constant.

## Continuous time

Galileo's mathematics of first and second increments was suited to the discrete-time measurements he was able to make. It would be for Newton to develop the continuous-time analog of increments. 

To start, we can imagine a function $x(t)$ that gives the position of the ball at any instant $t$. With this notation, Galileo's measured positions were $x(0), x(1), x(2), x(3), x(4), \ldots$, and the first increments were $x(1) - x(0)$, $x(2) - x(1)$, $x(3) - x(2)$, and so on. 

But just as position $x(t)$ is a continuous function of time $t$, the first increment can also be written as a continous function: $$\text{First increment function:}\ \ \ \ y(t) \equiv x(t+1) - x(t)\ .$$
Similarly, there is a second increment function: 
\begin{eqnarray}\text{Second increment function:}\ \ \ \ z(t) & \equiv&  y(t+1) - y(t)\\ & = & \left[x(t+2) - x(t+1)\right] - \left[x(t+1) - x(t)\right] \\ &=& x(t+2) - 2 x(t+1) + x(t)\ .
\end{eqnarray} 

The $+1$ and $+2$ in the first and second increment functions correspond to the time elapsed from one belled gate to the next. More generally, rather than using Galileo's unit of rhythmic time, we can define the increment functions using a time quantity of our own choice; we'll call it $h$.

Re-written using $h$, the first increment becomes $$\text{First increment function:}\ \ \ \ y(t) \equiv x(t+h) - x(t)\ .$$
The second increment function is 
\begin{eqnarray}\text{Second increment function:}\ \ \ \ z(t) & \equiv&  y(t+h) - y(t)\\ & = & \left[x(t+2h) - x(t+h)\right] - \left[x(t+h) - x(t)\right] \\ &=& x(t+2h) - 2 x(t+h) + x(t)\ .
\end{eqnarray} 

Evidently, the numerical values (dimension L) of the first and second increments depend on $h$, which is a choice made by the experimenter, not a fact of nature. If the experimenter selects a large $h$, the first and second increments will be large.

It would be nice to frame the ballistics theory so that $h$ does not appear. Newton's insight amounts to taking two steps:

::: {.column-margin}
Note that we're using the symbol ${\cal D}\_t$ and naming the rate of change function ${\cal D}_t y(t)$. Read ${\cal D}_t$ as "the rate of change with respect to $t$.
:::

1. Replace the simple difference $x(t+h) - x(t)$ with a ***rate of change***, that is:
$$\text{Rate of change of } x(t): \ \ \ \ {\cal D}_t y(t) \equiv \frac{x(t+h) - x(t)}{h}$$
::: {.column-margin}
Read ${\cal D}_t {\cal D}_t y(t)$ as "the rate of change of the rate of change of $y(t)$.
:::

Likewise, the second increment will become a "rate of change of a rate of change," a phrase that is easier to understood when written as a formula:



$$
{\cal D}_t {\cal D}_t y(t)  \equiv   {\cal D}_t \left(\strut \frac{{\cal D}_t y(t+h) - {\cal D}_t y(h)}{h}\right) \\
&=& \frac{y(t+h) - y(t)}{h} \\
&=& \frac{\frac{x(t+2h) - x(t+h)}{h}- \frac{x(t+h) - x(t)}{h}}{h}\\
&=& \frac{x(t+2h) - 2 x(t+h) + x(t)}{h^2}\ .
$$

Admittedly, this complicated expression for the rate-of-change equivalent of Galileo's second increment hardly looks like an improvement! And it still depends on $h$.

This is where the second step of Newton's insight comes in. 

2. Make $h$ vanishingly small. 

In the next chapters, we'll look at how these two steps---use rate of change rather than change and make $h$ vanishingly small---create mathematical entities that allowed Newton to extend Galileo's work to become a universal theory of motion.



PUT THIS IN THE NEXT CHAPTER


Over the next three centuries, calculus evolved from a set of techniques for describing motion into the general-purpose mathematics of change. Applying calculus in the real world involves understanding change relationships between quantities. To give some examples: 

- Electrical power is the rate of change with respect to time of electrical energy.
- Birth rate is one component of the rate of change with respect to time of population.
- Interest, as in bank interest or credit card interest, is the rate of change with respect to time of assets. 
- Inflation is the rate of change with respect to time of prices.
- Disease incidence is one component of the rate of change with respect to time of disease prevalence.
- Force is the rate of change with respect to position of energy.




## Instantaneous rate of change

On the radio once, I heard a baseball fanatic describing the path of a home run slammed just inside the left-field post. "Coming off the bat, the ball screamed upwards, passing five stories over the head of the first baseman and still gaining altitude. Then, somewhere over mid-left-field, gravity caught up with the ball, forcing it down faster and faster until it crashed into the cheap seats." A gripping image, perhaps, but wrong about the physics. Gravity doesn't suddenly catch hold of the ball. Even when upward bound, gravity influences the ball to the same extent as it does at the peak of the flight and as the ball falls back down. The vertical velocity of the ball is positive while climbing and negative on descent, but that velocity is steadily changing all through the flight: a smooth, almost linear numerical decrease in velocity from the time the ball leaves the bat to when it lands in the bleachers.

At each instant of time, the ball's vertical velocity has a numerical value in feet-per-second (L T^-1^). That value changes continuously. If $Z(t)$ is the height of the ball at time $t$, and $v_Z(t)$ is the vertical velocity at time $t$, then the slope function $${\cal D}_t Z(t) \equiv \frac{Z(t+h) - Z(t)}{h}$$ tells us the average velocity of the ball over a time interval of $h$.

The "average velocity" is a human construction. At each instant in time the ball has a continuously changing velocity. Velocity is an instantaneous quantity. The average velocity is merely a concession to the way we measure the velocity, by recording the height at two different times and computing the difference in height divided by the difference in time.

Our measurement of the average velocity gets closer to the instantaneous velocity when we make the time interval $h$ smaller. "Making $h$ smaller" is not the same thing as "setting $h$ to zero." If we were brusquely to set $h=0$, the slope function would be $${\cal D}_t Z(t) \equiv \frac{Z(t+0) - Z(t)}{0} = \frac{Z(t) - Z(t)}{0} = \frac{0}{0}\ .$$ This $0/0$ is not an arithmetical quantity.

::: {.column-margin}
Think of $\partial_t f()$ as the **name** of a function, the equivalent of "son" in the old-style of patronymic names where "Johnson" refers to the son of a man named John. The name $\partial_t f()$ tells us how the thus-named function is related to $f()$.
:::

The logic of calculus is not to abruptly set $h=0$, but to treat $h$ as a gradual, ***evanescent h*** that gently gets smaller and smaller. The type of slope function calculated with this (as yet undefined) evanescent h is called a ***derivative*** and corresponds to the instantaneous rate-of-change function. The process of constructing the derivative of a function $f(t)$ is called ***differentiation***. And to help us keep track of things, whenever we construct a derivative of $f(t)$ with respect to $t$, we will name the constructed function $\partial_t f(t)$. The small symbol $\partial$ is a reminder that we are looking only at a small difference, as opposed to the $\cal D$ of the slope operator where $h$ can potentially be not so small.

## Change relationships

As you know, ***function*** is a mathematical idea used to represent a relationship between quantities. For instance, the **water volume** of a reservoir behind a dam varies with the seasons and over the years. As a function, water volume is a relationship between water volume (one quantity) and time (another quantity). Similarly, the **flow** in a river feeding the reservoir has its own relationship with time. In spring, the river may be rushing with snow-melt, in late summer the river may be dry, but after a summer downpour the river flow again rises briefly. In other words, river flow is a function of time.

***Differentiation*** is a way of describing a *relationship between relationships*. The water volume in the reservoir has a relationship with time. The river flow has a relationship with time. Those two relationships are themselves related: the river flow feeds the reservoir and thereby influences the water volume.

It's not easy to keep straight what's going on in a "relationship between relationships." Consequently, we need tools such as differentiation to aid our understanding. For instance, Johannes Kepler (1572-1630) spent years analyzing the data collected by astronomer Tycho Brahe (1546-1601). The data showed clearly a relationship between time and the speed of a planet across the sky. Long-standing wisdom claimed that there is also a specific relationship between a planet's position and time. From antiquity, it had been claimed that planets moved in circular orbits. Kepler worked hard to find the relationship between the two relationships: speed versus time and position versus time. He was unsuccessful until he dropped the assumption that planetary orbits are circular. Testing the hypothesis that orbits are **elliptical**, Kepler was able to find a simple relationship between speed vs. time and position vs. time.  

Building on Kepler's earlier work, Newton hypothesized that planets might be influenced by the same gravity that pulls an apple to the ground. It was evident from human experience that gravity has the most trivial relationship with time: gravity is constant! But Newton could not find a link between this notion of gravity as a constant and Kepler's planetary motion as a function of time. Success came when Newton hypothesized---without any direct evidence from experience---that gravity is a function of distance. Newton's formulation of the relationship between relationships--- gravity-as-a-function-of-distance and orbital-position-as-a-function-of time---became thefou ndation of modern science. Newton's theories of gravity, force, and motion created an extremely complicated chain or reasoning that is still hard to grasp. Or, more precisely, it is hard to grasp *until* you have the language for describing relationships between relationships. Newton invented this language: differentiation. As you learn this language, you will find it easier to express and understand relationships between relationships, that is, the mechanisms that account for the ever-changing quantities around us.

## Slopes and motion

Consider a graph of the position of a car along a road as in @fig-stop-and-go.  Over the course of an hour, the car traveled about 25 miles. In other words, the ***average*** speed is 25 miles/hour: the *slope* of the tan-colored line segment. Given the traffic, sometimes the car was stopped (time C), sometimes crawling (time D) and sometimes much faster than average (time B).   

```{r echo=FALSE}
#| label: fig-stop-and-go2
#| fig-cap: "The position of an imagined car over an hour of time. (black) The tan-colored line shows what the position would have been if the car had travelled steadily at the average speed for the hour."
f <- rfun(~ t, seed=105, n=5)
raw <- function(t) 
        f(t) - t - 30*dnorm(t, 0, 3) + 60*dnorm(t,7,1)
speed <- function(t) {
    pmax(4*raw(20*(t-.5)), 0)
}
position <- antiD(speed(t) ~ t)
Pts <- tibble::tibble(
    t = c(0, 0.19, 0.4, 0.54, 0.65, 1),
    y = position(t) + 2,
    label=c("", "A", "B", "C", "D", "")
)
Intervals <- tibble::tribble(
    ~t0, ~ t1, ~color,
    0, 1, "orange3",
    # .54, .65, "orange",
    # .19, .4, "green",
    # .4, .54, "brown",
) %>%
    mutate(y0=position(t0), y1=position(t1))
FigA <- slice_plot(position(t) ~ t, domain(t = c(0, 1)), size=2) %>%
    gf_labs(y = "f(t): distance traveled (miles)",
            x = "Time since start (hours)") %>%
    gf_text(0 ~ t, data = Pts, label=~label, color="dodgerblue") %>%
    gf_segment(2 + y ~ t + t, data = Pts[-6,], color="dodgerblue") %>%
    gf_segment(y0 + y1 ~ t0 + t1, data = Intervals, color=~color, alpha=0.5, size=3) %>%
    gf_refine(scale_color_identity())
FigA
```

When driving, you are aware of the car's speed at any instant. You need only look at the speedometer to read off the value (in miles per hour). Speedometers don't show the average speed for the entire trip. The average speed is the slope of the tan-colored line in @fig-stop-and-go, 25 miles in one hour, usually stated 25 miles-per-hour. 

In terms of @fig-stop-and-go, the speedometer reading is the **slope** of $f(t)$ at the given instant. You can see from the Figure that at instant A the speed is very close to the average speed for the entire trip. At instant B the car is going faster; the slope is much steeper. On the other hand, at instant C the car is at a standstill; its position doesn't change at all. 

A car's speedometer shows the speed at each moment---or ***instant***---of the trip. As you can see in @fig-stop-and-go, the speed varies and is sometimes less than the average speed, sometimes greater, and occasionally equal to the average speed over the trip.  

From a graph of $f(t)$, you can easily judge whether the instantaneous speed is faster or slower than the average speed. Better, however, if we simply record the speedometer reading and graph that, as in @fig-instant-speed. Read off the speed from the graph at any instant of time by reference to the vertical axis.

```{r echo=FALSE}
#| label: fig-instant-speed
#| fig-cap: "The ***instantaneous*** speed of the car whose position vs time is shown in @fig-stop-and-go2."
f <- rfun(~ t, seed=105, n=5)
raw <- function(t) 
        f(t) - t - 30*dnorm(t, 0, 3) + 60*dnorm(t,7,1)
speed <- function(t) {
    pmax(4*raw(20*(t-.5)), 0)
}
Pts <- tibble::tibble(
    t = c(0, 0.19, 0.4, 0.56, 0.65, 1),
    y = speed(t) + 5,
    label=c("", "A", "B", "C", "D", "")
)
FigB <- slice_plot(speed(t) ~ t, domain(t=c(0,1)), npts=500) %>%
    gf_labs(y = "Instantaneous speed (miles/hour)", 
           x = "Time since start of trip.") %>%
    gf_text(2 ~ t, data = Pts, label=~label, color="dodgerblue") %>%
    gf_segment(5 + y ~ t + t, data = Pts[-1,], color="dodgerblue")
FigB
```
The two graphs in Figures \@ref(fig:stop-and-go2) and \@ref(fig:instant-speed) show the same car trip. For each of the two graphs, the presentation of the data makes it easy to see some things and hard to see others. For instance, figuring out when the car is at a standstill is harder in the position-vs-time graph than in the speed-vs-time graph. 

## Acceleration

Having worked out a theory of slope functions, Newton was ready to express the laws of motion in continuous time. He did this by denoting position as $x(t)$. He defined velocity and force in terms of slope functions of position and the "quantity of matter," which we call "mass."  

- Velocity is the slope function of position: $v(t) \equiv {\cal D}_t x(t)$.
- Net force is the slope function of velocity times mass: $F(t) \equiv m {\cal D}_t v(t) = m {\cal D}_{tt} x(t)$ 

To take mass out of the formulation, we give a name specifically to the slope function of velocity: ***acceleration***. 

- Acceleration is the slope function of velocity: $a(t) \equiv {\cal D}_t v(t) = {\cal D}_{tt} x(t)$.

Having defined acceleration, we can express net force as mass times acceleration. This is ***Newton's Second Law of Motion***.

::: {.why  data-latex=""}
We used **net force** as the quantity we related to mass and the slope function of velocity. There are different sources of forces that add up and can cancel out. Famously, Newton formulated the ***law of universal gravitation***, which ascribed the force between masses as proportional to the product of the two masses and inversely proportional to the square of the distance between them. But a mass on a table is subject to no net force, since the table pushes back (push = force) on the mass to cancel out the force due to gravity. "Net force" takes such cancellation into account. 
:::



## Notations for differentiation

There are several traditional notations for differentiation of a function named $f()$. Here's a list of some of them, along with the name associated with each: 

- Leibnitz: $\frac{df}{dx}$
- Partial: $\frac{\partial f}{\partial x}$
- Euler: $D_x f$
- Newton (or "dot"): $\dot{f}$
- Lagrange (or "prime"): $f'$
- One-line: $\partial_x f$ (This hybrid of partial and Euler notation, will be the main differential notation used in this book.)

::: {.intheworld  data-latex=""}
It is a fact of mathematical and scientific life that varied notations are used for differentiation. This reflects historical precedence and, to be honest, nationalistic European politics of the 18th century. To make sense of mathematical writing in the many areas in which calculus is used, you have to recognize all of them for what they are. Your skill will be enhanced if you also memorize the names of the different styles. It's not all that different from the pattern in English of having multiple words for the same sort of object, for instance: car, automobile, junker, ride, wheels, crate, jalopy, limo, motor car, horseless carriage.  

In the days when carriages where pulled by horses, the phrase "horseless carriage" made a useful distinction. Today, when horses are rarely seen on the road, it makes sense to trim down the notation to its essentials: ~~horseless~~ **car**~~iage~~. Think of $\partial_x$ as this sort of minification of older notations.^[Yes, ["minification" is a word!](https://en.wikipedia.org/wiki/Minification_(programming))]   
:::

You have likely seen the $f'$ notation if you've studied calculus before. $f'$ is admirably concise but is only viable in a narrow circumstance: functions that take a single input. What $f'$ leaves out is a means to specify a crucial aspect of differentiation, the **with-respect-to input**. The general situation for differentiation involves functions of one or more variables, for example, $g(x, y, z)$. For such functions, you need to specify which is the with-respect-to input. So, for instance, we can differentiate $g()$ three different ways, each way incrementing one or another of the three inputs: 



$$\partial_x g(x, y, z) \equiv \frac{g(x+h, y, z) - g(x, y, z)}{h}$$

$$\partial_y g(x, y, z) \equiv \frac{g(x, y+h, z) - g(x, y, z)}{h}$$
$$\partial_z g(x, y, z) \equiv \frac{g(x, y, z+h) - g(x, y, z)}{h}$$ 


At this point in your studies, you haven't seen why you might choose to differentiate a function with respect to one input or another. That will come as you progress through calculus. But we want to set you up with a notation that won't narrow your options. This book mainly use2 the one-line notation, $\partial_x f$, but it means the same as the Leibnitz and Partial notations, which are much more widely used in textbooks. 
 

Both the Leibnitz and Partial notations are explicit in identifying the function and the with-respect-to input. For example, using the Partial differentiation notation, the three ways of differentiating our example function $g(x, y, z)$ are labeled : 

$$\frac{\partial f}{\partial x},\ \ \ \frac{\partial f}{\partial y},\ \ \text{and}\ \ \frac{\partial f}{\partial z}$$

Our R/mosaic computer differentiation is longer but explicit:
```r
g <- makeFun(__formula__ ~ x & y & z) # define a function
dx_g <- D(g(x, y, z) ~ x)
dy_g <- D(g(x, y, z) ~ y)
dz_g <- D(g(x, y, z) ~ z)
```
The names assigned to the result of the `D()` operator can be any names you like. What's nice about `dx_g` and the others is that it mimics the math notation $\partial_x g()$.

Notice that the R/mosaic operator for differentiation is named `D()` and that it is a function. It follows the same pattern as `makeFun()` or `slice_plot()` or `contour_plot()`: the first argument is a tilde expression, for instance `g(x, y, z) ~ x`, which identifies the mathematical function to work with (`g()`) and the name of the with-respect-to input to that function. The R/mosaic notation makes it clear that differentiation is an ***operation*** on a function. The `D()` operator takes a function as input and produces as output **another function**. We've seen similar behavior with, say, `slice_plot()`, which takes a function as input and produces graphics as output. Both `D()` and `slice_plot()` need to know the identity of the with-respect-to input as well as the function to work with. That's why both pieces of input are packaged into a tilde expression. 

::: {.why  data-latex=""}
We're calling R/mosaic `D()` an ***operator*** rather than a ***function***. The reason is purely for communication with other people. There are so many "functions" in a calculus course that we thought it would be helpful to distinguish between the kinds of functions that take quantities as input and produce a quantity as output and the functions that take a *function* as input and produce a *function* as output.^[It's pretty easy to see in an expression like $f(x,y)$ why we call $f()$ a function. But an expression like $3+2$ also involves a function of two inputs. We just write the name of the function (`+`) in between the two inputs. This is called ***infix*** notation.] Both sorts are called "functions" in R terminology. But a sentence like, "Differentiation is a function that takes a function as input and produces a function as output," true though it be, is dizzying. 
:::





## Visualizing the slope function {#sec-slope-fun-visualization}

Look back at @fig-stop-and-go2 and @fig-instant-speed (which we reproduce here). We know the two functions are closely related---one is the position of the car and the other the speed. But it's hard to see the relationship at a glance. You have to go patiently back and forth between the two graphs, comparing a slope in one graph to an output value in the other graph.

```{r echo=FALSE}
#| out-width: "50%"
#| fig-show: "hold"
FigA
FigB
```

We can make things easier by taking an unconventional approach to graphing the slope function. Rather than showing the slope as the vertical position on a graph, let's show the slope with an actual slope! Perhaps this non-standard visualization will give you a better way to understand slope functions. If so, good. The ultimate benefit of a way to show $\diff{x} f(x)$ and $f(x)$ in the same frame will come when we introduce the operation of ***anti-differentiation***. 

Recall that the ***basic model of change*** in Calculus is the straight-line function $\line(x) \equiv a x + b$. The slope $a$ of $\line(x)$ tells how the output changes for a unit change in input. In differentiation, we  

i. approximate the parent function $f(x)$ as a series of local line segments.
ii. extract the **slope** of each line segment as the value of the slope function at each input $x$. 

@fig-segment-approx shows the segment by segment approximation around each of several input values (marked in green).  The ***slope function visualization*** is constructed by throwing away the vertical offset of each of the line segments and plotting them horizontally adjacent to one another. 

```{r echo=FALSE}
#| label: fig-segment-approx
#| fig-cap: "A function $f(x)$ shown along with the tangent line segment touching $f()$ at each of the green points. For the slope function visualization, the tangent line segments are moved down to the horizontal axis."
Segs <- create_segments(sin(x) ~ x, domain(x=c(-.1,pi)), nsegs=10)
gf_segment(yf + yfend ~ x + xend, data = Segs, 
           color=~slope,size=2, alpha=.9) %>%
    gf_refine(scale_color_viridis_c(begin=.3, end=1)) %>%
    slice_plot(sin(x) ~ x, color="black", domain(x=c(0, pi)),
               alpha = 0.85, size=1, inherit=FALSE) %>%
    gf_point(offset ~ start, size=1, color="green") %>%
    gf_segment(y + yend ~ x + xend, data = Segs, 
           color=~slope,size=1.3, lineend="round") %>%
    gf_point(0 ~ start, size=1, color="green") %>% 
  gf_labs(y = "f(x)")  
    
```
You can see that the slopes are a function of $x$, that is, the slope changes with $x$. Because the function and its slope function are shown on the same graph in the same way, it's easy to verify that the slope as a function of $x$ corresponds to the behavior of the function itself.


```{r eval=FALSE, echo=FALSE}
#| label: fig-finer-slope
## Leaving this figure out
Segs <- create_segments(sin(x) ~ x, domain(x=c(-.1,pi)), nsegs=100)
# gf_segment(yf + yfend ~ x + xend, data = Segs, 
#            color=~slope,size=2, alpha=.9) %>%
#     gf_refine(scale_color_continuous(type="gradient")) %>%
#     slice_plot(sin(x) ~ x, color="orange3", domain(x=c(0, pi)),
#                alpha = 0.5, size=1, inherit=FALSE) %>%
#     gf_point(offset ~ start, size=1, color="green") %>%
  gf_segment(y + yend ~ x + xend, data = Segs, 
           color=~slope,size=0.3) %>%
  gf_labs(y = "output") %>%
    gf_refine(coord_fixed(ratio=5), 
              scale_y_continuous(breaks=c(-0.01, 0.01)))  %>%
    gf_refine(scale_color_viridis_c())
    
```


@fig-slope-visualization-examples shows several examples of the slope function visualization.

```{r echo=FALSE, fig.height=3, fig.width=7, fig.show="hold", out.width="100%"} 
#| label: fig-slope-visualization-examples
#| fig-cap: "Slope-function visualizations (left) of several pattern-book functions (right)."
Segs <- create_segments(exp(x) ~ x, domain(x=c(-pi,pi)), nsegs=30)

ggpubr::ggarrange(
  slice_plot(exp(x) ~ x, domain(x=c(-pi, pi))) %>%
    gf_labs(title="exp(x)"),
gf_segment(y + yend ~ x + xend, data = Segs, 
           color=~slope,size=1.3, lineend="round") %>%
  gf_point(0 ~ start, size=1, color="green") %>%
    gf_labs(title="exp(x) slope-function visualization")  %>%
    gf_refine(scale_color_viridis_c(begin=.3, end=1)) %>%
  gf_theme(theme(legend.position = "none")), ncol = 2)
Segs <- create_segments(log(x) ~ x, domain(x=c(.2,pi)), nsegs=30)
ggpubr::ggarrange(
  slice_plot(log(x) ~ x, domain(x=c(.2, pi))) %>%
    gf_labs(title="log(x)"),
gf_segment(y + yend ~ x + xend, data = Segs, 
           color=~slope,size=1.3, lineend="round") %>%
  gf_point(0 ~ start, size=1, color="green") %>%
    gf_labs(title="log(x) slope-function visualization")  %>%
    gf_refine(scale_color_viridis_c(begin=.3, end=1)) %>%
  gf_theme(theme(legend.position = "none")), ncol = 2)
Segs <- create_segments(x^2 ~ x, domain(x=c(-pi,pi)), nsegs=30)
ggpubr::ggarrange(
  slice_plot(x^2 ~ x, domain(x=c(-pi, pi))) %>%
    gf_labs(title=expression(x^2)),
gf_segment(y + yend ~ x + xend, data = Segs, 
           color=~slope,size=1.3, lineend="round") %>%
  gf_point(0 ~ start, size=1, color="green") %>%
    gf_labs(title=expression(paste("x^2 slope-function visualization")))  %>%
    gf_refine(scale_color_viridis_c(begin=.3, end=1)) %>%
  gf_theme(theme(legend.position = "none")), ncol=2)
Segs <- create_segments(2*x -4 ~ x, domain(x=c(-pi,pi)), nsegs=30)
ggpubr::ggarrange(
  slice_plot(2*x - 4 ~ x, domain(x=c(-pi, pi))) %>%
    gf_labs(title="2x - 4"),
gf_segment(y + yend ~ x + xend, data = Segs, 
           color=~slope,size=1.3, lineend="round") %>%
  gf_point(0 ~ start, size=1, color="green") %>%
    gf_labs(title="line(x) = 2 x - 4 slope-function visualization") %>%
    gf_lims(y=c(-1,1))  %>%
    gf_refine(scale_color_viridis_c(begin=.3, end=1)) %>%
  gf_theme(theme(legend.position = "none")), ncol=2)
```


::: {.intheworld  data-latex=""}
Calculus and the *Wealth of Nations*

1776 can be reckoned as the birth year of two revolutions: the American *Declaration of Independence* and Adam Smith's publication of the *Wealth of Nations*.

Smith, considered the intellectual father of free-market economics, explored the origins of the supply and demand of commodities, labor, and money. A key figure of the Scottish Enlightenment, Smith would have been well aware of Newton, his work, and the many advances enabled by the creation of calculus. *Wealth of Nations* lays out dozens of relationships between different quantities --- wages, labor, stock, interest, prices, profits, and coinage among others. Yet *Wealth of Nations* does not use the concepts or language of calculus. Lacking this, Smith's arguments, sophisticated though they be, are based on the Aristotelian notions of tendency toward a "natural" resting place.^[For more discussion, see Tony Aspromourgos (2007) "Adam Smith's treatment of market prices and their relationship to <<supply>> and <<demand>>" *History of Economic Ideas* , 2007, Vol. 15, No. 3 (2007), pp. 27-57 [Link](https://www.jstor.org/stable/23723287)]

Consider this characteristic statement in *Wealth of Nations*:

>  *The market price of every particular commodity is regulated by the proportion between the quantity which is  brought to market, and the demand of those who are willing to pay the natural price of the commodity... Such people may be called the effectual demanders, and their demand the effectual demand.*

Smith's "natural price" and "effectual demand" are fixed quantities. But Smith lived near the end of a centuries-long period of ***static*** economies. Transportation, agriculture, manufacture, population were all much as they had been for the past 500 years or longer.^[Smith commented on the difference between "demand" and "effectual demand:" "A very poor man may be said, in some sense, to have a demand for a coach and six [a carriage pulled by six horses]; he might like to have it; but his demand is not an effectual demand, as the commodity can never be brought to market to satisfy it." In today's economy, of course, transportation superior to a coach and six is readily demanded and supplied.] Calculus was invented to deal with ***dynamics***: how things change.

It took the industrial revolution and nearly a century of intellectual development before economics was seen dynamically. In this dynamical view, supply and demand are not seen as mere quantities, but as ***functions*** of which price is the major input. The tradition in economics is to use the word "curve" instead of "function," giving us the phrases "supply curve" and "demand curve." Many students starting out in economics can easily see supply and demand as quantities. Making the transition from quantity to function, that is, between a single amount and a relationship between amounts is a core challenge to those learning economics. 

Once this transition is accomplished, economics students are taught essential concepts of calculus---particularly first and second derivatives, the subjects of this Block---although the names used are peculiar to economics, for instance, "elasticity", "marginal returns" and "diminishing marginal returns."

```{r echo=FALSE}
#| label: cournot-demand
#| fig-cap: "Demand as a *function* of price, as first published by Antoine-Augustin Cournot in 1836."
#| out-width: "50%"
knitr::include_graphics("www/cournot-demand-curve.png")
```

:::

## Dimension of derivatives

The function named $\partial_t f(t)$ which is the derivative of $f(t)$ takes the same input as $f(t)$; the notation makes that pretty clear. Let's suppose that $t$ is time and so the dimension of the input is $[t] = \text{T}$.

The outputs of the two functions, $\partial_t f(t)$ and $f(t)$ will not, in general, have the same dimension. Why not? Recall that a derivative is a special case of a slope function, the ***instantaneous slope function***. It's easy to calculate a slope function:

$${\cal D}_t f(t) \equiv \frac{f(t+h) - f(t)}{h}$$
The dimension of the quantity $f(t+h) - f(t)$ must be the same as the dimension of $f(t)$; the subtraction wouldn't be possible otherwise. The dimension of $h$, similarly, must be the same as the dimension of $t$; the addition wouldn't make sense otherwise. 

Whereas the dimension of the output $f(t)$ is simply $\left[f(t)\right]$, the dimension of the quotient $\frac{f(t+h) - f(t)}{h}$ will be different. The output of the derivative function $\partial_t f(t)$ will be $$\left[\partial_t f(t)\right] = \left[f(t)\right] / \left[t\right] .$$ 

Suppose $x(t)$ is the position of a car as a function of time $t$. Position has dimension L. Time has dimension T. The function $\partial_t x(t)$ will have dimension L/T; that's what velocity is, for instance miles-per-hour.

Another example: Imagine a function pressure() with input altitude i(in km) and output pressure (in kPa, "kiloPascal"^[Air pressure at sea level is about 100 kiloPascal.]).

The derivative function, let's call it $\partial_\text{altitude} \text{pressure}()$, also takes an input in km, but produces an output in kPA per km: a rate.

## Exercises



