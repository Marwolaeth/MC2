[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MOSAIC Calculus",
    "section": "",
    "text": "GIT_TRACE=1 git push\nor\ngit push --force origin main\n\n\n\nThis project was initiated by the Mathematical Sciences department at the US Air Force Academy. They recognized that a traditional calculus introduction is ill-suited to the needs of STEM in the 21st century.\nCritical support was given by the ARDI Foundation which awarded the Holland H. Coors Chair in Education Technology to one of the project members, Daniel Kaplan. This made possible a year-long residency at USAFA during which time he was able to work unhindered on this project.\nMacalester College, where Kaplan is DeWitt Wallace Professor of Mathematics, Statistics, and Computer science, was the site where the overall framework and many of the materials for a STEM-oriented calculus were developed. Particularly important in the germination were David Bressoud and Jan Serie, respectively chairs of the Macalester math and biology departments, as well as Prof. Thomas Halverson and Prof. Karen Saxe, who volunteered to team teach with Kaplan the first prototype course. Early grant support from the Howard Hughes Medical Foundation and the Keck Foundation provided the resources to carry the prototype course to a point of development where it became the entryway to calculus for Macalester students.\nProfs. Randall Pruim (Calvin University) and Nicholas Horton (Amherst College) were essential collaborators in developing software to support calculus in R. They and Kaplan formed the core team of Project MOSAIC, which was supported by the US National Science Foundation (NSF DUE-0920350).\nJoel Kilty and Alex McAllister at Centre College admired the Macalester course and devoted much work and ingenuity to write a textbook, Mathematical Modeling and Applied Calculus (Oxford Univ. Press), implementing their own version. Their textbook enabled us to reduce the use of sketchy notes in the first offering of this course at USAFA."
  },
  {
    "objectID": "preliminaries-part.html",
    "href": "preliminaries-part.html",
    "title": "Preliminaries",
    "section": "",
    "text": "In order to describe and use the relationships we find in the natural or designed world, we build mathematical representations of them. We call these mathematical models. On its own, the word “model” signifies a representation of something in a format which serves a specific purpose. A blueprint describing the design of a building is an everyday example of a model. The blueprint represents the building but in a way that is utterly different from the building itself. Blueprints are much easier to construct or modify than buildings, they can be carried and shared easily. Two of the purposes of a blueprint is to aid in the design of buildings and to communicate that design to the people securing the necessary materials and putting them together into the building itself.\n\n\nModels provide the link between the real world and the abstractions of mathematics.\nAtmospheric scientists build models of climate whose purpose is to explore scenarios for the future emission of greenhouse gasses. The model serves as a stand-in for the Earth, enabling predictions in a few hours of decades of future change in the climate. This is essential for the development of policies to stabilize the climate.\n\n\nA concise definition of a “model” is a representation for a purpose. Defining the purpose for your model is a crucial first step in building a mathematical representation that will serve that purpose. Useful models of the same real-world setting can be very different, depending on the purpose. For instance, one routine use for a model is to make a prediction. But other models are intended for exploring the connections among the components of the system being modeled.\nDesigning a building or modeling the climate requires expertise and skill in a number of areas. Nonetheless, constructing a model is relatively easy compared to the alternative. Models make it relatively easy to extract the information that’s needed for the purpose at hand. For instance, a blueprint gives a comprehensive overview of a building in a way that’s hard to duplicate just by walking around an actual building.\nModels are easy to manipulate compared to reality, easy to implement (think “draw a blueprint” versus “construct a building”), and easy to extract information from. We can build multiple models and compare and contrast them to gain insight into the real-world situation behind the models.\nA mathematical model is a model made out of mathematical and computational stuff. Example: a bank’s account books are a model made mostly out of numbers. But in technical areas—science and engineering are obvious examples, but there are many other fields, too—numbers don’t get you very far. By learning calculus, you gain access to important mathematical and computational concepts and tools for building models and extracting information from them.\nA major use of mathematics is building models constructed out of mathematical concepts and objects. The chapters in this Preliminaries section of this book introduce some of the fundamental mathematical entities that are the heart of modeling."
  },
  {
    "objectID": "Preliminaries/01-modeling-change.html",
    "href": "Preliminaries/01-modeling-change.html",
    "title": "1  Quantity, function, space",
    "section": "",
    "text": "This book presents calculus in terms of three concepts central to the study of change: quantities, functions, and spaces. Those words have everyday meanings which are, happily, close to the specific mathematical concepts that we will be using over and over again. Close … but not identical. So, pay careful attention to the brief descriptions that follow."
  },
  {
    "objectID": "Preliminaries/01-modeling-change.html#quantity-vs-number",
    "href": "Preliminaries/01-modeling-change.html#quantity-vs-number",
    "title": "1  Quantity, function, space",
    "section": "1.1 Quantity vs number",
    "text": "1.1 Quantity vs number\nA mathematical quantity is an amount. How we measure amounts depends on the kind of stuff we are measuring. The real-world stuff might be mass or time or length. It equally well can be velocity or volume or momentum or corn yield per acre. We live in a world of such stuff, some of which is tangible (e.g., corn, mass, force) and some of which is harder to get your hands on and your minds around (acceleration, crop yield, fuel economy). An important use of calculus is helping us conceptualize the abstract kinds of stuff as mathematical compositions of simpler stuff. For example, crop yield incorporates mass with length and time. Later, you’ll see us using the more scientific-sounding term dimension instead of “stuff.”\n\n\nChapter 15 covers units and dimension.\nMost people are inclined to think “quantity” is the same as “number”; they conflate the two. This is understandable but misguided. By itself a number is meaningless. What meaning does the number 5 have without more context? Quantity, on the other hand, combines a number with the appropriate context to describe some amount of stuff.\nThe first thing you need to know about any quantity is the kind of stuff it describes. A “mile” is a kind of stuff: length. A meter is the same kind of stuff: length. A liter is a different kind of stuff: volume. A gallon and an acre-foot are the same kind of stuff: volume. But an inch (length) is not the same kind of stuff as an hour (time).\n“Stuff,” as we mean it here, is what we measure. As you know, we measure with units. Which units are appropriate depends on the kind of stuff. Meters, miles, and microns are all appropriate units of length, even though the actual lengths of these units differ markedly. (A mile is roughly 1.6 million millimeters.)\nOnly after you know the units does the number have meaning as a quantity: a number is only part of specifying a quantity.\n\n\nExample: You can’t add feet and acres. They describe different kinds of things: length versus area. Yet you can multiply feet and acres. The unit “acre-foot” is widely used in water resource management.\nHere’s the salient difference between number and quantity when it comes to calculus: All sorts of arithmetic and other mathematical operations apply to numbers: addition, multiplication, square roots, etc. But for quantities, only multiplication and division are universally allowed. For addition and subtraction, square roots, and such, the operation makes sense only if the dimensions are suitable.\nThe mathematics of units and dimension are to the technical world what common sense is in our everyday world. For instance (and this may not make sense at this point), if people tell me they are taking the square root of 10 liters, I know immediately that either they are just mistaken or that they haven’t told me essential elements of the situation. It’s just as if someone said, “I swam across the tennis court.” You know that person either used the wrong verb—walk or run would work—or that it wasn’t a tennis court, or that something important was unstated, perhaps, “During the flood, I swam across the tennis court.”"
  },
  {
    "objectID": "Preliminaries/01-modeling-change.html#sec-functions",
    "href": "Preliminaries/01-modeling-change.html#sec-functions",
    "title": "1  Quantity, function, space",
    "section": "1.2 Functions",
    "text": "1.2 Functions\n\n\nOther examples of relationships:\n\nthe input is the altitude on your hike up Pikes Peak; the output is the air temperature. Typically, as you gain altitude the temperature goes down.\nthe input is the number of hours past noon; the output is the brightness of sunlight. As the afternoon progresses, the light grows dimmer, but only to a point.\n\nFunctions, in their mathematical and computing sense, are central to calculus. The introduction to the Preliminaries Block starts, “Calculus is about change, and change is about relationships.” The idea of a mathematical function gives a definite perspective on this. The relationship represented by a function is between the function’s input and the function’s output. The input might be day-of-year1, and the output cumulative rainfall up to that day. Every day it rains, the cumulative rainfall increases.\nA function is a mathematical concept for taking one or more inputs and returning an output. In calculus, we’ll deal mainly with functions that take one or more quantities as inputs and return another quantity as output. ::: {.column-margin} Pay careful attention to our use of “input” and “output.” We avoid using the word “variable” because it is too vague. (For instance, it doesn’t distinguish between what goes in and what comes out of a function.) There are two contexts in which we will use “variable,” neither of which has to do with inputs to functions. In talking about data, we will use “variable” in the statistical sense, meaning “a type of quantity” like height or pH. And in the final part of the text, involving systems whose configuration changes in time, we’ll use “variable” in the sense of “a quantity that varies over time.” Try to put the word “variable” out of mind for the present, until we get to discussing the nature of data. ::: But sometimes we’ll work with functions that take functions as input and return a quantity as output. And there will even be functions that take a function as an input and return a function as output.\nIn a definition like \\(f(x) \\equiv \\sqrt{\\strut x}\\), think of \\(x\\) as the name of an input. So far as the definition is concerned, \\(x\\) is just a name. We could have used any other name; it’s only convention that leads us to choose \\(x\\). The definition could equally well have been \\(f(y) \\equiv \\sqrt{y}\\) or \\(f(\\text{zebra}) \\equiv \\sqrt{\\strut\\text{zebra}}\\).\nNotation like \\(f(x)\\) is also used for something completely different from a definition. In particular, \\(f(x)\\) can mean apply the function \\(f()\\) to a quantity named \\(x\\). You can always tell which is intended—function definition or applying a function—by whether the \\(\\equiv\\) sign is involved in the expression.\n\n\nLater in this Preliminaries Block, we’ll introduce the “pattern-book functions.” These always take a pure number as input and return a pure number as output. In the Modeling Block, we’ll turn to functions that take quantities—which generally have units—as input and return another quantity as output. The output quantity also generally has units.\nOne familiar sign of applying a function is when the contents of the parentheses are not a symbolic name but a numeral. For example, when we write \\(\\sin(7.3)\\) we give the numerical value \\(7.3\\) to the sine function. The sine function then does its calculation and returns the value 0.8504366. In other words, \\(\\sin(7.3)\\) is utterly equivalent to 0.8504366.\nIn contrast, using a name on it’s own inside the parentheses indicates that the specific value for the input is being determined elsewhere. For example, when defining a function we often will be combining two or more functions, like this: \\[g(x) \\equiv \\exp(x) \\sin(x)\\] or \\[h(y,z) \\equiv \\ln(z) \\left(\\strut\\sin(z) - \\cos(y)\\right)\\ .\\] The \\(y\\) and \\(z\\) on the left side of the definition are the names of the inputs to \\(h()\\).2 The right side describes how to construct the output, which is being done by applying \\(\\ln()\\), \\(\\sin()\\) and \\(\\cos()\\) to the inputs. Using the names on the right side tells us which function is being applied to which input. We won’t know what the specific values those inputs will have until the function \\(h()\\) is being applied to inputs, as with \\[h(y=1.7, z=3.2)\\ .\\]\nOnce we have specific inputs, we (or the computer) can plug them into the right side of the definitionto determine the function output: \\[\\ln(3.2)\\left(\\sin(3.2) - \\strut \\cos(1.7)\\right) = 1.163(-0.0584 + 0.1288) =-0.2178\\ .\\]\n\n\nWe’ll introduce the idea of “spaces” in Section ?sec-spaces-intro. A function maps each point in the function’s input space into a single point in the function’s output space. The input and output spaces are also known respectively as the “domain” and “range” of the function.\n\nThe various mathematical functions that we will be studying in this book are in the service of practical problems. But there are so many such problems, often involving specialized knowledge of a domain or science, engineering, economics, and so on, that an abstract mathematical presentation can seem detached from reality.\nThe video linked here, How to shoot, breaks down a simple-sounding situation into its components. The function itself is literally a black box. The inputs are provided by a human gunner training a telescope on a target and setting control dials. The ultimate output is the deflection of the guns in a remote turret. The main function is composed of several others, such as a function that outputs target range given the target size based on knowledge of the size of the target and how large it appears in the telescopic sight.\n\n\n\n\n\nDividing the gunnery task into a set of inputs and a computed output allows for a division of labor. The gunner can provide the skills properly trained humans are good at, such as tracking a target visually. The computer provides the capabilities—mathematical calculation—to which electronics are well suited. Combining the inputs with the calculation provides an effective solution to a practical problem."
  },
  {
    "objectID": "Preliminaries/01-modeling-change.html#sec-space-intro",
    "href": "Preliminaries/01-modeling-change.html#sec-space-intro",
    "title": "1  Quantity, function, space",
    "section": "1.3 Spaces",
    "text": "1.3 Spaces\nWe said earlier that the functions used in calculus take quantities as input and produce a quantity as output. We’ve also said that a quantity is something like 2 light-years or 150 watts. Now we want to connect a new concept to input and output: the concept of spaces.\nA space3 is a collection of continuous possibilities. A child learning about numbers starts with the “counting numbers”: \\(1, 2, 3, \\ldots\\). In primary school, the set of numbers is extended to include zero and the negative numbers: \\(-1,-2,-3, \\ldots\\), giving a set called the “integers.” Counting numbers and integers are discrete sets. Between two consecutive members of the counting numbers or the integers, there is not another number of the set.\nThe next step in a child’s mathematical education is the “rational numbers,” that is, numbers that are written as a ratio: \\(\\frac{1}{2}, \\frac{1}{3}, \\frac{2}{3}, \\ldots, \\frac{22}{7}\\), and so on. Rational numbers fit in the spaces between the integers. That is, between any two integers, even consecutive ones, there is a rational number. For instance, the rational number \\(\\frac{1}{2}\\) falls between 0 and 1.\nBetween any two rational numbers, there is another rational number, indeed an infinite number of rational numbers. For instance, between \\(\\frac{1}{2}\\) and \\(\\frac{2}{3}\\) is \\(\\frac{6}{11}\\) (and many others, such as \\(\\frac{7}{11}\\) or \\(\\frac{13}{21}\\)). It’s useful to think of rational numbers as fitting in the spaces between integers.\nIf you didn’t stumble on the word “spaces” in the previous sentence, you are well on your way to understanding what is meant by “continuous.” For instance, between any two rational numbers there is another rational number. Think of rational numbers as stepping stones that provide a path from any number to any other number.\n\n\n\n\n\n\nDiscrete\n\n\n\nIt’s a deep question whether the rational numbers are a walkway instead of isolated stepping stones? A walkway is a structure on which you can move any amount, no matter how small, without risk of going off the structure. In contrast, a too-small move along a path of stepping stones will put you in the water.\n\n\n\n\n\n\nContinuous\n\n\n\nA continuous set is like a walkway; however little you move from an element of the set you will still be on the set. The continuous set of numbers is often called the number line, although a more formal name is the real numbers. (“Real” is a somewhat unfortunate choice of words, but we’re stuck with it.)\nThe underlying metaphor here is space. Between any two points in space, there is another point in space. We will be working with several different spaces, for instance:\n\n\nYour spatial intuition of lines, planes, etc. will suffice for our needs. Mathematicians as a class value precise definitions; we won’t need those. Widely accepted mathematical definitions of continuous sets date from the 1800s, 150 years after calculus was introduced. For instance, it’s been known for more than 2000 years that there are numbers—the irrational numbers—that cannot be exactly expressed as a ratio of integers. We know now that there is an irrational number between any two rational numbers; the rational numbers are indeed analogous to stepping stones. But the distinction between rational and irrational numbers will not be one we need in this book. Instead, we need merely the notion of continuous space.\n\nthe number line: all the real numbers\nthe positive numbers: the real numbers greater than zero\nthe non-negative numbers: this is the tiniest little extension of the positive numbers adding zero to the set.\na closed interval, such as the numbers between 5 and 10, which we will write like this: \\(5 \\leq x \\leq 10\\), where \\(x\\) is a name we’re giving to the set.\nthe Cartesian plane: all pairs of real numbers such as \\((5.62, -0.13)\\). Other metaphors for this: the points on a piece of paper or a computer screen.\nthree-dimensional coordinate spaces like our everyday three-dimensional world, generally written as a set of three real numbers such as \\((-2.14, 6.87, 4.03)\\).\nhigher-dimensional spaces, but we won’t go there until the last parts of the book.\n\nThe specialty of calculus is describing relationships between continuous sets. Functions such as \\(\\sin()\\) or \\(\\text{line}()\\), which are typical of the functions we study in calculus, take numbers as input.\nEvery function has a set of legitimate inputs. For the functions studied in calculus, this set is continuous: a space. The name given to a function’s space of legitimate inputs is the function domain. Functions such as \\(\\sin()\\) and many others have the real numbers as the function domain. The square-root function has the non-negative numbers for its domain. The logarithmic function, \\(\\ln()\\), has a domain of the positive numbers.\nJust as a “domain” is the set of legitimate inputs to a function, the function’s range is the set of values that the function can produce as output. For instance, the range of \\(\\sin()\\) is the numbers between \\(-1\\) and \\(1\\) which we’ll usually write in this format: \\(-1 \\leq x \\leq 1\\). Another example: the range of \\(\\ln()\\) is the entire space of real numbers."
  },
  {
    "objectID": "Preliminaries/01-modeling-change.html#all-together-now",
    "href": "Preliminaries/01-modeling-change.html#all-together-now",
    "title": "1  Quantity, function, space",
    "section": "1.4 All together now",
    "text": "1.4 All together now\nThe three mathematical concepts we’ve been discussing—quantity, function, space—are used together.\nA quantity can be a specific value, like 42.681\\(^\\circ\\)F. But you can also think of a quantity more broadly, for instance, “temperature.” Naturally, there are many possible values for temperature. The set of all possible values is a space. And, using the metaphor of space, the specific value 42.681\\(^\\circ\\)F is a single point in that space.\nFunctions relate input quantities to a corresponding output quantity. A way to think of this—which will be important in chap-graphs-and-graphics—is that a function is a correspondence between each point in the input space (domain) and a corresponding point in the output space (range)."
  },
  {
    "objectID": "Preliminaries/01-modeling-change.html#exercises",
    "href": "Preliminaries/01-modeling-change.html#exercises",
    "title": "1  Quantity, function, space",
    "section": "1.5 Exercises",
    "text": "1.5 Exercises"
  },
  {
    "objectID": "Preliminaries/02-notation.html",
    "href": "Preliminaries/02-notation.html",
    "title": "2  Notation",
    "section": "",
    "text": "The ideas which are here expressed so laboriously are extremely simple …. The difficulty lies, not in the new ideas, but in escaping from the old ones, which [branch]1, for those brought up as most of us have been, into every corner of our minds. — J. M Keynes, 1936, The General Theory of Employment, Interest, and Money, 1936\nThis chapter introduces more of the notation we will use for mathematics and for computing.\nGood use of notation should make the writer’s intent clear to the reader. In our study of calculus, each component of notation will refer to a mathematical object of some kind. Consequently, the notation should, on its own, clearly indicate the kind of object.\nIn the previous chapter, we described three different kinds of objects: functions, quantities, and spaces. We introduced mathematical and computer notation to make clear what is the name of a function and the names of inputs. In this chapter, we’ll introduce constants, parameters, and special inputs. We’ll see how input names, like \\(x\\) in \\(g(x) \\equiv x^3 + 3\\) refer to a kind of space called a domain.\nIt makes obvious sense to use a mathematical notation with which you are already familiar. We’ll supplement this notation with simple rules for naming, intended to make it clear just from the name what kind of mathematical object is being named.\nSince you’ll be using computing extensively, it will pay to be aware of when the the way you are used to writing mathematical statements conflicts with the requirements of computing.\nWe’ll attempt to use mathematical notation in a way that limits the conflict between tradition and computer notation. This conflict is particularly acute when it comes to the idea of an “equation,” so widely used in high-school mathematics but not a component of mainstream computer languages."
  },
  {
    "objectID": "Preliminaries/02-notation.html#functions-inputs-parameters",
    "href": "Preliminaries/02-notation.html#functions-inputs-parameters",
    "title": "2  Notation",
    "section": "2.1 Functions, inputs, parameters",
    "text": "2.1 Functions, inputs, parameters\nOur style of notation will be to give functions and their inputs explicit names. The basic principle is that a function name is a sequence of letters followed by an empty pair of parentheses, for instance, \\(\\sin()\\) or \\(\\ln()\\). The parentheses provide a clear indication that this is a function name.\n\n\nWhen we come to introduce computer notation in Section Section 3.2, you’ll see that function definition is done in a somewhat different manner. Why? We need to work within the syntax and grammar of the computer language. We will be using the R language, but other mainstream computer languages would impose similar requirements.\nAs you saw in Chapter Section 1, our notation for defining a function includes the names of the parameters. In our mathematical notation, both the name of the function and the names of the inputs are shown on the left-hand side of the \\(\\equiv\\) symbol. For instance, \\[g(u, z) \\equiv u\\,\\cos(z)\\] involves a function named \\(g()\\) and two inputs named \\(u\\) and \\(z\\) respectively. We’ll also use names with subscripts and superscripts, e.g. the function names \\(g_3()\\) or \\(h_\\text{water}()\\).\nA sensible person will define a function because they are planning to use it later on, perhaps multiple times. “Using” a function might mean including it in the formula in the definition of another function. But there is also a more specific sense of “using” to which we need to give a precise name. To apply a function means providing specific input quantities so that the output of the function can be calculated. An equivalent phrase is evaluate a function on an input(s). For instance, to apply the function \\(g()\\) to the input quantity 3, any of the following mathematical expressions might be used: \\[g(3)\\ \\ \\ \\text{or}\\ \\ \\ \\ g(x=3) \\ \\ \\ \\text{or}\\ \\ \\ \\ g(x)\\left.\\Large\\strut\\right|_{x=3}\\ .\\] Remember that \\(g(3)\\) or its equivalents are not themselves functions. They are the quantity that results from applying a the function to an input quantity.\n\n\nDistinguish carefully between the definition of a function, say, \\(g(t) \\equiv \\sin(t)/t\\) and the application of a function to an input. When a function is being applied, the argument can be a numeral or any name that contains the value to serve as input. For instance, any of \\(g(b)\\), \\(g(\\text{age})\\), or \\(g(\\text{population})\\) can be correct ways to apply \\(g()\\).\nThe right-hand side of a function definition is a formula. The formula specifies how each of the inputs will get used in a computation of the function output. When a function has more than one input, the input names serve to indicate where each input goes in the formula defining the calculation. For instance: \\[h(x, y) \\equiv x^2 e^y\\ .\\] \\(h()\\) is a completely different function than, say, \\(f(x, y) \\equiv y^2 e^x\\).\n\n2.1.1 Input names\n\n\nYou may notice that we use the function names \\(f()\\), \\(g()\\), and \\(h()\\) a lot. Consider these names to be the equivalent of pronouns in English like “this”, “that”, “it”, and so on. Function names like \\(f()\\) or \\(F()\\) or \\(G()\\) will be used when we need to refer to a function for just a moment: a sentence, a paragraph, a section.\nTo simplify identifying function definitions, we tend to use a small set of names for inputs:\n\n\\(\\large x\\) or \\(\\large y\\) or \\(\\large z\\).\n\\(\\large t\\). This name is typically used when the input is meant to be time.\nLess frequently, \\(u\\), \\(v\\), \\(w\\) when the other arguments are already in use.\n\nIn modeling, to make clearer the relationship of functions and the real-world setting, it’s a good idea to use more descriptive names, like \\(T\\) for “temperature” or \\(V\\) for volume, or even \\(\\text{altitude}\\) (which describes itself).\n\n\nIn everyday speech, an “argument” is a discussion between people with differing views. But in mathematics and computing, argument means something else entirely: it is a synonym for “input to a function.”\nOften, the functions we define will have formulas that include quantities other than the inputs. For instance, we might define: \\[h(t) \\equiv A \\sin(t) + B\\ .\\] This definition explicitly identifies \\(t\\) and the name of the function input. So what are \\(A\\) and \\(B\\)? These names also stand for quantities, and to apply the function—say, \\(h(t=3)\\)—we would have to know the values of these quantities. We use the word parameter to refer to such quantities.\nDistinguishing between inputs and parameters is an important way to communicate with the human reader. The idea is that a function, once defined, will be applied to inputs potentially many times. What changes between these function applications is the value of the input quantity. By writing a quantity as a parameter, we are signaling that these quantities will not be changing when we apply the function.\n\n\nThere is no absolute rule for identifying a named quantity used in a function’s formula as a parameter rather than as an input. It’s a matter of style and the conventions of the field in which you’re working. When we get to the computer notation for defining functions, you’ll see that we simplify things by considering all named quantities used in a function formula as inputs.\n\nA pendulum is a device that swings back and forth from a fixed pivot. The period of a pendulum is the time it takes to go through one complete cycle of motion—one “back” and one “forth.” It happens that it is simple to compute the period of a pendulum, \\[\\text{period}(L) \\equiv \\sqrt{\\strut L/g\\ }\\] where \\(L\\) is the length of the pendulum, \\(g\\) is the “acceleration due to gravity.”\nWe could have written the function as \\(\\text{period}(L, g) \\equiv \\sqrt{\\strut L/g\\ }\\), treating both quantities \\(L\\) and \\(g\\) as inputs. We wrote instead \\(\\text{period}(L)\\) to signify something to the human reader: that we are anticipating the user of \\(\\text{period}()\\) to be calculating the periods of various pendula, with different \\(L\\), but all in about the same location. That location will presumably be near the surface of the Earth, where \\(g \\approx 9.8\\) m/s2. In other words, the definition of \\(\\text{period}(L)\\) treats the acceleration due to gravity as a parameter rather than an input.\nOf course, you might be the kind of person who puts pendula in elevators or on Mars. If so, you would need to use a different value for \\(g\\) than \\(9.8\\) m/s2.\nYou’ll see much more use of parameters in Block ?sec-modeling-part when we use parameters to “fit” functions to data.\n\n\n\n2.1.2 Parameter names\nTo make it easy to recognize parameters, we’ll use names like \\(a\\), \\(b\\), \\(c\\), \\(\\ldots\\), or their upper-case cousins \\(A\\), \\(B\\), \\(\\ldots\\). For instance, here is a definition of a function called a “cubic polynomial”: \\[h(x)\\equiv a + b x + c x^2 + d x^3\\ .\\]\n\n\nPronounce names \\(a_0\\) or \\(b_3\\) as “a-sub-zero” and “b-sub-three” respectively.\nBut there will be occasions where we need to compare two or more functions and run out of appropriate names from the start of the alphabet. A way to keep things organized is to use subscripts on the letters, for instance comparing \\[g(x) \\equiv a_0 + a_1 x^2 + a_2 x^2 + a_3 x^3 + a_4 x^4\\] to \\[f(x) \\equiv b_0 + b_1 x^2 + b_2 x^2\\ .\\]\n\n\nThe tradition of using letters from the start of the alphabet as parameter names dates from the time of Isaac Newton.\nProfessional models often use Greek letters as parameter names: \\(\\alpha\\), \\(\\beta\\), \\(\\gamma\\), \\(\\delta\\), …\n\n\n2.1.3 Functions without names\nTraditional mathematical notation writes many functions both without a name and without the parentheses. Examples that you have likely seen are \\(x^2\\), \\(\\sqrt{\\strut x}\\), and \\(e^x\\). In the name/parentheses format these functions would be, say, square() and sqrt() and exp(). Notice that the \\(x\\) is not part of the function name in the name/parentheses format.\nSometimes we will use names like square() just to emphasize the point that we are talking about a function. But, for the most part, we will stick to the traditional form because it is ubiquitous and recognizable by most readers.\nThe name/parentheses notation, like exp() or sin() allows us to avoid having to write \\(x\\) as the indicator of where the input to the function goes. That’s helpful because, after all, the actual input might be something completely different from \\(x\\)."
  },
  {
    "objectID": "Preliminaries/02-notation.html#special-inputs",
    "href": "Preliminaries/02-notation.html#special-inputs",
    "title": "2  Notation",
    "section": "2.2 Special inputs",
    "text": "2.2 Special inputs\nWe’ll create functions as models of a real-world situation. Once created, we generally have to extract information from the function that informs the real-world choice, decision, or understanding that we need to make or develop.\nThere are many forms that the extracted information will take, depending on circumstance. With surprising frequency, two types of information turn out to be useful:\n\nThe set of inputs that produces a maximum or minimum output.\nInputs that produce a specific output.\n\nWe’ll call these special inputs and will study the techniques for determining them later in the book. For now, though, focus on the notation we will use so that you can spot when a special input is being used.\nAs we’ve stated before, the names of inputs will tend to be letters from the back of the alphabet: \\(t\\), \\(u\\), \\(v\\), \\(x\\), \\(y\\), \\(z\\). Each such name refers to the entire set of possible inputs to a function. When we want to refer to a specific input that describes a particular feature of a function, we will use the standard input names with a superscript—for instance, \\(x^\\star\\)—or a subscript like \\(y_1\\) or \\(u_0\\)."
  },
  {
    "objectID": "Preliminaries/02-notation.html#exercises",
    "href": "Preliminaries/02-notation.html#exercises",
    "title": "2  Notation",
    "section": "2.3 Exercises",
    "text": "2.3 Exercises\nrr if (knitr::is_latex_output()) knitr::knit_exit()\n\nExercise 2.1: TKWEW unassigned\n\nUse the MOSAIC Calculus naming conventions to answer these questions.\n\n\nPart A What is \\(h()\\)?\n\nThe name of a function\nThe name of an input.\nA specific numerical value\n\n\n\n\n\nPart B How come we write \\(f()\\) for the name of a function rather than just \\(f\\) or \\(f(x)\\)?\n\nNo good reason\nIt’s a reminder that we’re talking about a function with the name “\\(f\\)”.\nThe parentheses are part of the name.\n\n\n\n\n\nPart C What sort of thing is denoted by \\(x_0\\) or \\(y_\\star\\) or \\(y_{max}\\)?\n\nA particular numerical value\nThe name of an input\n\n\n\n\n\nPart D Which of these symbols might stand for the entire domain of a function?\n\\(y\\)\\(f()\\)\\(y_0\\)\n\n\n\n\nPart E Suppose you come across \\(v(w) \\equiv w + 3\\) in this book. What do \\(v\\) and \\(w\\) stand for?\n\n\\(v()\\) is the name of a function and \\(w\\) is the name of the input to that function.\nIt’s meaningless.\nIt’s the same thing as \\(v = w + 3\\).\n\n\n\n\n\nPart F Are \\(g(x) \\equiv x^2\\) and \\(h(w) \\equiv w^2\\) the same function?\n\nYes, although that function is being given two different names.\nOf course not!\n\n\n\n\nExercise 2.2: LDNE unassigned\n\nAccording to the notation style we use in CalcZ, which of these things is a function? Which a number?\n\n\nPart A What kind of a thing is \\(\\sqrt{z}\\)?\nA functionA number\n\n\n\n\nPart B What kind of a thing is \\(\\sqrt{y^\\star}\\)?\nA numberA function\n\n\n\n\nPart C What kind of a thing is \\(e^{k t}\\)?\nA functionA number\n\n\n\n\nPart D What kind of a thing is \\(k\\) in the definition \\(g(k) \\equiv e^k\\)?\n\nA number\nThe name of an input to a function.\nA function\n\n\n\n\nExercise 2.3: kZG5Fj unassigned\n\nThe following traditional-style notation is intended to define a function that is 2 times the pattern-book sinusoid. But something is wrong.\n\\[g(t) \\equiv 2 \\sin(x)\\]\n\n\nPart A What’s wrong with the definition?\n\n\\(g()\\) isn’t an appropriate name\nThe formula should be written \\(2 \\times \\sin(x)\\)\n\\(t\\) is not a good choice for the input name.\nThe input name in the formula doesn’t match the input name on the left side of \\(\\equiv\\).\n\n\n\n\nExercise 2.4: aeOnO5 unassigned\n\nConsider this expression in math notation:\n\n\\[\\frac{e^{k t}}{k}\\]\n\n\n\nPart A Which of the following R expressions implements the math-notation expression?\nk exp(kt)e^k*t / kexp(k t) / kexp(k*t) / k1/k e^kt\n\n\n\nExercise 2.5: ooJK5d unassigned\n\nSuppose you want to define a straight-line function named \\(f()\\) such that \\(f(x)\\equiv m x + b\\). Each of the following R statements is incorrect for this purpose. Say why.\n\n\nPart A f <- m*x + b\n\nNeed to use makeFun() to define a function.\nm is not defined.\nb is not defined.\nShould be y <- m*x + b.\n\n\n\n\n\nPart B f <- makeFun(m*x + b)\n\nThe first argument to makeFun() should be a tilde expression.\nm is not defined.\nb is not defined.\nmakeFun() requires two inputs.\n\n\n\n\n\nPart C f <- makeFun(x ~ m*x + b)\n\nThe tilde expression should have the input name on the right-hand side of the ~.\nm is not defined.\nb is not defined.\nThe first argument is not a tilde expression.\n\n\n\n\n\nPart D f <- makeFun(mx + b ~ x)\n\nThe tilde expression is missing the multiplication operator * between m and x\nm is not defined.\nb is not defined.\nThe name f is mis-spelled.\n\n\n\n\n\nPart E f <- makeFun(b*x + m ~ x)\n\nThe roles of m and b have been reversed.\nm is not defined.\nb is not defined.\nx is not defined.\n\n\n\n\n\nExercise 2.6: BXCA4 unassigned\n\nOpen a SANDBOX. (Just click on that link, although you may eventually be given other ways to open a sandbox.)\n\nWhen you see a breakout box like this, it means that we’re providing some computer code that you can paste into a sandbox and run. For this exercise, that code is\n\nx <- 2\nsin(x)*sqrt(x)\n\nPaste those two lines into the sandbox and press “Run code.” Verify that you get this as a result:\n[1] 1.285941\n\nEach line that you pasted in the sandbox is a command. The first command gives a value to \\(x\\). The second command uses that value for \\(x\\) to calculate a function output. The function is \\(g(x)\\equiv \\sin(x) \\times \\sqrt{\\strut x}\\).\n\nWhy not simplify the above code to the single line sin(2)*sqrt(2)? This would produce the same output but would introduce an ambiguity to the human reader. We want to make it clear to the reader (and the computer) that whatever \\(x\\) might be, it should be used as the input to both the \\(\\sin()\\) and the \\(\\sqrt{\\strut\\ \\ \\ }\\) functions.\n\nIn the following questions, numbers have been rounded to two or three significant digits. Select the answer closest to the computer output.\n\n\nPart A Change \\(x\\) to 1. What’s the output of \\(\\sin(x) \\ \\sqrt{\\strut x}\\)\n-1.510.2440.840.992.14NaN\n\n\n\n\nPart B Change \\(x\\) to 3. What’s the output of \\(\\sin(x) \\  \\sqrt{\\strut x}\\)\n-1.510.2440.840.992.14NaN\n\n\n\n\nPart C Change \\(x\\) to \\(-5\\). What’s the output of \\(\\sin(x) \\  \\sqrt{\\strut x}\\)\n-1.510.2440.840.992.14NaN\n\n\nIn the sandbox, change the function to be \\(\\sqrt{\\strut\\pnorm(x)}\\).\n\n\nPart D For \\(x=2\\), what’s the output of \\(\\sqrt{\\strut\\pnorm(x)}\\)?\n-1.510.2440.840.992.14NaN\n\n\n\nExercise 2.7: 0V510o R formula notation\n\nUsing the R console, translate each of the following mathematical expressions into R in order to calculate the numerical value of the expression.\n\n\\((16 - 3)/2\\) \n\\(\\sqrt{\\frac{19}{3}}\\) \n\\(\\cos(\\frac{2 \\pi}{3})\\) \n\\(\\pi^3 + 2\\) \n\\(\\pi^{3+2}\\) \n\n\nExercise 2.8: Ce79t3 makeFun()\n\nEach of these attempts to define a mathematical function using R leads to an error message. Modify the statement so that it works properly.\n\nf(x) <- makeFun(2*x + 3 ~ x)\nh <- makeFun(x ~ 2*x + 3)\nf <- makeFun(2x + 3)\ng(x) <- makeFun(4 sin(x))\nh2 <- 2*x + 3 ~ x\ng2 <- makeFun(2*x + 3 ~ y)\np(x,y) <- makeFun(2 x + 3 y~ x & y)\n\n\n\nExercise 2.9: BaEJkS unassigned\n\n\nMake this an exercise on “when things go wrong.”\n\nWhen your R command is not a complete sentence, the SANDBOX will display an error like this:\nError in parse(text = x, keep.source = TRUE) : :5:0: unexpected end of input \nThe “unexpected end of input” is the computer’s way of saying, “You haven’t finished your sentence so I don’t know what to do.”\nEach of these R expressions is incomplete. Your job, which you should do in a sandbox, is to turn each into a complete expression. Sometimes you’ll have to be creative, since when a sentence is incomplete you, like the computer, don’t really know what it means to say! But each of these erroneous expressions can be fixed by adding or changing text.\nOpen a sandbox and copy each of the items below, one at a time, into a sandbox. Press “Run code” for that item and verify that you get an error message.\nFor the first item, the sandbox will look like this:\nNEED TO SORT OUT IMAGE INCLUSION IN PDF ::: {.cell layout-align=“center” fig.showtext=‘false’}\n:::\nThen, fix the command so you get a numerical result rather than the error message.\nWorking through all of these will help you develop an eye and finger-memory for R commands.\n\nsin 3\n((16 - 4) + (14 + 2) / sqrt(7)\npnorm(3; mean=2, sd=4)\nlog[7]\n14(3 + 7)\ne^2\n3 + 4 x + 2 x^2"
  },
  {
    "objectID": "Preliminaries/03-computing.html",
    "href": "Preliminaries/03-computing.html",
    "title": "3  Computing with R",
    "section": "",
    "text": "Mathematical notation evolved for the purpose of communication among people. With the introduction of programmable computers in the middle of the 20th century, a notation was needed to communicate between people and hardware. It turns out that traditional mathematical notation in calculus is not fully adequate for this purpose.\nComputers need to distinguish between declarative and imperative statements. A declarative statement, like \\(g(z) \\equiv z \\cos(z)\\) defines and describes a relationship. An imperative statement is a direction to do some action. For instance, “The store is on the next block,” is declarative. “Bring some crackers from the store,” is imperative.\nThe names and format of such instructions—e.g. make a mathematical function from a formula, draw a graph of a function, plot data—are given in the same function notation we use in math. For example, makeFun() constructs a function from a formula, slice_plot() graphs a function, gf_point() makes one style of data graphic. These R entities saying “do this” are also called “functions.”\nWhen referring to such R “do this” functions, we’ll refer to the stuff that goes in between the parentheses as “arguments.” The word “input” would also be fine. The point of using “input” for math functions and “argument” for R “do-this” functions is merely to help you identify when we are talking about mathematics and when we are talking about computing.\nWith computers, writing an expression in computer notation goes hand-in-hand with evaluating the notation. We’ll start with the simplest mode of evaluation, where you are writing the expression in the console for the language. ?fig-R-console shows and example the console tab provided by the RStudio application.\n\n\n\n\n\nFigure 3.1: An RStudio console tab for writing expressions and evaluating them. The > is the prompt after which you write your expression, here shown in \\(\\color{blue}{\\text{blue}}\\). Pressing the “return” key causes the language interpreter to evaluate the command.\n\n\n\n\nIn Figure 3.1 we have come in to the story in the middle of the action. To start, there was just a prompt character.\n\\(\\color{blue}{\\mathtt >}\\)\nThe person at the keyboard then typed a simple expression: 2 + 3\n\\(\\color{blue}{\\mathtt >\\  2 + 3}\\)\nHaving completed the expression, the keyboarder presses “return.” The RStudio application sends the expression to the software that “interprets” it according to the rules of the R language. 2 + 3 is a complete, valid R expression, an imperative statement. Consequently, the R-language software carries out the action specified—adding 2 and 3—and returns the result to RStudio, which displays it just below the expression itself.\n\\(\\color{blue}{\\mathtt >\\  2 + 3}\\\\\\mathtt{[1]\\ 5}\\)\nNote that the value of the expression is simply the number 5. The R language is set up to format numbers with an index, which is helpful when the value of the expressions is a large set of numbers. In the case here, with just a single number in the result of evaluating the expression, the index is simply stating the obvious.\nHaving printed the result of evaluating the 2 + 3 expression, RStudio shows another prompt, signally that it’s ready for you to enter your next expression. In Figure 3.1 we’re seeing the console after the person at the keyboard has responded to the prompt by writing another expression, pressed return, had RStudio print the value of that expression, and displayed a new prompt.\nThe two expressions shown in the console in Figure 3.1 both evaluate to single numbers. We say, “the command returns a value.” The command is a valid R expression followed by the signal (pressing the “Return” key) to evaluate the command. The value of the expression is the result of evaluating the command.\n\n\nIn a mathematical statement like \\(h(x) \\equiv 3 x + 2\\), the \\(\\equiv\\) indicates that the statement is declarative. On the other hand, applying a function to a value, as in \\(h(3)\\), is an imperative statement.\nAnother common form of R expression is assignment, a declarative statement. An assignment gives a name to a value. It’s done using a symbolic name and the <- token:\n\nb <- 3\n\nThe result of evaluating this command is to store in the computer memory, under the name b, Because the value is being stored, R is designed not to display the value as happened with the first two commands in the console. If you want to see the value printed out, give the name as an imperative command:\n\nb\n## [1] 3\n\nOften, declarative and imperative statements are combined, for instance\n\nb <- 22/7\n\nThis book displays the command being evaluated in a gray box, without a prompt. The value returned by the command is displayed underneath the command, prefaced by \\(\\color{red}{\\mathtt{\\#\\#}}\\). In the book formatting, the four commands we have just described would be displayed in this way:\n\n2 + 3\n## [1] 5\nsqrt(16)\n## [1] 4\nb <- 3\nb <- 22/7\nb\n## [1] 3.142857\n\n\n\n\nWhen reading this book, take care to distinguish between the display of a command and the display of the value returned by that command. The first is something you type, the second is printed by the computer."
  },
  {
    "objectID": "Preliminaries/03-computing.html#sec-makefun",
    "href": "Preliminaries/03-computing.html#sec-makefun",
    "title": "3  Computing with R",
    "section": "3.2 Functions in R/mosaic",
    "text": "3.2 Functions in R/mosaic\nOne of the fundamental mathematical operations in this book is defining functions. You’ve already seen the way we use mathematical notation to define a function, for instance, \\[h(t) \\equiv 1.5\\, t^2 - 2\\ .\\] The R/mosaic equivalent to the definition of \\(h()\\) is:\n\nh <- makeFun(1.5*t^2 - 2 ~ t)\n\nOnce you have defined a function, you can evaluate it on an input. The R notation for evaluating functions is the same as with mathematical notation, for instance,\n\nh(4)\n## [1] 22\n\nor\n\nh(t=4)\n## [1] 22\n\nThere are obvious differences, however, between the mathematical and computing notation used to define a function. All the same information is being provided, but the format is different. That information is:\n\nthe name of the function: \\(h()\\) or h. When writing the name of a computer-defined function, we’ll put the reminder parentheses after the name, as in h().\nthe name of the input to the function: \\(x\\) or x\nthe calculation that the function performs, written in terms of the input name. \\(1.5 t^2 -2\\) or 1.5 * t^2 - 2.\n\nLaying out the two notation forms side by side let’s us label the elements they share:\n\n\n\n\n\n\n\n\n\nFor the human reading the mathematical notation, you know that the statement defines a function because you have been told so. Likewise, the computer needs to be told what to do with the provided information. That’s the point of makeFun(). There are other R/mosaic commands that could take the same information and do something else with it, for example create a graph of the function or (for those who have had some calculus) create the derivative or the anti-derivative of the function.\n\nIn R, things like makeFun() are called “functions” because, like mathematical functions, they turn inputs into outputs. In the case of makeFun(), the input is a form called a tilde expression, owing to the character tilde (~) in the middle. On the right-hand side of the tilde goes the name of the input. On the left-hand side is the R expression for the formula to be used, written as always in terms of the input name. The whole tilde expression is taken as the one argument to makeFun(). Although it may seem odd to have punctuation in the middle of an argument, remember that something similar happens when we write \\(h(t=3)\\)."
  },
  {
    "objectID": "Preliminaries/03-computing.html#names-and-assignment",
    "href": "Preliminaries/03-computing.html#names-and-assignment",
    "title": "3  Computing with R",
    "section": "3.3 Names and assignment",
    "text": "3.3 Names and assignment\nThe command\n\nh <- makeFun(1.5*t^2 - 2 ~ t)\n\ngives the name h to the function created by makeFun(). Good choice of names makes your commands much easier for the human reader.\nThe R language puts some restrictions on the names that are allowed. Keep these in mind as you create R names in your future work:\n\nA name is the only1 thing allowed on the left side of the assignment symbol <-.\nA name must begin with a letter of the alphabet, e.g. able, Baker, and so on.\nNumerals can be used after the initial letter, as in final4 or g20. You can also use the period . and underscore _ as in third_place. No other characters can be used in names: no minus sign, no @ sign, no / or +, no quotation marks, and so on.\n\nFor instance, while third_place is a perfectly legitimate name in R, the following are not: 3rd_place, third-place. But it’s OK to have names like place_3rd or place3, etc., which start with a letter.\nR also distinguishes between letter case. For example, Henry is a different name than henry, even though they look the same to a human reader."
  },
  {
    "objectID": "Preliminaries/03-computing.html#formulas-in-r",
    "href": "Preliminaries/03-computing.html#formulas-in-r",
    "title": "3  Computing with R",
    "section": "3.4 Formulas in R",
    "text": "3.4 Formulas in R\nThe constraint of the keyboard means that computer formulas are written in a slightly different way than the traditional mathematical notation. This is most evident when writing multiplication and exponentiation. Multiplication must always be indicated with the * symbol, for instance \\(3 \\pi\\) is written 3*pi. For exponentiation, instead of using superscripts like \\(2^3\\) you use the “caret” character, as in 2^3. The best way to learn to implement mathematical formulas in a computer language is to read examples and practice writing them.\nHere are some examples:\n\n\n\nTraditional notation\nR notation\n\n\n\n\n\\(3 + 2\\)\n3 + 2\n\n\n\\(3 \\div 2\\)\n3 / 2\n\n\n\\(6 \\times 4\\)\n6 * 4\n\n\n\\(\\sqrt{\\strut4}\\)\nsqrt(4)\n\n\n\\(\\ln 5\\)\nlog(5)\n\n\n\\(2 \\pi\\)\n2 * pi\n\n\n\\(\\frac{1}{2} 17\\)\n(1 / 2) * 17\n\n\n\\(17 - 5 \\div 2\\)\n17 - 5 / 2\n\n\n\\(\\frac{17 - 5}{\\strut 2}\\)\n(17 - 5) / 2\n\n\n\\(3^2\\)\n3^2\n\n\n\\(e^{-2}\\)\nexp(-2)\n\n\n\nEach of these examples has been written using numbers as inputs to the mathematical operations. The syntax will be the same when using an input name such as x or y or altitude, for instance (x - y) / 2. In order for that command using x and y to work, some meaning must have been previously attached to the symbols. We’ll come back to this important topic on another day."
  },
  {
    "objectID": "Preliminaries/04-graphs-and-graphics.html",
    "href": "Preliminaries/04-graphs-and-graphics.html",
    "title": "4  Visualizing functions",
    "section": "",
    "text": "In Chapter Section 1 we encouraged you to think of a function in terms of the space of possible inputs—the domain—and another space of outputs. In this chapter, we introduce ways to visualize the input and output space of a function together.\nLet’s start with a space suitable for representing a single quantity. That is, of course, the familiar number line.\nOn the number line, any specific quantity is a single point. For instance, let’s use the number line to show the two quantities \\(\\color{blue}{6.3}\\) and \\(\\color{magenta}{-4.5}\\).\nA function connects each point in the input space to a corresponding point in the output space. Figure Figure 4.1 gives a sketch of an arbitrary function where the input and output spaces are shown one above the other. Arrows are drawn for several input values, showing where those values are mapped to in the output space. (There are infinitely more arrows to be drawn in between those shown, but the graphic would become illegible.)\nFigure 4.1 gives information about the function, but it is in a format that is almost impossible to interpret. Renė Descartes (1596–1650) proposed a better visualization: place the input and output spaces at right angles to one another and, instead of the head and tail of the arrows connecting corresponding positions on the input and on the output spaces, use the head and tail values as coordinates in the joint input/output space. This setup is shown in Figure 4.2 and is called, as you know, the graph of the function.\nA major advantage of this format is that the function output can be displayed not just at a discrete set of input values, but at every point in the continuous input space. Figure 4.2 shows one function consistent with the discrete points, but there are many such functions. That is, the discrete arrows shown in Figure 4.1 do not completely specify a unique function.\nThe smooth curve in Figure 4.3 describes the relationship between current and voltage quantitatively. For example, if you know that the current is 0, you can use the curve to figure out what the voltage will be around -90 mV or -50 mV or -10 mV. But when the current is 0, the voltage will not be, say, -75 or -150.\nGraphs such as Figure 4.5 and Figure 4.3 are good ways of showing relationships. We can even do calculations simply using such graphs. Place your finger on a point of the S-shaped graph and you can read from the axes an allowed pair of voltage and current values. Place your finger on a point on the vertical axis. Moving it to the curve will reveal what current is associated with that voltage.\nFunctions are, like graphs, a way of representing relationships. For all their advantages as a means of communication, graphs have their limits. With a graph, it’s feasible only to show the relationship between two quantities or among three quantities. Functions can involve more quantities. For instance, the triangle-area function \\[A(a,b,c) \\equiv \\frac{1}{4}\\sqrt{\\strut 4a^2b^2-(a^2+b^2-c^2)^2}\\] gives the relationship between four quantities: the area and the lengths of the triangle’s three sides.\nOn the other hand, functions cannot represent all types of relationships. For instance, the curve in Figure 4.3 shows a relationship between current and voltage in nerve cells. But there is no mathematical function voltage(current) that does justice to the relationship. The reason is that mathematical functions can have one and only one output for any given input. There are three reasonable values for membrane voltage that are experimentally consistent with a zero current, not just one.\nCare needs to be taken in using functions to represent relationships. For the nerve-cell current-voltage relationship, for instance, we can construct a function current(voltage) to represent the relationship. That’s because for any given value of voltage there is just one corresponding current. But there is no voltage(current) function, even though knowing the current tells you a lot about the voltage."
  },
  {
    "objectID": "Preliminaries/04-graphs-and-graphics.html#function-graphs-in-rmosaic",
    "href": "Preliminaries/04-graphs-and-graphics.html#function-graphs-in-rmosaic",
    "title": "4  Visualizing functions",
    "section": "4.1 Function graphs in R/mosaic",
    "text": "4.1 Function graphs in R/mosaic\nGiven a function, it’s easy to draw the corresponding relationship as a graphic. This section describes how to do that for functions that have one or two inputs. The opposite—given a relationship, representing it using functions—is usually not so easy and will require modeling techniques that we’ll develop in Block 1.\nContemporary practice is to draw graphs of functions using a computer. R/mosaic provides several functions that do this, you need only learn how to use them.\nThere are two essential arguments shared by all of the R/mosaic functions drawing a graph:\n\nThe function that is to be graphed. This is to be written as a tilde expression in the same manner as described in ?sec-computing-with-R.\nThe domain interval. The domain of many functions reaches infinity, but our computer screens are not so big! Making a graph requires choosing a finite interval for each of the input quantities.\n\nThe tilde expression for a function with one input will have only one name on the right-hand side of the ~. The domain interval specification must use the same name:\n\n\n\nTilde expression\nDomain interval specification\n\n\n\n\nx^2 ~ x\ninterval(x = -3:3)\n\n\ny * exp(y) ~ y\ninterval(y = 0:10)\n\n\nlog(y) / exp(y) ~ y\ninterval(y = -5:5)\n\n\nsin(z) / z ~ z\ninterval(y = -3*pi:3*pi)\n\n\n\n\n4.1.1 Slice plot\nTo draw a graph of a function with one input, use slice_plot(). The tilde expression is the first argument; the domain interval specification is the second argument. For instance,\n\nslice_plot(y * exp(y) ~ y, domain(y=0:10))\n\n\n\n\n\nFigure 4.4: Graph of the function \\(f(y) \\equiv y e^y\\).\n\n\n\nRecall the situation seen in Figure 4.3 which shows a two-dimensional space of all possible (voltage, current) pairs for nerve cells. The experimental data identified many possible pairs—marked by the dots in Figure 4.3 —that are consistent with the relationships of the nerve-cell system.\nThe graphics frame in Figure 4.4 is a 2-dimensional area for drawing. The domain of the function being graphed in that frame, \\(f() \\equiv y e^y\\), is the number line, that is, the space of all real numbers. The plot, however, shows only a finite interval \\(0 \\leq y \\leq 10\\) of that domain.\nThe same is true of Figure 4.4, the graph of a function with a single input. The two-dimensional space shown in the Figure 4.4 contains (input, output) pairs, only a small fraction of which are consistent with the relationship described by the function. The points in that small fraction could be marked by individual dots, but instead of dots, we draw a continuous curve connecting the dots. Every point on the curve is consistent with the relationship between input and output represented by the function.\n\n\n4.1.2 Contour plot\n\n\n\n\n\n\nFigure 4.5: Phase diagram for CO_2_. Source Ben Finney, Mark Jacobs, CC0, via Wikimedia Commons\n\n\n\n\nSolid CO_2\nINTEGRATE THIS INTO THE CONTOUR-PLOT DISCUSSION. Talk about the discrete phases and that each point in the input space corresponds to one of the possible phases: solid, liquid, gas, … Then transition into continuous outputs.\nThere’s considerable interest in ways to remove CO_2 from the atmosphere and store it permanently underground. It’s hard to store gasses in the massive quantities needed to mitigate climate change. But CO_2_ storage is part of a system that includes temperature, pressure, and chemical affinity.\nFigure 4.5 shows the relationship between the physical form of pure CO_2_ and the temperature and pressure of the gas.\n\nFunctions with two inputs can be displayed with contour_plot(). Naturally, the tilde expression defining the function will have two names on the right-hand side of ~. Similarly, the domain specification will have two arguments, one for each of the names in the tilde expression.\n\ncontour_plot(exp(-z)*sin(y) ~ y & z, domain(y=-6:6, z=0:2))\n\n\n\n\nFigure 4.6: Contour plot of a function with two inputs \\(g(y,z) \\equiv e^{-z}\\sin(y)\\)\n\n\n\n\nContour plots will be a preferred format for displaying functions with two inputs. The main reason to prefer contour plots is the ease with which locations of points in the input space can be identified and the ability to read output values without much difficulty.\n\n\n4.1.3 Surface plot\nThere’s another way to think about graphing functions with two inputs. There are in such a situation three quantities involved in the relationship. Two of these are the inputs, the third is the output. A three-dimensional space consists of all the possible coordinate triples; the relationship between the inputs and the output is marked by ruling out almost all of the potential triples and marking those points in the space that are consistent with the function.\nthe space of all possibilities (y, z, output) is three-dimensional, but very few of those possibilities are consistent with the function to be graphed. You can imagine our putting dots at all of those consistent-with-the-function points, or our drawing lots and lots of continuous curves through those dots, but the cloud of dots forms a surface; a continuous cloud of points floating over the (y, z) input space.\nFigure 4.7 displays this surface. Since the image is drawn on a two-dimensional screen, we have to use painters’ techniques of perspective and shading. In the interactive version of the plot, you can move the viewpoint for the image which gives many people a more solid understanding of the surface.\n\n  surface_plot(exp(-z)*sin(y) ~ y & z, interval(y=-6:6, z=0:2))\n\n\n\n\n\n\nFigure 4.7: Displaying \\(g(y,z) \\equiv e^{-z}\\sin(y)\\) as a surface plot annotated with contour lines.\n\n\n\nNote that the surface plot is made with the R/mosaic surface_plot(), which takes arguments in the same way as contour_plot()."
  },
  {
    "objectID": "Preliminaries/04-graphs-and-graphics.html#sec-interpreting-contour-plots",
    "href": "Preliminaries/04-graphs-and-graphics.html#sec-interpreting-contour-plots",
    "title": "4  Visualizing functions",
    "section": "4.2 Interpreting contour plots",
    "text": "4.2 Interpreting contour plots\nIt may take some practice to learn to read contour plots fluently but it is a skill that’s worthwhile to have. Note that the graphics frame is the Cartesian space of the two inputs. The output is presented as contour lines. Each contour line has a label giving the numerical value of the function output. Each of the input value pairs on a given contour line corresponds to an output at the level labeling that contour line. To find the output for an input pair that is not on a contour line, you interpolate between the contours on either side of that point.\n\nWhat’s the value of the function being plotted here at input \\((\\text{input}_1=0, \\text{input}_2=0)\\)?\n\n\n\n\n\n\n\n\n\nThe input pair (0, 0)—which is marked by a small red dot—falls between the contours labeled “20” and “22.” This means that the output corresponding to input (0, 0) is somewhere between 20 and 22. The point is much closer to the contour labeled “20”, so it’s reasonable to see the output value as 20.5. This is, of course, an approximation, but that’s the nature of reading numbers off of graphs.\n\nOften, the specific numerical value at a point is not of primary interest. Instead, we may be interested in how steep the function is at a point, which is indicated by the spacing between contours. When contours are closely spaced, the hillside is steep. Where contours are far apart, the hillside is not steep, perhaps even flat.\nAnother common task for interpreting contour plots is to locate the input pair that’s at a local high point or low point: the top of a hill or the bottom of a hollow. Such points are called local argmax or local argmin respectively. The output of the function at a local argmax is called the local maximum; similarly for a local argmin, where the output is called a local minimum. (The word “argmax” is a contraction of “argument of the maximum.” We will tend to use the word “input” instead of “argument”, but it means the same thing to say “the inputs to a function” as saying “the arguments of a function.”)\n\nFor this contour graph\n\n\n\n\n\n\n\n\n\n\nFind an input coordinate where the function is steepest.\nFind input coordinates for the high and low points of the function .\n\nA function is steepest where contour lines are spaced closely together, that is, where the function output changes a lot with a small change in input. This is true near inputs \\((x=0, y=1)\\). But notice that steepness involves a direction. Near \\((x=0,y=1)\\), changing the \\(x\\) value does not lead to a big change in output, but a small change in the value of \\(y\\) leads to a big change in output. In other words, the function is steep in the y-direction but not in the x-direction.\nThe highest output value explicitly marked in the graph is 8. We can imagine from the shapes of the contours surrounding the 8 contour that the function reaches a peak somewhere in the middle of the region enclosed by the 8 contour, near the input coordinate \\((x=0, y=-1.5)\\).\nSimilarly, the lowest output value marked is -10. In the middle of the area enclosed by the -10 contour is a local low point. That there are two such regions, one centered near input coordinate \\((x=-0.5, y=3.3)\\), the other at \\((x=1.5, y=3.1)\\).\n\n\nWhy do you call the graphs of functions with one input slice plots rather than simply graphs?\nSaying “graph” for a display of \\(f(x)\\) versus \\(x\\) is correct and reasonable. But in MOSAIC Calculus we have another point to make.\nAlmost always, when mathematically modeling a real-world situation or phenomenon, we do not try to capture every nuance of every relationship that might exist in the real world. We leave some things out. Such simplifications make modeling problems easier to deal with and encourage us to identify the most important features of the most important relationships.\n\n\n\n\n\nFigure 4.8: A hypothetical relationship among three quantities.\n\n\n\n\nIn this spirit, it’s useful always to assume that our models are leaving something out and that a more complete model involves a function with more inputs than the present candidate. The present candidate model should be considered as a slice of a more complete model. Our slice leaves out one or more of the input quantities in a more complete model.\nAs you become practiced reading contour plots, you might prefer to read this one as a hilltop (shaded yellow) side-by-side with a hollow or bowl (shaded purple), with green, almost level flanks at the left and right edges of the frame.\nTo illustrate this, suppose that the actual system involves relationships among three quantities, which we represent in the form of a function of two inputs, as shown in Figure 4.8. (The third quantity in the relationship is the output of the function.)\nThe most common forms of slice involve constructing a simpler function that has one input but not the other. For example, our simpler function might ignore input 22. There are different ways of collapsing the function of two inputs into a function of one input. An especially useful way in calculus is to take the two-input function and set one of the inputs to a constant value.\nFor instance, suppose we set input 22 to the constant value 1.5. This means that we can consider any value of input 1, but input 2 has been replaced by 1.5. In Figure 4.9, we’ve marked in red the points in the contour plot that give the output of the simplified function.\n\n\n\n\n\nFigure 4.9: Left: A slice (red) through the domain of a contour plot. Right: The value of the function along the red slice presented as a mathematical graph, generated by slice_plot().\n\n\n\n\nEach point along the red line corresponds to a specific value of input #1. From the contours, we can read the output corresponding to each of those values of input #1. This relationship, output versus input #1 can be drawn as a mathematical graph (to the right of the contour plot). Study that graph until you can see how the rising and falling parts of the graph correspond to the contours being crossed by the red line.\nSlices can be taken in any direction or even along a curved path! The blue line in Figure 4.10 shows the slice constructed by letting input 2 vary and holding input 1 at the constant value 0.\n\n\n\n\n\nFigure 4.10: A path (blue) along which to cut a slice. The graph is made with contour_plot(). Right: Slice plot along the blue path. The graph is made with slice_plot()."
  },
  {
    "objectID": "Preliminaries/04-graphs-and-graphics.html#exercises",
    "href": "Preliminaries/04-graphs-and-graphics.html#exercises",
    "title": "4  Visualizing functions",
    "section": "4.3 Exercises",
    "text": "4.3 Exercises\n<!– Drill\n\n\nDrill A At which of these inputs is the function output nearly zero?\n\\((x=0, y=1)\\)\\((x=1, y=5)\\)\\((x=0, y=6)\\)\\((x=-2, y=6)\\)\n\n\n\n\nDrill B At which of these inputs is the function output nearly 1?\n\\((x=0, y=1)\\)\\((x=1, y=5)\\)\\((x=0, y=6)\\)\\((x=-2, y=6)\\)\n\n\n\n\nDrill C Which of these is a positive-going zero crossing of \\(g(t)\\)? \\[g(t) \\equiv \\sin\\left(\\frac{2\\pi}{5}t-3\\right)\\]\n\\(t=15/2\\pi\\)\\(t = 2 \\pi/15\\)\\(t = 3\\)None of the above\n\n\n\n\nDrill D Which of the following is a positive-going zero crossing of \\(g(t)\\)? \\[\\sin\\left(\\frac{2 \\pi}{5} (t - 3) \\right)\\]\n\\(t=-5\\)\\(t=-3\\)\\(t=0\\)\\(t=3\\)\\(t=5\\)\n\n\n\n\nDrill E Which input is a negative-going zero-crossing of the function graphed?\n\\(t = -2.5\\) \\(t = -1.25\\)\\(t = 0\\) \\(t = 1.25\\) \\(t = 2.5\\)\n\n\n\n\nDrill F Which input is a positive-going zero-crossing of the function graphed?\n\\(t = -5\\) \\(t = -2.5\\) \\(t = -1.25\\) \\(t = 1.25\\) \\(t = 2.5\\)\n\n\n\n\nDrill G At which of these inputs is the function output nearly \\(-1\\)?\n\\((x=0, y=1)\\)\\((x=1, y=5)\\)\\((x=0, y=6)\\)\\((x=-2, y=6)\\)\n\n\n\n\nDrill H Which command made this plot? \n\nslice_plot(x^2 ~ x, x=c(-3,3))\nplot(x^2 ~ x, domain=c(-3,3))\nslice_plot(x^2, domain(x=c(-3,3)))\nNone of them correspond to the plot.\nslice_plot(x^2 ~ x, domain(x=c(-3,3)))\n\n\n\n\n\nDrill I Which command made this plot? \n\nNone of them correspond to the plot.\nslice_plot(pnorm(x) ~ x, domain(x=(-4, 4))\nslice_plot(pnorm(x) ~ x, domain(x=c(-4, 4)))\nslice_plot(pnorm(x) ~ y, domain(x=c(-4, 4)))\n\n\n\n\n\nDrill J Only one of the following commands will successfully generate the graph of a function. Which one?\n\nslice_plot(dnorm(y)) ~ x, domain(y=c(-3,3)))\nslice_plot(pnorm(x) ~ x, domain(y=c(-4, 4)))\nslice_plot(exp(y) ~ y, domain(y=c(-4, 4)))\nslice_plot(log(x) ~ x, domain(x=c(0; 10)))\n\n\n\n->"
  },
  {
    "objectID": "Preliminaries/05-pattern-book-functions.html",
    "href": "Preliminaries/05-pattern-book-functions.html",
    "title": "5  Pattern-book functions",
    "section": "",
    "text": "In this Chapter, we introduce the pattern-book functions—a brief list of basic mathematical functions that provide a large majority of the tools for representing the real world as a mathematical object. Think of the items in the pattern-book list as different actors, each of whom is skilled in portraying an archetypal character: hero, outlaw, lover, fool, comic. A play brings together different characters, costumes them, and relates them to one another through dialog or other means.\nA mathematical model is a kind of story; a mathematical modeler is a kind of playwright. She combines mathematical character types to tell a story about relationships. We need only a handful of mathematical functions, the analog of the character actors in drama and comedy to sketch a model. In creating a mathematical model, you clothe the actors to suit the era and location and assemble them in harmony or discord.\nCostume designers use their imagination, often enhanced by referencing published collections of patterns and customizing them to the needs at hand. These references are sometimes called “pattern books.” (See Figure 5.1.)\nSimilarly, we will start with a pattern set of functions that have been collected from generations of experience. To remind us of their role in modeling, we’ll call these pattern-book functions. These pattern-book functions are useful in describing diverse aspects of the real world and have simple calculus-related properties that make them relatively easy to deal with. There are just a handful of pattern-book functions from which untold numbers of useful modeling functions can be constructed. Mastering calculus is in part a matter of becoming familiar with the mathematical connections among the pattern-book functions. (You’ll see these in due time.)\nHere is a list of our pattern-book functions written traditionally and in R:\nThe input name used in the table, \\(x\\), is entirely arbitrary. You can (and will) use the pattern-book functions with other quantities—\\(y\\), \\(z\\), \\(t\\), and so on, even zebra if you like.\nIn addition to the names of the pattern-book functions, you should be able to draw their shapes easily. ?tbl-pattern-book-shapes provides a handy guide.\nThese pattern-book functions are widely applicable. But nobody would confuse the pictures in a pattern book with costumes that are ready for wear. Each pattern must be tailored to fit the actor and customized to fit the theme, setting, and action of the story. We’ll study how this is done starting in Chapter Section 8."
  },
  {
    "objectID": "Preliminaries/05-pattern-book-functions.html#pattern-and-shape",
    "href": "Preliminaries/05-pattern-book-functions.html#pattern-and-shape",
    "title": "5  Pattern-book functions",
    "section": "5.1 Pattern and shape",
    "text": "5.1 Pattern and shape\nThe pattern-book functions are closely related to one another but each has a distinctive shape. The variety of shapes makes the small set of pattern-book functions suited to a wide range of modeling tasks.\n\n\n\n\n\n\n\n\n\nFigure 5.2: The output of the constant function is always 1, regardless of the input.\n\n\n\nThe constant function is so simple that you may be inclined to deny that it is a function at all. The output of the constant function is always numerical 1, regardless of the input. Its graph is therefore a horizontal line.\nYou may wonder why to take the trouble to make a function whose output is always the same. After all, in a formula it shows up simply as the number 1, not looking like a function at all. But formulas are not the only way of representing functions. For instance, in Block ?sec-vectors-linear-combinations we will use a mathematical structure called a “vector” to represent functions where the constant function won’t be just the number 1.\n\n\n\n\n\n\nFigure 5.3: The output of the proportional function is whatever the input value is.\n\n\n\nThe proportional function is also simple. Whatever is the input will become the output. (Another appropriate name for the proportional function is the “identity function” because the output is identical to the input.) The graph of the proportional function is a straight line going through \\((0,0)\\) with slope 1.\nDespite the simplicity of the proportional function, it is heavily used in modeling. In a formula, the proportional function appears as \\(x\\) or \\(y\\) or whatever the input name is to be. This can make it hard to remember that it is indeed a function.\nThe remaining pattern-book functions all have curved shapes.\n\n\n\n\n\n\n\n\n\nFigure 5.4: The “bell-shaped” Gaussian function.\n\n\n\nThe *Gaussian function is shaped like a mountain or, in many descriptions, like the outline of a bell. As the input becomes larger—in either the positive or negative directions—the output gets closer and closer to zero but never touches zero exactly.\nThe Gaussian function shows up so often in modeling that it has another widely used name: the normal function. But “normal” has additional meanings in mathematics, so we will not use that name in this book.\n\n\n\n\n\n\nFigure 5.5: The sigmoid function gives a smooth transition from zero to one.\n\n\n\nThe sigmoid function models smooth transitions. For large negative inputs, the output is (very nearly) zero. For large positive inputs, the output is (very nearly) one. The sigmoid is closely related to the Gaussian. As you progress in calculus, the relationship will become evident.\n\n\n\n\n\n\nFigure 5.6: The output of the exponential function grows faster and faster as the input increases.\n\n\n\nThe exponential function has important applications throughout science, technology, and the economy. For large negative inputs, the value is very close to zero in much the same way as for the Gaussian or sigmoid functions. But the output increases faster and faster as the input gets bigger. Note that the output of the exponential function is never negative for any input.\n\n\n\n\n\n\nFigure 5.7: The logarithm is defined only for inputs greater than zero.\n\n\n\nThe logarithmic function is defined only for positive inputs. As the input increase from just above zero, the output t constantly grows but at a slower and slower rate. It never levels out.\nThe exponential and logarithmic functions are intimate companions. You can see the relationship by taking the graph of the logarithm, and rotating it 90 degrees, then flipping left for right as in Figure 5.8.\n\n\n\n\n\n\nFigure 5.8: The exponential function is the same as the logarithm but—and this is a big but—reversing the roles of the input and output. Visually, that reversal of roles amounts to flipping the graph.\n\n\n\nThe output of the sinusoid function oscillates as the input changes. It’s a periodic function, meaning that the pattern repeats itself identically from left to right in the graph.\nIf you studied trigonometry, you may be used to the sine of an angle in the context of a right triangle. That’s the historical origin of the idea. For our purposes, think of the sinusoid just as a function that takes an input and returns an output. Starting in the early 1800s, oscillatory functions found a huge area of application in representing phenomena such as the diffusion of heat through solid materials and, eventually, radio communications.\nIn trigonometry, the sine has the cosine as a partner. But the two functions \\(\\sin()\\) and \\(\\cos()\\) are so closely connected that we will not often need to make the distinction, calling both of them simply “sinusoids.”\n\n\n\n\n\nFigure 5.9: The output of the sinusoid function oscillates as the input increases."
  },
  {
    "objectID": "Preliminaries/05-pattern-book-functions.html#sec-doubling-time",
    "href": "Preliminaries/05-pattern-book-functions.html#sec-doubling-time",
    "title": "5  Pattern-book functions",
    "section": "5.2 Exponentials & doubling time",
    "text": "5.2 Exponentials & doubling time\nThe exponential function has a characteristic property that makes it extremely important in models of many phenomena: The value doubles in constant time. That phrase, “doubles in constant time” can be obscure, so let’s look at it carefully with reference to a graph of the exponential function.\nFigure 5.10 is a graph of the exponential function, annotated with a set of evenly spaced vertical lines. The intersection of each vertical line with the function has been marked with a dot to make it easier to read off the output of the exponential when the input has any of the values marked by the vertical lines. For example, one of the vertical lines is at \\(t=0\\). From that you can confirm that \\(\\exp(t=0) = 1\\). Looking at the vertical line at \\(t = 1 \\times 0.693\\) you can confirm that \\(\\exp(t=0.693) = 2\\). Similarly \\(\\exp(t=2\\times 0.693) = 4\\) and \\(\\exp(t=3\\times 0.693) = 8\\).\n\n\n\n\n\nFigure 5.10: The exponential function doubles in constant time.\n\n\n\n\nIn other words, the output of the exponential function doubles whenever the input is increased by 0.693. Likewise, decreasing the input by 0.693 cuts the output by half. No other function than the exponential has this property that a constant change in the input (namely, 0.693) leads to a doubling of the output. So, 0.693 is “constant time” that leads to doubling."
  },
  {
    "objectID": "Preliminaries/05-pattern-book-functions.html#sec-power-law-family",
    "href": "Preliminaries/05-pattern-book-functions.html#sec-power-law-family",
    "title": "5  Pattern-book functions",
    "section": "5.3 The power-law family",
    "text": "5.3 The power-law family\nFour of the pattern-book functions—\\(1\\), \\(1/x\\), \\(x\\), \\(x^2\\)— belong to an infinite family called the power-law functions. Some other examples of power-law functions are \\(x^3, x^4, \\ldots\\) as well as \\(x^{1/2}\\) (also written \\(\\sqrt{x}\\)), \\(x^{1.36}\\), and so on. Some of these also have special (albeit less frequently used) names, but all of the power-law functions can be written as \\(x^p\\), where \\(x\\) is the input and \\(p\\) is a number. .\nWithin the power-law family, it is helpful to know and be able to distinguish between several groups:\n\nThe monomials. These are power-law functions such as \\(m_0(x) \\equiv x^0\\), \\(m_1(x) \\equiv x^1\\), \\(m_2(x) \\equiv x^2\\), \\(\\ldots\\), \\(m_p(x) \\equiv x^p\\), \\(\\ldots\\), where \\(p\\) is a whole number (i.e., a non-negative integer). Of course, \\(m_0()\\) is the same as the constant function, since \\(x^0 = 1\\). Likewise, \\(m_1(x)\\) is the same as the identity function since \\(x^1 = x\\). As for the rest, they have just two general shapes: both arms up for even powers of \\(p\\) (like in \\(x^2\\), a parabola); one arm up and the other down for odd powers of \\(p\\) (like in \\(x^3\\), a cubic). Indeed, you can see in Figure 5.11 that \\(x^4\\) has a similar shape to \\(x^2\\) and that \\(x^5\\) is similar in shape to \\(x^3\\). For this reason, high-order monomials are rarely needed in practice.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.11: The monomials \\(x^0\\), \\(x^1\\), \\(x^2\\), \\(x^3\\), \\(x^4\\), \\(x^5\\). The dashed \\(\\color{magenta}{\\text{magenta}}\\) line marks zero output.\n\n\n\n\n\nThe negative powers. These are power-law functions where \\(p<0\\), such as \\(f(x) \\equiv x^{-1}\\), \\(g(x) \\equiv x^{-2}\\), \\(h(x) \\equiv x^{-1.5}\\). For negative powers, the size of the output is inversely proportional to the size of the input. In other words, when the input is large (not close to zero) the output is small, and when the input is small (close to zero), the output is very large. This behavior happens because a negative exponent like \\(x^{-2}\\) can be rewritten as \\(\\frac{1}{x^2}\\); the input is inverted and becomes the denominator, hence the term “inversely proportional”.\n\n\n\n\n\n\n\nFigure 5.12: ?(caption)\n\n\n\n\n\n\n\nFigure 5.13: ?(caption)\n\n\n\n\n\n\n\n\n\nFigure 5.14: ?(caption)\n\n\n\n\n\n\n\nFigure 5.15: ?(caption)\n\n\n\n\n\n\n\n\n\n\nFigure 5.16: Graphs of power-law functions with negative integer exponents. The arrows point to the output being very large when \\(x\\) is near zero.\n\n\n\n\n\nThe non-integer powers, e.g. \\(f(x) = \\sqrt{x}\\), \\(g(x) = x^\\pi\\), and so on. When \\(p\\) is either a fraction or an irrational number (like \\(\\pi\\)), the real-valued power-law function \\(x^p\\) can only take non-negative numbers as input. In other words, the domain of \\(x^p\\) is \\(0\\) to \\(\\infty\\) when \\(p\\) is not an integer. You have likely already encountered this domain restriction when using the power law with \\(p=\\frac{1}{2}\\) since \\(f(x)\\equiv x^{1/2}=\\sqrt{x}\\), and the square root of a negative number is not a real number. You may have heard about the imaginary numbers that allow you to take the square root of a negative number, but for the moment, you only need to understand that when working with real-valued power-law functions with non-integer exponents, the input must be non-negative. (The story is a bit more complicated since, algebraically, rational exponents like \\(1/3\\) or \\(1/5\\) with an odd-valued denominator can be applied to negative numbers. Computer arithmetic, however, does not recognize these exceptions.)\n\n\n\n\n\n\nFigure 5.17: The domain of power-law functions with non-integer power is \\(0 \\leq x < \\infty\\).\n\n\n\n\n\n5.3.1 Computing note\nWhen a function like \\(\\sqrt[3]{x}\\) is written as \\(x^{1/3}\\) make sure to include the exponent in grouping parentheses: x^(1/3). Similarly, later in the book you will encounter power-law functions where the exponent is written as a formula. Particularly common will be power-law functions written \\(x^{n-1}\\) or \\(x^{n+1}\\). In translating this to computer notation, make sure to put the formula within grouping parentheses, for instance x^(n-1) or x^(n+1).\n\n\n5.3.2 Some power-law relationships\nYou have been using power-law functions from early in your math and science education. Some examples:1\n\n\nExamples of power-law relationships\n\n\n\n\n\n\n\n\n\n\n\nSetting\nFunction formula\nexponent\n\n\n\n\nCircumference of a circle\n\\(C(r) = 2 \\pi r\\)\n1\n\n\nArea of a circle\n\\(A(r) = \\pi r^2\\)\n2\n\n\nVolume of a sphere\n\\(V(r) = \\frac{4}{3} \\pi r^3\\)\n3\n\n\nDistance traveled by a falling object\n\\(d(t) = \\frac{1}{2} g t^2\\)\n2\n\n\nGas pressure versus volume\n\\(P(V) = \\frac{n R T}{V}\\)\n\\(-1\\)\n\n\n… perhaps less familiar …\n\n\n\n\nDistance traveled by a diffusing gas\n\\(X(t) = D \\sqrt{ \\strut t}\\)\n\\(1/2\\)\n\n\nAnimal lifespan (in the wild) versus body mass\n\\(L(M) = a M^{0.25}\\)\n0.25\n\n\nBlood flow versus body mass\n\\(F(M) = b M^{0.75}\\)\n0.75\n\n\n\n\n\n\nOne reason why power-law functions are so important in science has to do with the logic of physical quantities such as length, mass, time, area, volume, force, power, and so on. We’ll discuss this at length later in the course and the principles will appear throughout calculus."
  },
  {
    "objectID": "Preliminaries/05-pattern-book-functions.html#domains-of-pattern-book-functions",
    "href": "Preliminaries/05-pattern-book-functions.html#domains-of-pattern-book-functions",
    "title": "5  Pattern-book functions",
    "section": "5.4 Domains of pattern-book functions",
    "text": "5.4 Domains of pattern-book functions\nEach of our basic modeling functions, with two exceptions, has a domain that is the entire number line \\(-\\infty < x < \\infty\\). No matter how big or small is the value of the input, the function has an output. Such functions are particularly nice since we never have to worry about the input going out of bounds.\nThe two exceptions are:\n\nthe logarithm function, which is defined only for \\(0 < x\\).\nsome of the power-law functions: \\(x^p\\).\n\nWhen \\(p\\) is negative, the output of the function is undefined when \\(x=0\\). You can see why with a simple example: \\(g(x) \\equiv x^{-2}\\). Most students had it drilled into them that “division by zero is illegal,” and \\(g(0) = \\frac{1}{0} \\frac{1}{0}\\), a double law breaker.\nWhen \\(p\\) is not an integer, that is \\(p \\neq 1, 2, 3, \\cdots\\) the domain of the power-law function does not include negative inputs. To see why, consider the function \\(h(x) \\equiv x^{1/3}\\)."
  },
  {
    "objectID": "Preliminaries/05-pattern-book-functions.html#symbolic-manipulations",
    "href": "Preliminaries/05-pattern-book-functions.html#symbolic-manipulations",
    "title": "5  Pattern-book functions",
    "section": "5.5 Symbolic manipulations",
    "text": "5.5 Symbolic manipulations\nSeveral of the pattern book functions appear so often in MOSAIC Calculus that it’s worth reviewing how to manipulate them symbolically. As an example, consider the function \\[g(x) \\equiv e^x e^x\\ .\\] This is a perfectly good way of defining \\(g()\\), but it’s helpful to be able to recognize that the following definitions are exactly equivalent \\[f(x) \\equiv e^{x+x}\\\\\nh(x) \\equiv e^{2 x}\\ .\\] The symbolic manipulation we touch on in this chapter involves being able to recall and apply such equivalences. We’ll need only a small set of them, all or most of which are found in a high-school algebra course.\n\nHow come some function names, like \\(\\sin()\\) are written with other parentheses, while others such as \\(e^x\\) have the input name shown?\nThe \\(x\\) in the name \\(e^x\\) is a placeholder. A better, if longer, name would be \\(\\exp()\\), which would signal that we mean the abstract concept of the exponential function, and not that function applied to an input named \\(x\\).\nThe same is true for functions like \\(x\\) or \\(1/t\\) or \\(z^2\\). If absolute consistency of notation were the prime goal, we could have written this book in a style that gives a name to every pattern-book function in the name/parentheses style. Something like this:\n\nreciprocal <- makeFun(1/t ~ t)\none <- makeFun(1 ~ z)\nsquare <- makeFun(x^2 ~ x)\n\nThese would be used in the ordinary way, for instance:\n\nreciprocal(7)\n## [1] 0.1428571\none(123.67)\n## [1] 1\nsquare(19)\n## [1] 361\n\nWriting reciprocal(\\(x\\)) instead of \\(1/x\\) is long-winded, which is perhaps why you never see it. But when you see \\(1/x\\) you should think of it as a function being applied to \\(x\\) and not as a bit of arithmetic.\nBy the way … I used different names for the inputs in these three functions just to remind the reader that, for functions with one input, the name has no significance. You just have to make sure to use the same name on the left- and right-hand sides of the tilde expression.\n\n\nWe’ll be working with exponential and power-law functions in this chapter. It is essential that you recognize that these are utterly different functions.\nAn exponential function, for instance, \\(e^x\\) or \\(2^x\\) or \\(10^x\\) has a constant quantity raised to a power set by the input to the function.\nA power-law function works the reverse way: the input is raised to a constant quantity, as in \\(x^2\\) or \\(x^10\\).\nA mnemonic phrase for exponentials functions is\n\nExponential functions have \\(x\\) in the exponent.\n\nOf course, the exponential function can have inputs with names other than \\(x\\), for instance, \\(f(y) \\equiv 2^y\\), but the name “x” makes for a nice alliteration in the mnemonic.\n\n\n5.5.1 Exponential and logarithm\nWe will Basic symbolic patterns for exponentials are (i) and (ii)\n\n\n\\(\\LARGE\\mathbf{(i)}\\ \\ \\ \\ \\ e^x e^y \\leftrightarrow e^{x+y}\\)\n\\(\\LARGE\\mathbf{(ii)}\\ \\ \\ \\ \\ \\left(e^x\\right)^y \\leftrightarrow e^{x y}\\)\nExponentials with a base other than \\(e\\) can be converted to base \\(e\\).\n\n\n\\(\\LARGE\\mathbf{(iii)}\\ \\ \\ \\ \\ 2^x \\leftrightarrow e^{\\ln(2) x} = e^{0.69315 x}\\)\n\\(\\LARGE\\mathbf{(iv)}\\  \\ \\  \\ 10^x \\leftrightarrow e^{\\ln(10) x} = e^{2.30259 x}\\)$\nFor mental arithmetic, easier use base 2 or 10. The base \\(e = 2.718282\\) is not conducive to such calculations. In Block 2 we’ll discuss why it’s standard to write an exponential function as \\(e^x\\).\nThe logarithms, which we’ll return to in Chapter 15 are the inverse function of the exponential: Rule (v).\n\n\n\\(\\LARGE\\mathbf{(v).a}\\ \\ \\ \\ \\ \\ln(\\exp(x)) = x\\)\n\\(\\LARGE\\mathbf{(v).b}\\ \\ \\ \\ \\ \\exp(\\ln(x)) = x\\)\nOne place that we will encounter rules (ii) and (v) is in Chapter 8 when we look a “doubling times” and “half lives.” There we will deal with expressions such as \\(2^{x/\\tau} = e^{\\ln(2) x/\\tau}\\).\nImportant symbolic patterns for logarithms are Rules (vi) through (vii).\n\n\n\\(\\LARGE\\mathbf{(vi)}\\ \\ \\ \\ \\ \\ln(x\\ \\ \\!y) \\leftrightarrow \\ln(x) + \\ln(y)\\)\n\\(\\mathbf{(vii)}\\ \\ \\ \\ \\! \\ln(x / y) \\leftrightarrow \\ln(x) - \\ln(y)\\)\n\\(\\LARGE\\mathbf{(viii)}\\ \\ \\ \\ \\ \\ln(x^p) \\leftrightarrow p \\ln(x)\\)$\n\nNotice that the symbolic patterns for logarithms involve multiplication, division, and exponentiation, but not addition: \\(\\ln(x + y) \\neq \\ln(x) + \\ln(y)\\).\n\n\n\n5.5.2 Power-law functions\nIn power-law functions, the quantity in the exponent is constant: we’ll call it \\(m\\), \\(n\\), or \\(p\\) in the following examples.\n\n\n\\(\\LARGE\\mathbf{(ix)}\\ \\ \\ \\ x^m x^n \\leftrightarrow x^{m+n}\\)\n\\(\\LARGE\\mathbf{(x)}\\ \\ \\ \\ \\ \\ \\frac{x^m}{x^n} \\leftrightarrow x^{m-n}\\)\n\\(\\Huge\\mathbf{(xi)}\\ \\ \\ \\ \\ \\left(x^n\\right)^p \\leftrightarrow x^{n\\,p}\\)\n\\(\\LARGE\\mathbf{(xii)}\\ \\ \\ \\ \\ \\ x^{-n} \\leftrightarrow \\frac{1}{x^n}\\)\n\\(\\LARGE\\mathbf{(xiii)}\\ \\ \\ \\ \\ \\ \\ x^0 \\leftrightarrow 1\\)\n\n\n5.5.3 Sinusoids\n\\(\\sin(x)\\) is periodic with period \\(2\\pi\\). Zero-crossings of \\(\\sin(x)\\) are at \\(x=..., -2\\pi, -\\pi, 0, \\pi, 2\\pi, ...\\)\nAs we mentioned earlier, we will be calling both the \\(\\sin()\\) and \\(\\cos()\\) function “sinusoids.” They are merely shifted versions of one another: \\[\\cos(x) = \\sin\\left(x + \\frac{\\pi}{2}\\right)\\ .\\]\n\n\n5.5.4 The straight-line function\nYou are probably used to a function that we call the “straight-line function” \\[\\line(x) \\equiv m x + b\\ .\\] The name comes from the shape of a graph of \\(\\line(x)\\) versus \\(x\\), which is a straight line. You are likely used to calling the parameter \\(m\\) the “slope” of the line, and the parameter \\(b\\) the “intercept.” (In general, by “intercept” we will mean the value of the function output when the input is zero. In high-school, this is often called the “y-intercept.”)\nThere are two simple symbolic manipulations that you will be using often in MOSAIC Calculus:\n\nFind the input \\(x=x_0\\) for which the output \\(\\line(x=x_0) = 0\\). This input has many names in mathematics: the “root,” the “\\(x\\)-intercept,” the “zero crossing,” etc. We will call any input value that corresponds to an output of zero to be “a zero of the function.”\n\nFor the straight-line function, the zero is readily found symbolically: \\[x_0 = - b/m\\ .\\]\n\nRe-write the straight-line function in the form \\[\\line(x) = a \\left(x - x_0\\right)\\ .\\]\n\nHere, the slope is designated with \\(a\\). And, of course, \\(x_0\\) is the zero of the function, as you can see by setting \\(x=x_0\\): \\(\\line(x=x_0) = a (x - x_0){\\LARGE\\left.\\right|}_{x = x_0} = 0\\ .\\)\n\nWhy is it called the “logarithm?”\nThe name “logarithm” is anything but descriptive. The name was coined by the inventor, John Napier (1550-1617), to emphasize the original purpose of his invention: to simplify the work of multiplication and exponentiation. The name comes from the Greek words logos, meaning “reasoning” or “reckoning,” and arithmos, meaning “number.” A catchy marketing term for the new invention, at least for those who speak Greek!\nAlthough invented for the practical work of numerical calculation, the logarithm function has become central to mathematical theory as well as modern disciplines such as thermodynamics and information theory. The logarithm is key to the measurement of information and magnitude. As you know, there are units of information used particularly to describe the information storage capacity of computers: bits, bytes, megabytes, gigabytes, and so on. Very much in the way that there are different units for length (cm, meter, kilometer, inch, mile, …), there are different units for information and magnitude. For almost everything that is measured, we speak of the “units” of measurement. For logarithms, instead of “units,” by tradition another word is used: the base of the logarithm. The most common units outside of theoretical mathematics are base-2 (“bit”) and base-10 (“decade”). But the unit that is most convenient in mathematical notation is “base e,” where \\(e = 2.71828182845905...\\). This is genuinely a good choice for the units of the logarithm, but that’s hardly obvious to anyone encountering it for the first time. To make the choice more palatable, it’s marketed as the “base of the natural logarithm.” In this book, we’ll be using this natural logarithm as our official pattern-book logarithm."
  },
  {
    "objectID": "Preliminaries/05-pattern-book-functions.html#exercises",
    "href": "Preliminaries/05-pattern-book-functions.html#exercises",
    "title": "5  Pattern-book functions",
    "section": "5.6 Exercises",
    "text": "5.6 Exercises"
  },
  {
    "objectID": "Preliminaries/06-describing-functions.html",
    "href": "Preliminaries/06-describing-functions.html",
    "title": "6  Describing functions",
    "section": "",
    "text": "Knowing and correctly using a handful of phrases about functions with a single input goes a long way in being able to communicate with other people . Often, the words make sense in everyday speech (“steep”, “growing”, “decaying”, “goes up”, “goes down”, “flat”).\nSometimes the words are used in everyday speech but the casual person isn’t sure exactly what they mean. For instance, you will often hear the phrase “growing exponentially.” The graph of the exponential function illustrates exactly this sort of growth: flat for small \\(x\\) and growing steadily steeper and steeper as \\(x\\) increases.\nStill other words are best understood by those who learn calculus. “Concave up,” “concave down”, “approaching 0 asymptotically,” “continuous”, “discontinuous”, “smooth”, “having a minimum at …,” “having a minimum of …”, “approaching \\(\\infty\\) asymptotically,” “having a vertical asymptote.”\nThe next short sections describe seven simple function-shape concepts: slope, concavity, continuity, monotonicity, periodicity, asymptotes, and local extrema. Each of these concepts has the idea of a function at the core, because each one depends on how the function output changes as the input is changed.\nI’ll illustrate these concepts using three pattern-book functions graphed in Figure 6.1."
  },
  {
    "objectID": "Preliminaries/06-describing-functions.html#slope",
    "href": "Preliminaries/06-describing-functions.html#slope",
    "title": "6  Describing functions",
    "section": "6.1 Slope",
    "text": "6.1 Slope\nThe slope describes whether the output goes up or down, and to what extent, as the input changes. Typically, the slope is different for different input values. The only function type that has a slope that is the same for all inputs is the straight-line function.\nFigure 6.2 graphs the sinusoid function (black curve). At numerous points in the domain, the function has been overlaid with a straight-line segment that has the same slope as does the function itself. For \\(x\\) near \\(-3\\) the slope is negative; for \\(x\\) near zero the slope is positive, then swings back to negative again for \\(x\\) near \\(3\\).\n\n\n\n\n\nFigure 6.2: Short straight-line segments laid over a graph of the sinusoid. The slope of each line segment is selected to match the local slope of the sinusoid.\n\n\n\n\nWhen we speak of the slope of the sinusoid, or any other function, we mean the local slope as a function of the input. The value of the function doesn’t enter into it, just the slope. Figure 6.3 shows only the slope of the sinusoid, without the sinusoid output at all. Each line segment has a horizontal “run” of \\(0.1\\), so you can measure the slope of each segment—rise over run—as the vertical extent \\(\\Delta y\\) of the segment divided by \\(0.1\\).\n\n\n\n\n\nFigure 6.3: Showing just the slope of the sinusoid as a function of input \\(x\\). Top: representing the slope by the steepness of line segments. Bottom: The numerical value of the slope of each segment.\n\n\n\n\nFor instance, the \\(\\Delta y\\) for the slope segment at \\(x=0\\) is 0.1, so the slope at \\(x=0\\) is \\(\\Delta y/0.1 = 1\\). At \\(x=1\\), \\(\\Delta y \\approx 0.05\\), so the slope is 0.5. The graph colors the segment according to the slope, so large negative slopes are blue, slopes near zero are green, and large positive slopes are yellow.\n\nA more general word than “slope” for describing functions is rate of change. It’s absolutely crucial to distinguish between the change in the output value of a function and the rate of change of that output.\nTo illustrate, suppose we have a function \\(f(x) \\equiv x^2 + 3\\). When we talk about “change” we imagine a situation where we have to different values of the function input, say \\(x_1 = 3\\) and \\(x_2 = 6\\).\nThe “change” in output for these two different inputs is \\(f(x_2) - f(x_1)\\), or in this case \\(39 - 12 = 27\\).\nIn contrast, the “rate of change” is the change in output divided by the change in input, that is:\n\\[\\frac{f(x_2) - f(x_1)}{x_2 - x_1} = \\frac{27}{3} = 9\\ .\\]\nA “rate” in mathematics is a ratio: one measure divided by another. For instance, a heart rate is measured as beats-per-minute. To measure it, count the number of pulse waves in a given interval of time. A typical medical practice is to count for 15 seconds, an interval long enough to get a reliable count but short enough not to unduly prolong the process. If 18 pulse waves were counted in the 15 seconds, the heart rate is 18 beats per 15 seconds, more usually reported as 72 beats-per-minute.\nIn a rate of change, the ratio is the change in output divided by the change of input."
  },
  {
    "objectID": "Preliminaries/06-describing-functions.html#concavity",
    "href": "Preliminaries/06-describing-functions.html#concavity",
    "title": "6  Describing functions",
    "section": "6.2 Concavity",
    "text": "6.2 Concavity\nThe slope of a function at a given input tells how fast the function output is increasing or decreasing as the input changes slightly. Concavity is not directly about how the function output changes, but about how the function’s slope changes. For instance, a function might be growing slowly in some region of the domain and then gradually shift to larger growth in an adjacent region. Or, a function might be decaying steeply and then gradually shift to a slower decay. Both of these are instances of positive concavity. The opposite pattern of change in slope is called negative concavity. If the slope doesn’t change at all—only straight-line functions are this way— the concavity is zero.\nConcavity has a very clear appearance in a function graph. If a function is positive concave in a region, the graph looks like a smile or cup. Negative concavity looks like a frown. Zero concavity is a straight line.\nReferring to the three function examples in Figure 6.1, we’ll use the traditional terms concave up and concave down to refer to positive and negative concavity respectively.\n\nThe exponential is concave up everywhere in its domain.\nThe sinusoid alternates back and forth between concave up and concave down.\nThis particular power law \\(x^{-1}\\) is concave up for \\(0 < x\\) and concave down for \\(x < 0\\).\n\nWhen a function switches between positive concavity and negative concavity, as does the sinusoid as well as the gaussian and sigmoid functions, there is an input value where the switch occurs and the function has zero concavity. (Continuous functions that pass from negative to positive or vice versa must always cross zero.) Such in-between points of zero concavity are called inflection points. A function can have zero, one, or many inflection points. For instance, the sinusoid has inflection points at \\(x = \\ldots, -\\pi, 0, \\pi, 2\\pi, \\ldots\\), the cubic power function \\(f(x)\\equiv x^3\\) has one, and the exponential has none.\n\n\n\n\n\nA cubic function which is concave up until a point of inflection and concave down thereafter. [Source: Maj. Austin Davis]\n\n\n\n\n“Inflection point” appears in news stories, so it is important to know what it means in context. The mathematical definition is about the change in the direction of curvature of a graph. In business, however, it generally means something less esoteric, “a time of significant change in a situation” or “a turning point.”1 The business sense effectively means that the function—say profits as a function of time, or unemployment as a function of time—has a non-zero concavity, up or down. It’s about the existence of concavity rather than about the change in the sign of concavity.\nOne of the benefits of learning calculus is to gain a way to think about the previous paragraph that’s systematic, so it’s always easy to know whether you are talking about the slope of a function or the change in slope of a function."
  },
  {
    "objectID": "Preliminaries/06-describing-functions.html#sec-continuity-intro",
    "href": "Preliminaries/06-describing-functions.html#sec-continuity-intro",
    "title": "6  Describing functions",
    "section": "6.3 Continuity",
    "text": "6.3 Continuity\nA function is continuous if you can trace out the graph of the function without lifting pencil from the page. A function is continuous on an interval (a,b) if you can trace the function over that whole interval. All of the pattern-book functions are continuous over any interval in their domain except for power-law functions with negative exponents. (This includes the reciprocal since it is a power-law with a negative exponent: \\(1/x = x^{-1}\\).) Those exceptions are not defined at \\(x=0\\).\nTo illustrate, consider the power-law function graphed in Figure 6.1. On any interval (a,b) that does not include 0, the function is continuous. For inputs \\(x < 0\\), the function is negative. For inputs \\(0 < x\\), the function is positive. So, on an interval that includes \\(x=0\\) the function jumps discontinuously from negative to positive."
  },
  {
    "objectID": "Preliminaries/06-describing-functions.html#sec-monotonicity",
    "href": "Preliminaries/06-describing-functions.html#sec-monotonicity",
    "title": "6  Describing functions",
    "section": "6.4 Monotonicity",
    "text": "6.4 Monotonicity\nA function is monotonic on a domain when the sign of the slope never changes on that domain. Monotonic functions either steadily increase in value or, alternatively, steadily decrease in value.\nAnother way of thinking about monotonicity is to consider the order of inputs and outputs compared to a number line. If a function is monotonically increasing then it will preserve the order of inputs along the number line when it maps inputs to outputs, whereas a monotonically decreasing function will reverse the order. For instance, if the input \\(x\\) comes before an input \\(y\\) (i.e., \\(x<y\\)), then \\(f(x)<f(y)\\) for monotonically increasing functions (the order is preserved), but \\(f(y)<f(x)\\) for monotonically decreasing functions (the order of outputs is reversed).\nOf the pattern-book functions in Figure 6.1: both the exponential and the logarithm function are monotonic: the exponential grows monotonically as does the logarithm. The sinusoid is not monotonic over any domain longer than half a cycle: the function switchs between positive slope and negative slope in different parts of the cycle."
  },
  {
    "objectID": "Preliminaries/06-describing-functions.html#periodicity",
    "href": "Preliminaries/06-describing-functions.html#periodicity",
    "title": "6  Describing functions",
    "section": "6.5 Periodicity",
    "text": "6.5 Periodicity\nA phenomenon is periodic if it repeats a pattern over and over again. The pattern that is repeated is called a cycle; the periodic function as a whole is one cycle placed next to the previous one and so forth. The day-night cycle is an example of a periodic phenomenon, as is the march of the seasons. The period is the duration of one complete cycle; the period of the day-night cycle is 24 hours, the period of the seasonal progression is 1 year.\nReal-world periodic phenomena often show some slight variation from one cycle to the next. Of the pattern-book functions, only the sinusoid is periodic. And it is exactly periodic, repeating the same cycle over and over again. The period—that is, the length of an input interval that contains exactly one cycle—has a value of \\(2\\pi\\) for the pattern-book sinusoid. When used to model a periodic phenomenon, the model function needs to be tailored to match the period of the phenomena.\nThe idea of representing with sinusoids phenomena that are almost but not exactly periodic, for instance a communications signal or a vibration, is fundamental to many areas of physics and engineering."
  },
  {
    "objectID": "Preliminaries/06-describing-functions.html#asymptotic-behavior",
    "href": "Preliminaries/06-describing-functions.html#asymptotic-behavior",
    "title": "6  Describing functions",
    "section": "6.6 Asymptotic behavior",
    "text": "6.6 Asymptotic behavior\nAsymptotic refers to two possible situations depending on whether the input or output is being considered:\n\nWhen the input to a function gets bigger and bigger in size, going to \\(\\infty\\) or \\(-\\infty\\). If, as the input changes in this way the output gets closer and closer to a specific value, the function is said to have a horizontal asymptote of that value.\n\nAn example in Figure 6.1 is the exponential function. As \\(x \\rightarrow -\\infty\\), that is, as \\(x\\) goes more and more to the left of the domain, the output tends asymptotically to zero.\n\nWhen the output of a function gets bigger and bigger in size, going to \\(\\infty\\) or \\(-\\infty\\) without the input doing likewise. The visual appearance on a graph is like a sky-rocket: the output changes tremendously fast even though the input changes only a little. The vertical line that the skyrocket approaches is called a vertical asymptote. The power-law function \\(x^{-1}\\) has a vertical asymptote at \\(x=0\\). If you were to consider inputs closer and closer to \\(x=0\\), the outputs would grow larger and larger is magnitude, tending toward \\(\\infty\\) or \\(-\\infty\\).\n\nSeveral of the pattern-book functions have horizontal or vertical asymptotes or both. For instance, the function \\(x^{-1}\\) has a horizontal asymptote of zero for both \\(x \\rightarrow \\infty\\) and \\(x \\rightarrow -\\infty\\).\nThe sinusoid has neither a vertical nor a horizontal asymptote. As input \\(x\\) increases either to \\(-\\infty\\) or \\(\\infty\\), the output of the sinusoid continues to oscillate, never settling down to a single value. And, of course, the output of the sinusoid is everywhere \\(-1 \\leq \\sin(x) \\leq 1\\), so there is no possibility for a vertical asymptote."
  },
  {
    "objectID": "Preliminaries/06-describing-functions.html#sec-local-extremes",
    "href": "Preliminaries/06-describing-functions.html#sec-local-extremes",
    "title": "6  Describing functions",
    "section": "6.7 Locally extreme points",
    "text": "6.7 Locally extreme points\nMany continous functions have a region of the input domain where the output is gradually growing, then reaches a peak, then gradually diminishes. This peak is called a local maximum. “Maximum” because the output reaches a peak at a particular input, “local” because in the neighborhood of the peak the function output is smaller than at the peak.\n\n\n\nLikewise, functions can have a local minimum: the bottom of a bowl rather than the top of a peak.\nOf the three pattern-book functions in Figure 6.1, only the sinusoid has a local maximum, and, being periodic, it repeats that every cycle. The sinusoid similarly has a local minimum in every cycle..\nMany modeling applications involve finding an input where the function output is maximized. Such an input is called an argmax. “Argument” is a synonym for “input” in mathematical and computer functions, so “argmax” refers to the input at which the function reaches a maximum output. For instance, businesses attempt to set prices to maximize profit. At too low a price, sales are good but income is low. At too high a price, sales are too low to bring in much income. There’s a sweet spot in the middle.\nOther modeling applications involve finding an argmin, the input for which the output is minimized. For instance, aircraft have a speed at which fuel consumption is at a minimum for the distance travelled. All other things being equal, it’s best to operate at this speed.\nThe process of finding an argmin or an argmax is called optimization. And since maxima and minima are very much the same mathematically, collectively they are called extrema.\nAny function that has an extremum cannot possibly be monotonic, since the growth is positive on one side of the extremum and negative on the other side."
  },
  {
    "objectID": "Preliminaries/06-describing-functions.html#exercises",
    "href": "Preliminaries/06-describing-functions.html#exercises",
    "title": "6  Describing functions",
    "section": "6.8 Exercises",
    "text": "6.8 Exercises"
  },
  {
    "objectID": "Preliminaries/07-data-and-data-graphics.html",
    "href": "Preliminaries/07-data-and-data-graphics.html",
    "title": "7  Data and data graphics",
    "section": "",
    "text": "The decade of the 1660s was hugely significant in the emergence of science, although no one realized it at the time. 1665 was a plague year, the last major outbreak of bubonic plague in England. The University of Cambridge closed to wait out the plague, and Isaac Newton, then a 24-year old Cambridge student returned home to Woolsthorpe where he lived and worked in isolation for two years. Biographer James Gleich wrote: “The plague year was his transfiguration. Solitary and almost incommunicado, he became the world’s paramount mathematician.” During his years of isolation, Newton developed what we now call “calculus” and, associated with that, his theory of Universal Gravitation. He wrote a tract on his work in 1669, but withheld it from publication until 1711.\nPlague was also the motivating factor in another important work, published in 1661, Natural and Political Observations … Made upon the Bills of Mortality by John Graunt (1620-1674). Bills of mortality, listings of the number and causes of deaths in London, had been published intermittently starting in in the plague year of 1532, and then continuously from the onset of plague in 1603. Graunt, a haberdasher by profession, performed what we might now call data science, the extraction of information from data. For instance, Graunt was the first to observe the high rate of child mortality and that the number of deaths attributed to plague was underestimated by about one quarter. Graunt’s work led to his election to the Royal Society, the same august group of scientists of which Isaac Newton was a member (and later president). Graunt is considered the first demographer and epidemiologist.\nGraunt’s publication marks the start of statistics. He built upon a century of work by the city of London, collecting and tabulating data on a quarter of a million deaths. Indeed the word “statistics” stems from “state,” the only entity large enough to collect data on populations and the economy.\nWhereas advances in calculus over the next two centuries could be accomplished by the creativity of individuals, statistics could only develop based on the development of the infrastructure of government data collection, a process that took almost two centuries. But in the last 50 years, extensive data collection has entered non-state domains, such as genetic sequencing, remote sensing of Earth, commercial records, and the vast data warehouses of the social media giants, among others.\nThe ability to draw conclusions from masses of data—shown originally by John Graunt—is now an essential skill throughout science, government, and commerce. As you will see, particularly in Block 5, many of those skills are mathematical, effectively a part of calculus.\nThis chapter introduces some pre-calculus basics of working with data which we’ll use extensively in later Blocks of MOSAIC Calculus."
  },
  {
    "objectID": "Preliminaries/07-data-and-data-graphics.html#data-frames",
    "href": "Preliminaries/07-data-and-data-graphics.html#data-frames",
    "title": "7  Data and data graphics",
    "section": "7.1 Data frames",
    "text": "7.1 Data frames\nMost people encounter data in the form of printed tables, such as the 1665 Bill of Mortality shown below. These tables were developed to be legible to humans and to be compact when printed.\n\n\n\n\n\n\nFigure 7.3: Tables of data from the 1665 Bill of Mortality for London.\n\n\n\nAlthough published more than 350 years ago, it’s still possible for a literate human to sort out what the table is saying. But the volume of data has exploded beyond any possibility of putting it in print. Instead, today’s data are stored and accessed electronically. But the process of accessing such data is very much rooted in the notation of “table,” albeit tables that follow a strict set of principles. We’ll call such tables data frames and it’s important for you to learn a few of the core principles of data organization.\nFirst, recognize that the data shown in Figure 7.3 consist of several different tables. The first table, just under the title, starts with\n\n\nThe first two lines of the main table from the Bill of Mortality\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\ \\)\nBuried\nPlague\n\\(\\ \\)\nBuried\nPlague\n\\(\\cdots\\)\n\n\n\n\nSt Albans Woodstreet\n100\n121\nSt Clemens Eastcheap\n18\n20\n\\(\\cdots\\)\n\n\nSt Alhallowes Barking\n514\n330\nSt Diones Back-church\n78\n27\n\\(\\cdots\\)\n\n\n\n\n\n\nThe modern form of this is not spread out across the width of the page. It has a single set of columns rather than sets repeated side by side as in ?tbl-top-lines.\n\n\n\nIn a modern format, all the parishes are listed in one column, so that each row of the table corresponds to a single parish.\n\n\n\n\n\n\nparish\nburied\nplague\n\n\n\n\nSt Albans Woodstreet\n100\n121\n\n\nSt Clemens Eastcheap\n18\n20\n\n\nSt Alhallowes Barking\n514\n330\n\n\nSt Diones Back-church\n78\n27\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\nEach column of the modern table is called a variable. So there is a variable “buried” that contains the number buried and another variable “plague” containing the number who died of plague.\nEach row of the table is called a case, but often simply row is used. For each table, all the cases are the same kind of thing, for instance, here, a parish.\nAnother table displayed on the sheet is entitled, “The diseases and casualities this year.” In this table, the case is a disease or other cause of death, which we’ve put under the name “condition.”\n\n\n\ncondition\ndeaths\nyear\n\n\n\n\nAbortive and Stilborne\n617\n1665\n\n\nAged\n1545\n1665\n\n\nAgue and Feaver\n5257\n1665\n\n\nAppoplex and Suddenly\n116\n1665\n\n\nBedrid\n10\n1665\n\n\n\nWe’ve added the variable “year” with an eye toward consolidating many years of the Bills into one table.\n\nA modern organization for the data being presented in the Bill of Mortality would go back to the raw records that were collected in the field, stacking them into just two tables: Deaths and Births. The Deaths table might look like ?tbl-deaths.\n\n\nAn imagined re-organization of the data that went into the Bill of Mortality report.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\ndate\nparish\nsex\nage\ncause\n\n\n\n\nPercivell Bullingham\n1665-06-01\nSt Mary le Bow\nM\n29\nplague\n\n\nOwin Swancott\n1665-08-13\nTrinitie\nM\n2\nplague\n\n\nWinifred Romford\n1665-11-09\nSt Swithings\nF\n19\nchildbed\n\n\nElsebeth Cook\n1665-06-29\nSt Ethelborough\nF\n5\nplague\n\n\nHumfray Langham\n1665-06-05\nSt Bennet Fynch\nM\n53\naged\n\n\nAgnes Kirkwood\n1665-11-22\nSt Mary Hill\nF\n21\nague\n\n\nKatherine Murton\n1665-12-01\nSt Alholowes Lesse\nF\n24\nchildbed\n\n\nBainbridge Fletcher\n1665-03-17\nSt Martins\nM\n2\nplague\n\n\nCicely Ouston\n1665-03-08\nSt Austins\nF\n35\nplague\n\n\n\n\n\n\nThe modern conception of data makes a clear distinction between data and the construction of summaries of that data for human consumption. Such summaries might be graphical, or in the form model functions, or even in the form of a set of tables, such as seen in the Bill of Mortality. Learning how to generate such summaries is an essential task in statistics and data science. The automatic construction of model functions (without much human intervention) is a field called machine learning\nIn the Deaths table, which would have 97,306 rows for 1665, the each case is “a person who died.” Such a table could nowadays be re-tabulated into the “diseases and casualities” table, or the breakdown of burials by sex, or the parish-by-parish breakdown. But there are many other possibilities: looking at cause of death by age and season of year, or broken down by sex, etc."
  },
  {
    "objectID": "Preliminaries/07-data-and-data-graphics.html#accessing-data-tables",
    "href": "Preliminaries/07-data-and-data-graphics.html#accessing-data-tables",
    "title": "7  Data and data graphics",
    "section": "7.2 Accessing data tables",
    "text": "7.2 Accessing data tables\nIn a data science course you will learn several ways of storing and accessing tables of data. One of the most important in professional use is a relational database. (“Relation” is another word for “table,” just as functions are about the relationship between inputs and output.)\nData wrangling is a term used to describe working with and summarizing data. This includes merging multiple data frames. In MOSAIC Calculus our uses of data will be focused on constructing functions that show the patterns in data and plotting data to reveal those patterns to the eye.\nFor our work, you can access the data frames we need directly in R by name. For instance, the Engines data frame (?tbl-engine-table) records the characteristics of several internal combustion engines of various sizes:\n\n\nVarious attributes of internal combustion engines, from the very small to the very large.\n\n\n\n\n\n\nEngine\nmass\nBHP\nRPM\nbore\nstroke\n\n\n\n\nWebra Speed 20\n0.25\n0.78\n22000\n16.5\n16\n\n\nEnya 60-4C\n0.61\n0.84\n11800\n24.0\n22\n\n\nHonda 450\n34.00\n43.00\n8500\n70.0\n58\n\n\nJacobs R-775\n229.00\n225.00\n2000\n133.0\n127\n\n\nDaimler-Benz 609\n1400.00\n2450.00\n2800\n165.0\n180\n\n\nDaimler-Benz 613\n1960.00\n3120.00\n2700\n162.0\n180\n\n\nNordberg\n5260.00\n3000.00\n400\n356.0\n407\n\n\nCooper-Bessemer V-250\n13500.00\n7250.00\n330\n457.0\n508"
  },
  {
    "objectID": "Preliminaries/07-data-and-data-graphics.html#variable-names",
    "href": "Preliminaries/07-data-and-data-graphics.html#variable-names",
    "title": "7  Data and data graphics",
    "section": "7.3 Variable names",
    "text": "7.3 Variable names\nThe fundamental questions to ask first about any data frame are:\n\nWhat constitutes a row?\nWhat are the variables and what do they stand for?\n\nThe answers to these questions, for the data frames we will be using, are available via R documentation. To bring up the documentation for Engines, for instance, give the command:\n?Engines\nWhen working with data, it’s common to forget for a moment what are the variables, how they are spelled, and what sort of values each variable takes on. Two useful commands for reminding yourself are (illustrated here with Engines):\n\nnames(Engines) # the names of the variables\n## [1] \"Engine\"       \"mass\"         \"ncylinder\"    \"strokes\"      \"displacement\"\n## [6] \"bore\"         \"stroke\"       \"BHP\"          \"RPM\"\nhead(Engines) # the first several rows\n## # A tibble: 6 × 9\n##   Engine            mass ncylinder strokes displacement  bore stroke   BHP   RPM\n##   <chr>            <dbl>     <dbl>   <dbl>        <dbl> <dbl>  <dbl> <dbl> <dbl>\n## 1 Webra Speedy     0.135         1       2          1.8  13.5   12.5  0.45 22000\n## 2 Motori Cipolla   0.15          1       2          2.5  15     14    1    26000\n## 3 Webra Speed 20   0.25          1       2          3.4  16.5   16    0.78 22000\n## 4 Webra 40         0.27          1       2          6.5  21     19    0.96 15500\n## 5 Webra 61 Blackh… 0.43          1       2         10    24     22    1.55 14000\n## 6 Webra 6WR        0.49          1       2         10    24     22    2.76 19000\nnrow(Engines) # how many rows\n## [1] 39\n\nIn RStudio, the command View(Engines) is useful for showing a complete table of data."
  },
  {
    "objectID": "Preliminaries/07-data-and-data-graphics.html#plotting-data",
    "href": "Preliminaries/07-data-and-data-graphics.html#plotting-data",
    "title": "7  Data and data graphics",
    "section": "7.4 Plotting data",
    "text": "7.4 Plotting data\nWe will use just one graphical format for displaying data: the point plot. In a point plot, also known as a “scatterplot,” two variables are displayed, one on each graphical axis. Each case is presented as a dot, whose horizontal and vertical coordinates are the values of the variables for that case. For instance:\n\n\n\n\n\nFigure 7.4: A point plot showing the relationship between engine stroke and bore. Each individual point is one row of the data frame SHOWN IN GIVE TABLE A NAME\n\n\n\n\nThe data plotted here show a relationship between the stroke length of a piston and the diameter of the cylinder in which the piston moves. This relationships, however, is not being presented in the form of a function, that is, a single stroke value for each value of the bore diameter.\nFor many modeling purposes, it’s important to be able to represent a relationship as a function. At one level, this is straightforward: draw a smooth curve through the data and use that curve for the function.\nLater in MOSAIC Calculus, we’ll discuss ways to construct functions that are a good match to data using the pattern-book functions. Here, our concern is graphing such functions on top of a point plot. So, without explanation (until later chapters), we’ll construct a power-law function, called, stroke(bore), that might be a good match to the data. The we’ll add a second layer to the point-plot graphic: a slice-plot of the function we’ve constructed.\n\nstroke <- fitModel(stroke ~ A*bore^b, data = Engines)\ngf_point(stroke ~ bore, data = Engines) %>%\n  slice_plot(stroke(bore) ~ bore, color=\"blue\")\n\n\n\n\nFigure 7.5: A graphic composed of two layers: 1) a point plot; 2) a slice plot of a function fitted to the data in (1).\n\n\n\n\nThe second layer is made with an ordinary slice_plot() command. To place it on top of the point plot we connect the two commands with a bit of punctuation called a “pipe”: %>%.\nThe pipe punctuation can never go at the start of a line. Usually, we’ll use the pipe at the very end of a line; think of the pipe as connecting one line to the next.\nslice_plot() is a bit clever when it is used after a previous graphics command. Usually, you need to specify the interval of the domain over which you want to display the function, as with\n\n\n\n\n\n\n\n\n\nYou can do that also when slice_plot() is the second layer in a graphics command. But slice_plot() can also infer the interval of the domain from previous layers."
  },
  {
    "objectID": "Preliminaries/07-data-and-data-graphics.html#functions-as-data",
    "href": "Preliminaries/07-data-and-data-graphics.html#functions-as-data",
    "title": "7  Data and data graphics",
    "section": "7.5 Functions as data",
    "text": "7.5 Functions as data\nIn the previous chapters, we’ve used formulas to define functions. The link between functions and formulas is important, but not at all essential to the idea of functions.\nArguably more important in practice to the representation of functions are tables and algorithms. The computations behind the calculation of the output of functions such as \\(\\sin()\\) or \\(e^x\\) or other foundational functions that we’ll introduce in [Chapter -Section 5) relies on computer software that loops and iterates and which is invisible to almost everybody who uses it. Before the advent of modern computing, functions were presented as printed tables. For instance, the logarithm function, invented about 1600, relied almost complete on printed tables, such as the one shown in Figure 7.6.\n\n\n\n\n\nFigure 7.6: Part of the first table of logarithms, published by Henry Briggs in 1624.\n\n\n\n\nIn Section 5 we introduced a small set of pattern-book functions. Each of the functions is indeed a pattern that could be written down once and for all in tabular form. Generating such tables originally required the work of human “computers” who undertook extensive and elaborate arithmetical calculations by hand. What’s considered the first programmable engine, a mechanical device designed by Charles Babbage (1791-1871) and programmed by Ada Lovelace (1815-1852), was conceived for the specific purpose of generating printed tables of functions.\nIt’s helpful to think of functions, generally, as a sort of data storage and retrieval device that uses the input value to locate the corresponding output and return that output to the user. Any device capable of this, such as a table or graph with a human interpreter, is a suitable way of implementing a function.\nTo reinforce this idea, we ask you to imagine a long corridor with a sequence of offices, each identified by a room number. The input to the function is the room number. To evaluate the function for that input, you knock on the appropriate door and, in response, you’ll receive a piece of paper with a number to take away with you. That number is the output of the function.\nThis will sound at first too simple to be true, but … In a mathematical function each office gives out the same number every time someone knocks on the door. Obviously, being a worker in such an office is highly tedious and requires no special skill. Every time someone knocks on the worker’s door, he or she writes down the same number on a piece of paper and hands it to the person knocking. What that person will do with the number is of absolutely no concern to the office worker.\nThe utility of such functions depends on the artistry and insight of the person who creates them: the modeler. An important point of this course is to teach you some of that artistry. Hopefully you will learn through that artistry to translate your insight to the creation of functions that are useful in your own work. But even if you just use functions created by others, knowing how functions are built will be helpful in using them properly.\nIn the sort of function just described, all the offices were along a single corridor. Such functions are said to have one input, or, equivalently, to be “functions of one variable.” To operate the function, you just need one number: the address of the office from which you’ll collect the output.\nMany functions have more than one input: two, three, four, … tens, hundreds, thousands, millions, …. In this course, we’ll work mainly with functions of two inputs, but the skills you develop will be applicable to functions of more than two inputs.\nWhat does a function of two inputs look like in our office analogy? Imagine that the office building has many parallel corridors, each with a numeric ID. To evaluate the function, you need two numeric inputs: the number of the corridor and the number of the door along that corridor. With those two numbers in hand, you locate the appropriate door, knock on it and receive the output number in return.\nThree inputs? Think of a building with many floors, each floor having many parallel corridors, each corridor having many offices in sequence. Now you need three numbers to identify a particular office: floor, corridor, and door.\nFour inputs? A street with many three-input functions along it. Five inputs? A city with many parallel four-input streets. And on and on.\nApplying inputs to a function in order to receive an output is only a small part of most calculations. Calculations are usually organized as algorithms, which is just to say that algorithms are descriptions of a calculation. The calculation itself is … a function!\nHow does the calculation work? Think of it as a business. People come to your business with one or more inputs. You take the inputs and, following a carefully designed protocol, hand them out to your staff, perhaps duplicating some or doing some simple arithmetic with them to create a new number. Thus equipped with the relevant numbers, each member of staff goes off to evaluate a particular function with those numbers. (That is, the staff member goes to the appropriate street, building, floor, corridor, and door, returning with the number provided at that office.) The staff re-assembles at your roadside stand, you do some sorting out of the numbers they have returned with, again following a strict protocol. Perhaps you combine the new numbers with the ones you were originally given as inputs. In any event, you send your staff out with their new instructions—each person’s instructions consist simply of a set of inputs which they head out to evaluate and return to you. At some point, perhaps after many such cycles, perhaps after just one, you are able to combine the numbers that you’ve assembled into a single result: a number that you return to the person who came to your business in the first place.\nA calculation might involve just one function evaluation, or involve a chain of them that sends workers buzzing around the city and visiting other businesses that in turn activate their own staff who add to the urban tumult.\n\nThe reader familiar with floors and corridors and office doors may note that the addresses are discrete. That is, office 321 has offices 320 and 322 as neighbors. Calculus is about functions with a continuous domain. But it’s easy to create a continuous function out of a discrete table by adding on a small, standard calculation.\nIt works like this: for an input of, say, 321.487… the messenger goes to both office 321 and 322 and collects their respective outputs. Let’s imagine that they are -14.3 and 12.5 respectively. All that’s needed is a small calculation, which in this case will look like \\[-14.3 \\times (1 - 0.487...)   + 12.5 \\times 0.487...\\] This is called linear interpolation and lets us construct continuous functions out of discrete data. There are other types of interpolation have have desirable properties, like “smoothness,” which we’ll learn about later.\nIt’s very common in science to work with continuous domains by breaking them up into discrete pieces. As you’ll see, an important strategy in calculus to to make such discrete pieces very close together, so that they resemble a continuum.\n\nA table like REFERENCE TO THE TABLE PREVIOUS describes the general relationships between engine attributes. For instance, we might want to understand the relationship (if any) between RPM and engine mass, or relate the diameter (that is, “bore”) and depth (that is, “stroke”) of the cylinders to the power generated by the engine. Any single entry in the table doesn’t tell us about such general relationships; we need to consider the rows and columns as a whole.\nIf you examined the relationship between engine power (BHP) and bore, stroke, and RPM, you will find that (as a rule) the larger the bore and stroke, the more powerful the engine. That’s a qualitative description of the relationship. Most educated people are able to understand such a qualitative description. Even if they don’t know exactly what “power” means, they have some rough conception of it.\nOften, we’re interested in having a quantitative description of a relationship such as the one (bore, stroke) \\(\\rightarrow\\) power. Remarkably, many otherwise well-educated people are uncomfortable with the idea of using quantitative descriptions of a relationship: what sort of language the description should be written with; how to perform the calculations to use the description; how to translate between data (such as in the table) and a quantitative description; how to translate the quantitative description to address a particular question or make a decision.\n\nIn today’s world, software is the means by which expert knowledge and capability is communicated and applied. Before modern computers were available, the expertise was committed to print in the form of tables. Figure 7.7 shows part of the table from an 1899 A Short Table of Integrals.1 Incredibly, such tables were a standard feature of statistics textbooks up through 2010.\n\n\n\n\n\nFigure 7.7: Before the computer software era, some functions could only be presented using printed tables. This table supports calculations with a gaussian-like function for inputs from 0 to 1.\n\n\n\n\nIn addition to software being more compact and easier to use than printed tables, the interface to numerical integrals can be presented in the same format as any other mathematical function. That’s enabled us to include \\(\\pnorm()\\) among the pattern book functions."
  },
  {
    "objectID": "Preliminaries/07-data-and-data-graphics.html#exercises",
    "href": "Preliminaries/07-data-and-data-graphics.html#exercises",
    "title": "7  Data and data graphics",
    "section": "7.6 Exercises",
    "text": "7.6 Exercises\n\n<!– Drill\n\n\nDrill A In the book, what is meant by the word “variable”?\n\nIt’s the same as output.\nIt’s the same as input.\nA column in a data frame."
  },
  {
    "objectID": "modeling-part.html",
    "href": "modeling-part.html",
    "title": "Modeling",
    "section": "",
    "text": "This is where I’ll explain what the block is about and the overall goals."
  },
  {
    "objectID": "Modeling/01-parameters.html",
    "href": "Modeling/01-parameters.html",
    "title": "8  Parameters",
    "section": "",
    "text": "The variety of shapes of the nine pattern-book functions means that, often, one or another will be suitable for the modeling situation in hand. Marginal: Combining the functions to create a greater diversity of shapes is the subject of Chapter COMBINING\nEven if the shape of the function used is appropriate, the pattern still needs to be “adjusted” so that the units of output and input are well matched to the phenomenon being modeled. Let’s consider data from the outbreak of COVID-19 as an example. Figure 8.1 shows, day-by-day, the number of officially confirmed COVID-19 cases as the in the US in March 2020.\nDuring the outbreak, case numbers increased with time. As time went on, the rate of case-number increase itself grew faster and faster. This is the same pattern provided by the exponential function.\nAlongside the case-number data Figure 8.1 shows the function \\(\\text{cases}(t) \\equiv e^t\\) plotted as a \\(\\color{magenta}{\\text{magenta}}\\) curve.\nThere’s an obvious mismatch between the data and the function \\(e^t\\). Does this mean the COVID pattern is not exponential?\nThis chapter will introduce the way that modelers stretch and shift the individual patter-book functions so that they can be used in models of real-world situations such as the outbreak of COVID-19."
  },
  {
    "objectID": "Modeling/01-parameters.html#matching-numbers-to-quantities",
    "href": "Modeling/01-parameters.html#matching-numbers-to-quantities",
    "title": "8  Parameters",
    "section": "8.1 Matching numbers to quantities",
    "text": "8.1 Matching numbers to quantities\nThe coordinate axes in (figure19?) represent quantities. On the horizontal axis is time, measured in days. The vertical axis is denominated in “10000 cases,” meaning that the numbers on the vertical scale should be multiplied by 10000 to get the number of cases.\nThe exponential function takes as input a pure number and produces an output that is also a pure number. This is true for all the pattern-book functions. Since the graph axes don’t show pure numbers, it’s no surprise then that the pattern-book exponential function doesn’t align with the COVID case data.\nRecall that pure numbers, like 17.32, do not have units. Quantities, on the other hand, usually do have units, as in 17.3 days or 34 meters.\nIf we want the input to the model function \\(\\text{cases}(t)\\) to be denominated in days, we’ll have to convert \\(t\\) to a pure pure number (e.g. 10, not “10 days”) before the quantity is handed off as the argument to \\(\\exp()\\). We do this by introducing a parameter.\nIn every case, these parameters are arranged to translate a with-units quantity into a pure number suitable as an input to the pattern-book function. Similarly, parameters will translate the pure-number output from the pattern-book function into a quantity with units.\nThe standard parameterization for the exponential function is \\(e^{kt}\\). The parameter \\(k\\) will be a quantity with units of “per-day.” Suppose we set \\(k=0.2\\) per day. Then \\(k\\, t{\\LARGE\\left.\\right|}_{t=10 days} = 2\\). This “2” is a pure number because the units on the 0.2 (“per day”) and on the 10 (days) cancel out: \\[0.2\\, \\text{day}^{-1} \\cdot 10\\, \\text{days} = 2\\ .\\] The use of a parameter like \\(k\\) does more than handle the formality of converting input quantities into pure numbers. Having a choice for \\(k\\) allows us to stretch or compress the function to align with the data. Figure 8.2 plots the modeling version of the exponential function to the COVID-case data:\n\n\n\n\n\nFigure 8.2: Using the function form \\(A e^{kt}\\), with parameters \\(k=0.19\\) per day and \\(A = 0.0573\\) cases (in 10000s), matches the COVID-case data well."
  },
  {
    "objectID": "Modeling/01-parameters.html#parallel-scales",
    "href": "Modeling/01-parameters.html#parallel-scales",
    "title": "8  Parameters",
    "section": "8.2 Parallel scales",
    "text": "8.2 Parallel scales\n\n\n\n\n\n\n\n\n\nAt the heart of how we’re going to use the pattern-book functions to model the relationship between quantities is the idea of conversion between one scale and another. Consider these everyday objects: a thermometer and a ruler.\n\n\n\n\n\n\n\n\n\nEach object presents a read-out of what’s being measured—temperature or length—on two different scales. At the same time, the objects provide a way to convert one scale to another.\nA function gives the output for any given input. We represent the input value as a position on a number line—which we call an “axis”—and the output as a position on another output line, almost always drawn perpendicular to one another. But the two number lines can just as well be parallel to one another. To evaluate the function, find the input value on the input scale and read off the corresponding output.\nWe can translate the correspondance between one scale and the other into the form of a straight-line function. For instance, if we know the temperature in Fahrenheit (\\(^\\circ\\)F) and want to convert it to Celsius (\\(^\\circ C\\)) we have the following function: \\[C(F) \\equiv {\\small\\frac{5}{9}}(F-32)\\ .\\] Similarly, converting inches to centimeters can be accomplished with \\[\\text{cm(inches)} \\equiv 2.54 \\, (\\text{inches}-0)\\ .\\] Both of these scale conversion functions have the form of the straight-line function, which can be written as \\[f(x) \\equiv a x + b\\ \\ \\ \\text{or, equivalently as}\\ \\ \\ \\ f(x) \\equiv a(x-x_0)\\ ,\\] where \\(a\\), \\(b\\), and \\(x_0\\) are parameters.\nIn Section 8.3, we’ll use the \\(ax + b\\) form of scale conversion, to scale the input to pattern-book functions, but we could equally well have used \\(a(x-x_0)\\).\nIn Section 8.4 we’ll introduce a second scale conversion function, for the output from pattern-book functions. That scaling will also be in the form of a straight-line function: \\(A x + B\\). The use of the lower-case parameter names (\\(a\\), \\(b\\)) versus the upper-case parameter names (\\(A\\), \\(B\\)) will help us distinguish the two different uses for scale conversion, namely input scaling versus output scaling."
  },
  {
    "objectID": "Modeling/01-parameters.html#sec-input-scaling",
    "href": "Modeling/01-parameters.html#sec-input-scaling",
    "title": "8  Parameters",
    "section": "8.3 Input scaling",
    "text": "8.3 Input scaling\nFigure 8.3 is based on the data frame RI-tide which is a minute-by-minute record of the tide level in Providence, Rhode Island (USA) for the period April 1 to 5, 2010. The level variable is measured in meters; the hour variable gives the time of the measurement in hours after midnight at the start of April 1.\n\n\n\n\n\nFigure 8.3: Tide levels oscillate up and down over time. This is analogous to the \\(\\sin(t)\\) pattern-book function.\n\n\n\n\nThe pattern-book \\(\\sin()\\) and the function \\(\\color{magenta}{\\text{level}}\\color{blue}{(hour)}\\) have similar shapes, so it seems reasonable to model the tide data as a sinusoid. However, the scale of the axes is different on the two graphs.\nTo model the tide with a sinusoid, we need to modify the sinusoid to change the scale of the input and output. First, let’s look at how to accomplish the input scaling. Specifically, we want the pure-number input \\(t\\) to the sinusoid be a function of the quantity \\(hour\\). Our framework for this re-scaling is the straight-line function. We will replace the pattern-book input \\(t\\) with a function \\[t(\\color{blue}{hour}) \\equiv a\\, \\color{blue}{hour} + b\\ .\\]\nThe challenge is to find values for the parameters \\(a\\) and \\(b\\) that will transform the \\(\\color{blue}{\\mathbf{\\text{blue}}}\\) horizontal axis into the black horizontal axis, like this:\n\n\n\n\n\n\n\n\n\nBy comparing the two axes, we can estimate that \\(\\color{blue}{10} \\rightarrow 4\\) and \\(\\color{blue}{100} \\rightarrow 49\\). With these two coordinate points, we can find the straight-line function that turns \\(\\color{blue}{\\mathbf{\\text{blue}}}\\) into black by plotting the coordinate pairs \\((\\color{blue}{0},1)\\) and \\((\\color{blue}{100}, 51)\\) and finding the straight-line function that connects the points.\n\n\n\n\n\nFigure 8.4: The input scaling function must transform 10 into 4 and transform 100 into 49 to properly arrange the time scale with the scale for the pattern-book function.\n\n\n\n\nYou can calculate for yourself that the function that relates \\(\\color{blue}{\\mathbf{\\text{blue}}}\\) to black is \\[t(\\color{blue}{time}) = \\underbrace{\\frac{1}{2}}_a \\color{blue}{time}  \\underbrace{-1\\LARGE\\strut}_b\\]\nReplacing the pure number \\(t\\) as the input to pattern-book \\(\\sin(t)\\) with the transformed \\(\\frac{1}{2} \\color{blue}{time}\\) we get a new function: \\[g(\\color{blue}{time}) \\equiv \\sin\\left(\\strut {\\small\\frac{1}{2}}\\color{blue}{time} - 1\\right)\\ .\\] Figure 11.6 plots \\(g()\\) along with the actual tide data.\n\n\n\n\n\nFigure 8.5: The sinusoid with input scaling (black) aligns nicely with the tide-level data."
  },
  {
    "objectID": "Modeling/01-parameters.html#sec-output-scaling",
    "href": "Modeling/01-parameters.html#sec-output-scaling",
    "title": "8  Parameters",
    "section": "8.4 Output scaling",
    "text": "8.4 Output scaling\nJust as the natural input needs to be scaled before it reaches the pattern-book function, so the output from the pattern-book function needs to be scaled before it presents a result suited for interpreting in the real world.\n\n\n\n\n\nFigure 8.6: Natural quantities must be scaled to pure numbers before being suited to the pattern-book functions. The output from the pattern-book function is a pure number which is scaled to the natural quantity of interest.\n\n\n\n\nThe overall result of input and output scaling is to tailor the pattern-book function so that it is ready to be used in the real world.\nLet’s return to Figure 11.6 which shows that the function \\(g(\\color{blue}{time})\\), which scales the input to the pattern-book sinusoid, has a much better alignment to the tide data. Still, the vertical axes of the two graphs in the figure are not the same.\nThis is the job for output scaling, which takes the output of \\(g(\\color{blue}{time})\\) (bottom graph) and scales it to match the \\(\\color{magenta}{level}\\) axis on the top graph. That is, we seek to align the black vertical scale with the \\(\\color{magenta}{\\mathbf{\\text{magenta}}}\\) vertical scale. To do this, we note that the range of the \\(g(\\color{blue}{time})\\) is -1 to 1, whereas the range of the tide-level is about 0.5 to 1.5. The output scaling will take the straight-line form \\[{\\color{magenta}{\\text{level}}}({\\color{blue}{time}}) = A\\, g({\\color{blue}{time}}) + B\\] or, in graphical terms\n\n\n\n\n\n\n\n\n\nWe can figure out parameters \\(A\\) and \\(B\\) by finding the straight-line function that connects the coordinate pairs \\((-1, \\color{magenta}{0.5})\\) and \\((1, \\color{magenta}{1.5})\\) as in Figure 8.7.\n\n\n\n\n\nFigure 8.7: Finding the straight-line function that converts \\(-1 \\rightarrow \\color{magenta}{0.5}\\) and converts \\(1 \\rightarrow \\color{magenta}{1.5}\\)\n\n\n\n\nYou can confirm for yourself that the function that does the job is \\[{\\color{magenta}{\\text{level}}} = 0.5 g({\\color{blue}{time}}) + 1\\ .\\]\nPutting everything together, that is, scaling both the input to pattern-book \\(\\sin()\\) and the output from pattern-book \\(\\sin()\\), we get\n\\[{\\color{magenta}{\\text{level}}}({\\color{blue}{time}}) = \\underbrace{0.5}_A \\sin\\left(\\underbrace{\\small\\frac{1}{2}}_a {\\color{blue}{time}}  \\underbrace{-1}_b\\right) + \\underbrace{1}_B\\]"
  },
  {
    "objectID": "Modeling/01-parameters.html#a-procedure-for-building-models",
    "href": "Modeling/01-parameters.html#a-procedure-for-building-models",
    "title": "8  Parameters",
    "section": "8.5 A procedure for building models",
    "text": "8.5 A procedure for building models\nWe’ve been using pattern-book functions as the intermediaries between input scaling and output scaling, using this format.\n\\[f(x) \\equiv A e^{ax + b} + B\\ .\\] We can use the other pattern-book functions—the gaussian, the sigmoid, the logarithm, the power-law functions—in the same way. That is, the basic framework for modeling is this:\n\\[\\text{model}(x) \\equiv A\\, {g_{pattern\\_book}}(ax + b) + B\\ ,\\] where \\(g_{pattern\\_book}()\\) is one of the pattern-book functions. To construct a basic model, you task has two parts:\n\nPick the specific pattern-book function whose shape resembles that of the relationship you are trying to model. For instance, we picked \\(e^x\\) for modeling COVID cases versus time (at the start of the pandemic). We picked \\(\\sin(x)\\) for modeling tide levels versus time.\nFind numerical values for the parameters \\(A\\), \\(B\\), \\(a\\), and \\(b\\). In Chapter ?chap-fitting-by-eye we’ll show you some ways to make this part of the task easier.\n\nIt’s remarkable that models of a very wide range of real-world relationships between pairs of quantities can be constructed by picking one of a handful of functions, then scaling the input and the output. As we move on to other Blocks in MOSAIC Calculus, you’ll see how to generalize this to potentially complicated relationships among more than two quantities. That’s a big part of the reason you’re studying calculus."
  },
  {
    "objectID": "Modeling/01-parameters.html#other-formats-for-scaling",
    "href": "Modeling/01-parameters.html#other-formats-for-scaling",
    "title": "8  Parameters",
    "section": "8.6 Other formats for scaling",
    "text": "8.6 Other formats for scaling\nOften, modelers choose to use input scaling in the form \\(a (x - x_0)\\) rather than \\(a x + b\\). The two are completely equivalent when \\(x_0 = - b/a\\). The choice between the two forms is largely a matter of convention. But almost always the output scaling is written in the format \\(A y + B\\).\n\nFor the COVID case-number data shown in Figure 8.2, we found that a reasonable match to the data can be had by input- and output-scaling the exponential: \\[\\text{cases}(t) \\equiv  \\underbrace{573}_A e^{\\underbrace{0.19}_a\\ t}\\ .\\]\nYou might wonder why the parameters \\(B\\) and \\(b\\) aren’t included in the model. One reason is that cases and the exponential function already have the same range: zero and upwards. So there’s no need to shift the output with a parameter B.\nAnother reason has to do with the algebraic properties of the exponential function. Specifically, \\[e^{a x + b}= e^b e^{ax} = {\\cal A} e^{ax}\\] where \\({\\cal A} \\equiv e^b\\).\nIn the case of exponentials, writing the input scaling in the form \\(e^{a(x-x_0)}\\) can provide additional insight.\nA bit of symbolic manipulation of the model can provide some additional insight. As you know, the properties of exponentials and logarithms are such that \\[A e^{at} = e^{\\log(A)} e^{at} = e^{a t + \\log(A)} = e^{a\\left(\\strut t + \\log(A)/a\\right)} = e^{a(t-t_0)}\\ ,\\] where \\[t_0 = - \\log(A)/a = - \\log(593)/0.19 = -33.6\\ .\\] You can interpret \\(t_0\\) as the starting point of the pandemic. When \\(t = t_0\\), the model output is \\(e^{k 0} = 1\\): the first case. According to the parameters we matched to the data for March, the pandemic’s first case would have happened about 33 days before March 1, which is late January. We know from other sources of information, the outbreak began in late January. It’s remarkable that even though the curve was constructed without any data from January or even February, the data from March, translated through the curve-fitting process, pointed to the start of the outbreak. This is a good indication that the exponential form for the model is fundamentally correct."
  },
  {
    "objectID": "Modeling/01-parameters.html#parameterization-conventions",
    "href": "Modeling/01-parameters.html#parameterization-conventions",
    "title": "8  Parameters",
    "section": "8.7 Parameterization conventions",
    "text": "8.7 Parameterization conventions\nThere are conventions for the symbols used for input-scaling parameterization of the pattern-book functions. Knowing these conventions makes it easier to read and assimilate mathematical formulas. In several cases, there is more than one conventional option. For instance, the sinusoid has a variety of parameterization forms that get used depending on which feature of the function is easiest to measure. ?tbl-param that are used in practice.\n\n\nSome standard forms of input scaling parameterizations\n\n\n\n\n\n\n\n\n\n\n\n\nFunction\nWritten form\nParameter 1\nParameter 2\n\n\n\n\nExponential\n\\(e^{kt}\\)\n\\(k\\)\nNot used\n\n\nExponential\n\\(e^{t/\\tau}\\)\n\\(\\tau\\) “time constant”\nNot used\n\n\nExponential\n\\(2^{t/\\tau_2}\\)\n\\(\\tau_2\\) “doubling time”\nNot used\n\n\nExponential\n\\(2^{-\\tau_{1/2}}\\)\n\\(-\\tau_{1/2}\\) “half life”\nNot used\n\n\nPower-law\n\\([x - x_0]^p\\)\n\\(x_0\\) x-intercept\nexponent\n\n\nSinusoid\n\\(\\sin\\left(\\frac{2 \\pi}{P} (t-t_0)\\right)\\)\n\\(P\\) “period”\n\\(t_0\\) “time shift”\n\n\nSinusoid\n\\(\\sin(\\omega t + \\phi)\\)\n\\(\\omega\\) “angular frequency”\n\\(\\phi\\) “phase shift”\n\n\nSinusoid\n\\(\\sin(2 \\pi \\omega t + \\phi)\\)\n\\(\\omega\\) “frequency”\n\\(\\phi\\) “phase shift”\n\n\nGaussian\ndnorm(x, mean, sd)\n“mean” (center)\nsd “standard deviation”\n\n\nSigmoid\npnorm(x, mean, sd)\n“mean” (center)\nsd “standard deviation”\n\n\nStraight-line\n\\(mx + b\\)\n\\(m\\) “slope”\n\\(b\\) “y-intercept”\n\n\nStraight-line\n\\(m (x-x_0)\\)\n\\(m\\) “slope”\n\\(x_0\\) “center”"
  },
  {
    "objectID": "Modeling/01-parameters.html#exercises",
    "href": "Modeling/01-parameters.html#exercises",
    "title": "8  Parameters",
    "section": "8.8 Exercises",
    "text": "8.8 Exercises\n<!– Drill\n\n\nPart i What is the period of the function \\(\\sin(6\\pi t)\\)?\n1/31/2236\n\n\n\n\nPart ii What is the period of \\(g(t)\\)? \\[g(t) \\equiv \\frac{5}{\\sin(2 \\pi t)}\\]\n\n1\n5\n\\(2 \\pi/5\\)\n\\(5/2\\pi\\)\n\\(g(t)\\) isn’t periodic.\n\n\n\n\n\nPart iii What is the period of \\(g(t)\\)? \\[g(t) \\equiv \\text{dnorm}\\left(\\frac{2\\pi}{5}(t-3)\\right)\\]\n\n1\n5\n\\(2 \\pi/5\\)\n\\(5/2\\pi\\)\n\\(g(t)\\) isn’t periodic.\n\n\n\n\n\nPart iv One of the following choices is the standard deviation of the function graphed. Which one?\n01234\n\n\n\n\nPart v What is the value of the parameter “mean” for the function shown in the graph?\n\n-2\n-1\n0.5\n1\n2\n“mean” is not a parameter of this function.\n\n\n\n\n\nPart vi What is the value of the parameter “sd” for the function shown in the graph?\n\n-2\n-1\n0.5\n1\n2\n“sd” is not a parameter of this function.\n\n\n\n\n\nPart vii What is the value of the parameter “mean” for the function shown in the graph?\n\n-2\n-1\n0.5\n1\n2\n“mean” is not a parameter of this function.\n\n\n\n\n\nPart viii What is the value of the parameter “sd” for the function shown in the graph?\n\n-2\n-1\n0.5\n1\n2\n“sd” is not a parameter of this function."
  },
  {
    "objectID": "Modeling/02-assembling-functions.html",
    "href": "Modeling/02-assembling-functions.html",
    "title": "9  Assembling functions",
    "section": "",
    "text": "When we need a new function for some purpose, we practically always build it out of existing functions. For illustrate, a function like \\[f(x) \\equiv A \\sin\\left(\\frac{2 \\pi}{P}x\\right) + B\\] is built by assembling a straight-line input scaling (\\(2\\pi/P\\)), a pattern-book \\(\\sin()\\) function, and another straight-line function \\(A f(x) + B\\) for scaling the output from \\(\\sin()\\).\nIn this chapter, we’ll review four general frameworks for combining functions: linear combination of functions, function composition, function multiplication, and “piecewise” splitting of the domain. You have almost certainly seen all four of these frameworks in your previous mathematical studies, although you might not have known that they have names."
  },
  {
    "objectID": "Modeling/02-assembling-functions.html#linear-combination",
    "href": "Modeling/02-assembling-functions.html#linear-combination",
    "title": "9  Assembling functions",
    "section": "9.1 Linear combination",
    "text": "9.1 Linear combination\nOne of the most widely used sorts of combination is called a linear combination. The mathematics of linear combination is, it happens, at the core of the use of math in a large variety of real-world applications, whether that be constructing a Google-like search engine or analyzing medical data to see if a treatment has a positive effect.\nThere is a special name for a quantity used to scale the output of a function: a scalar. Scalars are ordinary quantities; the word “scalar” is merely a way to distinguish the quantity from the function it is multiplying. Scalars generally come with units. So we might well have a metric polynomial and an equivalent traditional-unit polynomial.\nTo illustrate how linear combination is used to create new functions, consider polynomials, for instance, \\[f(x) \\equiv 3 x^2 + 5 x - 2\\ .\\] There are three pattern-book functions in this polynomial. In polynomials the functions being combined are all power-law functions: \\(g_0(x) \\equiv 1\\), \\(g_1(x) \\equiv x\\), and \\(g_2(x) \\equiv x^2\\). With these functions defined, we can write the polynomial \\(f(x)\\) as \\[f(x) \\equiv 3 g_2(x) + 5 g_1(x) - 2 g_0(x)\\] Each of the functions is being scaled by a quantity: 3, 5, and -2 in this example. Then the scaled functions are added up. That’s a linear combination; scale and add.\nIn high school, polynomials are often presented as puzzles—factor them to find the roots! In calculus, however, polynomials are used as functions for modeling. They are a kind of modeling “clay,” which can be shaped as needed.\nThere are other places where you have seen linear combinations:\nNote that neither the parameterized exponential nor the parameterized sinusoid is a polynomial. A polynomial is always a linear combination of monomials. (As Section Section 5.3, describes, monomials are the power-law functions \\(x^0\\), \\(x_1\\), \\(x_2\\), and so on.)\n\nThe parameterized sinusoid \\[A \\sin\\left(\\frac{2 \\pi}{P}t\\right) + B\\] is a linear combination of the functions \\(h_1(t) \\equiv \\sin\\left(\\frac{2 \\pi}{P} t\\right)\\) and \\(h_2(t) \\equiv 1\\). The linear combination is \\(A\\,h_1(t) + B\\, h_2(t)\\).\nThe parameterized exponential \\[A e^{kt} + B\\] The functions being combined are \\(e^{kt}\\) and \\(1\\). The scalars are, again, \\(A\\) and \\(C\\).\nThe straight line function, such as \\(\\mbox{output}(x) \\equiv A x + B\\) and \\(\\mbox{input}(x) \\equiv a x + b\\). The functions being combined are \\(x\\) and \\(1\\), the scalars are \\(a\\) and \\(b\\).\n\nThere are a few reasons for us to be introducing linear combinations here.\n\nYou will see linear combinations everywhere once you know to look for them.\nThere is a highly refined mathematical theory of linear combinations that gives us powerful ways to think about them as well as computer software that can quickly find the best scalars to use to match input-output data.\nThe concept of linear combination generalizes the simple idea that we have been calling “scaling the output.” From now on, we’ll use the linear-combination terminology and avoid the narrower idea of “scaling the output.”\nMany physical systems are described by linear combinations. For instance, the motion of a vibrating molecule, a helicopter in flight, or a building shaken by an earthquake are described in terms of simple “modes” which are linearly combined to make up the entire motion. More down to Earth, the timbre of a musical instrument is set by the scalars in a linear combination of pure tones.\nMany modeling tasks can be put into the framework of choosing an appropriate set of simple functions to combine and then figuring out the best scalars to use in the combination. (Generally, the computer does the figuring.)\n\n\n\nThe declination angle is the latitude of the point on the earth’s surface pierced by an imagined line connecting the centers of the earth and the sun. This angle is a function of the “day of year” (\\(doy\\)) measured as 0 at midnight before January 1 and 365.25 at the midnight ending December 31.\n\nDeclination angle as a function of day-of-year:\n\\(\\delta(doy) = 23.44 \\sin\\left({\\small\\frac{2\\pi}{365.25}} (doy-9)\\right)\\)\nThe output has units in degrees.\nImage source\nComposing day_length\\((L, \\delta)\\) onto \\(\\delta(doy)\\) gives the length of daylight as a function of day of the year: \\[\\text{daylight}(L, doy) \\equiv {\\small\\frac{2}{15}} \\arccos\\left(-\\tan(L)*\\tan(\\delta(doy))\\right)\\ .\\] Function composition enables us to transform a function that takes one kind of thing as input (declination in this example) and turn it into a function that takes another kind of thing as input (day of year). :::"
  },
  {
    "objectID": "Modeling/02-assembling-functions.html#sec-function-composition",
    "href": "Modeling/02-assembling-functions.html#sec-function-composition",
    "title": "9  Assembling functions",
    "section": "9.2 Function composition",
    "text": "9.2 Function composition\nTo compose two functions, \\(f(x)\\) and \\(g(x)\\), means to apply one of the functions to the output of the other. “\\(f()\\) composed with \\(g()\\)” means \\(f(g(x))\\). This is generally very different from “\\(g()\\) composed with \\(f()\\)” which means \\(g(f(x))\\).\nFor instance, suppose you have recorded the outdoor temperature over the course of a day and packaged this into a function \\(\\text{AirTemp}(t)\\): temperature as a function of time \\(t\\). Your digital thermometer uses degrees Celsius, but you want the output units to be degrees Kelvin. The conversion function is \\[\\text{CtoK}(C) \\equiv C + 273.15\\] Notice that CtoK() takes temperature in \\(^\\circ C\\) as input. With this, we can write the “Kelvin as a function of time” as \\[\\text{CtoK}\\left(\\text{AirTemp}(t)\\right)\\]\nIt’s important to distinguish the above time \\(\\rightarrow\\) Kelvin function from something that looks very much the same but is utterly different: \\(\\text{AirTemp}\\left(\\text{CtoK}(C)\\right)\\). In the first, the input is time. In the second, it is temperature in celsius.\n\nAnyone who lives far from the equator is familiar with the annual cycle of short winter days and long summer days. The magnitude of this cycle is a function of latitude; the further away from the equator the larger the winter-summer day-length difference.\nA simple model accounts for the length of daylight (in hours) as a function of latitude \\(L\\) and the declination angle \\(\\delta\\) of the sun.\n\\[\\text{daylight}(L, \\delta) \\equiv {\\small\\frac{2}{15}} \\arccos\\left(-\\tan(L)*\\tan(\\delta)\\right)\\]"
  },
  {
    "objectID": "Modeling/02-assembling-functions.html#sec-function-multiplication",
    "href": "Modeling/02-assembling-functions.html#sec-function-multiplication",
    "title": "9  Assembling functions",
    "section": "9.3 Function multiplication",
    "text": "9.3 Function multiplication\nMultiplication is the third in our repertoire of methods for making new functions. With two functions \\(f(x)\\) and \\(g(x)\\), the product is simply \\(f(x)g(x)\\).\nIt’s essential to distinguish between function multiplication and function composition:\n\n\nIn function composition, the order of the functions matters: \\(f(g(x))\\) and \\(g(f(x))\\) are in general completely different functions.\nIn function multiplication, the order doesn’t matter because multiplication is commutative, that is, if \\(f()\\) and \\(g()\\) are the functions to be multiplied \\(f(x) \\times g(x) = g(x)\\times f(x)\\).\n\\[\\underbrace{f(x) g(x)}_\\text{multiplication}\\ \\ \\ \\ \\underbrace{f(g(x)) \\ \\ \\text{or}\\ \\ \\ g(f(x))}_\\text{composition}\\]\nIn function composition, only one of the functions—the interior function is applied to the overall input, \\(x\\) in the above example. The exterior function is fed its input from the output of the interior function.\nIn multiplication, each of the functions is applied to the input individually. Then their outputs are multiplied to produce the overall output.\n\nTransient vibration\nA guitar string is plucked to produce a note. The sound is, of course, vibrations of the air created by vibrations of the string.\nAfter plucking, the note fades away. An important model of this is a sinusoid (of the correct period to correspond to the frequency of the note) times an exponential.\nFunction multiplication is used so often in modeling that you’ll see it in many modeling situations. Here’s one example that is important in physics and communication: the wave packet. Overall, the wave packet is a localized oscillation as in Figure 9.2. The packet can be modeled with the product of two pattern-book functions: a gaussian times a sinusoid.\n\n\n\n\n\n\n\nFigure 9.1: The two components of the wave packet in Figure 9.2: an “envelope” and an oscillation. Multiplying these components together produces the wave packet.\n\n\n\n\n\n\n\n\nFigure 9.2: A wave packet constructed by multiplying a sinusoid and a gaussian function.\n\n\n\n\n\nThe initial rise in popularity of the social media platform Yik Yak was exponential. Then popularity leveled off, promising a steady, if static, business into the future. But, the internet being what it is, popularity collapsed to near zero and the company closed.\nOne way to model this pattern is by multiplying a sigmoid by an exponential. (See Figure 9.3.)\n\n\n\n\n\nFigure 9.3: Subscriptions to the web messaging service Yik Yak grew exponentially in 2013 and 2014, then collapsed. The company closed in 2017.\n\n\n\n\n\nFunctions constructed as a product of simple functions can look like this in tradition notation: \\[h(t) \\equiv \\sin(t) e^{-t}\\] and like this in computer notation:\n\nh <- makeFun(sin(t)*exp(-t) ~ t)"
  },
  {
    "objectID": "Modeling/02-assembling-functions.html#sec-piecewise-intro",
    "href": "Modeling/02-assembling-functions.html#sec-piecewise-intro",
    "title": "9  Assembling functions",
    "section": "9.4 Splitting the domain",
    "text": "9.4 Splitting the domain\nConsider the familiar absolute-value function:\n\n\n\n\n\n\nFigure 9.4: The absolute-value function\n\n\n\n\\[abs(x) \\equiv \\left|x\\right|\\] Written this way, the definition of \\(abs()\\) is a tautology: unless you already know what \\(\\left|x\\right|\\) means, you will have no clue what’s going on.\nCan we assemble \\(abs(x)\\) out of pattern-book functions? What’s distinctive about \\(abs(x)\\) is the break at \\(x=0\\). There’s no similarly sharp transition in any of the pattern-book functions.\nOne way to construct the sharp transition is to view \\(abs(x)\\) as two functions, one whose domain is the negative half of the number line and the other having a domain that is the non-negative half. That is, we’ll break the domain of \\(abs()\\) into two pieces. For the right piece of the domain, \\(abs(x)\\) is simply proportional\\((x)\\). For the left piece of the domain, \\(abs(x)\\) is \\(-\\)proportional\\((x)\\).\nA function defined separately on different pieces of its domain is called a piecewise function. In the conventional mathematical notation, there is a large \\(\\LARGE\\left\\{\\right.\\) followed by two or more lines. Each line gives a formula for that part of the function and indicates to which interval the formula applies.\n\\[abs(x) \\equiv \\left\\{\n\\begin{array}{rl}  x & \\text{for}\\ 0 \\leq x \\\\\n- x & \\text{otherwise}\\\\\\end{array}\n\\right.\\]\n\n\n\n\n\n\nFigure 9.5: The Heaviside function\n\n\n\nAnother piecewise function widely used in technical work, but not as familiar as \\(abs()\\) is the Heaviside function, which has important uses in physics and engineering.\n\\[\\text{Heaviside}(x) \\equiv \\left\\{\n\\begin{array}{cl} 1 & \\text{for}\\ 0 \\leq x \\\\0 & \\text{otherwise}\\end{array}\n\\right.\\]\nThe Heaviside function is defined on the same two pieces of the number line as \\(abs()\\). To the right of zero, Heaviside is identical to constant(). To the left, it’s identical to \\(0\\) times constant\\(()\\).\nThe vertical gap between the two pieces of the Heaviside function is called a discontinuity. Intuitively, you cannot draw a discontinuous function without lifting the pencil from the paper. The Heaviside’s discontinuity occurs at input \\(x=0\\).\n\n9.4.1 Computing notation\nThe usual mathematical notation for piecewise functions, spread out over multiple lines that are connected with a tall brace, is an obvious non-candidate for computer notation. In R, the stitching together of the two pieces can be done with the function ifelse(). The name is remarkably descriptive. The ifelse() function takes three arguments. The first is a question to be asked, the second is the value to return if the answer is “yes,” and the third is the value to return for a “no” answer.\nTo define \\(abs()\\) or Heaviside\\(()\\) the relevant question is, “Is the input on the right or left side of zero on the number line?” In widely-used computing languages such as R, the format for asking a question does not involve a question mark. For example, to ask the question, “Is 3 less than 2?” use the expression:\n\n3 < 2\n\nIn mathematics notation, \\(3 < 2\\) is a declarative statement and is an impossibility. More familiar would be \\(x < 2\\), which is again a declarative statement putting a restriction on the possible values of the quantity \\(x\\).\nIn computing notation, 3 < 2 or x < 2 is not a declaration, it is an imperative  statement that directs the computer to do the calculation to find out if the statement is true or false, or, as written in R, TRUE or FALSE.\n\n\nRemember that the tilde-expressions given as input to makeFun() are declarative, not imperative. makeFun() stores the tilde expression exactly as is, with symbols such as x being names rather than quantities. makeFun() packages up the stored tilde expression in the form of an R function. The assignment command Heaviside <- ... gives the name Heaviside to the function created by makeFun().\nOnly when you apply the function created by makeFun() to an input quantity will the tilde-expression be turned into an imperative statement that asks the question 0 <= x and then chooses the second or third argument to ifelse() as the result.\nHere’s a definition of Heaviside() written with ifelse().\n\nHeaviside <- makeFun(ifelse(0 <= x, 1, 0) ~ x)\n\n?tbl-R-questions shows computer notation for some common sorts of questions.\n\n\nEach of these imperative statements in R asks a question about numbers.\n\n\n\n\n\n\n\n\n\n\nR notation\nEnglish\n\n\n\n\nx > 2\n“Is \\(x\\) greater than 2?”\n\n\ny >= 3\n“Is \\(y\\) greater than or equal to 3?”\n\n\nx == 4\n“Is \\(x\\) exactly 4?”\n\n\n2 < x & x < 5\n“Is \\(x\\) between 2 and 5?” Literally, “Is \\(x\\) both greater than 2 and less than 5?”\n\n\nx < 2 | x > 6\n“Is \\(x\\) either less than 2 or greater than 6?”\n\n\nabs(x-5) < 2\n“Is \\(x\\) within two units of 5?”\n\n\n\n\n\n\n\nFigure 9.6 is a graph of monthly natural gas use in the author’s household versus average temperature during the month. (Natural gas is measured in cubic feet, abbreviated ccf.)\n\n\n\n\n\nFigure 9.6: The amount of natural gas used for heating the author’s home varies with the outside temperature.\n\n\n\n\nThe graph looks somewhat like a hockey stick. A sloping straight-line dependence of ccf on temperature for temperatures below \\(60^\\circ\\)F and constant for higher temperatures. The shape originates from the dual uses of natural gas. Gas is used for cooking and domestic hot water, the demand for which is more or less independent of outdoor temperature at about 15 ccf per month. Gas is also used for heating the house, but that’s needed only when the temperature is less than about \\(60^\\circ\\)F.\nWe can accomplish the hockey-stick shape with a linear combination of the ramp() function and a constant. The ramp function represents gas used for heating, the constant is the other uses of gas (which are modeled as not depending on temperature. Overall, the model is \\[\\text{gas}(x) \\equiv 4.3\\,  \\text{ramp}(62-x)  + 15\\ .\\] Even simpler is the model for the other uses of natural gas: \\[\\text{other}(x) \\equiv 15\\ .\\]"
  },
  {
    "objectID": "Modeling/02-assembling-functions.html#computing-outside-the-domain",
    "href": "Modeling/02-assembling-functions.html#computing-outside-the-domain",
    "title": "9  Assembling functions",
    "section": "9.5 Computing outside the domain",
    "text": "9.5 Computing outside the domain\nEach of our pattern-book functions, with two exceptions, has a domain that is the entire number line \\(-\\infty < x < \\infty\\). No matter how big or small is the value of the input, the function has an output. Such functions are particularly nice to work with since we never have to worry about the input going out of bounds.\nThe two exceptions are:\n\nthe logarithm function, which is defined only for \\(0 < x\\).\nsome of the power-law functions: \\(x^p\\).\n\nWhen \\(p\\) is negative, the output of the function is undefined when \\(x=0\\). You can see why with a simple example: \\(g(x) \\equiv x^{-2}\\). Most students had it drilled into them that “division by zero is illegal,” and \\(g(0) = \\frac{1}{0} \\frac{1}{0}\\), a double law breaker.\nWhen \\(p\\) is not an integer, that is \\(p \\neq 1, 2, 3, \\cdots\\) the domain of the power-law function does not include negative inputs. To see why, consider the function \\(h(x) \\equiv x^{1/3}\\).\n\n\n\nIt can be tedious to make sure that you are on the right side of the law when dealing with functions whose domain is not the whole number line. The designers of the hardware that does computer arithmetic, after several decades of work, found a clever system to make it easier. It’s a standard part of such hardware that whenever a function is handed an input that is not part of that function’s domain, one of two special “numbers” is returned. To illustrate:\n\nsqrt(-3)\n## [1] NaN\n(-2)^0.9999\n## [1] NaN\n1/0\n## [1] Inf\n\nNaN stands for “not a number.” Just about any calculation involving NaN will generate NaN as a result, even those involving multiplication by zero or cancellation by subtraction or division.1 For instance:\n\n0 * NaN\n## [1] NaN\nNaN - NaN\n## [1] NaN\nNaN / NaN\n## [1] NaN\n\nDivision by zero produces Inf, whose name is reminiscent of “infinity.” Inf infiltrates any calculation in which it takes part:\n\n3 * Inf\n## [1] Inf\nsqrt(Inf)\n## [1] Inf\n0 * Inf\n## [1] NaN\nInf + Inf\n## [1] Inf\nInf - Inf\n## [1] NaN\n1/Inf\n## [1] 0\n\nTo see the benefits of the NaN / Inf system let’s plot out the logarithm function over the graphics domain \\(-5 \\leq x \\leq 5\\). Of course, part of that graphics domain, \\(-5 \\leq x \\leq 0\\) is not in the domain of the logarithm function and the computer is entitled to give us a slap on the wrists. The NaN provides some room for politeness."
  },
  {
    "objectID": "Modeling/02-assembling-functions.html#exercises",
    "href": "Modeling/02-assembling-functions.html#exercises",
    "title": "9  Assembling functions",
    "section": "9.6 Exercises",
    "text": "9.6 Exercises"
  },
  {
    "objectID": "Modeling/03-functions-with-multiple-inputs.html",
    "href": "Modeling/03-functions-with-multiple-inputs.html",
    "title": "10  Functions with multiple inputs",
    "section": "",
    "text": "We can use linear combination and function multiplication to build up custom functions from the basic modeling functions. Similarly, linear combination and function multiplication provide ways to construct functions of multiple inputs."
  },
  {
    "objectID": "Modeling/03-functions-with-multiple-inputs.html#linear-combinations",
    "href": "Modeling/03-functions-with-multiple-inputs.html#linear-combinations",
    "title": "10  Functions with multiple inputs",
    "section": "10.1 Linear combinations",
    "text": "10.1 Linear combinations\nHousing prices are determined by several (or many!) factors. Translating the previous sentence into the language of functions, we can say that the price is a function of multiple inputs. Plausible inputs to the function include the amount of living area and the number of bedrooms and bathrooms. The inputs may also include quality of the neighborhood, length of commute, and so on.\nOften, the starting point for building a function with multiple inputs is a data frame whose variables include the function output (price) and the inputs to the function. Modelers often begin by constructing a function that is a linear combination of the input variables. To demonstrate what such functions look like, we can use the SaratogaHouses dataset, which records the sales price of 1728 houses in Saratoga County, New York, USA and 15 other variables for each house, such as livingArea and the number of bedrooms and bathrooms.\nThe techniques for constructing functions from data will be introduced in Block ?sec-vectors-linear-combinations. For now, let’s simply see what such functions look like. From SaratogaHouses we constructed this function:\n[These are not made-up scalars in the linear combination. They have been derived from the SaratogaHouses data using a method called linear regression. The “linear” in the name refers to “linear combination.”]\n\\[\\mathtt{price}(\\mathtt{livingArea}, \\mathtt{bedrooms}, \\mathtt{bathrooms}) \\equiv\\\\  21000 + 105\\, \\mathtt{livingArea}\\\\ - 13000\\,\\mathtt{bedrooms} + 26000\\, \\mathtt{bathrooms}\\]\nThe model function is a simple linear combination, but it effectively quantifies how different aspects of a house contribute to its sales price. The model (which is based on data from two decades ago) indicates that an additional square foot of living area is worth about 105 dollars per foot2. An extra bathroom is worth about $25,000. Bedrooms, strangely, are assigned a negative value by the model.\nPossibly you already understand what is meant by “an additional square foot” or “an extra bathroom.” These ideas can be intuitive, but they can be best understood with a grounding in calculus, which we turn to in Block ?sec-differentiation-block. For instance, the negative scalar on bedrooms will make sense when you understand “partial derivatives,” the subject of Chapter Section 25."
  },
  {
    "objectID": "Modeling/03-functions-with-multiple-inputs.html#fx-times-gt",
    "href": "Modeling/03-functions-with-multiple-inputs.html#fx-times-gt",
    "title": "10  Functions with multiple inputs",
    "section": "10.2 f(x) times g(t)",
    "text": "10.2 f(x) times g(t)\nWhen a guitar string is at rest it forms a straight line connecting its two fixed ends: one set by finger pressure along the neck of the guitar and the other at the bridge near the center of the guitar body. When a guitar string is plucked, its oscillations follow a sinusoid pattern of displacement. With the right camera and lighting setup, we can see these oscillations in action:\n\n\n\n\n\n\n\nFor a string of length \\(L\\), the string displacement is a function of position \\(x\\) along the string and is a linear combination of functions of the form \\[g_k(x) \\equiv \\sin(k \\pi x /L)\\] where \\(k\\) is an integer. A few of these functions are graphed in ?fig-guitar-string-modes with \\(k=1\\), \\(k=2\\), and \\(k=3\\).\n\n\n\n\n\nFigure 10.1: Vibrational modes of a guitar string.\n\n\n\n\n\n\n\nFigure 10.2: Vibrational modes of a guitar string.\n\n\n\n\nShapes of the sort in ?fig-guitar-string-modes are a stop-motion flash snapshot of the string. The string’s shape also changes in time, so the string’s displacement is a function of both \\(x\\) and \\(t\\). The displacement itself is a sinusoid whose time period depends on the length and tension of the string as well as the number of cycles of the spatial sine: \\[g_k(x, t) \\equiv \\sin(\\frac{k \\pi}{L} x) \\ \\sin(\\frac{k \\pi}{P}t)\\] Figure @ref(fig:string-motion) shows a few snapshots of the 1.5 cycle string at different moments in time, and the motion of the linear combination.\n\n\n\n\n\nString position changes over time.\n\n\n\n\n\n\n\nString position changes over time.\n\n\n\n\n\nWe left function composition out of the list of ways to build multi-input functions out of simpler functions with a single input.\nFor instance, consider the two functions \\(f(x)\\) and \\(g(t)\\). The composition \\(f(g(t))\\) has only one input: \\(t\\). Similarly, \\(g(f(x))\\) has only one input: \\(x\\)."
  },
  {
    "objectID": "Modeling/03-functions-with-multiple-inputs.html#constructing-your-own-from-data",
    "href": "Modeling/03-functions-with-multiple-inputs.html#constructing-your-own-from-data",
    "title": "10  Functions with multiple inputs",
    "section": "10.3 Constructing your own from data",
    "text": "10.3 Constructing your own from data\nEven if you don’t yet have a theoretical understanding of how to construct functions with multiple inputs from data, you can R/mosaic operations for doing so. A key function is fitModel(), which like makeFun(), constructs a function. And, like makeFun(), you need to use a tilde expression to specify the model formula. But, unlike makeFun(), you can leave it to the computer to find the parameters that will make the function align with data.\nTo illustrate, we can construct a housing-price model from the SaratogaHouses data:\n\nprice <- fitModel(price ~ A + B*livingArea + C*bedrooms + D*bathrooms,\n                  data = SaratogaHouses)\n\nNote that in applying the price() function to inputs, we are using the names of the inputs explicitly. To write the command price(2000,3,2) risks mixing up which input is which.\nUse the function in the ordinary way. For instance, here’s what the model has to say about the anticipated sales price of a house with 2000 square feet of living area, three bedrooms, and two bathrooms.\n\nprice(livingArea=2000, bedrooms=3, bathrooms=2)\n## [1] 242448.1\n\nThe units of the output are the same as the units of price in the SaratogaHouses data frame: dollars.\n\n\nTo look at a function, give the function name without parentheses, e.g. price. In contrast, you’ll always use parentheses when applying the function to inputs.\nFor technical reasons, the functions created by fitModel() have a lot of computer-programming jargon in them, as you can see by constructing the model itself and then looking at the function. But you will also see clearly the values of the parameters found by fitModel()."
  },
  {
    "objectID": "Modeling/03-functions-with-multiple-inputs.html#exercises",
    "href": "Modeling/03-functions-with-multiple-inputs.html#exercises",
    "title": "10  Functions with multiple inputs",
    "section": "10.4 Exercises",
    "text": "10.4 Exercises"
  },
  {
    "objectID": "Modeling/04-fitting-by-eye.html",
    "href": "Modeling/04-fitting-by-eye.html",
    "title": "11  Fitting features",
    "section": "",
    "text": "For more than three centuries, there has been a standard calculus model of an everyday phenomenon: a hot object such as a cup of coffee cooling off to room temperature. The model, called Newton’s Law of Cooling, posits that the rate of cooling is proportional to the difference between the object’s temperature and the ambient temperature. The technology for measuring temperature (Figure 11.1) was rudimentary in Newton’s era, raising the question of how Newton formulated a quantitative theory of cooling. (We’ll return to this question in Section 12.)\nUsing today’s technology, Prof. Stan Wagon of Macalester College investigated the accuracy of Newton’s “Law.” ?fig-Fun-4-intro-1 shows some of Wagon’s data from experiments with cooling water. He poured boiling water from a kettle into an empty room-temperature mug (26 degrees C) and measured the temperature of the water over the next few hours.\nThis chapter is about fitting, finding parameters that will align the functions with the data such as in Figure 11.2. In this chapter, we’ll work the the exponential, sinusoid, and gaussian functions. In Chapter Section 14 we’ll consider the power-law and logarithm functions.\nIn every instance, the first step, before finding parameters, is to determine that the pattern shown in the data is a reasonable match to the shape of the function you are considering. Here’s a reminder of the shapes of the functions we’ll be fitting to data in this chapter. If the shapes don’t match, there’s little point in looking for the parameters to fit the data!"
  },
  {
    "objectID": "Modeling/04-fitting-by-eye.html#gaussian",
    "href": "Modeling/04-fitting-by-eye.html#gaussian",
    "title": "11  Fitting features",
    "section": "11.1 Gaussian",
    "text": "11.1 Gaussian\nThe ability to perceive color comes from “cones”: specialized light-sensitive cells in the retina of the eye. Human color perception involves three sets of cones. The L cones are most sensitive to relatively long wavelengths of light near 570 nanometers. The M cones are sensitive to wavelengths near 540 nm, and the S cones to wavelengths near 430nm.\nThe current generation of Landsat satellites uses nine different wavelength-specific sensors. This makes it possible to distinguish features that would be undifferentiated by the human eye.\n\n\n\n\n\n\nFigure 11.3: Two views of the same scene synthesized by combining the output of different types of cones. The top picture uses V, M, and S cones; the bottom only S, M, and L cones. The dark geen leaves clearly revealed in the top picture are not distinguishable in the bottom picture. (Source: Tedore and Nilsson)\n\n\n\nBack toward Earth, birds have five sets of cones that cover a wider range of wavelengths than humans. (Figure 11.4) Does this give them a more powerful sense of the differences between natural features such as foliage or plumage? One way to answer this question is to take photographs of a scene using cameras that capture many narrow bands of wavelengths. Then, knowing the sensitivity spectrum of each set of cones, new “false-color” pictures can be synthesized recording the view from each set.1\n\n\n\n\n\nFigure 11.4: Sensitivity to wavelength for each of the five types of bird cones. [Source: Tedore and Nilsson]\n\n\n\n\nCreating the false-color pictures on the computer requires a mathematical model of the sensitivities of each type of cone. The graph of each sensitivity function resembles a Gaussian function.\nThe Gaussian has two parameters: the “mean” and the “sd” (short for standard deviation). It’s straightforward to estimate values of the parameters from a graph, as in Figure 11.5.\n\n\n\n\n\n\nFigure 11.5: A Gaussian function annotated to identify the parameters mean (location of peak of graph) and sd (half-width at half-height).\n\n\n\nThe parameter “mean” is the location of the peak. The standard deviation is, roughly, half the width of the graph at a point halfway down from the peak."
  },
  {
    "objectID": "Modeling/04-fitting-by-eye.html#sinusoid",
    "href": "Modeling/04-fitting-by-eye.html#sinusoid",
    "title": "11  Fitting features",
    "section": "11.2 Sinusoid",
    "text": "11.2 Sinusoid\nWe’ll use three parameters for fitting a sinusoid to data: \\[A \\sin\\left(\\frac{2\\pi}{P}\\right) + B\\] where\n\n\\(A\\) is the “amplitude”\n\\(B\\) is the “baseline”\n\\(P\\) is the period.\n\n\n\n\n\n\n\nFigure 11.6: A reproduction of the data originally shown in Figure 8.3. The baseline for the sinusoid is midway between the top of the oscillation and the bottom.\n\n\n\nThe baseline for the sinusoid is the value mid-way between the top of the oscillations and the bottom. For example, Figure 8.3 (reproduced in the margin) shows the sinusoidal-like pattern of tide levels. Dashed horizontal lines (\\(\\color{brown}{\\text{brown}}\\)) have been drawn roughly going through the top of the oscillation and the bottom of the oscillation. The baseline (\\(\\color{magenta}{\\text{magenta}}\\)) will be halfway between these top and bottom levels.\nThe amplitude is the vertical distance between the baseline and the top of the oscillations. Equivalently, the amplitude is half the vertical distance between the top and the bottom of the oscillations.\nIn a pure, perfect sinusoid, the top of the oscillation—the peaks—is the same for every cycle, and similarly with the bottom of the oscillation—the troughs. The data in Figure 8.3 is only approximately a sinusoid so the top and bottom have been set to be representative. In Figure 11.6, the top of the oscillations is marked at level 1.6, the bottom at level 0.5. The baseline is therefore \\(B \\approx = (1.6 + 0.5)/2 = 1.05\\). The amplitude is \\(A = (1.6 - 0.5)/2 = 1.1/2 = 0.55\\).\nTo estimate the period from the data, mark the input for a distinct point such as a local maximum, then count off one or more cycles forward and mark the input for the corresponding distinct point for the last cycle. For instance, in Figure 11.6, the tide level reaches a local maximum at an input of about 6 hours, as marked by a black dotted line. Another local maximum occurs at about 106 hours, also marked with a black dotted line. In between those two local maxima you can count \\(n=8\\) cycles. Eight cycles in \\(106-6 = 100\\) hours gives a period of \\(P = 100/8 = 12.5\\) hours."
  },
  {
    "objectID": "Modeling/04-fitting-by-eye.html#sec-exponential-water",
    "href": "Modeling/04-fitting-by-eye.html#sec-exponential-water",
    "title": "11  Fitting features",
    "section": "11.3 Exponential",
    "text": "11.3 Exponential\nTo fit an exponential function, we estimate the three parameters: \\(A\\), \\(B\\), and \\(k\\) in \\[A \\exp(kt)+ B\\]\n\n\n\n\n\n\n\n\n\n\n\nExp. growth\nExp. decay\n.\n.\n\n\n\n\n\n\n.\n.\n\n\n\nExponential decay is a left-to-right flip of exponential growth.\nFigure 11.2 illustrates the procedure. The first question to ask is whether the pattern shown by the data resembles an exponential function. After all, the exponential pattern book function grows in output as the input gets bigger, whereas the water temperature is getting smaller—the word decaying is used—as time increases. To model exponential decay, use \\(\\exp(-k t)\\), where the negative sign effectively flips the pattern-book exponential left to right.\nThe exponential function has a horizontal asymptote for negative inputs. The left-to-right flipped exponential \\(\\exp(-k t)\\) also has a horizontal asymptote, but for positive inputs.\nThe parameter \\(B\\), again called the “baseline,” is the location of the horizontal asymptote on the vertical axis. Figure 11.2 suggests the asymptote is located at about 25 deg. C. Consequently, the estimated value is \\(B \\approx 25\\) deg C.\n\n11.3.1 Estimating A\nThe parameter \\(A\\) can be estimated by finding the value of the data curve at \\(t=0\\). In Figure Figure 11.7 that’s just under 100 deg C. From that, subtract off the baseline you estimated earlier: (\\(B = 25\\) deg C). The amplitude parameter \\(A\\) is the difference between these two: \\(A = 99 - 25 = 74\\) deg C.\n\n\n11.3.2 Estimating k\nThe exponential has a unique property of “doubling in constant time” as described in Section Section 5.2. We can exploit this to find the parameter \\(k\\) for the exponential function.\n\nThe procedure starts with your estimate of the baseline for the exponential function. In Figure 11.7 the baseline has been marked in \\(\\color{magenta}{\\text{magenta}}\\) with a value of 25 deg C.\nPick a convenient place along the horizontal axis. You want a place such that the distance of the data from the baseline to be pretty large. In Figure 11.7 the convenient place was selected at \\(t=25\\).\n\n\n\n\n\n\n\nFigure 11.7: Determining parameter \\(k\\) for the exponential function using the doubling time.\n\n\n\n\nMeasure the vertical distance from the baseline at the convenient place. In Figure 11.7 the data curve has a value of about 61 deg C at the convenient place. This is \\(61-25 = 36\\) deg C from the baseline.\nCalculate half of the value from (c). In Figure 11.7 this is \\(36/2=18\\) deg C. But you can just as well do the calculation visually, by marking half the distance from the baseline at the convenient place.\nScan horizontally along the graph to find an input where the vertical distance from the data curve to the baseline is the value from (d). In Figure 11.7 that half-the-vertical-distance input is at about \\(t=65\\). Then calculate the horizontal distance between the two vertical lines. In Figure 11.7 that’s \\(65 - 25 = 40\\) minutes. This is the doubling time. Or, you might prefer to call it the “half-life” since the water temperature is decaying over time.\nCalculate the magnitude \\(\\|k\\|\\) as \\(\\ln(2)\\) divided by the doubling time from (e). That doubling time is 40 minutes, so \\(\\|k\\|= \\ln(2) / 40 = 0.0173\\). We already know that the sign of \\(k\\) is negative since the pattern shown by the data is exponential decay toward the baseline. So, \\(k=-0.0173\\)."
  },
  {
    "objectID": "Modeling/04-fitting-by-eye.html#graphics-layers",
    "href": "Modeling/04-fitting-by-eye.html#graphics-layers",
    "title": "11  Fitting features",
    "section": "11.4 Graphics layers",
    "text": "11.4 Graphics layers\nWhen fitting a function to data, it’s wise to plot out the resulting function on top of the data. This involves making graphics with two layers, as described in Chapter Section 7. As a reminder, here’s an example comparing the cooling-water data to the exponential function we fitted in Section Section 11.3.\nThe fitted function we found was \\[T_{water}(t) \\equiv 74 \\exp(-0.0173 t) + 25\\] where \\(T\\) stands for “temperature.”\nTo compare \\(T_{water}()\\) to the data, we’ll first plot out the data with gf_point(), then add a slice plot of the function. We’ll also show a few bells and whistles of plotting: labels, colors, and such.\n\nT_water <- makeFun(74*exp(-0.0173*t) + 25 ~ t)\ngf_point(temp ~ time, data=CoolingWater, alpha=0.5 ) %>%\n  slice_plot(T_water(time) ~ time, color=\"blue\") %>%\n  gf_labs(x = \"Time (minutes)\", y=\"Temperature (deg. C)\")\n\n\n\n\n\nFigure 11.8: A graphic with two layers: one for the cooling-water data and the other with the exponential function fitted to the data.\n\n\n\nThe slice_plot() command inherited the domain interval from the gf_point() command. This happens only when the name of the input used in slice_plot() is the same as that in gf_point(). (It’s time in both.) You can add additional data or function layers by extending the pipeline.\nBy the way, the fitted exponential function is far from a perfect match to the data. We’ll return to this mismatch in Chapter Section 16 when we explore the modeling cycle."
  },
  {
    "objectID": "Modeling/04-fitting-by-eye.html#fitting-other-pattern-book-functions",
    "href": "Modeling/04-fitting-by-eye.html#fitting-other-pattern-book-functions",
    "title": "11  Fitting features",
    "section": "11.5 Fitting other pattern-book functions",
    "text": "11.5 Fitting other pattern-book functions\nThis chapter has looked at fitting the exponential, sinusoid, and Gaussian functions to data. Those are only three of the nine pattern-book functions. What about the others?\n\n\nShapes of the pattern-book functions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst\nprop\nsquare\nrecip\ngaussian\nsigmoid\nsinusoid\nexp\nln\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn Blocks ?sec-differentiation-part and ?sec-accumulation-part, you’ll see how the Gaussian and the sigmoid are intimately related to one another. Once you see that relationship, it will be much easier to understand how to fit a sigmoid to data.\nThe remaining five pattern-book functions, the ones we haven’t discussed in terms of fitting, are the logarithm and the four power-law functions included in the pattern-book set. In Chapter Section 14 we’ll introduce a technique for estimating from data the exponent of a single power-law function.\nIn high school, you may have done exercises where you estimated the parameters of straight-line functions and other polynomials from graphs of those functions. In professional practice, such estimations are done with an entirely different and completely automated method called regression. We’ll introduce regression briefly in Chapter Section 16. However, the subject is so important that all of Block ?sec-vectors-linear-combinations is devoted to it and its background."
  },
  {
    "objectID": "Modeling/04-fitting-by-eye.html#exercises",
    "href": "Modeling/04-fitting-by-eye.html#exercises",
    "title": "11  Fitting features",
    "section": "11.6 Exercises",
    "text": "11.6 Exercises\n<!– Drill\n\n\nPart 1 What’s the period of this sinusoid?\n12345\n\n\n\n\nPart 2 Which function(s) have \\(k < 0\\)?\nblueblackbothneither\n\n\n\n\nPart 3 Which function(s) have \\(k < 0\\)?\nblueblackbothneither\n\n\n\n\nPart 4 Which function(s) have \\(k < 0\\)?\nblueblackbothneither\n\n\n\n\nPart 5 One of the functions has a half-life, the other a doubling time. Which is bigger, the half-life or the doubling time?\n\ndoubling time\nhalf-life\nabout the same\nthey aren’t exponential, so the concept of half-life/doubling-time doesn’t apply.\n\n\n\n\n\nPart 6 In this book, what is meant by the word “variable”?\n\nIt’s the same as output.\nIt’s the same as input.\nA column in a data table."
  },
  {
    "objectID": "Modeling/05-low-order-polynomials.html",
    "href": "Modeling/05-low-order-polynomials.html",
    "title": "12  Low-order polynomials",
    "section": "",
    "text": "Chapter Section 11 looked at the task of modifying a pattern-book function to display a desired pattern, focusing on patterns originating in graphs of data. The procedure involved identifying an appropriate pattern-book function, then using input and output scaling to stretch, flip, and lift that function so that it overlays, as much as possible, the desired pattern.\nIn this chapter, we’ll take on a different strategy for constructing appropriately shaped functions using linear combinations of a handful of simple functions: the monomials."
  },
  {
    "objectID": "Modeling/05-low-order-polynomials.html#polynomials",
    "href": "Modeling/05-low-order-polynomials.html#polynomials",
    "title": "12  Low-order polynomials",
    "section": "12.1 Polynomials",
    "text": "12.1 Polynomials\nRecall that the monomials are the power-law functions with non-negative, integer exponents: \\(x^0\\), \\(x^1\\), \\(x^2\\), \\(x^3\\), and so on. The “and so on” refers to even higher integer exponents such as \\(x^4\\) or \\(x^{51}\\) or \\(x^{213}\\), to name but a few. The more common name for a linear combination of monomials is polynomial.\n\n\nThe first two terms in the polynomial \\(g(t)\\) could be written using exponents, like this: \\[ g(t) \\equiv a_0 t^0 + a_1 t^1 + \\cdots\\] In practice, nobody writes out explicitly the \\(t^0\\) function. Instead, recognizing that \\(t^0 = 1\\), we write the first term simply as \\(a_0\\). Similarly, rather than writing \\(t^1\\) in the second term, we write \\(a_1 t\\), without the exponent. This practice makes the formulas for polynomials more concise but at the cost of failing to remind the reader that all the functions in the linear combination are monomials.\nFor instance, a fifth-order polynomial consists of a linear combination of monomials up to order 5. That is, up to \\(x^5\\). This will have six terms because we count the order of the monomials starting with 0. \\[g(t) \\equiv a_0 + a_1 t + a_2 t^2 + a_3 t^3 + a_4 t^4 + a_5 t^5\\ .\\]\nThe challenge in shaping a polynomial is to find the scalar multipliers—usually called coefficients when it comes to polynomials—that give us the shape we want. This might seem to be a daunting task, and it is for a human. But it can easily be handled using volumes of arithmetic, too much arithmetic for a human to take on but ideally suited for computing machines."
  },
  {
    "objectID": "Modeling/05-low-order-polynomials.html#low-order-polynomial-models",
    "href": "Modeling/05-low-order-polynomials.html#low-order-polynomial-models",
    "title": "12  Low-order polynomials",
    "section": "12.2 Low-order polynomial models",
    "text": "12.2 Low-order polynomial models\nPolynomials in general can show a wide variety of snake-like patterns. A fifth-order polynomial can have up to four internal curves. A tenth-order polynomial can have 9 internal curves, and so. There is, however, rarely a need for generating functions with all those curves. Instead, a great deal of modeling work can be accomplished with just first-order polynomials (no internal curves) or second-order polynomials (one internal curve).\n\\[\\begin{eqnarray}\n\\textbf{First-order: }\\ \\ \\ \\ \\ & f_1(t) \\equiv b_0 + b_1 t\\\\\n\\textbf{Second-order: }\\ \\ \\ \\ \\ & f_2(t) \\equiv c_0 + c_1 t + c_2 t^2\n\\end{eqnarray}\\]\n\n\nNote that we’re using different names for the coefficients in each of the polynomial examples. The only significance of this is a reminder that each of the coefficients can be any number at all and isn’t necessarily related to any of the other coefficients. In addition to the usual \\(a\\), \\(b\\), \\(c\\), we’ve used the Greek alpha, beta, and gamma, that is \\(\\alpha\\), \\(\\beta\\), and \\(\\gamma\\). The subscript on the coefficient name indicates which term it belongs to. For instance, the coefficient on the \\(y^2\\) term of the \\(h_c\\) polynomial is named \\(\\gamma_{yy}\\) while the coefficient on the \\(x y\\) term has the subscript \\(_{xy}\\). Always, the coefficients are constant quantities and not functions of \\(x\\) or any other input.\nIn high-school mathematics, polynomials are often written without subscript, for instance \\(a x^2 + b x + c\\). This can be fine when working with only one polynomial at a time, but in modeling we often need to compare multiple, related polynomials.\nYou may prefer to think about a first-order polynomial as a straight-line function. Similarly, a second-order polynomial is also known as a “quadratic” or even a “parabola.” Nonetheless, it’s good to see them as polynomials distinguished by their order. This puts them into a general framework, all of which can be handled by the technology of linear combinations. And polynomials can also involve more than one input. For instance, here are three polynomial forms that involve inputs \\(x\\) and \\(y\\):\n\\[\\begin{eqnarray}\nh_a(x, y) &\\equiv & \\alpha_0 + \\alpha_x\\, x + \\alpha_y\\, y\\\\\nh_b(x, y) &\\equiv & \\beta_0 + \\beta_x\\, x + \\beta_y\\, y + \\beta_{xy}\\, x y\\\\\nh_c(x, y) &\\equiv & \\gamma_0 + \\gamma_x\\, x + \\gamma_y\\, y + \\gamma_{xy}\\, x y + \\gamma_{xx}\\, x^2 + \\gamma_{yy}\\, y^2\n\\end{eqnarray}\\]\nThe reason to work with first- and second-order polynomials is rooted in the experience of modelers. Second-order polynomials provide a useful amount of flexibility while remaining simple and avoiding pitfalls."
  },
  {
    "objectID": "Modeling/05-low-order-polynomials.html#eight-simple-shapes",
    "href": "Modeling/05-low-order-polynomials.html#eight-simple-shapes",
    "title": "12  Low-order polynomials",
    "section": "12.3 Eight simple shapes",
    "text": "12.3 Eight simple shapes\nAn easy way to think about how to use low-order polynomials in modeling is to think about the shapes of their graphs. Figure 12.1 shows eight simple shapes for functions with a single input that occur often in modeling.\n\n\n\n\n\nFigure 12.1: The eight simple shapes of functions with one input.\n\n\n\n\nRecall that Chapter Section 6 introduced terms such as concavity, monotonicity, and slope for describing functions. To choose among these shapes, consider your modeling context:\n\nis the relationship positive (slopes up) or negative (slopes down)?\nis the relationship monotonic or not?\nis the relationship concave up, concave down, or neither?\n\nEach of the eight simple shapes corresponds to a particular set of answers to these equations. Consider these modeling contexts as examples:\n\nHow many minutes can you run as a function of speed? Concave down and downward sloping: Shape (F). In everyday terms, you wear out faster if you run at high speed.\nHow much fuel is consumed by an aircraft as a function of distance? For long flights, the function is concave up and positive sloping: Shape (D). In everyday terms: fuel use increases with distance, but the amount of fuel you have to carry also increases with distance. A heavy aircraft uses more fuel per mile.\nHow far can you walk as a function of time? Steep-then-shallow and concave down: Shape (E). Your pace slows as you get tired.\nHow does the stew taste as a function of saltiness? There’s a local maximum: Shape (H). The taste improves as the amount of salt increases … up to a point. Too much salt and the stew is unpalatable.\nThe incidence of an out-of-control epidemic versus time is concave up, but shallow-then-steep. As the epidemic is brought under control, the decline is steep-then-shallow and concave up. Over the whole course of an epidemic, there is a maximum incidence. Experience shows that epidemics can have a phase where incidence reaches a local minimum: a decline as people practice social distancing followed by an increase as people become complacent.\nIn micro-economic theory there are production functions that describe how much of a good is produced at any given price, and demand functions that describe how much of the good will be purchased as a function of price. As a rule, production increases with price and demand decreases with price.\nIn the short term, production functions tend to be concave down, since it’s hard to squeeze increased production out of existing facilities. Production functions are Shape (E).\n\nFor demand in the short term, functions will be concave up when there is some group of consumers who have no other choice than to buy the product. Downward sloping and concave up: Shape (C). In the long term, consumption functions can be concave down as consumers find alternatives to the high-priced good. For example, high prices of gasoline may, in the long term, prompt a switch to more efficient cars, hybrids, or electric vehicles. This will push demand down steeply.\n\n\nRemarkably, all the eight simple shapes can be generated by appropriate choices for the coefficients in a second-order polynomial: \\(g(x) = a_0 + a_1 x + a_2 x^2\\). So long as \\(a_2 \\neq 0\\), the graph of the second-order polynomial will be a parabola.\n\nThe parabola opens upward if \\(0 < a_2\\). That’s the shape of a local minimum.\nThe parabola opens downward if \\(a_2 < 0\\). That’s the shape of a local maximum\n\nConsider what happens if \\(a_2 = 0\\). The function becomes simply \\(a_0 + a_1\\, x\\), the straight-line function.\n\nWhen \\(0 < a_1\\) the line slopes upward.\nWhen \\(a_1 < 0\\) the line slopes downward.\n\nTo produce the steep-then-shallow or shallow-then-steep shapes, you also need to restrict the function domain to be on one side or another of the turning point of the parabola as shown in Figure 26.3.\n\n\n\n\n\nFigure 12.2: Four of the eight simple shapes correspond to the sides of the parabola. The labels refer to the graphs in Figure 12.1."
  },
  {
    "objectID": "Modeling/05-low-order-polynomials.html#sec-low-order-two",
    "href": "Modeling/05-low-order-polynomials.html#sec-low-order-two",
    "title": "12  Low-order polynomials",
    "section": "12.4 Polynomials with two inputs",
    "text": "12.4 Polynomials with two inputs\nFor functions with two inputs, the low-order polynomial approximation looks like this:\n\\[g(x, y) \\equiv a_0 + a_x x + a_y y + a_{xy} x y + a_{yy} y^2 + a_{xx} x^2\\]\nIt helps to have different names for the various terms. It’s not too bad to say something like, “the \\(a_{xy}\\) term.” (Pronunciation: “a sub x y” or “a x y”) But the proper names are: linear terms, quadratic terms, and interaction term. And a shout out to \\(a_0\\), the constant term.\n\\[g(x, y) \\equiv a_0 + \\underbrace{a_x x + a_y y}_\\text{linear terms} \\ \\ \\ +\n\\underbrace{a_{xy} x y}_\\text{interaction term} +\\ \\ \\  \\underbrace{a_{yy} y^2 + a_{xx} x^2}_\\text{quadratic terms}\\]\nThe interaction term arises in models of phenomena such as the spread of epidemics, the population dynamics of predator and prey animals, and the rates of chemical reactions. In each of these situations, one thing is interacting with another: a predator killing a prey animal, an infective individual meeting a person susceptible to the disease, one chemical compound reacting with another.\nUnder certain circumstances, modelers include one or both quadratic terms, as in \\[h_3(x, y) \\equiv c_0 + c_x\\, x + c_y\\, y + c_{xy}\\,x\\, y + \\underbrace{c_{yy}\\, y^2}_\\text{quadratic in y}\\] The skilled modeler can often deduce which terms to include from basic facts about the system being modeled. We’ll need some additional calculus concepts before we can explain this straightforwardly.\n\n\n\n\n\n\nA second-order polynomial with two inputs can take on any one of three shapes: a bowl, a hilltop, or a saddle.\n\n\n\n\n\nFigure 12.3: The three forms for a second-order polynomial with two inputs.\n\n\n\n\nOther shapes for modeling can be extracted from these three basic shapes. For example, the lower-right quadrant of the Saddle has the shape of seats in an amphitheater."
  },
  {
    "objectID": "Modeling/05-low-order-polynomials.html#theory-out-of-a-hat",
    "href": "Modeling/05-low-order-polynomials.html#theory-out-of-a-hat",
    "title": "12  Low-order polynomials",
    "section": "12.5 Theory out of a hat",
    "text": "12.5 Theory out of a hat\nThe start of Chapter Section 11 introduced a little mystery. Newton introduced his Law of Cooling in the 17th century: The rate at which an object cools depends on the difference in temperature between the object and its ambient environment. But in the 17th century, there was no precise way to measure a rate of temperature change. So how did Newton do it?\nEven with primitive thermometers, one can confirm that a mug of hot water will cool and a glass of cold water will warm to room temperature and stay there. So Newton could deduce that the rate of temperature change is zero when the object’s temperature is the same as the environment. Similarly, it’s easy to observe with a primitive thermometer that a big difference in temperature between an object and its environment produces a rapid change in temperature, even if you can’t measure the rate precisely. So the rate of cooling is a function of the temperature difference \\(\\Delta T\\) between object and environment.\nWhat kind of function?\nLow-order polynomials to the rescue! The simplest model is that the rate of cooling will be \\(a_0 + a_1 \\Delta T\\), a first-order polynomial. But we know that the rate of cooling is zero when \\(\\Delta T = 0\\), implying that \\(a_0=0\\). All that’s left is the first-order term \\(\\Delta T\\), which you can recognize as the proportional() function."
  },
  {
    "objectID": "Modeling/05-low-order-polynomials.html#exercises",
    "href": "Modeling/05-low-order-polynomials.html#exercises",
    "title": "12  Low-order polynomials",
    "section": "12.6 Exercises",
    "text": "12.6 Exercises\n<!– Drill\n\n\nPart i In the polynomial \\(a_0 + a_x x + a_y y + a_{xy} xy\\), what is the term \\(a_{xy}xy\\) called?\nConstant term Quadratic termInteraction term Linear term\n\n\n\n\nPart ii In the polynomial \\(a_0 + a_x x + a_y y + a_{xx} xx\\), what is the coefficient on the interaction term?\n\\(a_0\\)\\(a_{xy}\\)0\\(a_{xx}\\)\n\n\n\n\nPart iii Imagine a second-order polynomial in three inputs: \\(x\\), \\(y\\), and \\(z\\), like this: \\[b_0 + b_x x + b_y y + b_z z + b_{xy} xy + b_{xz} xz + b_{xx} x^2 + b_{yy} y^2 + b_zz z^2\\ .\\] All of the possible second-order (or less) terms are shown, except for one. Which term is missing?\n\nthe constant term\nthe quadratic term in \\(z\\)\nthe interaction between \\(y\\) and \\(z\\)\nthe linear term in \\(y\\)"
  },
  {
    "objectID": "Modeling/06-operations.html",
    "href": "Modeling/06-operations.html",
    "title": "13  Operations on functions",
    "section": "",
    "text": "Chapters Section 8 through Section 11 introduced concepts and techniques for constructing functions. This is an important aspect of building models, but it is not the only one. Typically, a modeler, after constructing appropriate functions, will manipulate them in ways that provide the information required to answer questions that motivated the modeling work.\nThis will introduce some of the operations and manipulations used to extract information from model functions.1 There are five such operations that you will see many times throughout this book. They are:\nThis chapter will introduce the first three of these. The remaining two—differentiation and integration—are the core operations of calculus. They will be introduced starting in Block ?sec-differentiation.\nWe will look at the three operations from two different perspectives: graphical and computational. Often, a graph can let you carry out the operation with sufficient precision for the purpose at hand. Graphs are relatively modern, coming into mainstream use only in the 1700s. Much of mathematics was developed before graphs were invented. One consequence of this is that function tasks that are easy using a graph might be very hard with the previous algebraic ways of implementing functions.\nMore refined work is done with a computer. We’ll show you software that will let you direct the computer to do precise calculations. The computing algorithms used for inversion and optimization are often based on concepts from calculus that we have not yet encountered. The magic of software is the way it allows experts in a field to communicate with newbies so that people new to a field can use the operation in practice without necessarily developing a complete theoretical understanding of the algorithm. At this stage, our computational focus will be on how to set up the calculation and how to interpret the results."
  },
  {
    "objectID": "Modeling/06-operations.html#zero-finding",
    "href": "Modeling/06-operations.html#zero-finding",
    "title": "13  Operations on functions",
    "section": "13.1 Zero finding",
    "text": "13.1 Zero finding\nA function is a mechanism for turning any given input into an output. Zero finding is about going the other way: given an output value, find the corresponding input. As an example, consider the exponential function \\(e^x\\). Given a specific input, say \\(x=2.135\\) you can easily compute the corresponding output:\n\nexp(2.135)\n## [1] 8.457047\n\nBut suppose the information you have at hand is in the form of an output from the function, say \\(e^{x_0} = 4.93\\). We don’t (yet) know \\(x_0\\) but, whatever it might be, we know that \\(e^{x_0}\\) will produce the value 4.93.\nHow do you find the specific input \\(x_0\\) that will produce that output? The answer typically presented in high school is to apply another function, \\(\\ln()\\), to the output:\n\nlog(4.93)\n## [1] 1.595339\n\nTo confirm that the result 1.595339 is correct, apply the exponential function to it and check that the output is the same as the original, given output 4.93.\n\nexp(1.595339)\n## [1] 4.93\n\nThis process works because we happen to have a function at hand, the logarithm, that is perfectly set up to “undo” the action of the exponential function. In high school, you learned a handful of function/inverse pairs: exp() and log() as you’ve just seen, sin() and arcsin(), square and square root, etc.\nAnother situation that is usually addressed in high school is inverting low-order polynomial functions. For instance, suppose your modeling function is \\(g(x) \\equiv 1.7 - 0.85 x + 0.063 x^2\\) and you seek the \\(x_0\\) such that \\(g(x_0) = 3\\). High school students are taught to approach such problems in a process using the quadratic formula. In order to apply the quadratic formula, you need to place the problem into a standard format, not \\[1.7 - 0.85 x + 0.063 x^2 = 3\\] but \\[0.063\\, x^2 - 0.85\\, x - 1.4 = 0\\]\nOne reason that low-order polynomials are popular in modeling is that such operations are straightforward.\nIf none of the high-school approaches are suited to your modeling function, as is often the case, you can still carry out the zero-finding operation.\n\n13.1.1 Graphical zero-finding\n\n\n\n\n\n\nFigure 13.1: Finding an \\(x_0\\) such that \\(h(x_0) = 3\\)\n\n\n\nSuppose you may have a function \\(h(x)\\) that you constructed by linear combination and/or function multiplication and/or function composition. To illustrate, we’ll work with the function \\(h(x)\\) graphed in Figure 13.1. And suppose the output for which we want to find a corresponding input is 3, that is, we want to find \\(x_0\\) such that \\(h(x_0)=3\\).\nThe steps of the process are:\n\n\nThe name “zero-finding” can be a little misleading. The objective is find \\(x_0\\) such that \\(h(x_0) = b\\). In this sense, “b-finding” would be a more appropriate name. Instead of chasing after honey as “b-finding” suggests, we reformat the problem into finding \\(x_0\\) such that \\(h(x_0) - b = 0\\). In other words, we look for zeros of the function \\(h(x) - b\\).\n\nGraph the function \\(h(x)\\) over a domain interval of interest.\nDraw a horizontal line located at the value on the right-hand side of the equation \\(h(x_0) = 3\\). (This is the \\(\\color{magenta}{\\text{magenta}}\\) line in Figure 13.1.)\nFind the places, if any, where the horizontal line intersects the graph of the function. In Figure 13.1, there are two such values: \\(x_0 = -3.5\\) or \\(x_0 = 2.75\\).\n\n\nThe graph shows a function \\(g(t)\\). Find a value \\(t_0\\) such that \\(g(t_0) = 5\\).\n\n\n\n\n\n\n\n\n\n\nDraw a horizontal line at output level 5.\nFind the t-value where the horizontal line intersects the function graph. There’s only one such intersection and that’s at about \\(t=1.2\\).\n\nConsequently, \\(t_0 = 1.2\\), at least to the precision possible when reading a graph.\n\nThe graphical approach to zero finding is limited by your ability to locate positions on the vertical and horizontal axis. If you need more precision than the graph provides, you have two options:\n\nTake a step-by-step approach. Use the graph to locate a rough value for the result. Then refine that answer by drawing another graph, zooming in on a small region around the result from the first step. You can iterate this process, repeatedly zooming in on the result you got from the previous step.\nUse software implementing a numerical zero-finding algorithm. Such software is available in many different computer languages and a variety of algorithms is available, each with its own merits and demerits.\n\n\n\n13.1.2 Numerical zero finding\nIn this book, we will use the R/mosaic Zeros() function. The first argument is a tilde expression and the second argument an interval of the domain over which to search.\nZeros() is set up to find inputs where the function defined in the tilde expression produces zero as an output. But suppose you are dealing with a problem like \\(f(x) = 10\\)? You can modify the tilde expression so that it implements a slightly different function: \\(f(x) - 10\\). If we can find \\(x_0\\) such that \\(f(x_0) - 10 = 0\\), that will also be the \\(x_0\\) satisfying \\(f(x_0) = 10\\).\n\nThe point of this example is to show how to use Zeros(), so we’ll define a function \\(f(x)\\) using rfun() from R/mosaic. This constructs a function by taking a linear combination of other functions selected at random. The argument seed=579 determines which functions will be in the linear combination.\n\nf <- rfun( ~ x, seed=579)\n\nWe want to find the zeros of the function \\(f(x) - 10\\) which corresponds to solving \\(f(x) = 10\\).\n\nZeros(f(x) - 10 ~ x, domain(x=-4:4))\n## # A tibble: 0 × 2\n## # … with 2 variables: x <dbl>, .output. <dbl>\n\nThe output produced by Zeros() is a data frame with one row for each of the \\(x_0\\) found. Here, two values were found: \\(x_0 = -2.92\\) and \\(x_0 = 0.0795\\). The .output column reports \\(f(x_0)\\) which should be zero. It’s not always feasible to reach zero exactly, since computer arithmetic is not always exactly precise.\nThink about Zeros() as a way to refine answers you found graphically. So before using Zeros(), make the graph. ::: {.cell .column-margin layout-align=“center” fig.showtext=‘false’}\nslice_plot(f(x) ~ x, domain(x=-4:4)) %>%\n  gf_hline(yintercept = ~ 10, color=\"magenta\")\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "Modeling/06-operations.html#optimization",
    "href": "Modeling/06-operations.html#optimization",
    "title": "13  Operations on functions",
    "section": "13.2 Optimization",
    "text": "13.2 Optimization\nOptimization problems consist of both a modeling phase and a solution phase.\n\n13.2.1 Graphical optimization\nLook for local peaks, then read off the input that generates the value at the peak.\n\n\n13.2.2 Numerical optimization\nWhen it comes to functions, maximization is the process of finding an input to the function that produces a larger output than any of the other, nearby inputs.\nTo illustrate, Figure 13.2 shows a function with two peaks.\n\n\n\n\n\nFigure 13.2: a function with two peaks\n\n\n\n\nJust as you can see a mountain top from a distance, so you can see where the function takes on its peak values. Draw a vertical line through each of the peaks. The input value corresponding to each vertical line is called an argmax, short for “the argument2 at which the function reaches a local maximum value.\nMinimization refers to the same technique, but where the vertical lines are drawn at the deepest point in each “valley” of the function graph. An input value located in one of those valleys is called an argmin.\nOptimization is a general term that covers both maximization and minimization.\n\n\n13.2.3 Numerical optimization\nThe R/mosaic argM() function a functions argmax and argmin over a given domain. It works in exactly the same way as slice_plot(), but rather than drawing a graphic it returns a data frame giving the argmax in one row and the argmin in another. For instance, the function shown in Figure 13.2 is \\(h()\\), generated by rfun():\n\nh <- rfun(~ x, seed=7293)\nargM(h(x) ~ x, domain(x=-5:5))\n## # A tibble: 2 × 3\n##        x .output. concavity\n##    <dbl>    <dbl>     <dbl>\n## 1 -1.68      1.93         1\n## 2  0.173     8.25        -1\n\nThe x column holds the argmax and argmin, the .output. column gives the value of the function output for the input x. The concavity column tells whether the function’s concavity at x is positive or negative. Near a peak, the concavity will be negative; near a valley, the concavity is positive. Consequently, you can see that the first row of the data frame corresponds to a local minimum and the second row is a local maximum.\nargM() is set up to look for a single argmax and a single argmin in the domain interval given as the second argument. In Figure 13.2 there are two local peaks and two local valleys. argM() gives only the largest of the peaks and the deepest of the valleys."
  },
  {
    "objectID": "Modeling/06-operations.html#iteration",
    "href": "Modeling/06-operations.html#iteration",
    "title": "13  Operations on functions",
    "section": "13.3 Iteration",
    "text": "13.3 Iteration\nMany computations involve starting with a guess followed by a step-by-step process of refining the guess. A case in point is the process for calculating square roots. There isn’t an operational formula for a function that takes a number as an input and produces the square root of that number as the output. When we write \\(\\sqrt{\\strut x}\\) we aren’t saying how to calculate the output, just describing the sort of output we are looking for.\nThe function that is often used to calculate \\(\\sqrt{x}\\) is better():\n\\[\\text{better(guess)} = \\frac{1}{2}\\left( \\text{guess} + \\frac{x}{\\text{guess}}\\right)\\ .\\]\nIt may not be at all clear why this formula is related to finding a square root. Let’s put that matter off until the end of the section and concentrate our attention on how to use it.\nTo start, let’s define the function for the computer:\n\nbetter <- makeFun((guess + x/guess)/2 ~ guess)\n\nNotice that \\(x\\) is cast in the role of a parameter of the function rather than an input to the function.\nSuppose we want to apply the square root function to the input 55, that is, calculate \\(\\sqrt{\\strut x=55}\\). The value we should assign to \\(x\\) is therefore 55.\nTo calculate better(guess) we need not only \\(x=55\\) but a value for the guess. What should be this value and what will we do with the quantity better(guess) when we’ve calculated it.\nWithout explanation, we’ll use guess = 1, regardless of the value of \\(x\\). Calculating the output …\n\nbetter(1, x=55)\n## [1] 28\n\nNeither our guess 1 nor the output 28 are \\(\\sqrt{\\strut x=55}\\). (Having long-ago memorized the squares of integers, we know \\(\\sqrt{\\strut x=55}\\) will be somewhere between 7 and 8. Neither 1 nor 28 are in that interval.)\nThe people—more than two thousand years ago—who invented the ideas behind the better() function were convinced that better() constructs a better guess for the answer we seek. It’s not obvious why 28 should be a better guess than 1 for \\(\\sqrt{\\strut x=55}\\) but, out of respect, let’s accept their claim.\nThis is where iteration comes in. Even if 28 is a better guess than 1, 28 is still not a good guess. But we can use better() to find something better than 28:\n\nbetter(28, x=55)\n## [1] 14.98214\n\nTo iterate an action means to perform that action over and over again. (“Iterate” stems from the Latin word iterum, meaning “again.”) A bird iterates its call, singing it over and over again. In mathematics, “iterate” has a twist. When we repeat the mathematical action, we will draw on the results of the previous angle rather than simply repeating the earlier calculation.\nWe’ll continue our iteration of better(). ::: {.cell layout-align=“center” fig.showtext=‘false’}\nbetter(14.98214, x=55)\n## [1] 9.326589\nbetter(9.326589, x=55)\n## [1] 7.611854\nbetter(7.611854, x=55)\n## [1] 7.418713\nbetter(7.418713, x=55)\n## [1] 7.416199\nbetter(7.416199, x=55)\n## [1] 7.416198\n::: In the last step, the output of better() is practically identical to the input, so no reason to continue. We can confirm that the last output is a good guess for \\(\\sqrt{\\strut x=55}\\): ::: {.cell layout-align=“center” fig.showtext=‘false’}\n7.416198^2\n## [1] 54.99999\n:::\n\n13.3.1 Graphical iteration\n\nggcobweb <- function(tilde, domain, x0, n=5) {\n  myarrow = grid::arrow(ends=\"last\", length=unit(.1, \"cm\"),\n                        type=\"closed\")\n  f <- makeFun(tilde)\n  Seq <- Iterate(f, x0=1, n=n)\n  names(Seq) <- c(\"step\", \"xstart\")\n  Seq <- Seq %>% \n    mutate(xend=lead(xstart))\n  \n    \n    gf_abline(intercept = ~ 0, slope = 1, color=\"blue\", linetype = \"dotted\") %>%\n    gf_refine(coord_fixed()) %>%\n    gf_segment(xstart + xend ~ xstart + xstart, data= Seq, color=\"magenta\", arrow = myarrow, inherit=FALSE) %>%\n    gf_segment(xend+xend ~ xstart + xend, data = Seq, color=\"magenta\", arrow = myarrow) %>%\n    slice_plot(f(x) ~ x, domain, npts=500)  %>%\n    gf_lims(y=range(unlist(domain))) \n}\n\nTo iterate graphically, we graph the function to be iterated and mark the initial guess on the horizontal axis. For each iteration step, trace vertically from the current point to the function, then horizontally to the line of identity (blue dots). The result will be the starting point for the next guess.\n\n\n\n\n\nFigure 13.3: Three steps of iteration of better() starting with an initial guess of 1.\n\n\n\n\n\n\n13.3.2 Numerical iteration\nUse the R/mosaic Iterate() function. The first argument is a tilde expression defining the function to be iterated. The second is the starting guess. The third is the number of iteration steps. For instance:\n\nIterate(better(guess, x=55) ~ guess, x0=1, n=8)\n##   n     guess\n## 1 0  1.000000\n## 2 1 28.000000\n## 3 2 14.982143\n## 4 3  9.326590\n## 5 4  7.611854\n## 6 5  7.418713\n## 7 6  7.416199\n## 8 7  7.416198\n## 9 8  7.416198\n\nThe output produced by Iterate() is a data frame. The initial guess is in the row with \\(n=0\\). Successive rows give the output, step by step, with each new iteration step.\n\nWhere does better() come from?\nFor calculating square roots, we used the function \\[\\text{better}(y) = \\frac{1}{2}\\left( y + \\frac{x}{y}\\right)\\ .\\] Let’s suppose you happened on a guess that is exactly right, that is \\(y = \\sqrt{x}\\). There’s no way to improve on a guess that is exactly right, so the best better() can do is to return the guess unaltered. Indeed it does: \\[\\text{better}\\left(y=\\!\\!\\sqrt{\\strut x}\\ \\right) = \\frac{1}{2}\\left( \\sqrt{\\strut x} + \\frac{x}{\\sqrt{x}} \\right)\\ = \\frac{1}{2}\\left(\\sqrt{\\strut x} + \\sqrt{\\strut x}\\right) = \\sqrt{\\strut x}.\\]\nOf course, the initial guess \\(y\\) might be wrong. There are two ways to be wrong:\n\nThe guess is too small, that is \\(y < \\sqrt{\\strut x}\\).\nThe guess is too big, that is \\(\\sqrt{\\strut x} < y\\).\n\nThe formula for better() is the average of the guess \\(y\\) and another quantity \\(x/y\\). If \\(y\\) is too small, then \\(x/y\\) must be too big. If \\(y\\) is too big, then \\(x/y\\) must be too small.\nAs guesses, the two quantities \\(y\\) and \\(x/y\\) are equivalent in the sense that \\(\\text{better}(y) = \\text{better}(x/y)\\). The average of \\(y\\) and \\(x/y\\) will be closer to the true result than the worst of \\(y\\) or \\(x/y\\); the average will be a better guess."
  },
  {
    "objectID": "Modeling/06-operations.html#functions-with-multiple-inputs-draft",
    "href": "Modeling/06-operations.html#functions-with-multiple-inputs-draft",
    "title": "13  Operations on functions",
    "section": "13.4 Functions with multiple inputs [DRAFT]",
    "text": "13.4 Functions with multiple inputs [DRAFT]\nDO I NEED THIS???\nSHOW A contour plot: find the zeros and extrema graphically.\nWe can’t readily graph functions with three or more inputs. So zero finding or optimization with such functions requires other methods. The calculus concepts and tools we’ll study in Block ?sec-differentiation-part will provide the basis for these methods."
  },
  {
    "objectID": "Modeling/06-operations.html#exercises",
    "href": "Modeling/06-operations.html#exercises",
    "title": "13  Operations on functions",
    "section": "13.5 Exercises",
    "text": "13.5 Exercises"
  },
  {
    "objectID": "Modeling/07-magnitudes.html",
    "href": "Modeling/07-magnitudes.html",
    "title": "14  Magnitude",
    "section": "",
    "text": "People accomplish a familiar mathematical task with hardly any mental effort: comparing two numbers to determine which is bigger. This is easy because we have adopted a system for writing numbers that makes it easy. For the Romans and Europeans up through the 13th century, numbers were hard to work with. For instance, which of these three numbers is bigger? \\[\\text{MLI or CXII or XXXIII}\\]\nNow try the same task with Arabic numerals: Which is bigger?\n\\[\\text{512 or 33 or 1051}\\] You can see the answer at a glance. The algorithm is straightforward: select the number with the largest number of digits. If there is a tie, refer to the first digit. If there is still a tie, refer to the next digit. In contrast, it takes much more work with Roman numerals. For instance, IC is about fifteen times bigger than VI, even though I is much smaller than V."
  },
  {
    "objectID": "Modeling/07-magnitudes.html#order-of-magnitude",
    "href": "Modeling/07-magnitudes.html#order-of-magnitude",
    "title": "14  Magnitude",
    "section": "14.1 Order of magnitude",
    "text": "14.1 Order of magnitude\nWe’ll refer to judging the size of numbers by their count of digits as reading the magnitude of the number. To get started, consider numbers that start with 1 followed by zeros, e.g. 100 or 1000. We’ll quantify the magnitude as the number of zeros: 100 has a magnitude of 2 and 1000 has a magnitude of 3. In comparing numbers by magnitude, we way things like, “1000 is an order of magnitude greater than 100,” or “1,000,000” is five orders of magnitude larger than 10.\nMany phenomena and quantities are better understood in terms of magnitude than in terms of number. An example: Animals, including humans, go about the world in varying states of illumination, from the bright sunlight of high noon to the dim shadows of a half-moon. To be able to see in such diverse conditions, the eye needs to respond to light intensity across many orders of magnitude.\nThe lux is the unit of illuminance in the Système international. This table1 shows the illumination in a range of familiar outdoor settings:\n\n\n\nIlluminance\nCondition\n\n\n\n\n110,000 lux\nBright sunlight\n\n\n20,000 lux\nShade illuminated by entire clear blue sky, midday\n\n\n1,000 lux\nTypical overcast day, midday\n\n\n400 lux\nSunrise or sunset on a clear day (ambient illumination)\n\n\n0.25 lux\nA full Moon, clear night sky\n\n\n0.01 lux\nA quarter Moon, clear night sky\n\n\n\nFor a creature active both night and day, the eye needs to be sensitive over 7 orders of magnitude of illumination. To accomplish this, eyes use several mechanisms: contraction or dilation of the pupil accounts for about 1 order of magnitude, photopic (color, cones) versus scotopic (black-and-white, rods, nighttime) covers about 3 orders of magnitude, adaptation over minutes (1 order), squinting (1 order).\nMore impressively, human perception of sound spans more than 16 orders of magnitude in terms of the energy impinging on the eardrum. The energy density of perceptible sound ranges from the threshold of hearing at 0.000000000001 Watt per square meter to a conversational level of 0.000001 W/m2 to 0.1 W/m2 in the front rows of a rock concert. But in terms of our subjective perception of loudness, each order of magnitude change is perceived in the same way, whether it be from street traffic to vacuum cleaner or from whisper to normal conversation. (The unit of sound measurement is the decibel (dB), with 10 decibels corresponding to an order of magnitude in the energy density of sound.)\n\n\n\nEnergy density of sound in various situations. Sound at 85 dB, for extended periods, can cause permanent hearing loss. Exposure to sound at 120 dB over 30 seconds is dangerous.\n\n\n\n\n\n\nSituation\nEnergy level (dB)\n\n\n\n\nRustling leaves\n10 dB\n\n\nWhisper\n20 dB\n\n\nMosquito buzz\n40 dB\n\n\nNormal conversation\n60 dB\n\n\nBusy street traffic\n70 dB\n\n\nVacuum cleaner\n80 dB\n\n\nLarge orchestra\n98 dB\n\n\nEarphones (high level)\n100 dB\n\n\nRock concert\n110 dB\n\n\nJackhammer\n130 dB\n\n\nMilitary jet takeoff\n140 dB\n\n\n\n\n\n6, 60, 600, and 6000 miles-per-hour are quantities that differ in size by orders of magnitude. Such differences often point to a substantial change in context. A jog is 6 mph, a car on a highway goes 60 mph, a cruising commercial jet goes 600 mph, and a rocket passes through 6000 mph on its way to orbital velocity. From an infant’s crawl to highway cruising is 2 orders of magnitude in speed.\nOf course, many phenomena are not well represented in terms of orders of magnitudes. For example, the difference between normal body temperature and high fever is 0.01 orders of magnitude in temperature.2 An increase of 1 order of magnitude in blood pressure from the normal level would cause instant death! The difference between a very tall adult and a very short adult is about 1/4 of an order of magnitude.\nOrders of magnitude are used when the relevant comparison is a ratio. “A car is 10 times faster than a person,” refers to the ratio of speeds. In contrast, quantities such as body temperature, blood pressure, and adult height are compared using a difference. Fever is 2\\(^circ\\)C higher in temperature than normal. A 30 mmHg increase in blood pressure will likely correspond to developing hypertension. A very tall and a very short adult differ by about 2 feet.\nOne clue that thinking in terms of orders of magnitude is appropriate is when you are working with a set of objects whose range of sizes spans one or many factors of 2. Comparing baseball and basketball players? Probably no need for orders of magnitudes. Comparing infants, children, and adults in terms of height or weight? Orders of magnitude may be useful. Comparing bicycles? Mostly they fit within a range of 2 in terms of size, weight, and speed (but not expense!). Comparing cars, SUVs, and trucks? Differences by a factor of 2 are routine, so thinking in terms of order of magnitude is likely to be appropriate.\nAnother clue is whether “zero” means “nothing.” Daily temperatures in the winter are often near “zero” on the Fahrenheit or Celcius scales, but that in no way means there is a complete absence of heat. Those scales are arbitrary. Another way to think about this clue is whether negative values are meaningful. If so, thinking in terms of orders of magnitude is not likely to be useful."
  },
  {
    "objectID": "Modeling/07-magnitudes.html#counting-digits",
    "href": "Modeling/07-magnitudes.html#counting-digits",
    "title": "14  Magnitude",
    "section": "14.2 Counting digits",
    "text": "14.2 Counting digits\nImagine having a digit counting function called digit(). It takes a number as input and produces a number as output. We don’t have a formula for digit(), but for some inputs, the output can be calculated just by counting. For example:\n\ndigit(10) \\(\\equiv\\) 1\ndigit(100) \\(\\equiv\\) 2\ndigit(1000) \\(\\equiv\\) 3\n… and so on …\ndigit(1,000,000) \\(\\equiv\\) 6\n… and on.\n\nThe digit() function easily can be applied to the product of two numbers. For instance:\n\ndigit(1000 \\(\\times\\) 100) = digit(1000) + digit(100) = 3 + 2 = 5.\n\nSimilarly, applying digit() to a ratio gives the difference of the digits of the numerator and denominator, like this:\n\ndigit(1,000,000 \\(\\div\\) 10) = digit(1,000,000) - digit(10) = 6 - 1 = 4\n\nIt is not clear that \\(\\ln()\\) is a better user interface as a pattern-book function than digit(), or, as it is written, \\(\\log_{10}()\\) and log10(). People find it much easier to count by magnitudes of 10 than by the natural logarithm’s 2.718282….\nIn practice, digit() is so useful that it could well have been one of our basic modeling functions: \\[\\text{digit(x)} = 2.302585 \\ln(x)\\] or, in R, log10(). We elected the natural logarithm \\(\\ln()\\) rather than digit() for reasons that will be seen when we study differentiation.\nYou may have guessed that digits() is handy for computing differences in terms of orders of magnitude. Here’s how:\n\nMake sure that the quantities are expressed in the same units.\nCalculate the difference between the digits() of the numerical part of the quantity.\n\n\nWhat is the order-of-magnitude difference in velocity between a snail and a walking human? A snail slides at about 1 mm/sec, a human walks at about 5 km per hour. Putting human speed in the same units as snail speed: \\[\\begin{eqnarray}5 \\frac{km}{hr} = \\left[\\frac{1}{3600} \\frac{hr}{sec}\\right] 5 \\frac{km}{hr} &=& \\\\\n\\left[10^6 \\frac{mm}{km}\\right] \\left[\\frac{1}{3600} \\frac{hr}{sec}\\right] 5 \\frac{km}{hr} &=& 1390 \\frac{mm}{sec}\n\\end{eqnarray}\\] Calculating the difference in digits() between 1 and 1390:\n\nlog10(1390) - log10(1)\n## [1] 3.143015\n\nSo, about 3 orders of magnitude difference in speed. To a snail, we walking humans must seem like rockets on their way to orbit!\n\nThe use of factors of 10 in counting orders of magnitude is arbitrary. A person walking and a person jogging are on the edge of being qualitatively different, although their speeds differ by a factor of only 2. Aircraft that cruise at 600 mph and 1200 mph are qualitatively different in design, although the speeds are only a factor of 2 apart. A professional basketball player (height 2 meters or more) is qualitatively different from a third grader (height about 1 meter)."
  },
  {
    "objectID": "Modeling/07-magnitudes.html#sec-magnitude-graphics",
    "href": "Modeling/07-magnitudes.html#sec-magnitude-graphics",
    "title": "14  Magnitude",
    "section": "14.3 Magnitude graphics",
    "text": "14.3 Magnitude graphics\nTo display a variable from data that varies over multiple orders of magnitude, it helps to plot the logarithm rather than the variable itself. Let’s illustrate using the Engine data frame, which contains measurements of many different internal combustion engines of widely varying sizes. For instance, we can graph engine RPM (revolutions per second) versus engine mass, as in Figure 14.2.\n\ngf_point(RPM ~ mass, data = Engines)\n\n\n\n\n\nFigure 14.2: Engine RPM versus mass for 39 different enginges plotted on the standard linear axis.\n\n\n\nIn the graph, most of the engines have a mass that is … zero. At least that’s what it appears to be. The horizontal scale is dominated by the two huge 100,000-pound monster engines plotted at the right end of the graph.\nPlotting the logarithm of the engine mass spreads things out, as in Figure 14.3.\n\ngf_point(RPM ~ mass, data = Engines) %>%\n  gf_refine(scale_x_log10())\n\n\n\n\n\nFigure 14.3: Engine RPM versus mass on semi-log axes.\n\n\n\nNote that the horizontal axis has been labeled with the actual mass (in pounds), with the labels evenly spaced in terms of their logarithm. This presentation, with the horizontal axis constructed this way, is called a semi-log plot.\nWhen both axes are labeled this way, we have a log-log plot, as shown in Figure 14.4.\n\ngf_point(RPM ~ mass, data = Engines) %>%\n  gf_refine(\n    scale_x_log10(),\n    scale_y_log10()\n    )\n\n\n\n\n\nFigure 14.4: Engine RPM versus mass on log-log axes.\n\n\n\nSemi-log and log-log axes are widely used in science and economics, whenever data spanning several orders of magnitude need to be displayed. In the case of the engine RPM and mass, the log-log axis shows that there is a graphically simple relationship between the variables. Such axes are very useful for displaying data but can be hard for the newcomer to read quantitatively. For example, calculating the slope of the evident straight-line relationship in Figure 14.4 is extremely difficult for a human reader and requires translating the labels into their logarithms.\n\nRobert Boyle (1627-1691) was a founder of modern chemistry and the scientific method in general. As any chemistry student already knows, Boyle sought to understand the properties of gasses. His results are summarized in Boyle’s Law.\nThe data frame Boyle contains two variables from one of Boyle’s experiments as reported in his lab notebook: pressure in a bag of air and volume of the bag. The units of pressure are mmHg and the units of volume are cubic inches.3\nFamously, Boyle’s Law states that, at a constant temperature, the pressure of a constant mass of gas is inversely proportional to the volume occupied by the gas. Figure 14.5 shows a cartoon of the relationship.\n\n\n\n\n\nFigure 14.5: A cartoon illustrating Boyle’s Law. Source: NASA Glenn Research Center\n\n\n\n\nFigure 14.6 plots out Boyle’s actual experimental data. I\n\ngf_point(pressure ~ volume, data = Boyle) %>%\n  gf_lm()\n\n\n\n\n\nFigure 14.6: A plot of Boyle’s pressure vs volume data on linear axes. The straight line model is a poor representation of the pattern seen in the data.\n\n\n\nYou can see a clear relationship between pressure and volume, but it’s hardly a linear relationship.\nPlotting Boyle’s data on log-log axes reveals that, in terms of the logarithm of pressure and the logarithm of volume, the relationship is linear.\n\ngf_point(log(pressure) ~ log(volume), data = Boyle) %>%\n  gf_lm()\n\n\n\n\n\nFigure 14.7: Plotting the logarithm of pressure against the logarithm of volume reveals a straight-line relationship.\n\n\n\n\nFigure 14.7 shows that Boyle’s log-pressure and log-volume data are a straight-line function. In other words:\n\\[\\ln(\\text{Pressure}) = a + b \\ln(\\text{Volume})\\]\nYou can find the slope \\(b\\) and intercept \\(a\\) from the graph. For now, we want to point out the consequences of the straight-line relationship between logarithms.\nExponentiating both sides gives \\[e^{\\ln(\\text{Pressure})} = \\text{Pressure} = e^{a + b \\ln(\\text{Volume})} = e^a\\  \\left[e^{ \\ln(\\text{Volume})}\\right]^b = e^a\\, \\text{Volume}^b\\] or, more simply (and writing the number \\(e^a\\) as \\(A\\))\n\\[\\text{Pressure} = A\\,  \\text{Volume}^b\\] A power-law relationship!"
  },
  {
    "objectID": "Modeling/07-magnitudes.html#sec-reading-log-axes",
    "href": "Modeling/07-magnitudes.html#sec-reading-log-axes",
    "title": "14  Magnitude",
    "section": "14.4 Reading logarithmic scales",
    "text": "14.4 Reading logarithmic scales\nPlotting the logarithm of a quantity gives a visual display of the magnitude of the quantity and labels the axis as that magnitude. A useful graphical technique is to label the axis with the original quantity, letting the position on the axis show the magnitude.\nTo illustrate, ?fig-mag-scales-1(left) is a log-log graph of horsepower versus displacement for the internal combustion engines reported in the Engines data frame. The points are admirably evenly spaced, but it is hard to translate the scales to the physical quantity. The right panel in ?fig-mag-scales-1 shows the same data points, but now the scales are labeled using the original quantity.\n\ngf_point(log(BHP) ~ log(displacement), data = Engines)\ngf_point(BHP ~ displacement, data = Engines) %>%\n  gf_refine(scale_y_log10(), scale_x_log10()) \n\n\n\n\nFigure 14.8: Horsepower versus displacement from the Engines data.frame plotted with log-log scales.\n\n\n\n\n\n\n\nFigure 14.9: Horsepower versus displacement from the Engines data.frame plotted with log-log scales.\n\n\n\n\nThe tick marks on the vertical axis in the left pane are labeled for 0, 2.5, 5.0, 7.5, and 10. That doesn’t refer to the horsepower itself, but to the logarithm of the horsepower. The right pane has tick labels that are in horsepower at positions marked 1, 10, 100, 1000, and 10000.\nSuch even splits of a 0-100 scale are not appropriate for logarithmic scales. One reason is that 0 cannot be on a logarithmic scale in the first place since \\(\\log(0) = -\\infty\\).\nAnother reason is that 1, 3, and 10 are pretty close to an even split of a logarithmic scale running from 1 to 10. It’s something like this:\n1              2            3          5            10     x\n|----------------------------------------------------|\n0               1/3         1/2        7/10          1     log(x)\nIt’s nice to have the labels show round numbers. It’s also nice for them to be evenly spaced along the axis. The 1-2-3-5-10 convention is a good compromise; almost evenly separated in space yet showing simple round numbers."
  },
  {
    "objectID": "Modeling/07-magnitudes.html#exercises",
    "href": "Modeling/07-magnitudes.html#exercises",
    "title": "14  Magnitude",
    "section": "14.5 Exercises",
    "text": "14.5 Exercises"
  },
  {
    "objectID": "Modeling/08-dimensions.html",
    "href": "Modeling/08-dimensions.html",
    "title": "15  Dimensions and units",
    "section": "",
    "text": "Next time you’re at a family gathering with your 10-year-old cousin, give her the following math quiz.\nI don’t know your cousin, but I suspect she will have an easy time answering (1) and (2) correctly. As for (3), she might give the correct answer, “5 miles,” or just say “5.” If so, you’ll follow up with “5 what?” at which point she’ll respond, “miles.”\n10-year-olds are pretty creative, so I’m not sure how she’ll answer (5). But if you ask your Ph.D. aunt, she’ll answer along the lines of “silly question,” or “there’s no such thing.” That’s true.\nConsider these everyday quantities:\nHow would you measure such things?\nIt makes sense to multiply and divide different types of quantities: feet, gallons, kilometers, kilograms, pounds, hours, etc. But you won’t ever see a quantity constructed by adding or subtracting miles and hours or gallons and square feet. You can square feet and cube centimeters, but can you take the square root of a gallon? Does it make sense to raise 2 to the power of 3 yards?\nThis section is about the mathematical structure of combining quantities; which kinds of mathematical operations are legitimate and which are not."
  },
  {
    "objectID": "Modeling/08-dimensions.html#mathematics-of-quantity",
    "href": "Modeling/08-dimensions.html#mathematics-of-quantity",
    "title": "15  Dimensions and units",
    "section": "15.1 Mathematics of quantity",
    "text": "15.1 Mathematics of quantity\n\nThe first step in understanding the mathematics of quantity is to make an absolute distinction between two concepts that, in everyday life, are used interchangeably: dimension and unit.\nLength is a dimension. Meters is a unit of length. We also measure length in microns, mm, cm, inches, feet, yards, kilometers, and miles, to say nothing of furlongs, fathoms, astronomical units (AU), and parsecs.\nTime is a dimension. Seconds is a unit of time. We also measure time in micro-seconds, milliseconds, minutes, hours, days, weeks, months, years, decades, centuries, and millenia.\nMass is a dimension. Kilograms is a unit of mass.\nLength, time, and mass are called fundamental dimensions. This is not because length is more important than area or volume. It’s because you can construct area and volume by multiplying lengths together. This is evident when you consider units of area like square inches or cubic centimeters, but obscured in the names of units like acre, liter, gallon.\n\n\nWe’ll write the few basic fundamental dimensions using capital letters: L, T, M, P, S, \\(\\Theta\\). Dimensions are never expressed in terms of units. In contrast, quantities are a number value combined with the unit that value refers to.\nThe square brackets \\([\\) and \\(]\\) signify that we are looking at the dimension of the quantity inside the brackets. For instance, the population of the US state Colorado is about 5.8 million people. Surround that with square brackets and you get [5.8 million people] which is a dimension, namely, P.\nWe use the notation L, T, and M to refer to the fundamental dimensions. (Electrical current Q is also a fundamental dimension, but we won’t have much use for it in our examples. Also useful are \\(\\Theta\\) (“theta”) for temperature, S for money, and P for a count of organisms such as the population of the US or the size of a sheep herd.)\nBrackets translate between a quantity and the dimension. For instance, [1 yard] = L, [1000 kg] = M, [3 years] = T, [10 \\(\\mu\\) (microns)] = L,"
  },
  {
    "objectID": "Modeling/08-dimensions.html#compound-dimensions",
    "href": "Modeling/08-dimensions.html#compound-dimensions",
    "title": "15  Dimensions and units",
    "section": "15.2 Compound dimensions",
    "text": "15.2 Compound dimensions\nThere are other dimensions: volume, force, pressure, energy, torque, velocity, acceleration, and such. These are called compound dimensions because we represent them as combinations of the fundamental dimensions, L, T, and M. The notation for these combinations involves multiplication and division. For instance:\n\nVolume is L \\(\\times\\) L \\(\\times\\) L \\(=\\) L\\(^3\\), as in “cubic centimeters”\nVelocity is L/T, as in “miles per hour”\nForce is M L/T\\(^2\\), which is obscure unless you remember Newton’s Second Law that \\(\\text{F} = \\text{m}\\,\\text{a}\\): “force equals mass times acceleration.” In terms of dimension, mass is M, acceleration is L/T\\(^2\\). Multiply the two together and you get the dimension “force.”\n\nMultiplication and division are used to construct a compound dimension from the fundamental dimensions L, T, and M.\nAddition and subtraction are never used to form a compound dimension.\nMuch of the work in understanding dimensions involves overcoming the looseness of everyday speech. Remember the weight scale graduated in pounds and kilograms. The unit kilograms is a way of measuring M, but the unit of pounds is a way of measuring force: M L/T\\(^2\\).\nWeight is not the same as mass. This makes no sense to most people and doesn’t matter in everyday life. It’s only when you venture off the surface of the Earth that the difference shows up. The Mars rover Perseverance weighs 1000 kg on Earth. It was weightless for most of its journey to Mars. After landing on Mars, Perseverence weighed just 380 kg. But the rover’s mass didn’t change at all.\nAnother source of confusion carried over from everyday life is that sometimes we measure the same quantity using different dimensions. You can measure a volume by weighing water; a gallon of water weighs 8 pounds; a liter of water has a mass of 1 kg. Serious bakers measure flour by weight; a casual baker uses a measuring cup. We can measure water volume with length because water has a (more-or-less) constant mass density. But 8 pounds of gasoline is considerably more than a gallon. It turns out that the density of flour varies substantially depending on how it’s packed, humidity, etc. This is why it matters whether you weigh flour for baking or measure it by volume. You can measure time by the swing of a pendulum. To measure the same time successfully with different pendula they need to have the same length, not the same mass.\nA unit is a conventional amount of a quantity of a given dimension. All lengths are the same dimensionally, but they can be measured with different conventions: inches, yards, meters, … Units for the same dimension can all be converted unambiguously one into the other. A meter is the same quantity of length as 39.3701 inches, a mile is the same length as 1609.34 meters. Liters and gallons are both units of volume (L\\(^3\\)): a gallon is the same as 3.78541 liters.\nYou will hear it said that a kilogram is 2.2 pounds. That’s not strictly true. A kilogram has dimension M and a pound has dimension ML/T\\(^2\\). Quantities with different dimensions cannot be “equal” or even legitimately compared to one another. Unless you bring something else into the game that physically changes the situation, for instance, gravity (dimension of acceleration due to gravity (dimension \\(\\text{L}/\\text{T}^2\\)). The weight of a kilogram on the surface of the Earth is 2.2 pounds because gravitational acceleration is (almost) the same everywhere on the surface of the Earth.\nIt’s also potentially confusing that sometimes different dimensions are used to get at the same idea. For instance, the same car that gets 35 miles / gallon in the US (dimension \\(\\text{L}/\\text{L}^3 = 1/\\text{L}^2\\)) will use 6.7 liters per 100 kilometers (\\(\\text{L}^3 / L = \\text{L}^2\\)) in Europe. Same car. Same fuel. Different conventions using different dimensions.\nKeeping track of the various compound dimensions can be tricky. For many people, it’s easier to keep track of the physical relationships involved and use that knowledge to put together the dimensions appropriately. Often, the relationship can be described using specific calculus operations, so knowing dimensions and units helps you use calculus successfully.\nEasy compound dimensions that you likely already know:\n\n[Area] \\(= \\text{L}^2\\). Some corresponding units to remind you: “square feet”, “square miles”, “square centimeters.”\n[Volume] \\(= \\text{L}^3\\). Units to remind you: “cubic centimeters”, “cubic feet”, “cubic yards.” (What landscapers informally call a “yard,” for instance “10 yards of topsoil” should properly be called “10 cubic-yards of topsoil.”)\n[Velocity] \\(= \\text{L}/\\text{T}\\). Units: “miles per hour,” “inches per second.”\n[Momentum] \\(= \\text{M}\\text{L}/\\text{T}\\). Units: “kilogram meters per second.”\n\nAnticipating that you will return to this section for reference, we’ve also added some dimensions that can be understood through the relevant calculus operations.\n\n[Acceleration] \\(= \\text{L}/\\text{T}^2\\). Units: “meters per second squared,” In calculus, acceleration is the derivative of velocity with respect to time, or, equivalently, the 2nd derivative of position with respect to time.\n[Force] \\(= \\text{M}\\, \\text{L}/\\text{T}^2\\) In calculus: force is the derivative of momentum with respect to time.\n[Energy] or [Work] \\(= \\text{M}\\, \\text{L}^2/\\text{T}^2\\) In calculus, energy is the integral of force with respect to length.\n[Power] \\(= \\text{M}\\, \\text{L}^2/\\text{T}^3\\) In the language of calculus, power is the derivative of energy with respect to time.\n\n\nDensity sounds like a specific concept, but there are many different kinds of densities. These have in common that they are a ratio of a physical amount to a geometric extent:\n\na physical amount: which might be mass, charge, people, etc.\na geometric extent: which might be length, area, or volume.\n\nSome examples:\n\n“paper weight” is the mass per area, typically grams-per-square-meter\n“charge density” is the amount of electrical charge, usually per area or volume\n“lineal density of red blood cells” is the number of cells in a capillary divided by the length of the capillary. (Capillaries are narrow. Red blood cells go through one after the other.)\n“population density” is people per area of ground.\n\n\n\nThe theory of dimensions and units was developed for the physical sciences. Consequently, the fundamental dimensions are those of physics: length, mass, time, electrical current, and luminous intensity.\nSince proper use of units is important even outside the physical sciences, it’s helpful to recognize the dimension of several other kinds of quantity.\n\n“people” / “passengers” / “customers” / “patients” / “cases” / “passenger deaths”: these are different different ways to refer to people. We’ll consider such quantities to have dimension P, for population.\n“money”: Units are dollars (in many varieties: US, Canadian, Australian, New Zealand), euros, yuan (synonym: renminbi), yen, pounds (many varieties: UK, Egypt, Syria, Lebanon, Sudan, and South Sudan), pesos (many varieties), dinar, franc (Swiss, CFA), rand, riyal, rupee, won, and many others. Conversion rates depend on the situation and national policy, but we will consider money a dimension, denoted by S (from the name of the first coinage, the Mesopotamian Shekel).\n\nExamples:\n\nPassenger-miles is a standard unit of transport.\nPassenger-miles-per-dollar is an appropriate unit of the economic efficiency of transport.\nPassenger-deaths per million passenger-mile is one way to describe the risk of transport."
  },
  {
    "objectID": "Modeling/08-dimensions.html#arithmetic-with-dimensions",
    "href": "Modeling/08-dimensions.html#arithmetic-with-dimensions",
    "title": "15  Dimensions and units",
    "section": "15.3 Arithmetic with dimensions",
    "text": "15.3 Arithmetic with dimensions\nRecall the rules for arithmetic dimensioned quantities. We restate them briefly with the square-bracket notation for “the dimension of.” For instance, “the dimension of \\(b\\)” is written \\([b]\\). We also write \\([1]\\) to stand for the dimension of a pure number, that is, a quantity without dimension.\n::: {#tbl-allowed-operations .column-page-right}\n\n\n\n\n\n\n\n\n\nOperation\nResult\nOnly if satisfies\nMetaphor\n\n\n\n\nMultiplication\n\\([a \\times b] = [a] \\times [b]\\)\nanything goes\npromiscuous\n\n\nDivision\n\\([a \\div b] = [a] \\div [b]\\)\nanything goes\npromiscuous\n\n\nAddition\n\\([a + b] = [a]\\)\n\\([a] = [b]\\)\nmonogomous\n\n\nSubtraction\n\\([a - b] = [a]\\)\n\\([a] = [b]\\)\nmonogomous\n\n\nTrigonometric\n\\([\\sin(a)] = [1]\\)\n\\([a] = [1]\\)\ncelibate\n\n\nExponential\n\\([e^a] = [1]\\)\n\\([a] = [1]\\) (of course, \\([e] = [1]\\))\ncelibate\n\n\nPower-law\n\\([b ^ a] = \\underbrace{[b]\\times[b]\\times ...\\times [b]}_{a\\ \\ \\text{times}}\\)\n\\([a] = [1]\\) with \\(a\\) an integer\nexponent celibate\n\n\nSquare root\n\\([\\sqrt{b}] = [c]\\)\n\\([b] = [c\\times c]\\)\nidiosyncratic\n\n\nCube root\n\\([\\sqrt[3]{b}] = [c]\\)\n\\([b] = [c \\times c \\times c]\\)\nidiosyncratic\n\n\nHump\n\\([\\text{hump}(a)] = [1]\\)\n\\([a] = [1]\\)\ncelibate\n\n\nSigmoidal\n\\([\\text{sigmoid}(a)] = [1]\\)\n\\([a] = [1]\\)\ncelibate\n\n\n\nConditions under which functions can be applied to dimensionful quantitities. Note that \\([a] = [b]\\) means that the dimension of \\(a\\) and of \\(b\\) are the same. For instance, even though 1 mm and 500 miles are very different distances, [1 mm]\\(=\\)[500 miles]. Both [1 mm] and [500 miles] are dimension L."
  },
  {
    "objectID": "Modeling/08-dimensions.html#sec-pendulum-dimensions",
    "href": "Modeling/08-dimensions.html#sec-pendulum-dimensions",
    "title": "15  Dimensions and units",
    "section": "15.4 Example: Dimensional analysis",
    "text": "15.4 Example: Dimensional analysis\nWe want to relate the period (in T) of a pendulum to its length and mass. Acceleration due to gravity also plays a role; that has dimension \\(\\text{L}\\cdot \\text{T}^{-2}\\). For simplicity, we’ll assume that only the bob at the end of the pendulum cable or rod has mass.\nThe analysis strategy is to combine the four quantities we think play a role into one total quantity that is dimensionless. Since it is dimensionless, it can be constant regardless of the mass, length, period, or gravity of each situation.\n\\[\\text{[Period]}^a \\cdot \\text{[Mass]}^b \\cdot \\text{[Length]}^c \\cdot \\text{[Gravity]}^d = T^a \\cdot M^b \\cdot L^c \\cdot L^d \\cdot T^{-2d} = [1]\\] To be dimensionless:\n\n\\(c = -d\\), cancel out the L\n\\(a = 2d\\), cancel out the T\n\\(b=0\\), there’s no other mass term, and we need to cancel out the M\n\nAll of the exponents can be put in terms of \\(d\\). That doesn’t tell us what \\(d\\) should be, but whatever value for \\(d\\) we decide to choose, we get a ratio that’s equivalent to:\n\\[ \\frac{[\\text{Gravity}]\\cdot [\\text{Period}]^2}{[\\text{Length}]} = [1]\\]\nThis is a relationship between dimensions of quantities. To render it into a formula involving the quantities themselves we need to take into account the units.\n\\[ \\frac{\\text{Gravity}\\cdot \\text{Period}^2}{\\text{Length}} = B\\]\nWe can experimentally determine the numerical value of the dimensionless constant \\(B\\) by measuring the period and length of a pendulum and (on Earth) recognizing that gravitational acceleration on Earth’s surface is 9.8 meters-per-second-squared. Such experiments and mathematical models using differential equations give \\(B = (2\\pi)^2\\)."
  },
  {
    "objectID": "Modeling/08-dimensions.html#conversion-flavors-of-1",
    "href": "Modeling/08-dimensions.html#conversion-flavors-of-1",
    "title": "15  Dimensions and units",
    "section": "15.5 Conversion: Flavors of 1",
    "text": "15.5 Conversion: Flavors of 1\nNumbers are dimensionless but not necessarily unitless. Failure to accept this distinction is one of the prime reasons people have trouble figuring out how to convert from one unit to another.\nThe number one is a favorite of elementary school students because its multiplication and division tables are completely simple. Anything times one, or anything divided by one, is simply that thing. Addition and subtraction are pretty simple, too, a matter of counting up or down.\nWhen it comes to quantities, there’s not just one one but many. And often they look nothing like the numeral 1. Some examples of 1 as a quantity:\n\n\\(\\frac{180}{\\pi} \\frac{\\text{degrees}}{\\text{radians}}\\)\n\\(0.621371 \\frac{\\text{mile}}{\\text{kilometer}}\\)\n\\(3.78541 \\frac{\\text{liter}}{\\text{gallon}}\\)\n\\(\\frac{9}{5} \\frac{^\\circ F}{^\\circ C}\\)\n\\(\\frac{1}{12} \\frac{\\text{dozen}}{\\text{item}}\\)\n\nI like to call these and others different flavors of one.\nIn every one of the above examples, the dimension of the numerator matches the dimension of the denominator. The same is true when comparing feet and meters ([feet / meter] is L/L = [1]), or comparing cups and pints ([cups / pint] is \\(\\text{L}^3/\\text{L}^3 = [1]\\)) or comparing miles per hour and feet per second ([miles/hour / ft per sec] = L/T / L/T = [1]). Each of these quantities has units but it has no dimension.\nIt’s helpful to think about conversion between units as a matter of multiplying by the appropriate flavor of 1. Such conversion will not change the dimension of the quantity but will render it in new units.\n\nExample: Convert 100 feet-per-second into miles-per-hour. First, write the quantity to be converted as a fraction and alongside it, write the desired units after the conversion. In this case that will be \\[100 \\frac{\\text{feet}}{\\text{second}} \\ \\ \\ \\text{into} \\ \\ \\ \\frac{\\text{miles}}{\\text{hour}}\\]\nFirst, we’ll change feet into miles. This can be accomplished by multiplying by the flavor of one that has units miles-per-foot. Second, we’ll change seconds into hours. Again, a flavor of 1 is involved.\nWhat number will give a flavor of one? One mile is 5280 feet, so \\[\\frac{1}{5280} \\frac{\\text{miles}}{\\text{foot}}\\] is a flavor of one.\nNext, we need a flavor of one that will turn \\(\\frac{1}{\\text{second}}\\) into \\(\\frac{\\text{1}}{\\text{hour}}\\). We can make use of a minute being 60 seconds, and an hour being 60 minutes. \\[\\underbrace{\\frac{60\\  \\text{s}}{\\text{minute}}}_\\text{flavor of 1}\\  \\underbrace{\\frac{60\\ \\text{minutes}}{\\text{hour}}}_\\text{flavor of 1} = \\underbrace{3600\\frac{\\text{s}}{ \\text{hour}}}_\\text{flavor of 1}\\]\nMultiplying our carefully selected flavors of one by the initial quantity, we get \\[\n\\underbrace{\\frac{1}{5280} \\frac{\\text{mile}}{\\text{foot}}}_\\text{flavor of 1} \\times \\underbrace{3600 \\frac{\\text{s}}{\\text{hour}}}_\\text{flavor of 1} \\times \\underbrace{100 \\frac{\\text{feet}}{\\text{s}}}_\\text{original quantity} = 100 \\frac{3600}{5280} \\frac{\\text{miles}}{\\text{hour}} = 68.18 \\frac{\\text{miles}}{\\text{hour}}\\]"
  },
  {
    "objectID": "Modeling/08-dimensions.html#dimensions-and-linear-combinations",
    "href": "Modeling/08-dimensions.html#dimensions-and-linear-combinations",
    "title": "15  Dimensions and units",
    "section": "15.6 Dimensions and linear combinations",
    "text": "15.6 Dimensions and linear combinations\nLow-order polynomials are a useful way of constructing model functions. For instance, suppose we want a model of the yield of corn in a field per inch of rain over the growing season, will call it corn(rain). The output will have units of bushels (of corn). The input will have units of inches (of rain). A second-order polynomial will be appropriate for reasons to be discussed in Chapter 24.\n\\[\\text{corn(rain)} \\equiv a_0 + a_1\\, \\text{rain} + \\frac{1}{2} a_2\\, \\text{rain}^2\\] Of course, the addition in the linear combination will only make sense if all three terms \\(a_0\\), \\(a_1\\,\\text{rain}\\), and \\(\\frac{1}{2}\\, a_2\\, \\text{rain}^2/2\\) have the same dimension. But clearly \\([\\text{rain}] \\neq [\\text{rain}^2]\\). In order for things to work out, the coefficients must themselves have dimension. We know the output of the function will have dimension \\([\\text{volume}] = \\text{L}^3\\). Thus, \\([a_0] = \\text{L}^3\\).\n\\([a_1]\\) must be different, because it has to combine with the \\([\\text{rain}] = \\text{L}\\) and produce \\(\\text{L}^3\\). Thus, \\([a_1] = \\text{L}^2\\).\nFinally, \\([a_2] = \\text{L}\\). Multiplying that by \\([\\text{rain}]^2\\) will give the required \\(\\text{L}^3\\)\n\n\nIn everyday communication as well as in most domains such as construction, geography, navigation, and astronomy we measure angles in degrees. 90 degrees is a right angle. But in mathematics, the unit of angle is radians where a right angle is 1.5708 radians. (1.5708 is the decimal version of \\(\\pi/2\\).) The conversion function, which we’ll call raddeg(), is \\[\\text{raddeg}(r) \\equiv \\frac{180}{\\pi} r\\] The function that converts degrees to radians, which we’ll call degrad() is very similar: \\[\\text{degrad}(d) \\equiv \\frac{\\pi}{180} d\\] (Incidentally, \\(\\frac{180}{\\pi} = 57.296\\) while \\(\\frac{\\pi}{180} = 0.017453\\).)\nIn traditional notation, the trigonometric functions such as \\(\\sin()\\) and \\(\\tan()\\) can be written with an argument either in degrees or radians. For instance, \\(\\sin(90^\\circ) = \\sin\\left(\\frac{\\pi}{2}\\right)\\). Similarly, for the inverse functions like \\(\\arccos()\\) the units of the output are not specified. This works because there is always a human to intervene between the written expression and the eventual computation.\nIn R, as in many other computer languages like Python or spreadsheet packages, there is no valid expression like sin(90 deg). In these languages, 90 deg is not a valid expression (although it might be good if it were valid!). In these and many other languages, angles are always given in radians. Such consistency is admirable, but people are not always so consistent. It is a common source of computer bugs that angles in degrees are handed off to functions like \\(\\sin()\\) and that the output of \\(\\arccos()\\) is (wrongly) interpreted as degrees rather than radians.\nFunction composition to the rescue!\nConsider this function given in the Wikipedia article on the position of the sun as seen from Earth.1 \\[\\delta_\\odot(n) \\equiv - 23.44^\\circ \\cdot \\cos \\left [ \\frac{360^\\circ}{365\\, \\text{days}} \\cdot \\left ( n + 10 \\right ) \\right ]\\] Where \\(n\\) is zero at the midnight marking New Years and increases by 1 per day. (The \\(n+10\\) has units of days and translates New Years back 10 days, to the day of the winter solstice.) \\(\\delta_\\odot()\\) gives the declination of the sun: the latitude pieced by an imagined line connecting the centers of the earth and the sun.\nThe Wikipedia formula is well written in that it uses some familiar numbers to help the reader see where the formula comes from. 365 is recognizably the length of the year in days. \\(360^\\circ\\) is the angle traversed when making a full cycle around a circle. \\(23.44^\\circ\\) is less familiar, but the student of geography might recognize it as the latitude of the Tropic of Cancer, the latitude farthest north where the sun is directly overhead at noon (on the day of the summer solstice).\nBut there’s a world of trouble for the programmer who implements the formula as\n\ndec_sun <- makeFun(-23.44 * cos((360/365)*(n+10)) ~ n)\n\nFor instance, the equinoxes are around March 21 (n=81) and Sept 21 (n=264). On an equinox, the declination of the sun is zero degrees. But let’s plug \\(n=81\\) and \\(n=264\\) into the formula and see what we get.\n\ndec_sun(81)\n## [1] 5.070321\ndec_sun(264)\n## [1] -23.38324\n\nThe equinoxes aren’t even equal! And they are not close to zero. Does this mean astronomy is wrong?\nThe Wikipedia formula should have been programmed this way, using 2 \\(\\pi\\) radians instead of 360 degrees in the argument to the cosine function:\n\ndec_sun_right <- \n  makeFun(-23.44 * cos(( 2*pi/365)*(n+10)) ~ n)\ndec_sun_right(81)\n## [1] -0.1008749\ndec_sun_right(264)\n## [1] -0.1008749\n\nThe deviation of one-tenth of a degree reflects rounding off the time of the equinox to the nearest day."
  },
  {
    "objectID": "Modeling/08-dimensions.html#exercises",
    "href": "Modeling/08-dimensions.html#exercises",
    "title": "15  Dimensions and units",
    "section": "15.7 Exercises",
    "text": "15.7 Exercises\n<!– Drill\n\n\nPart i Consider these quantities:\\(a = 25\\) ft \\(b = 3\\) hours\\(c = 4\\)\\(d = 1\\) meter\\(e = 2.718\\) Is this combination dimensionally valid? \\[a / c\\] Why or why not?\n\n\\(c\\) is a dimensionless quantity.\nDivision can accommodate any two quantities, regardless of dimension.\nYou can only divide two quantities of the same dimension.\n\n\n\n\n\nPart ii Consider these quantities:\\(a = 25\\) ft \\(b = 3\\) hours\\(c = 4\\)\\(d = 1\\) meter\\(e = 2.718\\) Is this combination dimensionally valid? \\[\\sqrt{a}\\] Why or why not?\n\nValid. It’s simply 5.\nInvalid. You can’t have a non-integer exponent on a dimension.\nInvalid. 25 feet is not a valid quantity.\n\n\n\n\n\nPart iii Consider these quantities:\\(a = 25\\) ft \\(b = 3\\) hours\\(c = 4\\)\\(d = 1\\) meter\\(e = 2.718\\) Is this combination dimensionally valid? \\[b^c\\] Why or why not?\n\nValid. Exponentiation by a dimensionless integer is always allowed.\nInvalid. Exponentiation of a dimensionful quantity isn’t allowed.\nInvalid. I can’t make any sense out of T\\(^4\\) as a dimension.\n\n\n\n\n\nPart iv Consider these quantities:\\(a = 25\\) ft \\(b = 3\\) hours\\(c = 4\\)\\(d = 1\\) meter\\(e = 2.718\\) Is this combination dimensionally valid? \\[c^b\\] Why or why not?\n\nValid. Exponentiation by a dimensionless integer is always allowed.\nInvalid. Exponentiation by a dimensionful quantity isn’t allowed.\nValid. You can do what you want with plain (dimensionless) numbers like 4.\n\n\n\n\n\nPart v Consider these quantities:\\(a = 25\\) ft \\(b = 3\\) hours\\(c = 4\\)\\(d = 1\\) meter\\(e = 2.718\\) Is this combination dimensionally valid? \\[\\sqrt[3]{a^2 d}\\] Why or why not?\n\nValid. \\(a^2 d\\) is a volume: L\\(^3\\). The cube root of L\\(^3\\) is L.\nInvalid. You can’t raise a dimensionful quantity to a non-integer power.\nInvalid. 25 feet squared is 625 square feet. It makes no sense to multiply square feet by meters.\n\n\n\n\n\nPart vi Consider these quantities:\\(a = 25\\) ft \\(b = 3\\) hours\\(c = 4\\)\\(d = 1\\) meter\\(e = 2.718\\) Is this combination dimensionally valid? \\[\\exp(a d)\\] Why or why not?\n\nValid. The \\(a\\) cancels out the dimension of the \\(b\\).\nInvalid. The input to \\(\\exp()\\) must be a dimensionless quantity.\nInvalid. 25 foot-meters doesn’t mean anything.\n\n\n\n\n\nPart vii Consider these quantities:\\(a = 25\\) ft \\(b = 3\\) hours\\(c = 4\\)\\(d = 1\\) meter\\(e = 2.718\\) Is this combination dimensionally valid? \\[\\exp(c d)\\] Why or why not?\n\nValid. The dimension will be L\\(^4\\)\nInvalid. The input to \\(\\exp()\\) must be a dimensionless quantity.\nInvalid. \\(c d\\) has dimension L.\n\n\n\n\n\nPart viii Consider these quantities:\\(a = 25\\) ft \\(b = 3\\) hours\\(c = 4\\)\\(d = 1\\) meter\\(e = 2.718\\) Is this combination dimensionally valid? \\[\\exp(c/d)\\] Why or why not?\n\nValid. The L dimension of \\(c\\) is cancelled out by the L\\(^{-1}\\) dimension of \\(1/d\\)\nInvalid. The input to \\(\\exp()\\) must be a dimensionless quantity.\nInvalid. \\(c / d\\) has dimension L\\(^{-1}\\).\n\n\n\n\n\nPart ix Here are some physical quantities and their dimension:[Force] = MLT\\(^{-2}\\)[Distance] = L[Area] = L\\(^2\\)[Velocity] = L T\\(^{-1}\\)[Acceleration] = L T\\(^{-2}\\)[Momentum] = M L T\\(^{-1}\\) Given that [Force] = [Pressure][Area], what is the dimension of Pressure?\nM L\\(^{1}\\) T\\(^{-2}\\)M L\\(^{-1}\\) T\\(^{-2}\\)M L\\(^{-2}\\) T\\(^{-1}\\)\n\n\n\n\nPart x Here are some physical quantities and their dimension:[Force] = MLT\\(^{-2}\\)[Distance] = L[Area] = L\\(^2\\)[Velocity] = L T\\(^{-1}\\)[Acceleration] = L T\\(^{-2}\\)[Momentum] = M L T\\(^{-1}\\)Which one of the following statements is true?\n\nVelocity = Mass / Momentum\nMomentum = Mass * Velocity\nMomentum = Mass * Acceleration\n\n\n\n\n\nPart xi Here are some physical quantities and their dimension:[Force] = MLT\\(^{-2}\\)[Distance] = L[Area] = L\\(^2\\)[Velocity] = L T\\(^{-1}\\)[Acceleration] = L T\\(^{-2}\\)[Momentum] = M L T\\(^{-1}\\)Which one of the following statements is true?\n\nArea = Distance / Volume\nVolume = Distance * Area\nForce = Momentum / Acceleration\n\n\n\n\n\nPart xii Here are some physical quantities and their dimension:[Force] = MLT\\(^{-2}\\)[Distance] = L[Area] = L\\(^2\\)[Velocity] = L T\\(^{-1}\\)[Acceleration] = L T\\(^{-2}\\)[Momentum] = M L T\\(^{-1}\\)The dimension of Energy is M L\\(^2\\) T\\(^{-2}\\). Which of the following is true?\n\nForce = Energy / Mass\nEnergy = Distance * Force\nEnergy = Momentum * Acceleration\n\n\n\n\n\nPart xiii Here are some physical quantities and their dimension:[Force] = MLT\\(^{-2}\\)[Distance] = L[Area] = L\\(^2\\)[Velocity] = L T\\(^{-1}\\)[Acceleration] = L T\\(^{-2}\\)[Momentum] = M L T\\(^{-1}\\)Which of the following is true?\n\nLength = Force / Momentum\nLength = Velocity / Acceleration\nArea = Velocity * Acceleration\n\n\n\n\n\nPart xiv Here are some physical quantities and their dimension:[Force] = MLT\\(^{-2}\\)[Distance] = L[Area] = L\\(^2\\)[Velocity] = L T\\(^{-1}\\)[Acceleration] = L T\\(^{-2}\\)[Momentum] = M L T\\(^{-1}\\)Which of the following is true?\n\nMass = Force / Momentum\nLength = Force / Momentum\nTime = Force / Momentum\nArea = Force / Momentum\n\n\n\n\n\nPart xv What kind of thing is \\[\\sqrt[3]{(\\text{4in})(\\text{2 ft})(\\text{1 mile})}\\  ?\\]\nIt’s meaninglessAreaLengthVolume\n\n\n\n\nPart xvi What kind of thing is \\[\\sin(\\pi\\ \\text{seconds})\\  ?\\]\nIt’s meaningless1 / LengthLengthThe number 0\n\n\n\n\nPart xvii If \\(t\\) is measured in seconds and \\(A\\) is measured in feet, what will be the dimension of \\(A \\sin(2\\pi t/P)\\) when \\(P\\) is two hours?\nTLL/T\n\n\n\n\nPart xviii Engineers often prefer to describe sinusoids in terms of their frequency \\(\\omega\\), writing the function as \\(\\sin(2 \\pi \\omega t)\\), where \\(t\\) is time. What is the dimension of \\(\\omega\\)?\nTT\\(^{-1}\\)T\\(^2\\)\n\n\n\n\nPart xix Suppose \\(t\\) is measured in hours and \\(x\\) in yards. What will be the dimension of \\(P\\) in \\[\\sin(2\\pi t x/P)\\ ?\\]\n\nT / L\nL T\nThere’s no such \\(P\\) that will make a valid input to \\(\\sin()\\)\nL / T\n\n\n\n\n\nPart xx What is the value of sin(180)?\n-0.8000.801"
  },
  {
    "objectID": "Modeling/09-modeling-cycle.html",
    "href": "Modeling/09-modeling-cycle.html",
    "title": "16  Modeling cycle [DRAFT]",
    "section": "",
    "text": "INCLUDE POLISHING IN THIS CHAPTER"
  },
  {
    "objectID": "Modeling/09-modeling-cycle.html#possible-introduction",
    "href": "Modeling/09-modeling-cycle.html#possible-introduction",
    "title": "16  Modeling cycle [DRAFT]",
    "section": "16.1 Possible introduction",
    "text": "16.1 Possible introduction\nSeen very abstractly, a mathematical model is a set of functions that represent the relationships between inputs and outputs.\nAt the most simple level, building a model can be a short process:\n\nDevelop an understanding of the relationship you want to model. Often, part of this “understanding” is the pattern seen in data.\nChoose a function type—e.g. exponential, sinusoidal, sigmoid—that you think would be a good match to the relationship.\nFind parameters that scales your function to be able to accept real-world inputs and generate real-world outputs.\n\nIt’s important to distinguish between two basic types of model:\n\nEmpirical models which are rooted in observation and data.\nMechanistic models such as those created by applying fundamental laws of physics, chemistry, and such.\n\nWe are going to put off mechanistic models for a while, for two reasons. First, the “fundamental laws of physics, chemistry, and such” are often expressed with the concepts and methods of calculus. We are heading there, but at this point you don’t yet know the core concepts and methods of calculus. Second, most students don’t make a careful study of the “fundamental laws of physics, chemistry, and such” until after they have studied calculus. So examples of mechanistic models will be a bit hollow at this point."
  },
  {
    "objectID": "Modeling/09-modeling-cycle.html#an-example-from-the-01-parameters-chapter",
    "href": "Modeling/09-modeling-cycle.html#an-example-from-the-01-parameters-chapter",
    "title": "16  Modeling cycle [DRAFT]",
    "section": "16.2 AN EXAMPLE FROM THE 01-parameters chapter",
    "text": "16.2 AN EXAMPLE FROM THE 01-parameters chapter\n\nYou can see in Figure @ref(fig:covid-exp2) that the exponential function plotted in \\(\\color{blue}{\\text{blue}}\\) does not align perfectly with the day-by-day data. For instance, during the interval from March 8 to 21, the function output is consistently higher than the data suggest it should be. As part of the modeling cycle it’s important to notice such discrepancies and try to understand them. In this case, it’s likely that during the early days of the pandemic the number of reported deaths understated the actual number of COVID-related deaths. This happens because, in the early days of the pandemic, many deaths from COVID were mis-attributed to other causes.\n\n\nEffective modelers treat models with skepticism. They look for ways in which models fail to capture salient features of the real world. They have an eye out for deviations between what their models show and what they believe they know about the system being modeled. They consider ways in which the models might not serve the purpose for which they were developed.\nWhen modelers spot a failure or deviation or lack of proper utility, they might discard the model but more often they make a series of small adjustments, tuning up the model until is successfully serves the purposes for which it is intended.\nThus, modeling is a cyclic process of creating a model, assessing the model, and revising the model. The process comes to a sort of preliminary end when the model serves its purposes. But even then, models are often revised to check whether the results are sensitive to some factor that was not included or to check whether some component that was deemed essential really is so."
  },
  {
    "objectID": "Modeling/09-modeling-cycle.html#example-cooling-water",
    "href": "Modeling/09-modeling-cycle.html#example-cooling-water",
    "title": "16  Modeling cycle [DRAFT]",
    "section": "16.3 Example: Cooling water",
    "text": "16.3 Example: Cooling water\nLooking back on the exponential fitted to the cooling water data in ?sec-fit-exponential, it looks like our original estimate of the half-life is a bit too small; the data doesn’t seem to decay at the rate implied by \\(k = -0.0277\\). Perhaps we should try a somewhat slower decay, say \\(k = -0.2\\) and see if that improves things.\n\nIn the cooling water example, we’re using only a subset of the data collected by Prof. Wagon. The next commands re-create that subset so that you can work with it. They also plot the data and an exponential model.\n\n# reconstruct the sample\nset.seed(101)\nStans_data <- CoolingWater %>% sample_n(20)\n# Plot the sample and overlay a model\ngf_point(temp ~ time, data=Stans_data) %>%\n  gf_lims(y = c(20, NA)) %>%\n  slice_plot(25 + 83.3*exp(-.0277*time) ~ time, color=\"dodgerblue\")\n\n\n\n\n\n\n\n\nSee if \\(k=-0.02\\) provides a better fit to the model. (You can add another slice_plot() to be able to compare the original and \\(k=-0.02\\) models.)\n\nLater in this course, we’ll study optimization. There are optimization techniques for directing the computer to refine the parameters to best match the data. Just to illustrate, here’s what we get:\n\n\n\n\nrefined_params <-\n  fitModel(temp ~ A + B*exp(k*time), data = Stans_data,\n           start = list(A = 25, B = 83.3, k = -0.0277))\ncoef(refined_params)\n##           A           B           k \n## 25.92628463 60.69255269 -0.01892572\nnew_f <- makeFun(refined_params)\ngf_point(temp ~ time, data = Stans_data) %>%\n  slice_plot(new_f(time) ~ time, color=\"dodgerblue\")\n\n\n\n\nFigure 16.1: Polishing the fit using the rough model as a starting point.\n\n\n\n\nThe refined parameters give a much better fit to the data than our original rough estimates by eye.\nWe had two rounds of the modeling cycle. First, choice of an exponential model and a rough estimate of the parameters A, B, and \\(k\\). Second, refinement of those parameters using the computer.\nLooking at the results of the second round, the experienced modeler can see some disturbing discrepancies. First, the estimated baseline appears to be too high. Related, the initial decay of the model function doesn’t seem to be fast enough and the decay of the model function for large \\(t\\) appears to be too slow. Prof. Stan Wagon noticed this. He used additional data to fill in the gaps for small \\(t\\) and refined his model further by changing the basis functions in the linear combination. He hypothesized that there are at least two different cooling processes. First, the newly poured water raises the temperature of the mug itself. Since the water and mug are in direct contact, this is a fast process. Then, the complete water/mug unit comes slowly into equilibrium with the room temperature.\nThe newly refined model was a even better match to the data. But nothing’s perfect and Prof. Wagon saw an opportunity for additional refinement based on the idea that there is a third physical mechanism of cooling: evaporation from the surface of the hot water. Prof. Wagon’s additional circuits of the modeling cycle were appropriate to his purpose, which was to develop a detailed understanding of the process of cooling. For other purposes, such as demonstrating the appropriateness of an exponential process or interpolating between the data points, earlier cycles might have sufficed.\nHere’s a graph of the model Prof. Wagon constructed to match the data.\n\n\n\n\n\nFigure 16.2: A model that combines three exponentials provides an excellent fit.\n\n\n\n\nThis is an excellent match to the data. But … matching the data isn’t always the only goal of modeling. Prof. Wagon wanted to make sure the model was physically plausible. And looking at the refined parameters, which include two exponential processes with parameters \\(k_1\\) and \\(k_2\\), he saw something wrong:\n\nBut what can we make of \\(k_1\\), whose [positive value] violates the laws of thermodynamics by suggesting that the water gets hotter by virtue of its presence in the cool air? The most likely problem is that our simple model (the proportionality assumption) is not adequate near the boiling point. There are many complicated factors that affect heat transportation, such as air movement, boundary layer dissipation, and diffusion, and our use of a single linear relationship appears to be inadequate. In the next section [of our paper] we suggest some further experiments, but we also hope that our experiments might inspire readers to come up with a better mathematical model.\n\nThe modeling cycle can go round and round!"
  },
  {
    "objectID": "Modeling/09-modeling-cycle.html#example-the-tides",
    "href": "Modeling/09-modeling-cycle.html#example-the-tides",
    "title": "16  Modeling cycle [DRAFT]",
    "section": "16.4 Example: The tides",
    "text": "16.4 Example: The tides\nIn ?sec-fit-periodic we looked at a sinusoid model of tide levels in Rhode Island. We left unresolved how to refine the estimate of the period \\(P\\) and find the time offset \\(t_0\\) in the sinusoidal model \\[\\text{tide}(t) \\equiv A \\sin\\left(\\frac{2\\pi}{P} (t-t_0)\\right) + B\\]\n\\[{\\color{blue}{\\text{tide}(t)} \\equiv 1.05 + 0.55 \\sin(2\\pi (t - t_0)/11)}\\]\nThe new parameter, \\(t_0\\), should be set to be the time of a positive-going crossing of the baseline. Looking at the tide data (black) plotted in Figure @ref(fig:Fun-4-a-3-4) we can pick out such a crossing at about time = 17. Happily, changing the phase does not itself necessitate re-estimating the other parameters: baseline, amplitude, period. This model, incorporating the phase, has been graphed in \\(\\color{blue}{\\text{blue}}\\).\n\n\n\n\n\nFigure 16.3: Shifting the phase of the sinusoid gives the flexibility needed to align the peaks and troughs of the model with the data. Performing this alignment for one peak makes it clear that the period is wrong.\n\n\n\n\n\n\n\nFigure 16.4: Shifting the phase of the sinusoid gives the flexibility needed to align the peaks and troughs of the model with the data. Performing this alignment for one peak makes it clear that the period is wrong.\n\n\n\n\nFor some modeling purposes, such as prediction of future tides, the phase information is essential. For others, say, description of the amplitude of the tides, not. But getting the phase roughly right can help point out other problems. For instance, in the left panel of Figure @ref(fig:Fun-4-a-3-4) the blue model is roughly aligned with the data. Not at all so in the right panel. What leads to the discrepancy is a bad estimate for the period. 13 hours is roughly right, but over a five-day period the error accumulates until, in the right panel, the model has a trough where the data peak, and vice versa.\nAlthough the blue sinusoid is not perfect, having it for comparison suggests that the previously estimated period of 13 hours is too long. We can shorten the period gradually in our model until we find something that better matches the data. For example: Figure @ref(fig:Fun-4-a-3-5) shows that a period of 12.3 hours is a good match to the data.\nWith this refinement the model is \\[{\\color{green}{\\text{tide}(t)} \\equiv 1.05 + 0.55 \\sin(2\\pi (t - 17)/12.3)}\\]\n\n\n\n\n\nFigure 16.5: With the phase about right, a better estimate can be made of the period: 12.3 hours.\n\n\n\n\nWe might call it quits with the model in Figure @ref(fig:Fun-4-a-3-5). But once we have a pretty good model fit, it’s easy to polish the parameter estimates, letting the computer do the tedious work of trying little tweaks to see if it can improve the fit.\nThe R/mosaic fitModel() can do this tweaking for us. As the following commands show, fitModel() takes a tilde expression as input. To the left of the tilde goes the name of the function output in the data frame being used. The right side is a formula for the model, with names used for each parameter and using the names of inputs from the data frame. The second argument is the data frame. The third argument is used to convey an estimate for each parameter; that estimate should be pretty good if fitModel() is to be able to refine it.\nThe output from fitModel() is a function, which we’re naming tide_mod().\n\ntide_mod <-\n  fitModel(level ~ A + B*sin(2*pi*(hour-t0)/P),\n  data = RI_tide,\n  start=list(A=1.05, B=0.55, t0=17, P=12.3))\ncoef(tide_mod)\n##          A          B         t0          P \n##  1.0220540  0.4998367 15.3899905 12.5593556\n\nThe command coef(tide_mod) displays the parameters found by fitModel() which will be an improvement—perhaps a big improvement, perhaps not—on our original estimates.\nThese new parameters differ only slightly from the ones shown in Figure @ref(fig:Fun-4-a-3-5), but the match to the data with the new coefficients is discernably better, even by eye.\n\n\n\n\n\nFigure 16.6: Polishing the parameters of the sinusoid\n\n\n\n\nThis last model seems capable of making reasonable predictions, so if we collected up-to-date data we might be able to fit a new model to predict the tide level pretty accurately a few days ahead of time. Also, the excellent alignment of the model peaks with the data tell us that the cyclic tide has a period that is constant, at least so far as we can tell.\nWith the period estimate \\(P=12.56\\) hours, we can go looking for other phenomena that might account for the tides. The period of the day-night cycle is, of course 24 hours. So the tides in Providence come in and out twice a day. But not exactly. Something else must be going on.\nIsaac Newton was the first to propose that the tides were caused by the gravitational attraction of the Moon. A complete cycle of the Moon—moon rise to moon rise—takes about 50 minutes longer than a full day: the Earth revolves once every 24 hours, but in that time the Moon has moved a bit further on in its orbit of the Earth. So the Moon’s period, seen from a fixed place on Earth is about 24.8 hours. Half of this, 12.4 hours, is awfully close to our estimate of the tidal period: 12.56 hours. The difference in periods, 8 minutes a day, might be hard to observe over only 4 days. Maybe with more data we’d get a better match between the tides and the moon.\nThis is the modeling cycle at work: Propose a model form (a sinusoid), adjust parameters to match what we know (the Providence tide record), compare the model to the data, observe discrepancies, propose a refined model. You can stop the model when it is giving you what you need. The period 12.56 hour model seems good enough to make a prediction of the tide level a few days ahead, and is certainly better than the “two tides a day” model. But our model is not yet able to implicate precisely the Moon’s orbit in tidal oscillations.\nDiscrepancies between a model and data play two roles: they help us decide if the model is fit for the purpose we have in mind and they can point the way to improved models. That the tidal data deviates from the steady amplitude of our model can be a clue for where to look next. It’s not always obvious where this will lead.\nHistorically, careful analysis of tides led to a highly detailed, highly accurate model: a linear combination of sinusoids with periods near a half-day 12.42 , 12.00, 12.66, and 11.97 hours as well components with periods that are about a day long 23.93, 25.82, 24.07, 26.87, and 24.00 hours. A tide-prediction model is constructed by finding the coefficients of the linear combination; these differ from locale to locale. There is no global model of tides, but rather a framework of linear combinations of sinusoids of different periods. What customizes the framework to the tides in a particular locale is the coefficients used in the linear combination.\n\nPolishing the phase (optional)\nLinear combination to represent phase shift. \\(\\sin(x + \\phi) = \\cos(\\phi)\\sin(x) + \\sin(\\phi) \\cos(x)\\)\n\\(C \\sin(x +\\phi) = A \\sin(x) + B \\cos(x)\\) where \\(C^2 = A^2 + B^2\\) and \\(\\phi=\\arctan(A/B)\\)"
  },
  {
    "objectID": "Modeling/09-modeling-cycle.html#modeling-project",
    "href": "Modeling/09-modeling-cycle.html#modeling-project",
    "title": "16  Modeling cycle [DRAFT]",
    "section": "16.5 Modeling project",
    "text": "16.5 Modeling project\nThe data frame SunsetLA records the number of minutes after 4 pm until the sun sets in Los Angeles, CA over a 4-year interval from January 2010 (month 1) through December 2013 (month 48).\n\nOpen a sandbox and make a plot of sunset time versus month.\n\n\ngf_point(Minutes ~ Month, data = SunsetLA) %>%\n  gf_line()\n\n\n\n\n\n\n\n\nWe’re using both gf_point() and gf_line(). With data that oscillates up and down, connecting the data points with lines makes it easier to see the pattern.\n\n\n\nPart A What is the range of the number of minutes until sunset over the whole 4-year period?\n40 to 190 minutes120 minutes40 to 180 minutes0 to 48 months\n\n\n\n\nPart B The data fall nicely on a sine-shaped curve. What is the period of that sine?\n6 months11 months12 months12 minutes\n\n\nThe function \\[\\text{sunset}(\\text{Month}) \\equiv A  \\sin(2 \\pi\\, \\text{Month} / 12) + C\\] is a linear combination of two functions:\n\nThe constant function one(Month)\nThe sine function sin(2*pi*Month/12)\n\nThe two functions are scaled by \\(C\\) and \\(A\\), respectively.\nMake rough but reasonable numeric estimates for \\(C\\) and \\(A\\) from the data. Then, in the sandbox, define the sunset() function using the numerical estimates in the linear combination. Plot your function as a layer on top of the data. (Pipe the gf_point() layer to slice_plot().)\n\n\nsunset <- makeFun(A + C*sin(2*pi*(Month - offset)/12), \n                  A = __your estimate__, \n                  C = __your estimate__,\n                  offset=0)\ngf_point(Minutes ~ Month, data = SunsetLA) %>%\n  gf_line() %>%\n  slice_plot(sunset(Month) ~ Month)\n\nThe domain for slice_plot() is inherited to that implied by the SunsetLA data. Notice that the input name in slice_plot() corresponds to that established in gf_point().\n\n\n\nPart C Your sunset() function should be a pretty good match to the data except for one thing. What is that thing?\n\nThe sunset() function has a completely different range than the data.\nThe period of the sunset() function doesn’t match the data.\nThere is a horizontal time shift between sunset() and the data.\n\n\n\nWe’re going to fix the problem with sunset() by defining a time offset to use as a reference. For a sine function, a suitable time offset is the value along the horizontal axis when the phenomenon being modeled crosses \\(C\\) with a positive slope. There are 4 such points along the horizontal axis readily identifiable in the data. (They may not be at an integer value of Month.)\n\n\nPart D Which of these is a suitable value for the time offset?\n0 months19 months21.5 months15.5 months\n\n\nIn the original scaffolding, the value of offset was zero. Change that to match your answer to the previous question.\nPlot out the modified sunset() function and confirm that it is a much better match to the data than the original (that is, the one without the time offset). You can “tune” your function by tweaking the numerical values of the \\(A\\), \\(C\\), and \\(offset\\) parameters until you get a solid match.\nAlternatively, you can use fitModel() to do the tuning for you. Plug in your estimates (a.k.a. “guesses”) for the parameters in place of the ___ in the following. Then run the code. You’ll see your estimate of the function compared to the result of having the computer refine your estimate. Chances are, the computer does a better job of stringing the function through the data.\n\n\n## rough estimates from graph\nrough_A <- __estimated_A__\nrough_C <- __estimated_C__\nrough_offset <- __estimated_offset___\nguessed_fun <-\n  makeFun(A*sin(2*pi*(Month - offset)/12) + C ~ Month,\n          A  = rough_A, C = rough_C,\n          offset = rough_offset)\n\ntuned_fun <-\n  fitModel(Minutes ~ A*sin(2*pi*(Month - offset)/12) + C,\n         data  = SunsetLA,\n         start = list(A = rough_A,\n                      C = rough_C,\n                      offset = rough_offset) )\n\ngf_point(Minutes ~ Month, data = SunsetLA) %>%\n  gf_line(color  = \"dodgerblue\") %>%\n  slice_plot(tuned_fun(Month) ~ Month) %>%\n  slice_plot(guessed_fun(Month) ~ Month,  color = \"orange3\")\n\n\nPerhaps you were expecting the tuned sine function to match the data exactly. It does not. One reason for this is that the Earth’s orbit around the Sun is not exactly circular. The sine function is only a model of the phenomenon, good for some purposes and not for others. For a more complete explanation, see this article on Wikipedia.\n(Thomas Swalm contributed to this project.)"
  },
  {
    "objectID": "differentiation-part.html",
    "href": "differentiation-part.html",
    "title": "Differentiation",
    "section": "",
    "text": "This is where I’ll explain what the block is about and the overall goals."
  },
  {
    "objectID": "Differentiation/16-rate-of-change.html",
    "href": "Differentiation/16-rate-of-change.html",
    "title": "17  Rate of change",
    "section": "",
    "text": "For our purposes, the definition of calculus is\nThe agenda of this chapter is to give specific mathematical meaning to the word “change.”"
  },
  {
    "objectID": "Differentiation/16-rate-of-change.html#change-and-slope",
    "href": "Differentiation/16-rate-of-change.html#change-and-slope",
    "title": "17  Rate of change",
    "section": "17.1 Change and slope",
    "text": "17.1 Change and slope\nYou have an solid, intuitive sense of what “change” means. In mathematics, and especially the mathematics of functions, change has a very simple meaning that you have already touched on in your previous math education.\nThe word that encapsulates “change” in high-school math is slope. For instance, you’ve undoubtedly had to calculate the slope of a straight line in a graph. You learned about “rise” and “run” and how to read them from a graph or from a formula. The slope is the ratio: rise over run.\nEveryone has a intuitive sense of the slope of a road or of a hillside. You learned to apply this intuition to reading graphs and the slope of a line. We’ll exploit the intuitive ability to read a landscape in order to introduce abstract mathematical ideas in a down-to-earth setting.\nMathematical modelers learn to think of “slope” abstractly, not just as referring to the incline of a road. For instance, the population of a country can change, as can the number of new cases of an epidemic disease, the temperature of a cup of coffee, or the distance from Earth of a spacecraft. A major part of learning calculus is generalizing and abstracting the mathematical concept of which “slope” is an example."
  },
  {
    "objectID": "Differentiation/16-rate-of-change.html#continuous-change",
    "href": "Differentiation/16-rate-of-change.html#continuous-change",
    "title": "17  Rate of change",
    "section": "17.2 Continuous change",
    "text": "17.2 Continuous change\nMost people are comfortable with the ideas of daily changes in temperature or monthly changes in credit-card debt or quarterly changes in the unemployment rate or annual changes in the height of a child. Such things are easy to record in, say, a spreadsheet. For example, as this paragraph is being written, the weather forecast for the next several days (in southeastern Colorado in mid-May) is\nMAYBE SEASONAL CHANGE\n\n\n\nDay\nHigh\nLow\nDescription\n\n\n\n\nThursday\n73\n43\nsunny\n\n\nFriday\n72\n48\nwindy\n\n\nSaturday\n66\n48\nthunderstorms\n\n\nSunday\n68\n43\nwindy\n\n\nMonday\n70\n39\nsunny\n\n\nTuesday\n70\n43\nsunny\n\n\nWednesday\n66\n45\npartly cloudy\n\n\n\nSuch data is said to be discrete. The day is listed, but not the time of day. The high temperature is forecast, but not the time of that high. The “description” is also discrete, one of the several words that are used to summarize the quality of the weather, as opposed to the quantity of rain.\nCalculus is about continuous change. For instance, if the weather bureau provide a web interface that let me enter the date and time to the nearest fraction of a second, they would be giving a way to track the change continuously. Many physical processes are intrinsically continuous, for instance the motion (change in position) of a spacecraft or the height of the tide or the stress on a tree as a function of wind velocity.\nFinding a language to describe continuous change—famously, the position of the moon or planets in their orbit, or the speed of a ball rolling down a ramp—was central to the emergence of what historians call the “Age of Enlightenment” or “modern scientific method.” The first complete presentation of that language was published by Isaac Newton based on his work in the 1660s. As you might guess, the name of the language is “calculus.”"
  },
  {
    "objectID": "Differentiation/16-rate-of-change.html#slope",
    "href": "Differentiation/16-rate-of-change.html#slope",
    "title": "17  Rate of change",
    "section": "17.3 Slope",
    "text": "17.3 Slope\nYou already know pretty much everything there is to know about the straight-line function,\n\nFormula: \\(f(x) \\equiv a x + b\\). The parameters \\(a\\) and \\(b\\) are the “slope” and “intercept” respectively. (More precisely, \\(b\\) is the “y-intercept.” But in statistics and modeling, it’s just the “intercept.”)\nReading parameters from a graph: You learned several ways to do this which are all equivalent. Maybe the easiest is to read the y-intercept off the graph. That’s \\(b\\). Then choose some non-zero \\(x_0\\) and read off from the graph the value of \\(f(x_1)\\). The slope is simply \\[\\frac{f(x_0) - b}{x_0}\\]\nThe y-intercept method is a special case of a more general method, the two-point method, that you can use even if the y-intercept isn’t shown on the graph. Pick two specific values of \\(x\\), which we’ll call \\(x_0\\) and \\(x_1\\). Evalate the function at these input values and compute the rise over run: \\[\\text{rise over run} \\equiv \\frac{f(x_1) - f(x_0)}{x_1 - x_0}\\] The rise over run is the slope of the straight line.\nThe y-intercept method is the same as the two-point method with \\(x_1 = 0\\).\nMatching a straight-line function to data: You might not have been taught this formally, but the basic process is easy to imitate. The process is called line fitting or, in statistics and other fields, linear regression."
  },
  {
    "objectID": "Differentiation/16-rate-of-change.html#average-rate-of-change",
    "href": "Differentiation/16-rate-of-change.html#average-rate-of-change",
    "title": "17  Rate of change",
    "section": "17.4 Average rate of change",
    "text": "17.4 Average rate of change\nSince the slope is our standard way of representing a relationship of change, we will often use it as a way of summarizing a function. To illustrate, consider the exponential model we constructed to match the cooling-water data in ?sec-fit-exponential:\n\nwater <- makeFun(60*exp(-0.0173*t) + 25 ~ t)\n\n\n\n\n\n\nFigure 17.1: The exponential function that was previously matched to the cooling-water data. The slope of the straight line connecting two points on the function graph is the average rate of change during the interval.\n\n\n\n\nDuring the interval \\([t_0, t_1]\\) the rate at which the water cools is higher at first and lower at the end. The average rate of change is a single number that summarizes the whole interval.\nFor all except straight-line models, the average rate of change depends on the interval chosen.\n\n“Slope” is a natural metaphor when thinking of a function as a graph. But a more general way to describe the concept is the rate of change of the output with respect to the input. The change in the output from one end of the interval is \\(f(x_1) - f(x_0)\\), the change in the input is \\(x_1 - x_0\\). If the input is time (in hours), and the output is the position of a car (in miles), then the rate of change is miles-per-hour: the car’s velocity.\nFor a straight-line function—think of a car driving at constant speed on a highway—it doesn’t matter what you choose for \\(x_1\\) and \\(x_0\\) (so long as they are not identical). But for other functions, the choice does matter.\nImagine a graph of the position of a car along a road as in Figure 17.2. Over the course of an hour, the car travelled about 25 miles. In other words, the average speed is 25 miles/hour: the slope of the tan line segment. Given the traffic, sometimes the car was stopped (time C), sometimes crawling (time D) and sometimes much faster than average (time B).\n\n\n\n\n\nFigure 17.2: The position of an imaginary car over time (black curve). The average rate of change over various intervals is the slope of the straight-line segment connecting the start and end of the black curve in that interval.\n\n\n\n\nDuring the interval from B to C, the car was travelling relatively fast. The slope of the \\(\\color{magenta}{\\text{magenta}}\\) segment connecting the position at times B and C is the average rate of change between times B and C. It’s easy to see that the average rate of change from B to C is larger than the overall average from \\(t=0\\) to \\(t=1\\). Calculating that slope is a matter of evaluating the position at the endpoints and dividing by the length of the interval.\n\n\nWhat is the average rate of change in the car’s position during the interval \\(t_B = 0.40\\) to \\(t_C=0.54\\)?\nThe length of the interval is \\(t_C - t_B = 0.54-0.40=0.14\\).\nEvaluating the function gives \\(x(t_C) = 18\\) and \\(x(t_B) = 12.6\\).\nRise is \\(x(t_C) - x(t_B) = 18 - 12.6 = 5.4\\).\nRun is \\(t_C - t_B = 0.54-0.40=0.14\\).\nThe average rate of change during the interval is \\(5.4/0.14 = 38.6\\) miles/hour.\n\n\nFigure 17.3 shows a simplified model of the amount of usable wood that can be harvested from a typical tree in a managed forest of Ponderosa Pine. (You can see some actual forestry research models here.)\n\n\n\n\n\nFigure 17.3: A model, somewhat realistic, of the amount of wood that can be harvested from a Ponderosa Pine as a function of years since planting to harvest.\n\n\n\n\nYou are writing a business plan for a proposed pine forest. Among other things, you have to forecast the revenue that will be generated and when you will have saleable product.\nThey say that “time is money.” Every year you wait before harvest is another year that you don’t have the money. On the other hand, every year that you wait means more wood at the end. How to decide when to harvest?\nThe tree continues to grow until year 50, when it seems to have reached an equilibrium: perhaps growth goes to zero, or rot balances what growth there is. There’s no point waiting until after year 50.\nAt year 25, the tree is growing as fast as it ever will. You’ll get about 600 board-feet of lumber. Should you harvest at year 25? No! That the tree is growing so fast means that you will have a lot more wood at year 26, 27, and so on. The time to harvest is when the growth is getting smaller, so that it’s not worth waiting an extra year.\nThe quantity of interest is the average rate of growth from seedling to harvest. Harvesting at year 25 will give a total change of 600 board feet over 25 years, giving an average rate of change of \\(600 \\div 25 = 24\\ \\text{board-feet-per-year}\\). But if you wait until year 35, you’ll have about 900 board feet, giving an average rate of change of \\(900 \\div 35 = 25.7\\  \\text{board-feet-per-year}\\).\nIt’s easy to construct a diagram that shows whether year 35 is best for the harvest. Recall that our fundamental model of change is the straight-line function. So we’re going to model the model of tree growth as a straight line function. Like the more realistic model, our straight-line model will start out with zero wood at the time of planting. And to be faithful to the realistic model, we’ll insist that the straight-line intersect or touch the realistic model at some point in the future.\nFigure 17.4 reiterates the realistic model of the tree but adds on to it several straight-line models that all give zero harvest-able wood at planting time. Each of the green lines captures a scenario where the tree is harvested at the indicated time: \\(t_1\\), \\(t_2\\), and so on. For the perspective of representing the rate of growth per year from planting to harvest, the straight-line green models do not need to replicate the actual growth curve. The complexities of the curve are not relevant to the growth rate, which can be simplified down to a straight-line model connecting the output at planting time to the output at harvest time. In contrast, the \\(\\color{magenta}{\\text{magenta}}\\) curve is not a suitable model because it doesn’t match the situation at any harvest time; it doesn’t touch the curve anywhere after planting!\n\n\n\n\n\nFigure 17.4: Modeling the tree-growth model with straight lines connecting planting time to various harvest times. The slope of each line is the average rate of growth for that planting time.\n\n\n\n\nTo maximize average lumber volume per year, choose a harvest time that produces the steepest possible green segment. From Figure 17.4 this is the model that glances the growth curve near year 31 (shown as \\(t_3\\) in the diagram).\nIt’s best to find the argmax by creating a function that shows explicitly what one is trying to optimize. (In Chapter 24 we’ll use the name objective function to identify such function.) Here, the objective function is \\(\\text{ave.growth(year)} \\equiv \\text{volume(year)} / \\text{year}\\). See Figure 17.5.\n\n\n\n\n\nFigure 17.5: Graph of the average-growth function ave_growth(year), constructed by dividing volume(year) by year.\n\n\n\n\nThe graph of ave_growth(year) makes it clear that the maximum average growth from planting to harvest will occur at about year 32."
  },
  {
    "objectID": "Differentiation/16-rate-of-change.html#sec-instantaneous-rate-of-change",
    "href": "Differentiation/16-rate-of-change.html#sec-instantaneous-rate-of-change",
    "title": "17  Rate of change",
    "section": "17.5 Instantaneous rate of change",
    "text": "17.5 Instantaneous rate of change\nThe average rate of change is the slope of a line segment connecting two points on the graph of a function, the points \\(\\left(\\strut t_0, f(t_0)\\right)\\) and \\(\\left(\\strut t_1, f(t_1)\\right)\\). It reflects all the point-to-point changes in the value of the function over the interval \\(t_0\\) to \\(t_1\\) in the function’s domain.\nIt turns out to be helpful to consider the rate of change of a function at an individual point \\(t_0\\) in the domain, rather than the interval between two points. This rate of change at a point is called the instantaneous rate of change. In Block 2, we’ll see that a good way to define an instantaneous rate of change at \\(t_0\\) is as the average rate of change over the interval \\(t_0 \\leq t \\leq t_0 + h\\) with the proviso that the interval length \\(h\\) goes as closely as it can to zero. Visually, this is the line that’s tangent to the function’s graph at the input value \\(t_0\\) as in Figure 17.6.\n\n\n\n\n\nFigure 17.6: A line tangent to a the curve at a single point. The slope of this line is the instantaneous rate of change.\n\n\n\n\nIt’s convenient to be able to find the slope of such a tangent line using just the definition \\(f(t)\\), rather than having to draw a graph and eyeball the tangent. For now, let’s approximate the slope of tangent line by the average rate of change over a small run from \\(t_0\\) to \\(t_0 + 0.1\\): \\[\\text{slope of}\\ f(t) \\ \\text{at}\\ t_0 \\approx\\frac{f(t_0 + 0.1) - f(t_0)}{0.1} = \\frac{\\text{amount of rise}}{\\text{length of run}}\\] The \\(\\approx\\) symbol means “is approximately.” For now, I want to put off the question of what “approximately” means. In modeling, whether the 0.1 gives a good enough approximation will depend on the function \\(f()\\) and the context in which the slope is needed. For instance, in drawing Figure 17.6 I needed to find the tangent line. Using 0.1 is entirely satisfactory in this setting but it might not be in other settings.\nThe notation “slope of \\(f(t)\\) at \\(t=t_0\\)” is long-winded and awkward. If we were looking at the “value of \\(f(t)\\) at \\(t_0\\) we have at hand a much more concise notation: \\(f(t_0)\\). But it doesn’t work to write”slope of \\(f(t_0)\\)” because \\(f(t_0)\\) is a quantity and not a function. Instead, let’s make a concise notation for “slope of \\(f(t)\\).” Following tradition, we’ll write \\({\\cal D}f(t)\\). The name of this “slope of \\(f(t)\\)” function is \\({\\cal D}f()\\): a two-letter name. When we want to say, “the (approximate) slope of the tangent line to \\(f(t)\\) at \\(t_0\\), we can write simply: \\[{\\cal D}f(t_0)\\] meaning, evaluate the”slope function of f()” at \\(t_0\\).\nTo formalize this, we’ll define the slope function of f() as \\[{\\cal D}f(t) \\equiv \\frac{f(t + 0.1) - f(t)}{0.1}\\] Let’s look at the slope functions that correspond to some of pattern-book functions: \\(e^x\\), \\(\\sin(x)\\), \\(x^{-1}\\) and \\(\\ln(x)\\). We can define them easily enough in R:\n\nDexp <- makeFun((exp(t+0.1) - exp(t))/0.1 ~ t)\nDsin <- makeFun((sin(t+0.1) - sin(t))/0.1 ~ t)\nDxm1 <- makeFun(((1/(t+0.1)) - (1/t))/0.1 ~ t)\nDlog <- makeFun((log(t+0.1) - log(t))/0.1 ~ t)\n\n\n\n\n\n\nFigure 17.7: Comparing the pattern-book function (blue) to its slope function (tan)\n\n\n\n\n\n\n\nFigure 17.8: Comparing the pattern-book function (blue) to its slope function (tan)\n\n\n\n\n\n\n\nFigure 17.9: Comparing the pattern-book function (blue) to its slope function (tan)\n\n\n\n\n\n\n\nFigure 17.10: Comparing the pattern-book function (blue) to its slope function (tan)\n\n\n\n\n\nWhy did you plot both the function and the slope function in the same graphics frame?\nExcellent question! In general, it is illegitimate to plot a function and it’s slope function on the same vertical axis. The reason is the units of the two functions will be different. For instance, the output of a function position(t) might have units of “miles,” while the output of the slope function of position (that is, \\({\\cal D}\\)position(t) would have units such as miles-per-hour.) So, as a general rule, never plot a function and its corresponding slope function on the same scale.\nAn exception is for the pattern-book functions. These always take a number as input and produce a number as output. The slope function of a pattern-book function also produces a number as output.\nThis exception is not a good excuse for indulging a bad practice. Perhaps you’ll forgive the authors if they claim they wanted to emphasize the point by demonstrating it.\n\n\nHere, we write the slope function of \\(f(t)\\) as \\({\\cal D}f(t)\\). That works for this chapter, which deals with functions with only one input. But in general modeling functions have more than one input, for instance \\(g(x, t)\\). To work with slope functions with more than one input, we need to extend the notation a little. We will place a small subscript after \\({\\cal D}\\) to indicate which input we are changing. Thus, there will be two slope functions for \\(g(x,t)\\): \\[{\\cal D}_{\\color{blue}x} g(x, t) \\equiv \\frac{g({\\color{blue}x + 0.1}, t) - g(x, t)}{0.1}\\] and\n\\[{\\cal D}_{\\color{magenta}t} g(x, t) \\equiv \\frac{g(x, {\\color{magenta}t + 0.1}) - g(x, t)}{0.1}\\] The input referred to in the subscript following \\({\\cal D}\\) is called the with-respect-to input.\n\nThe idealization of the slope function involves replacing \\(h=0.1\\) with something much smaller. What “much smaller” means has been a complicated issue in the history of calculus. Today, we write \\(h \\rightarrow 0\\) to signify the process of making \\(h\\) smaller and smaller, but never zero. When \\(h\\) has this “much smaller” value, the rate of change over the interval \\(x\\) to \\(x+h\\) becomes a rate of change “at \\(x\\)”, also called the instantaneous rate of change at \\(x\\). For the pattern-book functions, \\(h=0.1\\) or smaller gives a pretty good approximation to the instantaneous rate of change. Later, in Block 2, we’ll see how to arrange \\(h\\) so that it’s “much smaller” for functions in general.\n\nIn the previous section we looked at the optimal time to harvest a tree so that the average rate of growth in usable lumber over the tree’s life is maximized. Using a model of tree growth of a ponderosa pine we found the best harvest time to be 32 years.\nLet’s return to the modeling phase of the wood-harvest problem with a new perspective. The real objective of tree farming is to maximize the economic value of the wood. This depends on the market price of the wood which itself may be changing in time. A market-savvy modeler will want to exploit any information about the possibility of rising or falling prices in selecting the best harvest time. Companies often hire economists to forecast market trends, but this requires a deep knowledge of trends in supply and demand which is out of the scope of what we can cover in this book.\nHowever, there is one economic principle that we can incorporate into the model without such detailed, industry specific expertise. This is the economic principle of opportunity cost.\nOpportunity cost takes into account when valuing an asset the other possible uses of that asset. For example, lumber companies constantly invest in planting new trees for future harvest. In order to do this, they borrow money and they pay interest on the borrowed money. They need to borrow because their existing assets are tied up in the form of wood. The opportunity cost of not harvesting a tree is the interest on the loan the company needs to take out in order to invest for the future.\nBetween year 30 and 32, there is hardly any change in the value of the average-rate-of-change function. It’s increasing a little, but is it really worthwhile to wait? One argument is that at year 30 you already have a valuable resource: wood that could be money in the bank. If the money were in the bank, you could invest it and earn more money and at the same time get a new seedling in the ground to start its growth. You’re doing two things at once. Efficient!\nTo know what is the best year for harvest from this point of view, you want to calculate the effective “interest rate” on the present amount of wood that you earn in the form of new wood. That interest rate is the ratio of the instantaneous rate of growth of new wood divided by the amount of existing wood. Figure 17.11 shows this function.\n\n\n\n\n\nFigure 17.11: The instantaneous investment return from the tree is the instantaneous rate of change in wood volume divided by the wood volume itself. This falls over the age of the tree as the harvestable wood volume increases.\n\n\n\n\nEarly in the tree’s life, the growth is high compared to the volume of the tree. That’s because the tree is small. As the years pass, the tree gets bigger. Even though the rate of growth increases through year 23, the accumulated volume increases even faster, so there is a fall in the rate of return.\nThe best time to harvest is when the annual “interest rate” paid by the growing tree falls to the level of the next best available investment. Suppose that investment would pay 10% per year. Then harvest the tree when the function values falls below 10%. That happens at year 24. If the next best investment paid only 5% (blue horizontal line), the harvest should be made at about year 29. If money could be borrowed at 2%, it would be worthwhile to harvest the tree still later."
  },
  {
    "objectID": "Differentiation/16-rate-of-change.html#other-old-stuff",
    "href": "Differentiation/16-rate-of-change.html#other-old-stuff",
    "title": "17  Rate of change",
    "section": "17.6 Other old stuff",
    "text": "17.6 Other old stuff\nThe rate of change is based on a simple question: If the input changes from \\(x = A\\) to \\(x = B\\), how much does the output change? Of course, the output from function \\(f(x)\\) will be \\(f(x=A)\\) and \\(f(x=B)\\) respectively. The rate-of-change relationship is the ratio \\[\\frac{\\color{red}{f(x=B) - f(x=A)}}{\\color{blue}{B-A}}\\ \\ \\text{also written}\\ \\ \\frac{\\color{red}{\\text{rise}}}{\\color{blue}{\\text{run}}}\\]\nWhy do we focus on the rate of change rather than something simpler, for example the net change \\(\\color{red}{f(x=B) - f(x=A)}\\)? The reason goes back to a scientific breakthrough in the 1600s: the writing down of the Newton’s laws of motion. The language in which these laws were first successfully expressed is the language of rates of change. In the intervening 400 years, the laws have been updated with the theory of relativity and quantum mechanics. These laws too are expressed as rates of change. In undertaking to study just about any quantitative field from engineering to economics you’ll find that theory is expressed using functions and rates of change.\nYou may recognize in the formula for the rate of change a familiar quantity: the slope of a line. Everyone understands what a line is, but the geometry is not our primary concern here. We describe relationships using functions and for us the straight-line function will be a fundamental way of expressing a relationship. Straight-line functions can be written in several ways, but we’ll tend to use two predominant forms: \\[\\line(x) \\equiv a x + b\\ \\ \\ \\text{or}\\ \\ \\ \\ \\line(x) \\equiv a [x - x_0]\\] The two forms are interchangeable, but as you’ll see in upcoming chapters, sometimes it’s more convenient to use one form or the other. In either case, the rate of change is, quantitatively, the value of the parameter \\(a\\).\nThe simple function \\(\\line(x)\\), whose change relationship we understand intuitively, will be used to approximate more complicated change relationships. With the approximation in place, we can do calculations about the change relationships much more easily. Collectively, the set of mathematical concepts and techniques that support describing and calculating on change relationships has the name Calculus."
  },
  {
    "objectID": "Differentiation/16-rate-of-change.html#exercises",
    "href": "Differentiation/16-rate-of-change.html#exercises",
    "title": "17  Rate of change",
    "section": "17.7 Exercises",
    "text": "17.7 Exercises\n<!– Drill\n\n\nPart i What is the instantaneous rate of change of this function when the input is \\(t=-3\\)?(Choose the closest answer.)\n0.511.52\n\n\n\n\nPart ii What is the average rate of change of this function on the interval $-5 < t < 5?(Choose the closest answer.)\n0.511.52\n\n\n\n\nPart iii Consider the average rate of change of this function on the interval \\(-2 < t < 2\\). Which of these statements best describes that average rate of change.\n\nvery close to 1/2\nslightly less than 1\nslightly greater than 1\nvery close to 2"
  },
  {
    "objectID": "Differentiation/17-intro.html",
    "href": "Differentiation/17-intro.html",
    "title": "18  Change relationships",
    "section": "",
    "text": "As you know, a function is a mathematical idea used to represent a relationship between quantities. For instance, the water volume of a reservoir behind a dam varies with the seasons and over the years; there is a relationship between water volume (one quantity) and time (another quantity). Similarly, the flow in a river feeding the reservoir has a relationship with time. In spring the river may be rushing with snow-melt, in late summer the river may be dry, but after a summer downpour the river flow again rises briefly. In other words, river flow is a function of time.\nDifferentiation is a way of describing a relationship between relationships. The water volume in the reservoir has a relationship with time. The river flow has a relationship with time. Those two relationships are themselves related: the river flow feeds the reservoir and thereby influences the water volume.\nIt’s not so easy to keep straight what’s going on in a “relationship between relationships.” When you can describe such a thing, it often gives great insight to the mechanisms that drive the world. For instance, Johannes Kepler (1572-1630) spent years analyzing the data collected by astronomer Tycho Brahe (1546-1601). The data showed clearly a relationship between time and the speed of a planet across the sky. Long-standing wisdom claimed that there is also a specific relationship between a planet’s position and time. From antiquity it had been certain that planets moved in circular orbits. Kepler worked hard to find the relationship between the two relationships: speed vs time and position vs time. He was unsuccessful until he dropped the assumption that planet orbits are circular. Positing orbits as elliptical, Kepler was able to find a simple relationship between speed vs time and position vs time.\nBuilding on Kepler’s work, Newton hypothesized that planets might be influenced by the same gravity that pulls an apple to the ground. It was evident from human experience that gravity has the most trivial relationship with time: gravity is constant! But Newton could not find a link between this constant notion of gravity and Kepler’s planetary motion as a function of time. Success came when Newton hypothesized—without any direct evidence from experience—that gravity is a function of distance. Newton’s formulation of the relationship between relationships— gravity-as-a-function-of-distance and orbital-position-as-a-function-of time—became the a foundation of model science. Newton’s theories of gravity, force, and motion created an extremely complicated chain or reasoning that is still almost impossible to grasp. Or, more precisely, it is almost impossible to grasp until you have the language for describing relationships between relationships. Newton invented this language, the language of differentiation. As you learn to understand this language, you will find it easier to express and understand relationships between relationships, that is, the mechanisms that account for the ever changing quantities around us."
  },
  {
    "objectID": "Differentiation/17-intro.html#mathematics-in-motion",
    "href": "Differentiation/17-intro.html#mathematics-in-motion",
    "title": "18  Change relationships",
    "section": "18.1 Mathematics in motion",
    "text": "18.1 Mathematics in motion\nThe questions that started it all had to do with motion. There were words to describe speed: fast and slow. There were words to describe force: strong and weak, heavy and light. And there were words to describe location and distance: far and near, long and short, here and there. But what were the relationships among these things? And how did time fit in, an intangible quantity that had aspects of location (long and short) and of speed (quick and slow)?\nGalileo (1564-1642) started the ball rolling.1 As the son of a musician and music theorist, he had a sense of musical time, a steady beat of intervals. When a student of medicine in Pisa, he noted that swinging pendulums kept reliable time, regardless of the amplitude of their swing. After accidentally attending a lecture on geometry, he turned to mathematics and natural philosophy. Inventing the telescope, his observations put him on a collision course with the accepted classical truth about the nature of the planets. Seeking to understand gravity, he built an apparatus that enabled him to measure accurately the position in time of a ball rolling down a straight ramp. The belled gates he set up to mark the ball’s passage were spaced arithmetically in musical time: 1, 2, 3, 4, …. But the distance between the gates was geometric: 1, 4, 9, 16, …. Thus he established a mathematical relationship between increments in time and increments in position. Time advanced as 1, 1, 1, 1, … and position as 1, 3, 5, 7, …. He observed that the second increments of position, the increments of the increments 1, 3, 5, 7, …, were themselves evenly spaced: 2, 2, 2, ….\nPutting these observations in tabular form, and adding columns for the\n\nfirst increment \\(y(t) \\equiv x(t+1) - x(t)\\) and the\nsecond increment \\(y(t+1) - y(t)\\)\n\n\n\n\n\n\n\\(t\\)\n\\(x(t)\\)\nfirst increment\nsecond increment\n\n\n\n\n0\n0\n1\n2\n\n\n1\n1\n3\n2\n\n\n2\n4\n5\n2\n\n\n3\n9\n7\n\n\n\n4\n16\n\n\n\n\n\nGalileo had neither the mathematics nor the equipment to measure motion continuously in time. So what might be obvious to us now, that position is a function of time \\(x(t)\\), would have had little practical significance to him. But we discover in his first increments of \\(x\\) something very much like the slope function in ?sec-fun-slopes.\n\\[{\\cal D}_t\\, x(t) \\equiv \\frac{x(t + 1) - x(t)}{1}\\] From his data, he observed that \\({\\cal D}_t\\, x(t)\\) increases linearly in \\(t\\): \\[{\\cal D}_t x(t) = 2 t + 1\\]\nCalculating the second increments of \\(x\\) is done by the “slope function of the slope function,” which we can call \\({\\cal D}_{tt}\\): \\[{\\cal D}_{tt} x(t) \\equiv {\\cal D}_t \\left[{\\cal D}_t x(t)\\right] = {\\cal D_t} \\left[\\strut 2t+1\\right] = \\frac{\\left[\\strut2(t+1) + 1\\right] - \\left[\\strut 2 t + 1\\right]}{1} = 2\\]"
  },
  {
    "objectID": "Differentiation/17-intro.html#continuous-time",
    "href": "Differentiation/17-intro.html#continuous-time",
    "title": "18  Change relationships",
    "section": "18.2 Continuous time",
    "text": "18.2 Continuous time\nNewton placed the motion in continuous time rather than Galileo’s discrete time. He reframed the slope function from the big increments of the slope operator \\({\\cal D}_t\\) to imagined vanishingly small increments of a operator that we shall denote \\(\\partial_t\\) and call differentiation.\nThe kind of question for which Newton wanted to be able to calculate the answer was, “How to find the function \\(x(t)\\) whose second increment, \\(\\partial_{tt} x(t) = 2\\)?” His approach, which he called the “method of fluxions,” became so important that its name became, simply, “Calculus.”\nOver the next three centuries, calculus evolved from a set of techniques for describing motion into the general-purpose mathematics of change. Applying calculus in the real world involves understanding change relationships between quantities. To give some examples:\n\nElectrical power is the change with respect to time of electrical energy.\nBirth rate is one component of the change with respect to time of population.\nInterest, as in bank interest or credit card interest, is the change with respect to time of assets.\nInflation is the change with respect to time of prices.\nDisease incidence is one component of the change with respect to time of disease prevalence.\nForce is the change with respect to position of energy."
  },
  {
    "objectID": "Differentiation/17-intro.html#instantaneous-rate-of-change",
    "href": "Differentiation/17-intro.html#instantaneous-rate-of-change",
    "title": "18  Change relationships",
    "section": "18.3 Instantaneous rate of change",
    "text": "18.3 Instantaneous rate of change\nOn the radio once, I heard a baseball fanatic describing the path of a home run slammed just inside the left-field post. “Coming off the bat, the ball screamed upwards, passing five stories over the head of the first baseman and still gaining altitude. Then, somewhere over mid left-field, gravity caught up with the ball, forcing it down faster and faster until it crashed into the cheap seats.” A nice image, perhaps, but wrong about the physics. Gravity doesn’t suddenly catch hold of the ball; even when upward bound, gravity influences the ball to the same extent as it does at the peak of the flight and as the ball falls back down. The vertical velocity of the ball is positive while climbing and negative on descent, but that velocity is steadily changing all through the flight: a smooth, almost linear numerical decrease in velocity from the time the ball leaves the bat to when it lands in the bleachers.\nAt each instant of time, the vertical velocity of the ball has a numerical value in feet-per-second. That value changes continuously and is never the same at any two points in the ball’s flight. If \\(Z(t)\\) is the height of the ball at time \\(t\\), and \\(v_Z(t)\\) is the vertical velocity at time \\(t\\), then the slope function \\[{\\cal D}_t Z(t) \\equiv \\frac{Z(t+h) - Z(t)}{h}\\] tells us the average velocity of the ball over a time interval of \\(h\\).\nThe “average velocity” is a human construction. At each instant in time the ball has a velocity that is constantly changing. The reality of the ball is that it has only an instantaneous velocity. The average velocity is merely a concession to the way we might measure the velocity, by recording the height at two different times and computing the difference in height divided by the difference in time.\nOur measurement of the average velocity gets closer to the instantaneous velocity when we make the time interval \\(h\\) smaller. Ideally, to genuinely reflect the state of the ball at a instant, we would make the interval of time infinitely small, that is, we would make \\(h = 0\\).\nOne thing that happens when we make \\(h = 0\\) is that the formula for \\({\\cal D}_t Z(t)\\) suffers from a divide by zero; a meaningless arithmetic operation. So it would seem that “instantaneous velocity” is a mathematical non-starter, even if it is a physical reality. But there’s something else that happens when \\(h = 0\\), the two heights \\(Z(t + h)\\) and \\(Z(t)\\) become equal, so \\(Z(t + h) - Z(t) = 0\\). Not only are we dividing by zero when calculating \\({\\cal D}_t Z(t)\\), the quantity that we are dividing zero into is itself zero. We have 0/0. That’s a doubly mysterious quantity, an arithmetic non-entity.\nThe mystery of 0/0 baffled mathematicians and philosophers for thousands of years. It was Newton who turned it into a computational reality, although his reasoning was regarded with suspicion for two hundred years.\nThe world’s best mathematicians struggled for centuries with the logic of finding a mathematical framework for making sense of what a baseball and gravity do naturally. Rather than ourselves dealing with the intricacies of mathematical logic, we can gain an adequate understanding of the situation by avoiding \\(h=0\\) in favor of a gentler, gradual, evanescent h.\nThe type of slope function calculated with this (as yet undefined) evanescent h is called a derivative and corresponds to the instantaneous rate-of-change function. The process of constructing the derivative of a function \\(f(t)\\) is called differentiation. And to help us keep track of things, whenever we construct a derivative of \\(f(t)\\), we will name the constructed function \\(\\partial_t f(t)\\). Similarly, the name of the function that is the derivative of \\(g(x)\\) will be \\(\\partial_x g(x)\\)"
  },
  {
    "objectID": "Differentiation/17-intro.html#slopes-and-motion",
    "href": "Differentiation/17-intro.html#slopes-and-motion",
    "title": "18  Change relationships",
    "section": "18.4 Slopes and motion",
    "text": "18.4 Slopes and motion\nConsider a graph of the position of a car along a road as in Figure 17.2. Over the course of an hour, the car traveled about 25 miles. In other words, the average speed is 25 miles/hour: the slope of the tan-colored line segment. Given the traffic, sometimes the car was stopped (time C), sometimes crawling (time D) and sometimes much faster than average (time B)."
  },
  {
    "objectID": "Differentiation/18-evanescent-h.html",
    "href": "Differentiation/18-evanescent-h.html",
    "title": "19  Evanescent h",
    "section": "",
    "text": "In the very early days of calculus, the vanishing \\(h\\) was described as “evanescent.” (Dictionary definition: “tending to vanish like vapor.”1) Another good image of \\(h\\) becoming as small as possible comes from the same University of Oxford mathematician whose poem The Jabberwocky we introduced in ?sec-fun-notation. In Alice in Wonderland, Dodgson introduced the character of the Cheshire Cat.\n\n\n\n\n\nFigure 19.1: Vanishing \\(h\\) in the form of the Chesire Cat from Alice in Wonderland.\n\n\n\n\n\n\n\n\n\n\nFigure 19.2: The pattern-book sigmoidal function. A vertical blue line marks the input \\(t=0\\).\n\n\n\nStart our story with two of the basic modeling functions that, like the characters from Alice in Wonderland, have considerable “personality”: the sinusoid (sin()) and the sigmoid (pnorm()).\nThe computer can easily construct the slope functions for the sinusoid and sigmoid, which we’ll call Dsin() and Dsigma() respectively.\n\nDsin   <- makeFun((  sin(t+h) -   sin(t))/h ~ t, h=0.1)\nDsigma <- makeFun((pnorm(t+h) - pnorm(t))/h ~ t, h=0.1)\n\n\n\n\n\n\n\nFigure 19.3: The pattern-book sinusoid.\n\n\n\nIn the tilde expression handed to makeFun(), we’ve identified t as the name of the input and given a “small” default value to the h parameter. But R recognizes that both Dsin() and Dsigma() are functions with two inputs, t and h, as you can see in the parenthesized argument list for the functions.\n\nDsin\n## function (t, h = 0.1) \n## (sin(t + h) - sin(t))/h\nDsigma\n## function (t, h = 0.1) \n## (pnorm(t + h) - pnorm(t))/h\n\nThis is a nuisance, since when using the slope functions we will always need to think about h, a number that we’d like to describe simply as “small,” but for which we always need to provide a numerical value. A surprisingly important question in the development of calculus is, “What can we do to avoid this nuisance?” To find out, let’s look at Dsin() and Dsigma() for a range of values of h, as in Figure 19.4.\n\n\n\n\n\nFigure 19.4: The slope functions of the sinusoid and sigmoid. Each curve shows the slope function for a particular numerical choice of h. Both panels show \\(h=2, 1, 0.5, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001\\).\n\n\n\n\nSome observations from this numerical experiment:\n\nAs \\(h\\) gets very small, the slope function doesn’t depend on the exact value of \\(h\\). As you can see in Figure 19.4, the graphs of the functions with the smallest \\(h\\) (blue), with labels near the top of the graph) lie on top of one another.\nThis will provide a way for us, eventually, to discard \\(h\\) so that the slope function will not need an \\(h\\) argument.\nFor small \\(h\\), we have \\(\\partial_t \\sin(t) = \\sin(t + \\pi/2) = \\cos(t)\\). That is, taking the slope function of a sinusoid gives another sinusoid, shifted left by \\(\\pi/2\\) from the original. Or, in plain words, for small \\(h\\) the cosine is the slope function of the sine.\nFor small \\(h\\), we have \\(\\partial_t \\pnorm(t) = \\dnorm(t)\\). That is, for small \\(h\\) the gaussian function is the slope function of the sigmoid \\(\\dnorm()\\) function.\n\nYou can confirm these last two statements by comparison with the original functions, especially the alignment of the peaks of the slope functions with respect to the peak of the sinusoid and the half-way point of the sigmoid.\n\nHere you use \\(t\\) as the name of the input and \\(\\partial_t\\) as the notation for differentiation. Previously in this block you used \\(x\\) as the input name and \\(\\partial_x\\) for differentiation. Are they the same?\nMathematically, the name of the input makes no difference whatsoever. We could call it \\(x\\) or \\(t\\) or \\(y\\) or Josephina. What’s important is that the name be used consistently on the left and right sides of \\(\\equiv\\), and that the derivative symbol \\(\\partial\\) has a subscript that identifies the with-respect-to input. All these are the same statement mathematically:\n\\[\\partial_x\\, x = 1\\ \\ \\ \\ \\partial_t\\, t = 1\\ \\ \\ \\ \\partial_y\\, y = 1\\ \\ \\ \\ \\partial_\\text{Josephina} \\text{Josephina} = 1\\] Admittedly, the last one is hard to read.\nWhen we look at derivatives of functions with multiple inputs we will need to be thoughtful about our choice of the with-respect-to input. But we want you to get used to seeing different input names used for differentiation.\n\nNow consider the slope functions of the logarithm and exponential functions.\n\n\n\n\n\nFigure 19.5: The slope functions of the logarithm and exponential.\n\n\n\n\nThese numerical experiments with the logarithm and exponential functions are more evidence that, as \\(h\\) gets small, the slope function doesn’t depend strongly on \\(h\\). And, we find that:\n\nFor small \\(h\\), the slope function of the logarithm is a power-law function: \\(\\partial_t \\ln(t) = \\frac{1}{t}\\).\nFor small \\(h\\), the slope function of the exponential is the exponential itself: \\(\\partial_t e^x = e^x\\).\n\nYou can confirm these by evaluating the slope function of the exponential at \\(t=0\\) and \\(t=1\\), and the slope function of the logarithm at \\(t= 2, 1, 1/2, 1/4, 1/8.\\)\n“Small” and “zero,” although related, are different. In constructing a derivative, we use smaller and smaller \\(h\\), but never zero. Let’s see what happens if instead of evanescent h, we use zero h. For example, we can use the slope function Dsin() and Dsigma() that we created earlier. Setting \\(h\\) to zero does not give a result that is the instantaneous rate of change of anything:\n\nDsin(t=1, h=0)\n## [1] NaN\nDsigma(t=0, h=0)\n## [1] NaN\n\nIn NaN, you can hear the echo of your fourth-grade teacher reminding you that it is illegal to divide by zero.\nThink of evanescent \\(h\\) as the vapor in the definition of “evanescent”: “tending to vanish like vapor.” This vapor is like the solvent in paint. You don’t want the solvent once the paint is on the wall; wet paint is a nuisance. But getting the paint from the container to the wall absolutely needs the solvent.\nWe used the solvent \\(h\\) earlier in the chapter in the numerical experiments that led us to the derivatives of the pattern-book functions, for instance \\(\\partial_x e^x = e^x\\) or \\(\\partial_x \\sin(x) = \\cos(x)\\). Eventually, we’ll construct an \\(h\\)-free theory of differentiation, reducing the process to a set of algebraic rules in which \\(h\\) never appears. With this as our goal, let’s continue using \\(h\\) for a while to find some additional useful facts about derivatives.\n\n\n\n\n\nSource↩︎"
  },
  {
    "objectID": "Differentiation/19-computing.html",
    "href": "Differentiation/19-computing.html",
    "title": "20  Computing derivatives",
    "section": "",
    "text": "To differentiate a function \\(g(x)\\) means simply to produce the corresponding function \\(\\partial_t g(x)\\). This is often called “finding the derivative,” language that resonates with the high-school algebra task of “finding \\(x\\).” Rather than conjuring an image of searching high and low for a missing function, it’s more accurate to say, “compute the derivative.”\nIn this chapter we’ll introduce two ways of computing a derivative. For simplicity we will write \\(x\\) for the with-respect-to input, although in practice you might be using \\(t\\) or \\(z\\) or something else.\nIn the days when functions were always presented using formulas, symbolic differentiation was usually the only method taught. Nowadays, when functions are just as likely to be described using data and an algorithm, finite-differencing provides the practical approach."
  },
  {
    "objectID": "Differentiation/19-computing.html#a-function-from-a-function",
    "href": "Differentiation/19-computing.html#a-function-from-a-function",
    "title": "20  Computing derivatives",
    "section": "20.1 A function from a function",
    "text": "20.1 A function from a function\nRecall that the goal of differentiation is to make a function out of an already known function. We’ll call the already known function \\(g(x)\\). In ?sec-change-relationships we’ve outlined the properties that the new function should have and gave a nice naming convention, \\(\\partial_x g(x)\\) that shows where the new function comes from. In this section we’ll put that aside and focus on the question of what it means to “make a function.”\nWhen mathematics is done with paper and pencil, “making a function” is a matter of writing a formula, such as \\(x^2 \\sin(x) + 3\\) and sometimes giving a name to the formula, e.g. \\(h(x) \\equiv x^2 \\sin(x) + 3\\). We are essentially writing something down that will make sense when viewed by another person trained in the conventions of mathematical notation.\nFor a computer, on the other hand, a function is a definite kind of thing. We “make a function” by creating that kind of thing and, usually, giving it a name. We evaluate a function—that is, apply the function to inputs to produce an output—by using specific punctuation, which in R involves the use of parentheses, for instance name(input).\nThe computer language itself provides specific means to define a new function. In R/mosaic, you first construct a tilde expression naming the function inputs (right side of the tilde) and specifying the algorithm of that function (left side of the tilde), as with this formula:\n\nf_description <- x^2 * sin(x) + 3 ~ x   # a tilde expression\n\nOn its own, f_description cannot be used like a function because it was constructed as something else: a tilde expression. Trying to use f_description in the way one uses a function produces an error.\nf_description(2)\n Error in f_description(2): could not find function \"f_description\"\nIn between the tilde expression and the final result—a function—is software that translates from tilde-expressions into functions:\n\nf <- makeFun(f_description)\n\nThe new creation, f() can now be used like any other function, e.g.\n\nf(2)\n## [1] 6.63719\n\nDown deep inside, makeFun() uses a more basic function-creation syntax which looks like this\n\nfunction(x) {x^2 * sin(x) + 3}\n## function(x) {x^2 * sin(x) + 3}\n\nYou can see all the same information that was in the tilde description, just arranged differently.\nAlmost every computer language provides something like function. The internal workings of function are elaborate and detailed … only advanced programmers need to be aware of them. This, in much the same way as it’s unnecessary to understand the workings of a transistor in order to use a computer, or comprehend the biochemistry of a COVID vaccine in order to benefit from it.\nIn the same spirit as makeFun(), which translates a tilde-expression into the corresponding function, in R/mosaic you have D() which takes a tilde expression and translates it into the derivative of the function described.1 For example:\n\nD(f_description)\n## function (x) \n## x * (2 * sin(x) + x * cos(x))"
  },
  {
    "objectID": "Differentiation/19-computing.html#finite-differencing",
    "href": "Differentiation/19-computing.html#finite-differencing",
    "title": "20  Computing derivatives",
    "section": "20.2 Finite differencing",
    "text": "20.2 Finite differencing\nYou can use the definition of the slope function \\[{\\cal D}_x f(x) = \\frac{f(x+0.1) - f(x)}{0.1}\\] to create an approximation to the derivative of any function. Like this:\n\ng <- makeFun(sin(2*x)*(pnorm(x/3)-0.5) ~ x)\ndg <- makeFun((g(x+0.1) - g(x))/0.1 ~ x)\n\nWhenever you calculate a derivative function, you should check against mistakes or other sources of error. For instance, whenever the derivative is zero, the original function should have an instantaneous slope of zero. Figure 20.1 shows a suitable plot for supporting this sort of check.\n\nzeros_of_dg <- Zeros(dg(x) ~ x, domain(x=-5:5))\nslice_plot(g(x) ~ x, domain(x=-5:5), npts=500) %>%\n  slice_plot(dg(x) ~ x, color=\"magenta\", npts=500) %>%\n  gf_hline(yintercept = ~ 0, color = \"orange\", size=2, alpha=0.2) %>%\n  gf_vline(xintercept = ~ x, data=zeros_of_dg, color=\"blue\")\n\n\n\n\nFigure 20.1: The x-position of zero crossings of the derivative function (magenta) are marked with blue lines. The zero crossings correspond to local maxima or minima in the original function (black). This is because the original function has slope zero at maxima and minima.\n\n\n\n\nLook very closely at Figure 20.1, particularly at the places where the blue vertical markers cross the function \\(g(x)\\) (black). They should cross exactly at the flat zone, but they are a little shifted to the left. (You might have to zoom in on the plot to see the offset between the vertical blue marker and the local maximum of the function.) That’s the sense in which the finite-difference approach gives an approximation. The small left-shift stems from the use of 0.1 in the definition of the zero function. Use a smaller value, say 0.01 or 0.001, and you won’t be able to see the shift at all.\n\nIn modeling work, there’s nothing wrong with an approximation so long as it is good enough for your purposes. We picked the value 0.1 for our definition of the slope function because it works very well with the pattern-book functions. Here, “very well” means you can’t easily see in the graph any deviation compared to the exact derivative.\nWhen a calculation can be done exactly (without outrageous effort) it certainly makes sense to use the exact method. However:\n\nIt’s useful to have an easy, approximate method always at hand. This lets you check the results of other methods for the possibility of some blunder or mis-conception. The slope function approach to differentiation is certainly easy, and if you think the approximation isn’t good enough, then instead of 0.1 use something smaller. (Section 19 discusses how small is too small.)\nThe computer makes it practical to employ the slope function as a useful approximation to the derivative. There are many other mathematical methods that the computer has made feasible, for instance the methods of machine learning. These methods create functions that sometimes cannot be handled by the traditional (“exact”) methods of differentiation."
  },
  {
    "objectID": "Differentiation/19-computing.html#the-slope-function-operator",
    "href": "Differentiation/19-computing.html#the-slope-function-operator",
    "title": "20  Computing derivatives",
    "section": "20.3 The slope-function operator",
    "text": "20.3 The slope-function operator\nTake a look at the statement we used to construct the slope function of g():\ndg <- makeFun((g(x+0.1) - g(x))/0.1 ~ x)\nThere is almost nothing about this statement that has anything to do with the specifics of how we defined g(); we could have used any \\(g()\\). The “almost” in the previous sentence is about the choice of 0.1, which isn’t guaranteed to be small enough.\n\nIn today’s world, considerable mathematical content is conveyed to users not directly with formulas but with software that implements the formulas. And in software, it’s a good idea to have a name for each operation so that the readers and authors of software have a completely explicit indication that a particular operation is being used.\nWhen you have many slope functions to compute in some application, it can be error prone to write many statements that are versions of\ndg <- makeFun((g(x+0.1) - g(x))/0.1 ~ x)\nIt’s too easy to make a mistake in copying this over, producing a wrong computation that can be hard to detect in the code. For instance, each of these statements looks a lot like the above, but all of them are different and none is constructing a slope function:\ndf <- makeFun((f(x-0.1) - f(x))/0.1)\ndh <- makeFun((h(x+0.1) - f(x))/0.1)\ndu <- makeFun((u(x+0.1) - u(x))/1.0)\ndg <- makeFun(g(x+0.1) - g(x)/0.1)\nMuch easier to read and more reliable would be something like this:\ndf <- slopeFun(f(x) ~ x)\ndh <- slopeFun(h(x) ~ x)\ndu <- slopeFun(u(x) ~ x)\nCreating such an R operator is a programming task and in that sense beyond the scope of this course. Still, it’s a good idea to get in the habit of reading programming code. So here goes …\nCreating a slopeFun() operator:\n\nInstead of makeFun() which is really just maknig for mathematical functions, R programmers use a construction named function(). The name of the arguments goes inside the parentheses. The function algorithm goes between curly braces: { }\nWe’re going to use a tilde expression as the input to slopeFun(). This is how the other R/mosaic operators work. That will be easier for the user and will also give us access to those other operators if we need them in writing slopeFun().\nThe object returned by the slopeFun() operator will be, of course, a function. We’ve been using makeFun() to make our mathematical functions, so expect to see that in the code for slopeFun().\nThere’s the matter of whether 0.1 is small enough. So let’s use an h argument in place of 0.1 that we can change when needed.\n\nPutting this together, here is a slopeFun() operator that takes a tilde expression (as do makeFun() and slice_plot()) and produces a new mathematical function that is the slope function for the mathematical function described in the tilde expression. (There are a couple of R programming elements in slopeFun() that you aren’t expected to understand completely. But do try reading the code to see what sense you can make of it.)\n\n# two arguments, a tilde expression and a choice for h\n# with a default value\nslopeFun <- function(tilde, h=0.1) { \n   # Turn the tilde expression into a function\n   g <- makeFun(tilde) \n   # just like before, with h instead of 0.1\n   makeFun((g(x + h) - g(x))/h ~ x, h=h) \n}\n\nAnother important advantage of centralizing computations in a single operator is that the operator can be made more sophisticated without being harder to use. For instance, R/mosaic provides the D() operator for computing derivatives. This knows the rules for symbolic differentiation that will be introduced in Section 23 and switches to a finite-difference method (like slopeFun(), but more sophisticated) when symbolic differentiation isn’t applicable.\n\nIn practice, instead of home-brewed functions like slopeFun(), you can use the R/mosaic D() instead, which takes a more careful approach to the computer numerics and uses symbolic differentiation whenever possible to give results without numerical error."
  },
  {
    "objectID": "Differentiation/19-computing.html#sec-symbolic-differentiation",
    "href": "Differentiation/19-computing.html#sec-symbolic-differentiation",
    "title": "20  Computing derivatives",
    "section": "20.4 Symbolic differentiation",
    "text": "20.4 Symbolic differentiation\nSymbolic differentiation is the process of taking a formula and translating it to a new formula according to certain patterns or rules. Each rule is ultimately derived from the definition of the slope function and the differencing operator.\nAs you recall, the differencing operator \\(\\diff{x}\\) turns a function into its slope function \\[\\diff{x} f(x) \\equiv \\frac{f(x+h) - f(x)}{h}\\]\n\n20.4.1 The line rule\nLet’s look at one where we already know the result: The straight line function \\(\\line(x) \\equiv a x + b\\) has a slope function that is constant: \\(\\diff{x}\\line(x) = a\\)\n\\[\\diff{x}\\line(x) = \\frac{\\line(x+h) - \\line(x)}{h} = \\frac{\\left[\\strut a (x+h) + b\\right] - \\left[\\strut a x + b\\right]}{h} = \\frac{ah}{h} = a\\] The derivative is the slope function with \\(h\\) made as small as possible. It’s tempting to think of this as \\(h = 0\\), but that would imply dividing by zero in the differencing operator.\nBeing wary about the possibility of dividing by zero, mathematicians adopt a convention which indicates clearly that \\(h\\) is to be small, but not zero. This convention is marked with the notation \\(\\lim_{h \\rightarrow 0}\\), which means “as close as you can get to zero, but not zero exactly”.\n\\[\\partial_x \\line(x) \\equiv \\lim_{h\\rightarrow 0} \\frac{\\line(x+h) - \\line(x)}{h} =\\\\\n\\ \\\\\n= \\lim_{h\\rightarrow 0} \\frac{a h}{h} = a\\]\nThis derivation is unarguably correct for any non-zero \\(h\\).\nThis short derivation gives us a basic differentiation rule which we can divide into 3 special cases.\n\nLine rule: \\(\\partial_x ax + b = a\\)\n\n\\(\\partial_x ax = a\\). The function \\(ax\\) is \\(\\line(x)\\) with \\(b=0\\).\n\\(\\partial_x b = 0\\). The function \\(b\\) is \\(\\line(x)\\) with \\(a=0\\) and thus is the constant function.\n\\(\\partial_x x = 1\\). The function \\(x\\) is \\(\\line(x)\\) with \\(a=1\\) and \\(b=0\\).\n\n\nRemember that \\(\\partial_x f(x)\\) is always a function no matter what kind of function \\(f(x)\\) is. The functions associated with the line rule are all constant functions, meaning the output doesn’t depend on the input.\n\n\n20.4.2 The square rule\nOnly for the \\(\\line()\\) function and its three special cases is the derivative a constant function. And \\(\\line()\\) is the only function for which the \\(h\\) in the differencing operator disappears on its own. For instance, consider the square function: \\(g(x) \\equiv x^2\\).\n\\[\\begin{eqnarray}\n\\partial_x [x^2] & = & \\lim_{h\\rightarrow 0}\\frac{(x+h)^2 - x^2}{h}\\\\\n& = & \\lim_{h\\rightarrow 0}\\frac{(x^2 + 2 x h + h^2) - x^2}{h}\\\\  \n& = & \\lim_{h\\rightarrow 0}\\frac{2 x h + h^2}{h} \\\\\n& = &\\lim_{h\\rightarrow 0} [2x + h]\\\\\n\\end{eqnarray}\\]\nIt’s accepted that the limit of a sum is the sum of the limits, so … \\[\\lim_{h\\rightarrow 0} \\left[\\strut 2 x + h\\right]= \\lim_{h\\rightarrow 0} 2x + \\lim_{h\\rightarrow 0}h\\] The limit of something not involving \\(h\\) is just that thing, giving \\[\\lim_{h\\rightarrow 0}2x = 2x\\ .\\] Finally, when an expression including \\(h\\) doesn’t involve division by \\(h\\), we can remove the \\(\\lim_{h\\rightarrow 0}\\) and just use \\(h=0\\) instead, so \\[\\lim_{h\\rightarrow 0} h = 0\\ .\\]\nPutting these together gives\n\\[\\partial_x [x^2] = 2x + \\lim_{h\\rightarrow 0}h = 2x\\]\nWe’ll write this as another differentiation rule.\n\nQuadratic rule: \\(\\partial_x [x^2] = 2x\\)\n\n\n\n20.4.3 The exponential rule\nLet’s take on the exponential function \\(h(x) \\equiv e^x\\):\n\\[\\partial_x e^x = \\lim_{h\\rightarrow 0}\\frac{e^{x+h} - e^x}{h} = e^x \\lim_{h\\rightarrow 0}\\left[\\frac{e^h - 1}{h}\\right]\\] At a glance, it can be hard to know what to make of \\(\\lim_{h\\rightarrow 0} (e^h-1)/h\\). Setting \\(h=0\\) in the denominator is perfectly legitimate and gives \\(e^0 - 1 = 0\\). But that still leaves the \\(h\\) in the numerator. Still, for any non-zero \\(h\\), the division is legitimate, so let’s see what happens as \\(h \\rightarrow 0\\):\n\nf <- makeFun((exp(h) - 1)/h ~ h)\nf(0.1)\n## [1] 1.051709\nf(0.01)\n## [1] 1.005017\nf(0.001)\n## [1] 1.0005\nf(0.0001)\n## [1] 1.00005\nf(0.0000001)\n## [1] 1\nf(0.0000000001)\n## [1] 1\n\nSetting \\(h\\) exactly to zero, however, won’t work: it produces NaN.\n\nf(0)\n## [1] NaN\n\nSince \\(\\lim_{h\\rightarrow 0} (e^h-1)/h = 1\\), we have\n\nExponentiation rule: \\(\\partial_x e^x = e^x\\)\n\n\n\n20.4.4 The reciprocal rule\nStill another example: the reciprocal function, written equivalently as \\(1/x\\) or \\(x^{-1}\\)\n\\[\\begin{eqnarray}\n\\partial x^{-1} & = &\\lim_{h\\rightarrow 0}\\frac{\\frac{1}{x+h} - \\frac{1}{x}}{h} \\\\\n& = & \\lim_{h\\rightarrow 0} \\frac{\\frac{x - (x+h)}{x(x+h)}}{h}\\\\\n& = & \\lim_{h\\rightarrow 0}\\frac{x - x+h}{x(x+h)h} = -\\lim_{h\\rightarrow 0}\\frac{h}{x(x+h)h} \\\\\n& = & -\\lim_{h\\rightarrow 0}\\frac{1}{x^2 + hx}\n\\end{eqnarray}\\] So long as \\(x \\neq 0\\), there is no divide-by-zero problem even when \\(h=0\\), but let’s see what the computer thinks:\n\ng <- makeFun(-1/(x^2 + h*x) ~ h, x=10)\ng(0.1)\n## [1] -0.00990099\ng(0.01)\n## [1] -0.00999001\ng(0.001)\n## [1] -0.009999\ng(0.0001)\n## [1] -0.0099999\ng(0.0000001)\n## [1] -0.01\ng(0.0000000001)\n## [1] -0.01\ng(0)\n## [1] -0.01\n\nSetting \\(h\\) to zero in the last expression gives another differentiation rule:\n\nReciprocal rule: \\(\\partial_x \\frac{1}{x} = -\\frac{1}{x^2}\\)\n\n\n\n20.4.5 Power-law rule\nWe don’t yet have the tools needed to prove a formula for the derivative of power-law functions, but we already have some instances where we know the derivative:\n\n\\(\\partial_x x^2 = 2 x\\)\n\\(\\partial_x x^1 = 1\\)\n\\(\\partial_x x^0 = 0\\)\n\nA rule that fits all these examples is \\[\\partial_x x^p = p\\, x^{p-1}\\ .\\] For instance, when \\(p=2\\) the rule gives \\[\\partial_x x^2 = 2\\, x^1 = 2 x\\] since \\(p-1\\) will be 1$.\nIt’s not too hard to do the algebra to find the derivative of \\(x^3\\). According to the proposed rule, the derivative should be \\[\\partial_x x^3 = 3 x^2\\ .\\] Let’s check this via the definition of the derivative: \\[\\partial_x x^3 = \\lim_{h \\rightarrow 0}\\frac{(x+h)^3 - x^3}{h}\\] Direct multiplication \\((x+h)(x+h)(x+h)\\) gives \\[(x+h)^3 = x^3 + 3\\, x^2 h + 3\\, x h^2 + h^3\\] Consequently, the limit definition amounts to: \\[\\partial_x x^3 = \\lim_{h\\rightarrow 0}\\frac{3\\, x^2 h + 3\\, x h^2 + h^3}{h} = \\lim_{h\\rightarrow 0} \\left[\\strut 3\\, x^2 + 3\\,x h + h^2\\right]\\] But there is no divide-by-\\(h\\) in sight, so we can resolve \\(\\lim_{h\\rightarrow 0}\\) to \\(h=0\\), giving \\[\\partial_x x^3 = 3 x^2\\ ,\\] consistent with the proposed rule.\nThose familiar with the use of Pascal’s Triangle for finding the terms of binomial expansions such as \\((x + h)^p\\) will gain insight into the \\(p x^{p-1}\\) rule.\n\n\n20.4.6 List of pattern-book rules\nWe’ll save for later the derivation of the derivatives of the other pattern-book functions, but note that the gaussian function is defined to be the derivative of the sigmoidal function.\n\n\n\nName\n\\(f(x)\\)\n\\(\\partial_x f(x)\\)\n\n\n\n\nexponential\n\\(e^x\\)\n\\(e^x\\)\n\n\nlogarithm (natural)\n\\(\\ln(x)\\)\n\\(1/x\\)\n\n\nsinusoid\n\\(\\sin(x)\\)\n\\(\\cos(x)\\)\n\n\nsquare\n\\(x^2\\)\n\\(2x\\)\n\n\nproportional\n\\(x\\)\n\\(1\\)\n\n\nconstant\n1\n0\n\n\nreciprocal\n\\(1/x\\) or \\(x^{-1}\\)\n\\(-1/x^2\\)\n\n\ngaussian (hump)\n\\(\\dnorm(x)\\)\n\\(-x\\, \\dnorm(x)\\)\n\n\nsigmoid\n\\(\\pnorm(x)\\)\n\\(\\dnorm(x)\\)\n\n\n\n\n\n\n\n\nFigure 20.2: A diagram showing how differentiation connects the pattern-book functions to one another."
  },
  {
    "objectID": "Differentiation/19-computing.html#exercises",
    "href": "Differentiation/19-computing.html#exercises",
    "title": "20  Computing derivatives",
    "section": "20.5 Exercises",
    "text": "20.5 Exercises\n<!– Drill\n\n\nPart i Which pattern-book function is the derivative of the sigmoid function pnorm()? That is, \\[{\\large \\text{pnorm}(x)}  \\underset{\\scriptsize \\text{anti-diff}}{{\\stackrel{\\text{diff}}{\\ \\ \\ \\ {\\Huge\\rightleftharpoons}\\ \\ \\ }}}  {\\LARGE ?}\\]\nGaussian dnorm(x)Exponential \\(e^x\\)Sinusoid \\(\\sin(x)\\)Constant \\(1\\)Reciprocal \\(1/x\\)\n\n\n\n\nPart ii Which pattern-book function is the anti-derivative of the reciprocal \\(1/x\\)? That is, \\[{\\LARGE ?}  \\underset{\\scriptsize \\text{anti-diff}}{{\\stackrel{\\text{diff}}{\\ \\ \\ \\ {\\Huge\\rightleftharpoons}\\ \\ \\ }}}  {\\large \\frac{1}{x}}\\]  NOTE: Differentiation produces a “child” function from a “parent” function. The child is the derivative of the parent. Putting the relationship the other way, the parent is the anti-derivative of the child. “Derivative” and “anti-derivative” are two ways of looking at the same relationship between a pair of functions. So, if \\(f(x)\\) is the derivative of \\(F(x)\\), then \\(F(x)\\) is the anti-derivative of \\(f(x)\\).\n\nGaussian \\(\\text{dnorm(x)}\\)\nLogarithm \\(\\ln(x)\\)\nSinusoid \\(\\sin(x)\\)\nConstant \\(1\\)\nReciprocal \\(1/x\\)\n\n\n\n\n\nPart iii Which pattern-book function is the anti-derivative of the gaussian \\(\\text{dnorm()}\\)? That is, \\[{\\LARGE ?}  \\underset{\\scriptsize \\text{anti-diff}}{{\\stackrel{\\text{diff}}{\\ \\ \\ \\ {\\Huge\\rightleftharpoons}\\ \\ \\ }}}  {\\large \\text{dnorm}(x)}\\]  NOTE: Differentiation produces a “child” function from a “parent” function. The child is the derivative of the parent. Putting the relationship the other way, the parent is the anti-derivative of the child. “Derivative” and “anti-derivative” are two ways of looking at the same relationship between a pair of functions. So, if \\(f(x)\\) is the derivative of \\(F(x)\\), then \\(F(x)\\) is the anti-derivative of \\(f(x)\\). In other words: \\[{\\large F(x)}  \\underset{\\scriptsize \\text{anti-diff}}{{\\stackrel{\\text{diff}}{\\ \\ \\ \\ {\\Huge\\rightleftharpoons}\\ \\ \\ }}}  {\\Large f(x)}\\]\n\nGaussian \\(\\text{dnorm(x)}\\)\nLogarithm \\(\\ln(x)\\)\nSigmoid \\(\\text{pnorm(x)}\\)\nConstant \\(1\\)\nReciprocal \\(1/x\\)\n\n\n\n\n\nPart iv What is the derivative of the power-law function \\(x^p\\)?i That is, \\[{\\Large x^p}  \\underset{\\scriptsize \\text{anti-diff}}{{\\stackrel{\\text{diff}}{\\ \\ \\ \\ {\\Huge\\rightleftharpoons}\\ \\ \\ }}}  {\\LARGE ?}\\]\n\n\\((p-1)\\, x^{p-1}\\)\n\\((p-1)\\, x^p\\)\n\\(p\\, x^{p-1}\\)\n\\(\\frac{1}{p} x^{p+1}\\)\n\\(p\\, x^p\\)\n\n\n\n\n\nPart v There are two pattern-book functions whose second derivative is proportional to the function itself. Which are they?\n\nSinusoid and gaussian\nExponential and sigmoid\nExponential and sinusoid\nExponential and logarithm\n\n\n\n\n\nPart vi What is the derivative of \\(t^5\\) with respect to \\(t\\)? That is, \\[{\\Large t^5}  \\underset{\\scriptsize \\text{anti-diff}}{{\\stackrel{\\text{diff}}{\\ \\ \\ \\ {\\Huge\\rightleftharpoons}\\ \\ \\ }}}  {\\Large ?}\\]\n\\(\\frac{1}{4} t^5\\)\\(4 t^5\\)\\(5 t^4\\)\\(\\frac{1}{5} t^4\\)\n\n\n\n\nPart vii What is \\(\\partial_x x^2\\)?\n\\(2/x\\)\\(2\\)\\(2 x\\)\\(2 x^2\\)\n\n\n\n\nPart viii What is \\(\\partial_t \\sin(x)\\)\n\\(-\\cos(x)\\)0\\(\\cos(x)\\)\\(-\\sin(x)\\)\n\n\n\n\nPart ix Suppose you know only this one fact about \\(f(x)\\), that \\(\\partial_{xx}\\, f(7.3) = 1.6\\). Which of these statements must be true?\n\n\\(f(x)\\) is concave up at \\(x=7.3\\), but eventually it will become concave down.\n\\(f(x)\\) is concave up and decreasing at \\(x=7.3\\)\n\\(f(x)\\) is increasing at \\(x=7.3\\).\n\\(f(x)\\) is concave up at \\(x=7.3\\)\n\n\n\n\n\nPart x If \\(f(x)\\) is discontinuous at \\(x=5\\), can it possibly be smooth at \\(x=6\\)?\nNoYes\n\n\n\n\nPart xi If \\(g(x)\\) is discontinuous at \\(x=1\\), what will be the value of \\(\\partial_x g(x)\\) at \\(x=1\\)?\n\nDepends on how big the gap is at the discontinuity.\n0\n\\(1/x\\)\nThe derivative isn’t defined at a discontinuity.\n\n\n\n\n\nPart xii Which of the following is the correct construction for \\(\\partial_t g(t)\\)?\n\n\\(\\lim_{x \\rightarrow 0} \\frac{g(t + h) - g(t)}{h}\\)\n\\(\\lim_{h \\rightarrow 0} \\frac{g(t + h) - g(t)}{t}\\)\n\\(\\lim_{h \\rightarrow 0} \\frac{g(t + h) - g(t)}{h}\\)\n\\(\\lim_{h \\rightarrow 0} \\frac{g(t) - g(t+h)}{h}\\)\n\n\n\n\n\nPart xiii Which of these is a reasonable definition of a derivative?\n\nA derivative is the slope of a function.\nA derivative is a function whose value tells, for any input, the instantaneous rate of change of the function from which it was derived.\nA derivative is a function whose value tells, for any input, the instantaneous change of the function from which it was derived.\n\n\n\n\n\nPart xiv Which one of these is not the derivative of a pattern-book function?\nSigmoidZeroReciprocalOne\n\n\n\n\nPart xv Which of the following shapes of functions is not allowed? You are strongly advised to try to draw each shape.\n\nIncreasing and concave up.\nDecreasing and concave up.\nIncreasing and concave down.\nDecreasing and concave down.\nNone of them are allowed.\nAll of them are allowed."
  },
  {
    "objectID": "Differentiation/20-concavity.html",
    "href": "Differentiation/20-concavity.html",
    "title": "21  Concavity and curvature",
    "section": "",
    "text": "Looking at the graph of a function, our eyes immediately register the slope at any point we focus on. A glance shows whether the slope at that point is positive or negative. Comparing the slopes at two locales is also an automatic visual task: most people have little difficulty saying which slope is steeper.\nOne consequence of this visual ability is that it’s easy to recognize whether a line that touches the graph at a point is tangent to the graph.\nThere are other aspects of functions, introduced in Section @ref(word-descriptions), that are also readily discerned from a glance at the function graph.\nThe following exercises are simply meant to test your visual acuity in spotting concavity, tangency, and smoothness. Then we’ll move on to the calculations involved."
  },
  {
    "objectID": "Differentiation/20-concavity.html#quantifing-concavity-and-curvature",
    "href": "Differentiation/20-concavity.html#quantifing-concavity-and-curvature",
    "title": "21  Concavity and curvature",
    "section": "21.1 Quantifing concavity and curvature",
    "text": "21.1 Quantifing concavity and curvature\nIt often happens in building models that the modeler (you!) knows something about the concavity and/or curvature of a function. For example, concavity is important in classical economics; the curve for supply is concave down while the curve for demand is concave up. For a train, car, or plane, there are forces that depend on the curvature of the track, road, or trajectory. If you are designing a road, you’ll need to calculate the curvature in order to know if the road is safe at the indicated speed.\nIt turns out that quantifying these properties of functions or shapes is naturally done by calculating derivatives.\n\nImagine designing a highway. Due to the terrain, part of the road is oriented east-west and another part north-south. For vehicles to use the road, those two parts need to be connected together! (In math-speak, we might say that the road has to be continuous, but this is just common sense.)\nFrom your experience with highways, you know the connection will be a smooth curve. If the curve is part of a circle, then the design needs to specify the radius of curvature of the circle. Too tight a radius and the traffic won’t be able to handle the centrifugal force and will drift or skid off the road. A big radius is needed for safety, but making the radius bigger than required adds additional cost to road construction.\nIt’s not as simple as finding the radius of the curve. The radius needs to change at the entry and exit of the curve. Why? Here’s an explanation from the American Association of State Highway and Transportation Officials *Policy on Geometric Design of Highways and Streets (1994):\nAny motor vehicle follows a transition path as it enters or leaves a circular horizontal curve. The steering change and the consequent gain or loss of centrifugal force cannot be effected instantly. For most curves the average driver can effect a suitable transition path within the limits of normal lane width. However, with combinations of high speed and sharp curvature the resultant longer transition can result in crowding and sometimes actual occupation of adjoining lanes. In such instances transition curves would be appropriate because they make it easier for a driver to confine the vehicle to his or her own lane. The employment of transition curves between tangents and sharp circular curves and between circular curves of substantially different radii warrants consideration.\nLater in this chapter, you’ll see the calculus concepts that relate to designing a road with a gently changing curvature. (Hint, but don’t get scared: It’s the third derivative, not the first or the second.)\n\nLet’s frame the calculations in terms of a function \\(f(x)\\). Depending on the setting, \\(x\\) might be the price of a product and \\(f(x)\\) the demand for that product. Or the graph of \\(f(x)\\) might be the path of a road drawn in \\((x,y)\\) coordinates or the reach of a robot arm as a function of time. Remember that \\(f()\\) is just a pronoun that I’m using instead of a proper descriptive name. I use such pronouns (also, \\(g()\\), \\(h()\\), the “she” and “he” of mathematical language) when writing about the general properties of functions."
  },
  {
    "objectID": "Differentiation/20-concavity.html#sec-concavity-deriv",
    "href": "Differentiation/20-concavity.html#sec-concavity-deriv",
    "title": "21  Concavity and curvature",
    "section": "21.2 Concavity",
    "text": "21.2 Concavity\nRecall that to find the slope of a function \\(f(x)\\) at any input \\(x\\), you compute the derivative of that function, which we’ve been writing \\(\\partial_x\\,f(x)\\). Plug in some value for the input \\(x\\) and the output of \\(\\partial_x\\, f(x)\\) will be the slope of \\(f(x)\\) at that input. (Section 20 introduced some techniques for computing the derivative of any given function.)\nNow we want to show how differentiation can be used to quantify the concavity of a function. It will help if we augment our nomenclature a bit. When we speak of the “derivative” of a function, we mean something that might be more completely expressed as the first derivative of the function. Just that name naturally suggests that there will be a second derivative, a third derivative, and so on.\nFigure 21.1 shows a simple function that is concave down.\n\n\n\n\n\n\nFigure 21.1: A function that is concave down.\n\n\n\nNotice that the concavity is not about the slope. The curve in Figure 21.1 is concave down everywhere in the domain \\(0 \\leq x \\leq 4\\), but the slope is positive for \\(0 \\leq x \\leq 1\\) and negative for larger \\(x\\). Slope and concavity are two different aspects of a function.\nAs introduced in ?sec-fun-describing, the concavity of a function depends not on the slope, but on the change in the slope. Figure 21.2 adds some annotations on top of the graph in Figure 21.1. In the subdomain marked A, the function slope is positive while in the subdomain B, the function slope is negative. It is this transition from the slope in A to the slope in B that corresponds to the concavity of the function between A and B.\n\n\n\n\n\n\nFigure 21.2: Concavity is about how the slope changes from one place in the domain to another.\n\n\n\nSimilarly, the concavity of the function between B and C, reflects the transition in the slope from B to C. Even though the slope is negative in both B and C, the change in slope tells us about the concavity.\nLet’s look at this using symbolic notation. Keep in mind that the function graphed is \\(f(x)\\) while the slope is the function \\(\\partial_x\\,f(x)\\). We’ve seen that the concavity is indicated by the change in slope of \\(f()\\), that is, the change in \\(\\partial_x\\, f(x)\\). We’ll go back to our standard way of describing the rate of change near an input \\(x\\):\n\\[\\text{concavity.of.f}(x) \\equiv\\ \\text{rate of change in}\\ \\partial_x\\, f(x) = \\partial_x [\\partial_x f(x)] \\\\\n\\\\\n= \\lim_{h\\rightarrow 0}\\frac{\\partial_x f(x+h) - \\partial_x f(x)}{h}\\] We’re defining the concavity of a function \\(f()\\) at any input \\(x\\) to be \\(\\partial_x [\\partial_x f(x)]\\). We create the concavity_of_f(x) function by applying differentiation twice to the function \\(f()\\).\nSuch a double differentiation of a function \\(f(x)\\) is called the second derivative of \\(f(x)\\). The second derivative is so important in applications that it has it’s own compact notation: \\[\\text{second derivative of}\\ f()\\ \\text{is written}\\ \\partial_{xx} f(x)\\] Look carefully to see the difference between the first derivative \\(\\partial_x f(x)\\) and the second derivative \\(\\partial_{xx} f(x)\\): it’s all in the double subscript \\(_{xx}\\).\nComputing the second derivative is merely a matter of computing the first derivative \\(\\partial_x f(x)\\) and then computing the (first) derivative of \\(\\partial_x f(x)\\). In R this process looks like:\n\ndx_f  <- D(   f(x) ~ x)   # First deriv. of f()\ndxx_f <- D(dx_f(x) ~ x)   # Second deriv. of f()\n\n\nAs a shortcut for the two-step process above, for the second derivative you can use a notation which doubles up on the x on the right-hand side of the tilde: dxx_f <- D(f(x) ~ x & x)"
  },
  {
    "objectID": "Differentiation/20-concavity.html#sec-curvature-definition",
    "href": "Differentiation/20-concavity.html#sec-curvature-definition",
    "title": "21  Concavity and curvature",
    "section": "21.3 Curvature",
    "text": "21.3 Curvature\nAs you see from Section 21.2, it’s easy to quantify the concavity of a function \\(f(x)\\): just evaluate the second derivative \\(\\partial_{xx} f(x)\\). But it turns out that people are very poor at estimating the quantitative value of concavity by eye.\nTo illustrate, consider the square function, \\(f(x) \\equiv x^2\\). (See Figure 21.3.)\n\n\n\n\n\n\nFigure 21.3: Does the concavity of the square function vary with \\(x\\)?\n\n\n\nClearly, the square function is concave up. Now a test: Looking at the graph of the square function, where is the concavity the largest? Don’t read on until you’ve pointed where you think the concavity is largest.\nWith your answer to the test question in mind, let’s calculate the concavity of the square function using derivatives.\n\\[f(x) \\equiv x^2\\ \\text{      so     }\\\n\\partial_x f(x) = 2 x\\ \\text{     and therefore     }\\ \\partial_{xx} f(x) = 2\\]\nThe second derivative of \\(f(x)\\) is positive, as you would expect for a function that is concave up. What you might not expect, however, is that the second derivative is constant.\nThe concavity-related property that the human eye reads from the graph of a function is not the concavity itself, but the curvature of the function. The curvature of \\(f(x)\\) at a point \\(x_0\\) is defined to be the radius of the circle that is tangent to the function at \\(x_0\\).\nFigure 21.4 illustrates the changing curvature of \\(f(x) \\equiv x^2\\) by inscribing tangent circles at several points on the function graph, marked with dots. You can see the tangency of the circle to the function graph; the function’s thin black line goes right down the middle of the broader lines used to draw the circles.\n\n\n\n\n\nFigure 21.4: At any point on the graph of a smooth function, a circle tangent to the graph can be drawn. The radius of this circle is \\(1/{\\cal K}\\).\n\n\n\n\nBlack dots have been put along the graph at the points where the graph of the function is tangent to the inscribed circle. The visual sign of tangency is that the graph of the function goes right down the center of the circle.\nThe inscribed circle at \\(x=0\\) is tightest. The circle at \\(x=1\\) has a somewhat larger radius. The radius of the circle at \\(x=-1.5\\) is the largest of all. Whereas the concavity is the same at all points on the graph, the visual impression that the function is most highly curved near \\(x=0\\) is better captured by the radius of the inscribed circle. The radius of the inscribed circle at any point is the reciprocal of a quantity \\({\\cal K}\\) called the curvature.\nThe curvature \\({\\cal K}\\) of a function \\(f(x)\\) depends on both the first and second derivative. The formula for curvature \\(K\\) is somewhat off-putting; you are not expected to memorize it. But you can see where \\(\\partial x f()\\) and \\(\\partial_{xx}f()\\) come into play.\n\\[{\\cal K}_f  \\equiv \\frac{\\left|\\partial_{xx} f(x)\\right|}{\\ \\ \\ \\ \\left|1 + \\left[\\strut\\partial_x f(x)\\right]^2\\right|^{3/2}}\\]\nMathematically, the curvature \\(\\cal K\\) corresponds to the reciprocal of the radius of the tangent circle. When the tangent circle is tight, \\(\\cal K\\) is large. When the tangent circle has a very large radius, that is, the function is very close to approximating a straight line, \\(\\cal K\\) is very small.\n\nReturning to the highway design example earlier in the chapter … The Policy on geometric design of highways and streets called for the curvature of a road to change gently, giving the driver time to adjust the steering and accomodate the centrifugal force of the car going around the curve.\nChanging curvature implies that \\(\\partial_x {\\cal K}\\) is non-zero. Since \\({\\cal K}\\) depends on the first and second derivatives of \\(f(x)\\), the Policy on gradual change means that the third derivative of \\(f(x)\\) is non-zero."
  },
  {
    "objectID": "Differentiation/20-concavity.html#exercises",
    "href": "Differentiation/20-concavity.html#exercises",
    "title": "21  Concavity and curvature",
    "section": "21.4 Exercises",
    "text": "21.4 Exercises"
  },
  {
    "objectID": "Differentiation/21-cont-and-smooth.html",
    "href": "Differentiation/21-cont-and-smooth.html",
    "title": "22  Continuity and smoothness",
    "section": "",
    "text": "You’ve seen how various properties of a function—whether it is monotonic, how it slopes, whether it is concave up or down (or not at all), curvature, etc.—can be related to the first and second derivatives of the function.\nIn this chapter, we’ll elaborate on continuity, one of the ideas introduced in ?sec-word-descriptions, and use the concept of continuity to characterize functions in a new way: their smoothness."
  },
  {
    "objectID": "Differentiation/21-cont-and-smooth.html#continuity",
    "href": "Differentiation/21-cont-and-smooth.html#continuity",
    "title": "22  Continuity and smoothness",
    "section": "22.1 Continuity",
    "text": "22.1 Continuity\nThe intuition behind continuity is simple: If you can draw the graph of a function without lifting the pencil from the paper, the function is continuous.\nContinuity can be an important attribute of a modeling function. Often, we are modeling phenomena where a small change in input is expected to produce a small change in output. For instance, if your income changes by one penny, you would expect your lifestyle not to change by much. If the temperature of an oven changes by 1 degree, you don’t expect the quality of the cake you are baking to change in any noticeable way.\n\n\n\n\n\n\nFigure 22.1: The Heaviside function is piecewise constant with a discontiuity at \\(x=0\\).\n\n\n\nAll of our basic modeling functions are continuous over their entire input domain.1 To illustrate discontinuity we’ll consider piecewise functions, as introduced in ?sec-fun-piecewise. The Heaviside function, graphed in Figure 22.1 is discontinuous.\nDrawing the graph of the Heaviside function \\(H(x)\\) involves lifting the pencil at \\(x=0\\).\nIn contrast, the piecewise ramp function (Figure 22.2) is continuous; you don’t need to lift the pencil from the paper in order to draw the ramp function.\n\n\n\n\n\n\nFigure 22.2: The ramp function is a continuous piecewise function.\n\n\n\nImagine that you were constructing a model of plant growth as a function of the amount of water (in cc) provided each day. The plant needs about 20 cc of water to thrive. Let’s say that you use the Heaviside function for the model, say \\(H(W-20)\\), where an output of 1 means the plant thrives and a output 0 means the plant does not. The model implies that if you provide 20.001 cc of water, the plant will thrive. But if you are stingy, and provide only 19.999 cc of water, the plant will die. In other words, a very small change in the input can lead to a large change in the output.\nCommon sense suggests that a change of 0.002 cc in the amount of water—that’s a small fraction of a drop, 2 cubic millimeters of volume, is not going to lead to a qualitative change in output. So you might prefer to use a sigmoidal function as your model rather than a Heaviside function.\nOn the other hand, sometimes a very small change in input does lead to a large change in output. For instance, a sensible model of the hardness of water as a function of temperature would include a discontinuity at \\(32^\\circ\\)F, the temperature at which water turns to ice.\nOne of author Charles Dickens’s famous characters described the relationship between income, expenditure, and happiness this way:\n\n“Annual income 20 pounds, annual expenditure 19 [pounds] 19 [shillings] and six [pence], result happiness. Annual income 20 pounds, annual expenditure 20 pounds ought and six, result misery.” — the character Wilkins Micawber in David Copperfield\n\nMacawber was referring to the common situation in pre-20th century England of putting debtors in prison, regardless of the size of their debt. Macawber’s statement suggests he would model happiness as a Heaviside function \\(H(\\text{income}- \\text{expenditure})\\).\nWhenever the output of a function is a binary (yes-or-no) value, you can anticipate that a model will involve a discontinuous function."
  },
  {
    "objectID": "Differentiation/21-cont-and-smooth.html#discontinuity",
    "href": "Differentiation/21-cont-and-smooth.html#discontinuity",
    "title": "22  Continuity and smoothness",
    "section": "22.2 Discontinuity",
    "text": "22.2 Discontinuity\nRecall the logical path that led us to the idea of the derivative of a function. We started with the differencing operator, which takes as input a function and a “small” value of \\(h\\): \\[{\\cal D}_x f(x) \\equiv \\frac{f(x+h) - f(x)}{h}\\] Then, through algebraic manipulation and numerical experiments we found that, once \\(h\\) is small enough, the graph of the slope function \\({\\cal D}_x f(x)\\) does not depend on \\(h\\). And so we defined a function \\(\\partial_x f(x)\\) where \\(h\\) doesn’t play a role, writing \\(\\lim_{h\\rightarrow 0}\\) to remember our care to never divide by zero. \\[\\partial_x f(x) \\equiv \\lim_{h\\rightarrow 0} \\frac{f(x+h) - f(x)}{h}\\ .\\] Conveniently, we found that the derivatives of the pattern-book functions can be written in terms of the pattern-book functions without making any reference to \\(h\\). For instance:\n\n\\(\\partial_x \\ln(x) = 1/x\\) No \\(h\\) appears.\n\\(\\partial_x e^x = e^x\\) No \\(h\\) appears\n\\(\\partial_x x^p = p\\, x^{p-1}\\) No \\(h\\) appears.\nand so on.\n\nWith discontinuous functions, we have no such luck. Figure 22.3 shows what happens if we compute \\({\\cal D}_x H(x)\\), the derivative of the Heaviside function, for smaller and smaller \\(h\\).\n\nH <- makeFun(ifelse(x >=0, 1, 0) ~ x)\nDH01   <- makeFun((H(x + 0.1) - H(x))/0.1 ~ x)\nDH001  <- makeFun((H(x + 0.01) - H(x))/0.01 ~ x)\nDH0001 <- makeFun((H(x + 0.001) - H(x))/0.001 ~ x)\nslice_plot(DH01(x) ~ x, domain(x=-0.02:0.02),\n           npts=500, color=\"red\", size=2) %>%\n  slice_plot(DH001(x) ~ x,\n           color=\"darkgreen\", npts=500, size=3, alpha=0.5) %>%\n  slice_plot(DH0001(x) ~ x,\n           color=\"blue\", npts=500, alpha=0.5, size=2) \n\n\n\n\nFigure 22.3: \\({\\cal D}_x H(x)\\), the slope function of the discontinuous Heaviside, function, depends on the value of \\(h\\) used for the slope function. (Red: \\(h=0.1\\); Green: \\(h=0.01\\); Blue \\(h=0.001\\))\n\n\n\n\nDifferencing the Heaviside function produces very different functions depending on the value of \\(h\\). The bump near \\(x=0\\) gets taller and taller as \\(h\\) gets smaller. Mathematicians would describe this situation as \\[\\lim_{h\\rightarrow0}{\\cal D}_x H(x=0) \\equiv \\lim_{h\\rightarrow 0} \\frac{H(0+h) - H(0)}{h}\\ \\ \\ \\text{does not exist}.\\] Of course, for any given value of \\(h\\), e.g. \\(h=0.000001\\), the function \\({\\cal D}_x H(x)\\) has a definite shape. But that shape keeps changing as \\(h \\rightarrow 0\\), so we can’t point to any specific shape as the “limit as \\(h \\rightarrow 0\\).”\nSince there is no convergence in the shape of \\({\\cal D}_x H(0)\\) as \\(h\\) gets smaller, it’s fair to say that the Heaviside function does not have a derivative at \\(x=0\\). But away from \\(x=0\\), the Heaviside function has a perfectly sensible derivative: \\(\\partial_x H(x) = 0\\) for \\(x\\neq 0\\). But there is no derivative at \\(x=0\\)."
  },
  {
    "objectID": "Differentiation/21-cont-and-smooth.html#smoothness",
    "href": "Differentiation/21-cont-and-smooth.html#smoothness",
    "title": "22  Continuity and smoothness",
    "section": "22.3 Smoothness",
    "text": "22.3 Smoothness\nSmoothness is a different concept than continuity, although the two are related. Most simply, any discontinuous function is not smooth at any input where a discontinuity occurs. But even the continuous ramp function is not smooth at the start of the ramp. Intuitively, imagine you were sliding your hand along the ramp function. You would feel the crease at \\(x=0\\).\nA function is not smooth if the derivative of that function is discontinuous. For instance, the derivative of the ramp function is the Heaviside function, so the ramp is not smooth at \\(x=0\\).\nAll of our basic modeling functions are smooth everywhere in their domain. In particular, the derivatives of the basic modeling functions are continuous, as are the second derivative, third derivative, and so on down the line. Such functions are called C-infinity, written \\(C^\\infty\\). The superscript \\(\\infty\\) means that every order of derivative is continuous.\n\n\n\nYou cannot tell from the plot that the second derivative is discontinuous. But if you were in a plane flying along that trajectory, you would feel a jerk as you crossed \\(x=0\\).\nMathematicians quantify the “smoothness” of a function by looking at the continuity of the function and its derivatives. The mathematical definition of smoothness is straightforward and phrased in terms of derivatives. Suppose you are examining the smoothness of a function \\(f(x)\\). The smoothness is assessed on a scale \\(C^0, C^1, C^2, \\ldots, C^\\infty\\).\n\n\\(C^0\\): the function \\(f()\\) is continuous. Intuitively, this means that a graph of the function can be drawn without lifting the pencil from the paper.\n\\(C^1\\): the function \\(f()\\) has a derivative over its entire domain and that derivative \\(\\partial_x f(x)\\) is continuous. (See ?fig-c1-function for an example.)\n\\(C^2\\): the function \\(\\partial_x f(x)\\) has a derivative over its entire domain and that derivative is continuous. In other words, \\(\\partial_{xx} f(x)\\) exists and is continuous.\n\\(C^n\\): Like \\(C^2\\), but we’re talking about the \\(n\\)th-derivative of \\(f(x)\\) existing and being continuous.\n\\(C^\\infty\\): Usually when we denote a sequence with an infinite number of terms, we write down something like \\(C^0, C^1, C^2, \\ldots\\). It would be entirely valid to do this in talking about the \\(C^n\\) sequence. But many of the mathematical functions we work with are infinitely differentiable, that is \\(C^\\infty\\).\n\nExamples of \\(C^\\infty\\) functions:\n\n\\(\\sin(x)\\): the derivatives are \\(\\partial_x \\sin(x) = \\cos(x)\\), \\(\\partial_{xx} \\sin(x) = -\\sin(x)\\), \\(\\partial_{xxx} \\sin(x) =-\\cos(x)\\), \\(\\partial_{xxxx} \\sin(x) =\\sin(x)\\), … You can keep going infinitely.\n\\(e^x\\): the derivatives are \\(\\partial_x e^x = e^x\\), \\(\\partial_{xx} e^x = e^x\\), and so on.\n\\(x^2\\): the derivatives are \\(\\partial_x x^2 = 2 x\\), \\(\\partial_{xx} x^2 = 2\\), \\(\\partial_{xxx} x^2 = 0\\), … Higher order derivatives are all simply 0. Boring, but still existing.\n\nExample of non-\\(C^2\\) functions: We see these often when we take two or more different \\(C^\\infty\\) functions and split their domain, using one function for one subdomain and the other(s) for other subdomain(s).\n\n\\(|x|\\), the absolute value function. \\(|x|\\) is a pasting together of two \\(C^\\infty\\) functions: \\[|x| \\equiv \\left\\{\\begin{array}{rcl}+x & \\text{for} & 0 \\leq x\\\\-x&\\text{for}& \\text{otherwise}\\end{array} \\right.\\ .\\] The domain is split at \\(x=0\\).\n\n\nFor engineering and design problems, smoothness means something substantially different than described by the mathematical concepts above. Later in the course we’ll introduce cubic splines which are continuous functions defined by a finite set of coordinate pairs, as in a data frame. Each line of the data frame corresponds to a dot in a scatter plot, but in a cubic spline it is called a “knot point.” The spline consists of cubic polynomials drawn between consecutive knot points. The domain is split at each of the knot points. Between any two adjacent knot points, the function is an ordinary cubic polynomial. At a knot point, the cubics on either side have been arranged to have their first and second derivatives match. Thus, the first two derivatives are continuous. The function is at least \\(C^2\\). The second derivative of a cubic is a straight-line function, so the second derivative of a cubic spline is a series of straight-line functions connected at the knot points. The second derivative does not itself have a derivative at the knot points. So, a cubic spline cannot satisfy the requirements for being \\(C^3\\); it is \\(C^2\\)."
  },
  {
    "objectID": "Differentiation/21-cont-and-smooth.html#exercises",
    "href": "Differentiation/21-cont-and-smooth.html#exercises",
    "title": "22  Continuity and smoothness",
    "section": "22.4 Exercises",
    "text": "22.4 Exercises"
  },
  {
    "objectID": "Differentiation/22-rules.html",
    "href": "Differentiation/22-rules.html",
    "title": "23  Derivatives of assembled functions",
    "section": "",
    "text": "In Section 20.4 we used the rules associated with \\(\\lim_{h\\rightarrow 0}\\) to confirm our claims about the derivatives of many of the pattern-book functions. We’ll call these rules h-theory for short. In this chapter, we’re going to use h-theory to find algebraic rules to calculate the derivatives of linear combinations of functions, products of functions, and composition of functions. Remarkably, we can figure out these rules without having to say specifically which functions are being combined. So the rules can be written in terms of abstractions: \\(f()\\), \\(g()\\), and \\(h()\\). Later, we’ll apply those rules to specific functions, to show how the rules are used in practical work."
  },
  {
    "objectID": "Differentiation/22-rules.html#sec-using-the-rules",
    "href": "Differentiation/22-rules.html#sec-using-the-rules",
    "title": "23  Derivatives of assembled functions",
    "section": "23.1 Using the rules",
    "text": "23.1 Using the rules\nWhen you encounter a function that you want to differentiate, you first have to examine the function to decide which rule you want to apply. In the following, we’ll to use the names \\(f()\\) and \\(g()\\), but in practice the functions will often be basic modeling functions, for instance \\(e^{kx}\\) or \\(\\sin\\left(\\frac{2\\pi}{P}t\\right)\\), etc.\nStep 1: Identify f() and g()\nWe will write the rules in terms of two function names, \\(f()\\) and \\(g()\\), which can stand for any functions whatsoever. It’s rare to see the product or the composition written explicitly as \\(f(x)g(x)\\) of \\(f(g(x))\\). Instead, you are given something like \\(e^x \\ln(x)\\). The first step in differentiating the product or composition is to identify what are \\(f()\\) and \\(g()\\) individually.\nIn general, \\(f()\\) and \\(g()\\) might be complicated functions, themselves involving linear combinations, products, and composition. But to get started, we’ll practice with cases where they are simple, pattern-book functions.\nStep 2: Find f’() and g’()\nFor differentiating either products or compositions, you will need to identify both \\(f()\\) and \\(g()\\) (the first step) and then compute the derivatives \\(\\partial_x f()\\) and \\(\\partial_x g()\\). That is, you’ll write down four functions.\nStep 3: Apply the relevant rule\nRecall from ?sec-fun-assembling that will will be working with three important forms for creating new functions out of existing functions:\n\nLinear combinations, e.g. \\(a f(x) + bg(x)\\)\nProducts of functions, e.g. \\(f(x) g(x)\\)\nCompositions of functions, e.g. \\(f\\left(g(x)\\right)\\)"
  },
  {
    "objectID": "Differentiation/22-rules.html#differentiating-linear-combinations",
    "href": "Differentiation/22-rules.html#differentiating-linear-combinations",
    "title": "23  Derivatives of assembled functions",
    "section": "23.2 Differentiating linear combinations",
    "text": "23.2 Differentiating linear combinations\nLinear combination is one of the ways in which we make new functions from existing functions. As you recall, linear combination involves scaling functions and then adding the scaled functions as in \\(a f(x) + b g(x)\\), alinear combination of \\(f(x)\\) and \\(g(x)\\). We can easily use \\(h\\) to show what is the result of differentiating a linear combination of functions. First, let’s figure out what is \\(\\partial_x\\, a f(x)\\), Going back to writing \\(\\partial_x\\) in terms of a slope function: \\[\\partial_x\\, a\\,f(x) = \\frac{a\\, f(x + h) - a\\,f(x)}{h}\\\\\n\\ \\\\\n= a \\frac{f(x+h) - f(x)}{h} = a\\, \\partial_x f(x)\\] In other words, if we know the derivative \\(\\partial_x\\, f(x)\\), we can easily find the derivative of \\(a\\, f()\\). Notice that even though \\(h\\) was used in the derivation, it appears nowhere in the result \\(\\partial_x\\, b\\,f(x) = b\\, \\partial_x\\, f(x)\\). The \\(h\\) is solvent to get the paint on the wall and evaporates once its job is done.\nNow consider the derivative of the sum of two functions, \\(f(x)\\) and \\(g(x)\\): \\[\\begin{eqnarray}\n\\partial_x\\, \\left[f(x) + g(x)\\right] & =\\frac{\\left[f(x + h) + g(x + h)\\right] - \\left[f(x) + g(x)\\right]}{h} \\\\\n\\ \\\\\n&= \\frac{\\left[f(x+h) -f(x)\\right] + \\left[g(x+h) - g(x)\\right]}{h}\\\\\n\\ \\\\\n&= \\frac{\\left[f(x+h) -f(x)\\right]}{h} + \\frac{\\left[g(x+h) - g(x)\\right]}{h}\\\\\n\\ \\\\\n&= \\partial_x\\, f(x) + \\partial_x\\, g(x)\n\\end{eqnarray}\\]\nBecause of the way that \\(\\partial_x\\) can be “passed through” a linear combination, mathematicians say that differentiation is a linear operator. Consider this new fact about differentiation as a down payment on what will eventually become a complete theory telling us how to differentiate a product of two functions or the composition of two functions. We’ll lay out the \\(h\\)-theory based algebra of this in the next two sections.\nWe can summarize the h-theory result for linear combinations this way:\n\nThe derivative of a linear combination is the linear combination of the derivatives.\n\nThat is:\n\\[\\partial_x \\left[\\strut \\color{magenta}{a} \\color{brown}{f(x)} + \\color{magenta}{b} \\color{brown}{g(x)}\\right] = \\color{magenta}{a} {\\large\\color{brown}{f'(x)}} + \\color{magenta}{b} {\\large\\color{brown}{g'(x)}}\\] as well as \\[\\partial_x \\left[\\strut \\color{magenta}{a}\\, \\color{brown}{f(x)} + \\color{magenta}{b}\\, \\color{brown}{g(x)}  + \\color{magenta}{c}\\, \\color{brown}{h(x)} + \\cdots\\right] = \\color{magenta}{a}\\, {\\large\\color{brown}{f'(x)}} + \\color{magenta}{b}\\, {\\large\\color{brown}{g'(x)}} + \\color{magenta}{c}\\, {\\large\\color{brown}{h'(x)}} + \\cdots\\]\n\nThe derivative of a polynomial is a polynomial of a lower order.\nConsider the polynomial \\[h(x) = \\color{magenta}{a}\\color{brown}{x^0}  + \\color{magenta}{b} \\color{brown}{x^1} + \\color{magenta}{c} \\color{brown}{x^2}\\] The derivative is \\[\\partial_x h(x) = \\color{brown}{0}\\, \\color{magenta}{a}  + \\color{brown}{1}\\, \\color{magenta}{b}  + \\color{magenta}{c}\\, \\color{brown}{2 x} = \\color{magenta}{b} +  \\color{magenta}{2 c}\\  x\\]"
  },
  {
    "objectID": "Differentiation/22-rules.html#product-rule-for-multiplied-functions",
    "href": "Differentiation/22-rules.html#product-rule-for-multiplied-functions",
    "title": "23  Derivatives of assembled functions",
    "section": "23.3 Product rule for multiplied functions",
    "text": "23.3 Product rule for multiplied functions\nThe question at hand is how to compute the derivative \\(\\partial_x f(x) g(x)\\). Of course, you can always use numerical differentiation. But let’s look at the problem from the point of view of symbolic differentiation. And since \\(f(x)\\) and \\(g(x)\\) are just pronoun functions, we’ll assume you are starting out already knowing the derivatives \\(\\partial_x f(x)\\) and \\(\\partial_x g(x)\\).\nThis situation arises particularly when \\(f(x)\\) and \\(g(x)\\) are pattern-book functions for which you already have memorized \\(\\partial_x f(x)\\) and \\(\\partial_x g(x)\\) or are basic modeling functions whose derivatives you will memorize in Section @ref(basic-derivs).\nThe purpose of this section is to derive the formula for \\(\\partial_x f(x) g(x)\\) in terms of \\(f(x)\\), \\(g(x)\\), \\(\\partial_x f(x)\\) and \\(\\partial_x g(x)\\). This formula is called the product rule. The point of showing a derivation of the product rule is to let you see how the logic of evanescent \\(h\\) plays a role. In practice, everyone simply memorizes the rule, which has a beautiful, symmetric form:\n\\[\\text{Product rule:}\\ \\ \\ \\ \\partial_x \\left[\\strut f(x)g(x)\\right] = \\left[\\strut \\partial_x f(x)\\right]\\, g(x) + f(x)\\, \\left[\\strut\\partial_x g(x)\\right]\\] and is even prettier in Lagrange notation (where \\(\\partial_x f(x)\\) is written \\(f'\\)): \\[ \\left[\\strut f g\\right]' = f' g + g' f\\]\nAs with all derivatives, the product rule is based on the instantaneous rate of change \\[F'(x) \\equiv \\lim_{h\\rightarrow 0} \\frac{F(x+h) - F(x)}{h}\\] introduced in Section 17.5.\nWe also need two other statements about \\(h\\) and functions:\n\nThe derivative \\(F'(x)\\) is the slope of of \\(F()\\) at input \\(x\\). Taking a step of size \\(h\\) from \\(x\\) will induce a change of output of \\(h F'(x)\\), so \\[F(x+h) = f(x) + h F'(x)\\ .\\]\nAny result of the form \\(h F(x)\\), where \\(F(x)\\) is finite, gives 0. More precisely, \\(\\lim_{h\\rightarrow 0} h F(x) = 0\\)\n\nAs before, we’ll put the standard \\(\\lim_{h\\rightarrow 0}\\) disclaimer against dividing by \\(h\\) until there are no such divisions at all, at which point we can safely use the equality \\(h = 0\\).\nSuppose the function \\(F(x) \\equiv f(x) g(x)\\), a product of the two functions \\(f(x)\\) and \\(g(x)\\).\n\\[F'(x) = \\partial_x \\left[\\strut f(x) g(x) \\right] \\equiv \\lim_{h\\rightarrow 0}\\frac{f(x+h) g(x+h) - f(x) g(x)}{h}\\] We’ll replace \\(g(x_h)\\) with its equivalent \\(g(x) + h g'(x)\\) giving\n\\[= \\lim_{h\\rightarrow 0} \\frac{f(x+h) \\left[\\strut g(x) + h g'(x) \\right] - f(x) g(x)}{h} \\] \\(g(x)\\) appears in both terms in the numerator, once multiplied by \\(f(x+h)\\) and once by \\(f(x)\\). Collecting those terms give:\n\\[=\\lim_{h\\rightarrow 0}\\frac{\\left[\\strut f(x+ h) - f(x)\\right]  g(x) + \\left[\\strut f(x+h) h\\, g'(x)\\right]}{h}\\] This has two bracketed terms added together over a common denominator. Let’s split them into separate terms:\n\\[=\\lim_{h\\rightarrow 0}\\underbrace{\\left[\\strut \\frac{f(x+h) - f(x)}{h}\\right]}_{f'(x)} g(x) + \\lim_{h\\rightarrow 0}\\frac{\\left[\\strut f(x) + h f'(x)\\right]h\\,g'(x)}{h}\\]\nThe first term is \\(g(x)\\) multiplied by the familiar form for the derivative of \\(f(x)\\) \\[= f'(x) g(x) + \\lim_{h\\rightarrow 0}\\frac{f(x) h g'(x)}{h} + \\lim_{h\\rightarrow 0}\\frac{h f'(x) h g'(x)}{h}\\] In each of the last two terms there is an \\(h/h\\) involved. This is safely set to 1, since the \\(\\lim_{h\\rightarrow 0}\\) implies that \\(h\\) will not be exactly zero. There remain no divisions by \\(h\\) so we can drop the \\(\\lim_{h\\rightarrow 0}\\) in favor of \\(h=0\\): \\[= f'(x) g(x) + f(x) g'(x) + \\cancel{h f'(x) g'(x)}\\]\n\\[=f'(x) g(x) + g'(x) f(x)\\]\nThe last step relies on statement (2) above.\nSome people find it easier to read the rule in Lagrange shorthand, where \\(f\\) and \\(g\\) stand for \\(f(x)\\) and \\(g(x)\\) respectivly, and \\(f'\\) (“f-prime”) and \\(g'\\) (“g-prime”) stand for \\(\\partial f()\\) and \\(\\partial g()\\).\n\\[\\large\\text{Lagrange shorthand:}\\ \\   \\partial[\\color{magenta}f \\times \\color{brown}g] = [\\color{magenta}f \\times \\color{brown}g]' = \\color{magenta}{f'}\\color{brown}g + \\color{brown}{g'}\\color{magenta}f\\]\n\nThe expression \\(\\partial_x x^3\\) is the same as \\(\\partial_x \\left[\\strut x\\  x^2\\right]\\). Since we already know \\(\\partial_x x\\) (it’s 1) and \\(\\partial_x x^2\\) (it’s \\(2x\\)) let’s apply the product rule to find \\(\\partial_x x^3\\): \\[\\large\\partial [\\color{magenta}x \\times \\color{brown}{x^2}] = \\color{magenta}{[\\partial x]} \\times \\color{brown}{x^2} \\ +\\  \\color{brown}{[\\partial x^2]} \\times \\color{magenta}x =\\color{magenta}1\\times \\color{brown}{x^2} + \\color{brown}{2x} \\times \\color{magenta}x = 3 x^2\\]\n\n\nOccasionally, mathematics gives us a situation where being more general produces simplicity.\nIn the case of function products, the generalization is from products of two functions \\(f(x)\\cdot g(x)\\) to products of more than two functions, e.g. \\(u(x) \\cdot v(x) \\cdot w(x)\\).\nThe chain rule here takes a form that makes the overall structure much clearer:\n\\[\\begin{eqnarray}\n\\partial_x \\left[\\strut u(x) \\cdot v(x) \\cdot w(x)\\right] = \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\\\\n\\color{blue}{\\partial_x u(x)} \\cdot v(x) \\cdot w(x)\\ + \\\\\nu(x) \\cdot \\color{blue}{\\partial_x v(x)} \\cdot w(x)\\ + \\\\\nu(x) \\cdot v(x) \\cdot \\color{blue}{\\partial_x w(x)}\\ \\  \\ \\\n\\end{eqnarray}\\]\\end{eqnarray}\nIn the Lagrange shorthand, the pattern is even more evident: \\[\\left[ u\\cdot v\\cdot w\\right]' = \\color{blue}{u'}\\cdot v\\cdot w\\ +\\ u\\cdot \\color{blue}{v'}\\cdot w\\ +\\ u\\cdot v\\cdot \\color{blue}{w}'\\]"
  },
  {
    "objectID": "Differentiation/22-rules.html#chain-rule-for-function-composition",
    "href": "Differentiation/22-rules.html#chain-rule-for-function-composition",
    "title": "23  Derivatives of assembled functions",
    "section": "23.4 Chain rule for function composition",
    "text": "23.4 Chain rule for function composition\nA function composition, as described in Section 9.2, involves inserting the output of one function (the “interior function”) as the input of the other function (the “exterior function”). As we so often do, we’ll be using pronouns a lot. A list might help keep things straight:\n\nThere are two functions involved in a composition. We’ll call them \\(f(y)\\) and \\(g(x)\\). In the composition \\(f(g(x))\\), the exterior function is \\(f()\\) and the interior function is \\(g()\\).\nEach of the two functions \\(f()\\) and \\(g()\\) has an input. In our examples, we’ll use \\(y\\) to stand for the input to the exterior function and \\(x\\) as the pronoun for the input to the interior function.\nAs with all rules for differentiation, we’ll need to compute the derivatives of the functions involved, each with respect to its own input. So these will be \\(\\partial_y f(y)\\) and \\(\\partial_x g(x)\\).\n\nA reason to use different pronouns for the inputs to \\(f()\\) and \\(g()\\) is to remind us that the output \\(g(x)\\) is in general not the same kind of quantity as the input \\(x\\). In a function composition, the \\(f()\\) function will take the output \\(g(x)\\) as input. But since \\(g(x)\\) is not necessarily the same kind of thing as \\(x\\), why would we want to use the same name for the input to \\(f()\\) as we use for the input to \\(g()\\).\nWith this distinction between the names of the inputs, we can be even more explicit about the composition, writing \\(f(y=g(x))\\) instead of \\(f(g(x))\\). Had we used the pronound \\(x\\) for the input to \\(f()\\) but our explicit statement, although technically correct, would be confusing: \\(f(x = g(x))\\)!\nWith all these pronouns in mind, here is the chain rule for the derivative \\(\\partial_x f(g(x))\\):\n\\[\\large\\partial_x \\left[\\strut \\color{magenta}{f\\left(\\strut\\right.}\\strut \\color{brown}{g(x)}\\color{magenta}{\\left.\\right)}\\right] = [\\color{magenta}{\\partial_y f}](\\color{brown}{g(x)}) \\times [\\color{brown}{\\partial_xg(x)}]\\] Or, using the Lagrange prime notation, where \\('\\) stands for the derivative of a function with respect to its input, we have \\[\\large\\text{Lagrange shorthand:}\\ \\   [\\color{magenta}f(\\color{brown}g)]' = \\color{magenta}{f'} (\\color{brown}g) \\times \\color{brown}{g}'\\]\n\nIn news and policy discussions, you will often hear about “inflation rate” or “birth rate” or “interest rate” or “investment rate of return.” In each case, there is a function of time combined with a derivative of that function: with the general form \\[\\frac{\\partial_t f(t)}{ f(t)}\\ .\\]\n\nInflation rate: The function is cost_of_living(\\(t\\)). The derivative is the rate of change with respect to time in the cost of living: \\(\\partial_t\\,\\)cost_of_living(\\(t\\)).\nBirth rate: The function is population(\\(t\\)). The derivative is \\(\\partial_t\\,\\)population(\\(t\\)), or at least that component of the overall \\(\\partial_t\\,\\)population(\\(t\\)) that is related to births. (Other components are deaths and the balance of in-migration and out-migration.)\nInterest rate: The function is account_balance(\\(t\\)) and the derivative is \\(\\partial_t\\,\\)account_balance(\\(t\\)).\nInvestment returns: The function is net_worth(\\(t\\)) and the derivative is \\(\\partial_t\\,\\)net_worth(\\(t\\)).\n\nIn all these cases, The “rate” is not merely “per time” as would be the case for \\(\\partial_t f(t)\\). Instead the rate is “per unit of the whole per time.” Thus the birth rate is “births per capita per year.”1 Interest and return rates are “percent per year” where the “percent” understood to be the “change-in-value divided by the current value.”\nThanks to the chain rule, there is a shortcut way of writing these sorts of “rates per time.” Exactly equivalent to the ratio \\(\\frac{\\partial_t f(t)}{ f(t)}\\) is \\[\\partial_t \\ln(f(t))\\ .\\]\nSuch changes in logarithms are encountered in fields such as economics or finance, where it’s common to consider the logarithm of the economic quantity in order to render changes as percent of the whole.\nIt’s also something to keep in mind when interpreting graphs of an amount versus time, as in Figure 23.1. Source\n\n\n\n\n\nFigure 23.1: Growth in the number of Coronavirus cases in Italy and the US early in the pandemic.\n\n\n\n\nLook closely at the two graphs in Figure 23.1. They show the same data about growing numbers of coronavirus cases, the left graph on linear axes, the right on the now-familiar semi-log axes.\nMost people are excellent at comparing slopes, even if they find it difficult or tedious to quantify a slope with a number and units. For instance, a glance suffices to show that in the left graph, well through mid-March the red curve (Italy) is steeper on any given date than the blue curve (US). This means that the number of people with coronavirus was growing faster (per day) in Italy.\nThe right graph tells a different story: up until about March 1, the Italian cases were increasing faster than the US cases. Afterwards, the US sees a larger growth rate than Italy until, around March 19, the US growth rate is substantially larger than the Italy growth rate.\nThe previous two paragraphs and their corresponding graphs may seem to contradict one another. But they are both accurate, truthful depictions of the same events. What’s different between the two graphs is that the left shows one kind of rate and the right shows another kind of rate. In the left, the slope is new-cases-per-day, the output of the derivative function  On the right, the slope is the proportional increase in cases per day, that is,  From the chain rule, we know that \\[\\partial_t \\left[\\strut\\ln(f(t))\\right] = \\frac{\\partial_t f(t)}{f(t)}\\] Since the right graph is on semi-log axes, the slope we perceive visually is \\(\\partial_t \\left[\\strut\\ln(f(t))\\right]\\). That’s an obscure-looking bunch of notation until the chain rule reveals it to be the rate of change at time \\(t\\) divided by the value at time \\(t\\).\n\nThe derivation of the chain rule relies on two closely related statements which are expressions of the idea that near any value \\(x\\) a function can be expressed as a linear approximation with the slope equal to the derivative of the function :\n\n\\(g(x + h) = g(x) + h g'(x)\\)\n\\(f(y + \\epsilon) = f(y) + \\epsilon f'(y)\\), which is the same thing as (1) but uses \\(y\\) as the argument name and \\(\\epsilon\\) to stand for the small quantity we usually write with an \\(h\\).\n\nWe’ll now look at \\(\\partial_x f\\left({\\large\\strut} g(x)\\right)\\) by writing down the fundamental definition of the derivative. This, of course, involves the disclaimer \\(\\lim_{h\\rightarrow 0}\\) until we’re sure that there is no division by \\(h\\) involved.\n\\[\\partial_x \\left[{\\large\\strut} f\\left(\\strut g(x)\\right)\\right]  \\equiv \\lim_{h\\rightarrow 0}\\frac{\\color{magenta}{f(g(x+h))} - f(g(x))}{h}\\]\nLet’s examine closely the expression \\(\\color{magenta}{f\\left(\\strut g(x+h)\\right)}\\). Applying rule (1) above turns it into \\[\\lim_{h\\rightarrow 0} f\\left(\\strut g(x) + \\color{blue}{h g'(x)}\\right)\\] Now apply rule (2) but substituting in \\(g(x)\\) for \\(y\\) and \\(\\color{blue}{h g'(x)}\\) for \\(\\epsilon\\), giving\n\\[\\lim_{h\\rightarrow 0} \\color{magenta}{f\\left(\\strut g(x+h)\\right)} = \\lim_{h\\rightarrow 0} \\color{brown}{\\left[{\\large\\strut} f\\left(g(x)\\right) + \\color{blue}{h g'(x)}f'\\left(g(x)\\right)\\right]}\\] We’ll substitute the \\(\\color{blue}{blue}\\) and \\(\\color{brown}{brown}\\) expression for the \\(\\color{magenta}{magenta}\\) expression in \\[\\partial_x f\\left(\\strut g(x)\\right)  \\equiv \\lim_{h\\rightarrow 0}\\frac{\\color{magenta}{f(g(x+h))} - f(g(x))}{h}\\] giving \\[\\partial_x f\\left(\\strut g(x)\\right)  \\equiv \\lim_{h\\rightarrow 0}\\frac{\\color{brown}{f\\left(g(x)\\right) + \\color{blue}{h g'(x)}f'\\left(g(x)\\right)} - f\\left(g(x)\\right)}{h}\\] In the denominator, \\(f\\left(g(x)\\right)\\) appears twice and cancels itself out. That leaves a single term with an \\(h\\) in the numerator and an \\(h\\) in the denominator. Those \\(h\\)’s cancel out, at the same time obviating the need for \\(\\lim_{h\\rightarrow 0}\\) and leaving us with the chain rule: \\[\\partial_x f\\left(\\strut g(x)\\right)  \\equiv \\lim_{h\\rightarrow 0}\\frac{\\color{brown}{ \\color{blue}{h g'(x)} f'\\left(g(x)\\right)}}{h} = f'\\left(g(x)\\right)\\ g'(x)\\]\n\nUse the chain rule to find the derivative \\(\\partial_x e^{2x}\\).\nRecognize that \\(g(x) \\equiv 2x\\) is the interior function in \\(e^{2x}\\) and \\(f(x) \\equiv \\exp(x)\\) is the exterior function. Thus \\[\\partial_x e^{2x} = f'(g(x)) g'(x) = \\exp(g(x)) 2 = 2 e^{2x}\\ .\\] Happily, this is the same result as we got from using the product rule to find \\(\\partial_x e^{2x}\\).\nRecognizing \\(e^{2x}\\) as \\(e^x \\times e^x\\), we can apply the product rule.\n\n\nThe chain rule can be used in a clever way to find a formula for \\(\\partial_x \\ln(x)\\).\nWe’ve already seen that the logarithm is the inverse function to the exponential, and vice versa. That is: \\[e^{\\ln(y)} = y \\ \\ \\ \\text{and}\\ \\ \\ \\ln(e^y) = x\\] Since \\(\\ln(e^y)\\) is the same function as \\(y\\), the derivative \\(\\partial_y \\ln(e^y) = \\partial_y y = 1\\).\nLet’s differentiate the second form using the chain rule: \\[\\partial_y \\ln(e^y) = \\left[\\partial_y \\ln\\right](e^y)\\, e^x = 1\\] giving \\[\\left[\\partial_y \\ln\\right](e^y) = \\frac{1}{e^y} = \\recip(e^y)\\] Whatever the function \\(\\partial_x \\ln()\\) might be, it takes its input and produces as output the reciprocal of that input. In other words: \\[\\partial_x \\ln(x) = \\frac{1}{x}\\ .\\]\n\n\nKnowing that \\(\\partial_x \\ln(x) = 1/x\\) and the chain rule, we’re in a position to demonstrate the power-law rule \\(\\partial_x x^p = p\\, x^{p-1}\\). The key is to use the identity \\(e^{\\ln(x)} = x\\).\n\\[\\partial_x x^p = \\partial_x \\left[e^{\\ln(x)}\\right]^p\\] The rules of exponents allow us to recognize \\[\\left[e^{\\ln(x)}\\right]^p = e^{p \\ln(x)}\\] Thus, \\(x^p\\) can be seen as a composition of the exponential function onto the logarithm function.\nApplying the chain rule to this composition gives \\[\\partial_x e^{p \\ln(x)} = e^{p\\ln(x)}\\partial_x [p \\ln(x)] =\ne^{p\\ln(x)} \\frac{p}{x}\\ .\\] Of course, we already know that \\(e^{p \\ln(x)} = x^p\\), so we have \\[\\partial_x x^p = x^p \\frac{p}{x} = p x^{p-1}\\ .\\]\n\n\n\\(\\large\\partial_x [\\color{brown}\\sin(\\color{magenta}{a x + b})] = [\\partial_x \\color{brown}{\\sin}](\\color{magenta}{a x + b}) \\times \\partial_x [\\color{magenta}{ax + b}] = \\color{brown}{\\cos}(\\color{magenta}{ax + b}) \\times \\color{magenta}a\\).\n\n\n\nIn 1734, famous philosopher George Berkeley (1685-1753) published a long-titled book: The Analyst: A Discourse Addressed to an Infidel Mathematician: Wherein It Is Examined Whether the Object, Principles, and Inferences of the Modern Analysis Are More Distinctly Conceived, or More Evidently Deduced, Than Religious Mysteries and Points of Faith. In The Analyst, Berkeley took issue with the arguments of that time that it is legitimate to divide by \\(h\\) when, ultimately, \\(h\\) will be replaced by zero. Calling \\(h\\) an “evanescent increment,” he asked,\n\n“And what are these same evanescent Increments? They are neither finite Quantities nor Quantities infinitely small, nor yet nothing. May we not call them the ghosts of departed quantities?”\n\nInteresting, Berkeley believed that the ghost of \\(h\\) yielded correct results. His objection was that the framers of calculus had made two, canceling errors.\n\n“[B]y virtue of a two fold mistake you arrive, though not at science, yet truth.”\n\nBerkeley was saying that calculus had not yet been put on a solid logical foundation. It wasn’t until more than a century after Berkeley’s death that this work was accomplished. Once accomplished, the results that had been claimed true all along were confirmed."
  },
  {
    "objectID": "Differentiation/22-rules.html#sec-basic-derivs",
    "href": "Differentiation/22-rules.html#sec-basic-derivs",
    "title": "23  Derivatives of assembled functions",
    "section": "23.5 Derivatives of the basic modeling functions",
    "text": "23.5 Derivatives of the basic modeling functions\nThe basic modeling functions are the same as the pattern-book functions, but with bare \\(x\\) replaced by \\(\\line(x)\\). In other words, each of the basic modeling functions is a composition of the corresponding pattern-book function with \\(\\line(x)\\). As such, the derivatives of the basic modeling functions can be found using the chain rule.\nSuppose \\(f()\\) is one of our pattern-book functions. Then \\[\\large\\partial_x f(\\color{magenta}{ax + b}) = \\color{brown}{a} f'(\\color{magenta}{ax + b})\\] where \\(\\color{brown}{a}\\) is the derivative with respect to \\(x\\) of \\(\\color{magenta}{ax + b}\\).\nHere are the steps for differentiating a basic modeling function \\(\\color{brown}{f}(\\color{magenta}{a x + b})\\) where \\(f()\\) is one of the pattern-book functions:\n\nStep 1: Identify the particular pattern-book function \\(\\color{brown}{f}()\\) and write down its derivative \\(\\color{brown}{f'}\\). For example, if \\(f()\\) is \\(\\sin()\\), then \\(f'()\\) is \\(\\cos()\\).\nStep 2: Find the derivative of the linear interior function. If the function is \\(\\color{magenta}{ax + b}\\), then the derivative is \\(\\color{magenta}{a}\\). If the interior function is \\(\\frac{2\\pi}{P}(t-t_0)\\), the derivative is \\(\\frac{2 \\pi}{P}\\).\nStep 3: Write down the original function \\(\\large\\color{brown}{f}(\\color{magenta}{a x + b})\\) but replace \\(\\large\\color{brown}{f}\\) with \\(\\large \\color{brown}{f'}\\) and pre-multiply by the derivative of the interior function. For instance, \\[\\partial_x f(\\color{magenta}{ax + b}) = {\\large \\color{magenta}{a}}{\\large f'}(\\color{magenta}{ax + b})\\] Another example: \\[\\partial_t \\color{brown}{\\sin}\\left(\\color{magenta}{\\frac{2 \\pi}{P}(t-t_0)} \\right) = {\\large \\color{magenta}{\\frac{2 \\pi}{P}}}\\color{brown}{\\large\\cos}\\left(\\color{magenta}{\\frac{2 \\pi}{P}(t-t_0) }\\right) \\]\n\nBy convention, there are different ways of writing \\(\\line(x)\\) for the different pattern-book functions, for instance:\n\n\n\n\n\n\n\nPattern-book function \\(\\longrightarrow\\)\nBasic modeling\n\n\n\n\n\\(\\sin(x)\\ \\ \\ \\longrightarrow\\)\n\\(\\sin\\left(\\strut2 \\pi \\left[x-x_0\\right]/P\\right)\\)\n\n\n\\(\\exp(x)\\ \\ \\ \\longrightarrow\\)\n\\(\\exp(k x)\\)\n\n\n\\(x^2 \\ \\ \\ \\longrightarrow\\)\n\\(\\left[mx + b\\right]^2\\)\n\n\n\\(1/x \\ \\ \\ \\longrightarrow\\)\n\\(1/\\left[mx + b\\right]\\)\n\n\n\\(\\ln(x) \\ \\ \\ \\longrightarrow\\)\n\\(\\ln(a x + b)\\)\n\n\n\nThe rule for the derivative of any basic modeling function \\(f(\\line(x))\\) is \\[\\partial_x f(\\line(x)) = \\partial_x \\line(x) \\times \\partial_x f\\left(\\strut\\line(x)\\right)\\]\nTo illustrate:\n\n\\(\\partial_x e^{\\color{magenta}{kx}} = {\\large\\color{magenta}{k}}\\, e^{\\color{magenta}{kx}}\\) where \\(\\line(x) = kx\\).\n\\(\\partial_x \\sin(2\\pi (x-x_0)/P) = \\frac{2\\pi}{P} \\sin(2\\pi (x-x_0)/P)\\) where \\(\\line(x) = 2\\pi (x-x_0)/P)\\).\n\\(\\partial_x (mx + b)^2 = m\\, 2 (m x + b) = 2 m^2 x + m^2 b\\) where \\(\\line(x) = mx + b\\).\n\\(\\partial_x \\text{reciprocal}(mx + b) = \\partial_x \\frac{1}{mx + b} = - \\frac{m}{(mx + b)^2}\\) where \\(\\line(x) = mx + b\\) and we use the fact that \\(\\partial_x \\text{reciprocal}(x) = - 1/x^2\\)\n\\(\\partial_x \\ln(a x + b) = a/(ax+b)\\)\n\\(\\partial_x \\pnorm(x, \\text{mean}, \\text{sd}) = dnorm(x, \\text{mean}, \\text{sd})\\).\n\\(\\partial_x \\dnorm(x, \\text{mean}, \\text{sd}) = - \\frac{x-m}{\\text{sd}^2} \\dnorm(x, \\text{mean}, \\text{sd})\\)\n\nYou will be using the derivatives of the basic modeling functions so often, that you should practice and practice until you can write the derivative at a glance.\n\nThere are many possible implementations of the general concept of hump functions and sigmoidal functions. The one we use in this book is \\(\\dnorm()\\) for the hump and \\(\\pnorm()\\) for the sigmoid.\nThe names \\(\\dnorm\\) and \\(\\pnorm\\) are worth remarking on. As we’ve said before, \\(\\dnorm()\\) is called the gaussian function in many fields of science and engineering. It is also a centrally important function in statistics, where it is usually called the normal function. (That’s how important it is: it’s just “normal.”) You may also have heard the normal function described as a “bell-shaped curve.”\nIn statistical nomenclature, \\(\\dnorm()\\) is called the “normal probability density function (PDF)” and \\(\\pnorm()\\) is called the “normal cumulative density function (CDF).” That’s way too wordy for our purposes. So, for brevity, we have adopted the R name for those functions: dnorm() and pnorm().\nOwing to the origin of the names \\(\\dnorm\\) and \\(\\pnorm\\), we are writing the parameters of the functions—mean and sd—using the computer language notation. The pattern-book functions are just \\(\\dnorm(x)\\) and \\(\\pnorm(x)\\), without listing the parameters. But the basic modeling functions, with parameters, are written \\(\\dnorm(x, \\text{mean}, \\text{sd})\\) and \\(\\dnorm(x, \\text{mean}, \\text{sd})\\). This violates the convention that the basic modeling functions are the composition of the pattern-book functions with \\(\\line(x)\\). But \\(\\dnorm()\\) doesn’t work this way because, by convention, the amplitude of the peak of \\(\\dnorm()\\) changes with the input parameter sd. That’s not true for any other basic modeling function.\n\n\nComposition or product?\nThere is one family of functions for which function composition is the same thing as multiplying functions: the power-law family.\nConsider, for instance, the function \\(h(x) \\equiv \\left[3x\\right]^4\\). Let’s let \\(g(x) \\equiv 3x\\) and \\(f(y) \\equiv y^4\\). With these definitions, \\(h(x) = f(g(x))\\).\nRecognizing that \\(\\partial_y f(y) = 4 y^3\\) and \\(\\partial_x g(x) = 3\\), the chain rule gives \\[\\partial_x h(x) =\n\\underbrace{4 g(x)^3}_{f'(g(x))} \\times \\underbrace{3}_{g'(x)} = \\underbrace{4 (3 x)^3}_{f'(g(x))} \\times 3 = 4\\cdot 3^4 \\times x^3 = 324\\ x^3\\] Another way to look at the same function is \\(g(x)\\) multiplied by itself 3 times: \\[h(x) = g(x)\\cdot g(x) \\cdot g(x) \\cdot g(x)\\] This is a product of 4 terms. Applying the product rule gives \\[\\begin{eqnarray}\n\\partial_x h(x) &=& \\color{blue}{g'(x)}\\cdot g(x)\\cdot g(x) \\cdot g(x) +\\\\\n&\\ & g(x)\\cdot \\color{blue}{g(x)}'\\cdot g(x) \\cdot g(x) +\\\\\n&\\ & g(x)\\cdot g(x)\\cdot \\color{blue}{g(x)'} \\cdot g(x) +\\\\\n&\\ & g(x)\\cdot g(x)\\cdot g(x) \\cdot \\color{blue}{g'(x)}\n\\end{eqnarray}\\] Since multiplication is commutative, all of these four terms are the same, each being \\(3^4 x^3\\). The sum of all four is therefore \\(4 \\times 3^4 x^3 = 324 x^3\\).\nThese are two long-winded ways of getting to the result. For most people, differentiating power-law functions algebraically is simplified by using the rules of exponentiation rather than the product or chain rule. Here, \\[h(x) \\equiv \\left[3x\\right]^4 = 3^4 x^4\\]so \\(\\partial_x h(x)\\) is easily handled as a scalar (\\(3^4\\)) times a function \\(x^4\\). Consequently, applying the rule for differentiating power laws, \\[\\partial_x h(x) = 3^4 \\times \\partial_x x^4 = 3^4 \\times 4 x^3 = 324 x^3\\] As another example, take \\(h(x) \\equiv \\sqrt[4]{\\strut x^3}\\). This is, of course, the composition \\(f(g(x))\\) where \\(f(y) \\equiv y^{1/4}\\) and \\(g(x) \\equiv x^3\\). Applying the chain rule to find \\(\\partial_x h(x)\\) will work (of course!), but is more work than applying the rules of exponentiation followed by a simple power-law differentiation. \\[h(x) = \\sqrt[4]{\\strut x^3} = x^{3/4}\\ \\ \\text{so}\\ \\  \\partial_x h(x) = \\frac{3}{4} x^{(3/4 - 1)} = \\frac{3}{4} x^{-1/4}\\]"
  },
  {
    "objectID": "Differentiation/22-rules.html#exponentials-and-logarithms-optional",
    "href": "Differentiation/22-rules.html#exponentials-and-logarithms-optional",
    "title": "23  Derivatives of assembled functions",
    "section": "23.6 Exponentials and logarithms (optional)",
    "text": "23.6 Exponentials and logarithms (optional)\nThe natural logarithm function, \\(\\ln(x)\\), is one of our basic modeling functions. As you know, there are other logarithmic functions. The one most often used is the logarithm-base-10, written \\(\\log_{10}(x)\\) or log10(x). Ten is an integer, and a nice number to use in arithmetic. So in practice, it’s sensible to use \\(\\log_{10}()\\). (Indeed, \\(\\log_{10}()\\) is the digit() function, introduced in ?sec-magnitudes).\nThe “natural” in the “natural logarithm” means something different.\nThe base of the natural logarithm is the number called Euler’s constant and written \\(e\\). As a celebrity number, \\(e\\) is right up there with \\(\\pi\\) and \\(i\\). Just as \\(\\pi\\) has a decimal expansion that is infinitely long, the familiar \\(\\pi = 3.14159265358979...\\), Euler’s constant has an infinitely long decimal representation: \\(e = 2.71828182845905...\\)\nIt’s not obvious at first glance why \\(e = 2.71828182845905...\\) should be called “natural” by mathematicians. The reason is not the number itself, but\n\n\\(\\ln(x)\\) is the inverse of \\(e^x\\), which is special for being invariant under differentiation: \\(\\partial_x e^x = e^x\\).\nThe derivative \\(\\partial_x \\ln(x)\\) which has a particularly simple form, namely, \\(1/x\\).\n\nLet’s look at the log-base-10 and it’s computer-savvy cousin log-base-2. The very definition of logarithms means that both 10 and 2 can be written \\[10 = e^{\\ln(10)}\\ \\ \\ \\text{and}\\ \\ \\ 2 = e^{\\ln(2)}\\] This implies that the base-10 and base-2 exponential functions can be written\n\\[10^x = \\left[\\strut e^{\\strut\\ln(10)}\\right]^x = e^{\\ln(10)x} \\ \\ \\ \\text{and}\\ \\ \\ 2^x = \\left[\\strut e^{\\strut\\ln(2)}\\right]^x = e^{\\ln(2) x}\\] Calculating \\(\\partial_x 10^x\\) or \\(\\partial_x 2^x\\) is a matter of applying the chain rule:\n\\[\\partial_x [10^x] = \\partial_x [e^{\\ln(10)x}] = e^{\\ln(10)x} \\times \\ln(10) \\ =\\  10^x \\times 2.3026\\] and \\[\\partial_x [2^x] = \\partial_x [e^{\\ln(2)x}] = e^{\\ln(2)x} \\times \\ln(2) \\ = \\ 2^x \\times 0.6931\\] Like \\(e^x\\), the derivatives of \\(10^x\\) and \\(2^x\\) are proportional to themselves. For \\(e^x\\) the constant of proportionality is 1, a very natural number indeed."
  },
  {
    "objectID": "Differentiation/22-rules.html#exercises",
    "href": "Differentiation/22-rules.html#exercises",
    "title": "23  Derivatives of assembled functions",
    "section": "23.7 Exercises",
    "text": "23.7 Exercises\n<!– Drill\n\n\nPart i Which of the derivative rules should you use to find \\[\\partial_t e^{t^2}\\ ?\\]\n\nThe constant multiplier rule\nThe linear combination rule\nThe product rule\nThe chain rule\nNo rule needed, it’s so basic.\n\n\n\n\n\nPart ii Which of the derivative rules should you use to find \\[\\partial_t e^{x^2}\\ ?\\]\n\nThe constant multiplier rule\nThe linear combination rule\nThe product rule\nThe chain rule\nNo rule needed, it’s so basic.\n\n\n\n\n\nPart iii Which of the derivative rules should you use to find \\[\\partial_t e^t \\sin(t)\\ ?\\]\n\nThe constant multiplier rule\nThe linear combination rule\nThe product rule\nThe chain rule\nNo rule needed, it’s so basic.\n\n\n\n\n\nPart iv Which of the derivative rules should you use to find \\[\\partial_t e^t \\sin(x)\\ ?\\]\n\nThe constant multiplier rule\nThe linear combination rule\nThe product rule\nThe chain rule\nNo rule needed, it’s so basic.\n\n\n\n\n\nPart v Which of the derivative rules should you use to find \\[\\partial_t \\ln(t)\\ ?\\]\n\nThe constant multiplier rule\nThe linear combination rule\nThe product rule\nThe chain rule\nNo rule needed, it’s so basic.\n\n\n\n\n\nPart vi Which of the derivative rules should you use to find \\[\\partial_t\\, t\\, e^{-t}\\ ?\\]\n\nThe constant multiplier rule\nThe linear combination rule\nThe product rule\nThe chain rule\nNo rule needed, it’s so basic.\n\n\n\n\n\nPart vii Which of the derivative rules should you use to find \\[\\partial_x\\ 37 x^5\\ ?\\]\n\nThe constant multiplier rule\nThe linear combination rule\nThe product rule\nThe chain rule\nNo rule needed, it’s so basic.\n\n\n\n\n\nPart viii Which of the derivative rules should you use to find \\[\\partial_x\\ 19\\ ?\\]\n\nThe constant multiplier rule\nThe linear combination rule\nThe product rule\nThe chain rule\nNo rule needed, it’s so basic.\n\n\n\n\n\nPart ix Which of the derivative rules should you use to find \\[\\partial_x\\ 15 x^2 - 3 x + 7 \\ln(x)\\ ?\\]\n\nThe constant multiplier rule\nThe linear combination rule\nThe product rule\nThe chain rule\nNo rule needed, it’s so basic.\n\n\n\n\n\nPart x What is \\(\\partial_x\\ 15 x^2 - 3 x + 7 \\ln(x)\\)?\n\\(30 x - 3 - 7/x\\)\\(30 x - 3 + 7/x\\)\\(15 x - 3 + 7/x\\)\\(30 x - 3x + 7/x\\)\n\n\n\n\nPart xi What is \\(\\partial_t e^k + \\ln(e^2) - t\\)?\n\n\\(k e^{k} + 2 / e - t\\)\n0\n-1\n\\(e^{k} + 1/e\\)\n\n\n\n\n\nPart xii What is \\(\\partial_{x} \\ln(x)/x^2\\)? (Hint: You can write the function in a simpler way.)\n\n\\(-2 x^{-3} \\left(1/x - 1\\right)\\)\n\\(-2 x^{-3} \\ln(x)\\)\n\\(-2 x^{-1} \\ln(x)\\)\n\\(x^{-3} \\left(1 - 2 \\ln(x)\\right)\\)\n\n\n\n\n\nPart xiii What is \\(\\partial_{t} \\left(4 \\sin(2\\pi t) - 5\\right)\\)?\n\n\\(8 \\cos(2 \\pi t)\\)\n\\(4 \\pi \\cos(2 \\pi t)\\)\n\\(4 \\cos(2\\pi t) - 5\\)\n\\(8 \\pi \\cos(2 \\pi t)\\)\n\n\n\n\n\nPart xiv What is \\(\\partial_{t} \\left(7 + 8 t^2 + 3 t^4\\right)\\)?\n\\(4 t + 12 t^2\\)\\(8 t + 4 t^3\\)\\(16 t + 12 t^3\\)\\(16 t^2 + 9 t^3\\)\n\n\n\n\nPart xv The derivative \\(\\partial_x \\text{dnorm}(x) = - x\\, \\text{dnorm}(x)\\). What is \\[\\partial_x \\text{dnorm}\\left(\\frac{x^2}{4}\\right)\\ ?\\]\n\n$ - ()$\n$ - ()$\n\\(- \\frac{x^3}{8} \\text{dnorm}\\left(\\frac{x^2}{4}\\right)\\)\n$ - ()$\n\n\n\n\n\nPart xvi What is \\(\\partial_{t} \\left(6 t - 3 t^2 + 2 t^4\\right)\\)?\n\\(6 - 3 t + 8 t^2\\)\\(6 - 3 t + 6 t^3\\)\\(6 - 6 t + 8 t^3\\)\\(-3 t + 6 t^3\\)\n\n\n\n\nPart xvii What is \\(\\partial_t \\ln(t^2 + 1)\\)?\n\\(2 t \\ln(t^2 + 1)\\)\\(1/{t^2 + 1}\\)\\(\\frac{2t}{t^2+1}\\)\\(1/2t\\)\n\n\n\n\nPart xviii For the function \\[g(t) \\equiv \\sin\\left(\\frac{2 \\pi}{P} (t - t_0)\\right)\\] is the interior function linear?\nYesNo\n\n\n\n\nPart xix For the function \\[g(P) \\equiv \\sin\\left(\\frac{2 \\pi}{P} (t - t_0)\\right)\\] is the interior function linear?\nYesNo\n\n\n\n\nPart xx For the function \\[h(u) \\equiv \\ln(a^2 u - \\sqrt{b})\\] is the interior function linear?\nYesNo\n\n\n\n\nPart xxi For the function \\(f(w) \\equiv e^{kw}\\), is the interior function linear?\nYesNo\n\n\n\n\nPart xxii Saying “the interior function is linear” is not an entirely complete statement. A full statement is “the interior function is linear in terms of the input \\(x\\)” or “in terms of the input \\(u\\)” or whatever name we choose to use for the input.  Is the expression \\(V x + U\\) linear in terms of \\(U\\)?\nYesNo\n\n\n\n\nPart xxiii Saying “the interior function is linear” is not an entirely complete statement. A full statement is “the interior function is linear in terms of the input \\(x\\)” or “in terms of the input \\(u\\)” or whatever name we choose to use for the input.  Is the expression \\(V x^2 + U\\) linear in terms of \\(U\\)?\nYesNo\n\n\n\n\nPart xxiv Saying “the interior function is linear” is not an entirely complete statement. A full statement is “the interior function is linear in terms of the input \\(x\\)” or “in terms of the input \\(u\\)” or whatever name we choose to use for the input.  Is the expression \\(V x^2 + U\\) linear in terms of \\(X\\)?\nYesNo"
  },
  {
    "objectID": "Differentiation/23-optim.html",
    "href": "Differentiation/23-optim.html",
    "title": "24  Optimization",
    "section": "",
    "text": "To “optimize” means to make something as good as possible with the available resources. Optimization problems are common in science, logistics, industry, and any other area where one seeks the best solution to a problem. Some everyday examples:"
  },
  {
    "objectID": "Differentiation/23-optim.html#structure-of-the-problem",
    "href": "Differentiation/23-optim.html#structure-of-the-problem",
    "title": "24  Optimization",
    "section": "24.1 Structure of the problem",
    "text": "24.1 Structure of the problem\nIn an optimization problem, there is one or more input quantities whose value you have to choose. The amount of salt; the years to wait from planting to harvesting a tree; the angle of the trail with respect to the slope. We’ll call this the decision quantity.\nSimilarly, there is one or more output quantity that you value and want to make as good as possible. The taste of the stew; the amount of usable wood harvested; the time it takes to walk up the hill. The output quantities are called the objectives.\nIn this chapter, we will deal with optimization problems that involve only a single objective. Problems with multiple objectives are among the most interesting and important in real-world decision making. Single-objective optimization techniques are a component of the more complex decision making, but they are a good place to get started.\nThe model that relates inputs to the objective output is called the objective function. Solving an optimization problem—once the modeling phase is complete—amounts to finding a value for the decision quantity (the input to the objective function) that produces the best output from the objective function.\nSometimes the objective is something that you want to minimize, make as small as possible. In the hiking trail problem, we seek to minimize the amount of time it takes to walk up the trail. Sometimes you want to maximize the objective, as in the wood-harvest problem where the objective is to harvest the most wood per year.\n\n\nMathematically, maximization and minimization are the same thing. Every minimization problem can be turned into a maximization problem by putting a negative sign in front of the objective function. To simplify the discussion, in talking about finding the solution to an optimization problem we’ll imagine that the goal is to maximize. But keep in mind that many circumstances in the real world, “best” can mean minimization.\nRecall from Section 6.7 that there are two components to the task of maximization or minimization. The argmax is the input to the objective function which produces the largest output. The maximum is the value of that output.1 Argmin and minimum are the words used in a situation where you seek the smallest value of the objective function.\nOnce you have found the argmax you can plug that value into the objective function to find the value of the output. That value is the maximum.\n\nPeople often talk about “finding the maximum.” This is misleading. The setup for an optimization problem is:\n\nConstruct (that is, model) the objective function.\nNow that you know the objective function, find the input to that function—that is, the argmax—that produces the maximum output.\n\n\nTo illustrate the setup of an optimization problem, imagine yourself in the situation of a contest to see who can shoot a tennis ball the farthest into a field with a slingshot. During the contest, you will adjust the vertical angle of launch, place the ball into the slingshot’s cradle, pull back as far as possible, and let go. To win the contest, you need to optimize how you launch the ball.\nThe objective is to maximize the distance traveled by the ball. The objective function models the distance travelled as a function of the quantities you can control, for instance the vertical angle of launch or the amount by which you pull back the slingshot. For simplicity, we’ll imagine that the slingshot is pulled back by a standard amount, producing a velocity of the ball at release of \\(v_0\\). Since \\(v_0\\) is fixed, you’ll win or lose based on the angle of launch you choose.\nBefore you head out into the field to experiment, let’s do a bit of preparation for constructing the objective function. Using some principles of physics and mathematics (which you may not yet understand), we’ll model how far the ball will travel (horizontally) as a function of the angle of launch \\(\\theta\\) and the initial velocity \\(v_0\\).\nThe mathematics of such problems involves an area called differential equations, an important part of calculus which we’ll come to later in the course. Since you don’t have the tools yet, we’ll just state a simple model of how long the ball stays in the air. \\[\\text{duration}(v_0, \\theta) = 2 v_0 \\sin(\\theta)/g\\] \\(g\\) is the acceleration due to gravity, which is about \\(9.8 \\text{m}\\text{s}^{-2}\\), assuming that the contest is being held on Earth.\nThe horizontal distance travelled by the tennis ball will be \\[\\text{hdist}(v_0, \\theta) = \\cos(\\theta) v_0\\, \\text{duration}(v_0, \\theta) = 2 v_0^2 \\cos(\\theta)\\sin(\\theta) / g\\] Our objective function is hdist(), and we seek to find the argmax. The input \\(v_0\\) is (we have assumed) fixed, so the only decision quantity is the angle \\(\\theta\\).\nThe best choice of \\(\\theta\\) will make the quantity \\(\\cos(\\theta)\\sin(\\theta)\\) as large as possible. So in finding the argmax, we don’t need to be concerned with \\(v_0\\) or \\(g\\).\nFinding the argmax can be accomplished simply by plotting the function \\(\\cos(\\theta)\\sin(\\theta)\\). We’ll implement the function so that the input is in units of degrees.\n\n\n\n\n\n\nFigure 24.1: In the simple model of a tennis ball launched at an angle \\(\\theta\\) from the horizontal, the distance travelled is \\(2 v_0^2 / g\\) times \\(\\cos(\\theta)\\sin(\\theta)\\).\n\n\n\nYou can see that the maximum value is about 0.5 and that this occurs at an argmax \\(\\theta\\) that’s a little bit less than 50\\(^\\circ\\).\nZooming in on the \\(\\theta\\) axis let’s you find the argmax with more precision:\n\n\n\n\n\n\nFigure 24.2: Zooming in on the argmax of the objective function. It’s important to look at the scale of the vertical axis. Any value of \\(\\theta\\) between about 40 and 50 gives a very close approximation to the maximum.\n\n\n\nFrom the graph, especially the zoomed-in version, you can read off the argmax as \\(\\theta = 45^\\circ\\).\nFinding the argmax solves the problem. You may also want to present your solution by saying what the value of the output of hdist() is when the argmax is given as input. You can read off the graph that the maximum of \\(\\cos(\\theta)\\sin(\\theta)\\) is 0.5 at \\(\\theta = 45^\\circ\\), so overall the distance will be \\(v_0^2 / g\\)"
  },
  {
    "objectID": "Differentiation/23-optim.html#interpreting-the-argmax",
    "href": "Differentiation/23-optim.html#interpreting-the-argmax",
    "title": "24  Optimization",
    "section": "24.2 Interpreting the argmax",
    "text": "24.2 Interpreting the argmax\nThe graphical solution given to the slingshot problem is entirely satisfactory. Whether that solution will win the contest depends of course on whether the model we built for the objective function is correct. There are potentially important things we have left out, such as air resistence.\nSolving the optimization problem has prepared us to go out in the field and test the result. Perhaps we’ll find that the real-world optimum angle is somewhat steeper or shallower than \\(\\theta = 45^\\circ\\).\nBesides the argmax, another important quantity to read from the graph in Figure 24.1 is the precision of the argmax. In strict mathematical terms, the argmax for the tennis-ball problem is exactly 45 degrees at which point \\(\\cos(\\theta)\\sin(\\theta) = 0.5\\). Suppose, however, that the ball were launched at only 40 degrees. Five degrees difference is apparent to the eye, but the result will be essentially the same as for 45 degrees: \\(\\cos(\\theta)\\sin(\\theta) = 0.492\\). The same is true for a launch angle of 50 degrees. For both “sub-optimal” launch angles, the output is within 2 percent of the 45-degree result. It’s easy to imagine that a factor outside the scope of the simple model—the wind, for instance—could change the result by as much or more than 2 percent, so a practical report of the argmax should reasonable be “40 to 50 degrees” rather than “exactly 45 degrees.”\nContests are won or lost by margins of less than 1%, so you should not casually deviate from the argmax. On the other hand, \\(45^\\circ\\) is the argmax of the model. Reality may deviate from the model. For instance, suppose that air resistance or wind might have an effect of about 1% on the distance. Since the real-world function might deviate by as much as 1% of the model value, we shouldn’t expect the real-world argmax to be any closer to 45\\(^\\circ\\) than \\(\\pm 5^\\circ\\), since anywhere in that input domain generates an output that is within 1% of the maximum output for the model."
  },
  {
    "objectID": "Differentiation/23-optim.html#derivatives-and-optimization",
    "href": "Differentiation/23-optim.html#derivatives-and-optimization",
    "title": "24  Optimization",
    "section": "24.3 Derivatives and optimization",
    "text": "24.3 Derivatives and optimization\nWe’re now going to reframe the search for the argmax and it’s interpretation in terms of derivatives of the objective function with respect to the decision quantity (\\(\\theta\\) in the slingshot problem). For a function with one input, this will not be an improvement from the look-at-the-graph technique to find the argmax. A genuine reason to use derivatives is to set us up in the future to solve problems with more than one input, where it is hard to draw or interpret a graph. Also, describing functions in the language of derivatives can help us think more clearly about aspects of the problem, such as the precision of the argmax.\nWith a graph such as Figure 24.1, it’s easy to find the argmax; common sense carries the day. So it won’t be obvious at first why we are going to take the following approach:\nLet’s denote an argmax of the objective function \\(f(x)\\) by \\(x^\\star\\). Let’s look at the derivative \\(\\partial_x f(x)\\) in the neighborhood of \\(x^\\star\\). Referring to Figure 24.1, where \\(x^\\star = 45^\\circ\\), you may be able to see that \\(\\partial_x f(x^\\star)\\) is zero; the line tangent to the function’s graph at \\(x^\\star\\) is horizontal.\nSeen another way, the slope of \\(f(x)\\) to the left of \\(x^\\star\\) is positive. Move a tiny bit to the right (that is, increase \\(x\\) by a very small amount) leads to an increase in the output \\(f(x)\\). Just to the right of \\(x^\\star\\), the slope of \\(f(x)\\) is negative; as you reach the top of a hill and continue on, you will be going downhill. So the derivative function is positive on one side of \\(x^\\star\\) and negative on the other, suggesting that it crosses zero at the argmax.\nCommon sense is correct: Walk uphill to get to the peak, walk downhill to move away from the peak. When you come to the top of a smooth hill, the terrain is level. (Since our modeling functions are smooth, so must be the hills that we visualize the functions with.)\nInputs \\(x^\\star\\) such that \\(\\partial_x f(x^\\star) = 0\\) are called critical points. Why not call them simply argmaxes? Because a the slope will also be zero at an argmin. And it’s even possible to have the slope be zero at a point that’s neither an argmin or an argmax.\nAt this point, we know that values \\(x^\\star\\) that give \\(\\partial_x f(x^\\star) = 0\\) are “critical points,” but we haven’t said how to figure out whether a given critical point is an argmax, an argmin, or neither. This is where the behavior of \\(\\partial_x f(x)\\) near \\(x=x^\\star\\) is important. If \\(x^\\star\\) is an argmax, then \\(\\partial_x f(x)\\) will be positive to the left of \\(x^\\star\\) and negative to the right of \\(x^\\star\\); walk up the hill to get to \\(x^\\star\\), at the top the hill is flat, and just past the top the hill has a negative slope.\nFor an argmin, changing \\(x\\) from less than \\(x^\\star\\) to greater than \\(x^\\star\\); you will be walking down into the valley, then level at the very bottom \\(x=x^\\star\\), then back up the other side of the valley after you pass \\(x=x^\\star\\). Figure 24.3 shows the situation.\n\n\n\n\n\nFigure 24.3: Top row: An objective function near an argmax (left) and an argmin (right). Bottom row: The derivative of the objective function. A horizontal line (orange) has been added to mark zero on the vertical axis.\n\n\n\n\nThe bottom row of graphs in Figure 24.3 shows the derivative of the objective function \\(f(x)\\), that is, \\(\\partial_x f(x)\\). You can see that for the argmax of \\(f(x)\\), the derivative \\(\\partial_x f(x)\\) is positive to the left and negative to the right. Similarly, near the argmin of \\(f(x)\\), the derivative \\(\\partial_x f(x)\\) is negative to the left and positive to the right.\nStated another way, the derivative \\(\\partial_x f(x)\\) has a negative slope just to the left of an argmin and a positive slope to the left of an argmax.\nThe second derivative of the objective function \\(f(x)\\) at a critical point \\(x^\\star\\) is what tells us whether the critical point is an argmax, an argmin, or neither.\n\n\n\n\n\n\n\n\n\n\nCritical point \\(x^\\star\\)\n\\(\\partial_x f(x^\\star)\\)\n\\(\\partial_{xx} f(x^\\star)\\)\n\n\n\n\nargmax\n0\nnegative\n\n\nargmin\n0\npositive\n\n\nneither\n0\n0\n\n\n\n\nThroughout Block 2, we have translated features of functions that are evident on a graph into the language of derivatives:\n\nThe slope of a function \\(f(x)\\) at any input \\(x\\) is the value of the derivative function \\(\\partial_x f(x)\\) at that same \\(x\\).\nThe concavity of a function \\(f(x)\\) at any input is the slope of the derivative function, that is, \\(\\partial_{xx} f(x)\\).\nPutting (i) and (ii) together, we get that the concavity of a function \\(f(x)\\) at any input \\(x\\) is the value of the second derivative function, that is, \\(\\partial_{xx} f(x)\\).\nAt an argmax \\(x^\\star\\) of \\(f(x)\\), the value of the derivative function \\(\\partial_x f(x^\\star)\\) is zero and the value of the second derivative function \\(\\partial_{xx} f(x^\\star)\\) is negative. The situation at an argmin is along the same lines, the derivative of the objective function is zero and the second derivative is positive.\n\n\n\nWhat’s the critical point?\nYou’re familiar with the quadratic polynomial: \\[g(x) = a_0 + a_1 x + a_2 x^2\\] The graph of a quadratic polynomial is a parabola, which might be concave up or concave down. As you know, a parabola has only one critical point, which might be an argmin or an argmax.\nLet’s find the critical point. We know that the critical point is \\(x^\\star\\) such that \\(\\partial_x g(x^\\star) = 0\\). Since we know how to differentiate a power law, we can see that \\[\\partial_x g(x) = a_1 + 2 a_2 x\\] and, more specifically, at the critical point \\(x^\\star\\) the derivative will be \\[a_1 + 2 a_2 x^\\star = 0\\] The above is an equation, not a definition. It says that whatever \\(x^\\star\\) happens to be, the quantity \\(a_1 + 2 a_2 x^\\star\\) must be zero. Using plain old algebra, we can find the location of the critical point \\[x^\\star = -\\frac{a_1}{2 a_2}\\]\n\n\n\n\nIn economics, a monopoly or similar arrangement can set the price for a good or commodity. Monopolists can set the price at a level that generates the most income for themselves.\n\n\n\n\n\nFigure 24.4: Demand as a function of price, as first published by Antoine-Augustin Cournot in 1836. Source)\n\n\n\n\nIn 1836, early economist Antoine-Augustin Cournot published a theory of revenue versus demand based on his conception that demand will be a monotonically decreasing function of price. (That is, higher price means lower demand.) We’ll write as \\(\\text{Demand}(p)\\) demand as a function of price.\nThe revenue generated at price \\(p\\) is \\(R(p) \\equiv p \\text{Demand}(p)\\): price times demand.\nTo find the revenue-maximizing demand, differentiate \\(R(p)\\) with respect to \\(p\\) and find the argmax \\(p^\\star\\) at with \\(\\partial_p R(p^\\star) = 0).\\) This can be done with the product rule.\n\\[\\partial_p R(p) = p \\ \\partial_p \\text{Demand}(p) + \\text{Demand}(p)\\] At the argmax \\(p^\\star\\) we have: \\[p^\\star \\partial_p \\text{Demand}(p^\\star) + \\text{Demand}(p^\\star) = 0 \\ \\ \\stackrel{\\text{solving for}\\ p^\\star}{\\Longrightarrow} \\ \\ p^\\star = - \\frac{\\text{Demand}(p^\\star)}{\\partial_p \\text{Demand}(p^\\star)}\\]\nIf the monopolist knows the demand function \\(D(p)\\), finding the revenue maximizing price is a simple matter. But in general, the monopolist does not know the demand function in advance. Instead, an informed guess is made to set the initial price \\(p_0\\). Measuring sales \\(D(p_0)\\) gives one point on the demand curve. Then, try another price \\(p_1\\). This gives another point on the demand curve as well as an estimate \\[\\partial_p D(p_0) = \\frac{D(p_1) - D(p_0)}{p_1 - p_0}\\] Now the monopolist is set to model the demand curve as a straight-line function and easily to find \\(p^\\star\\) for the model. For instance, if the demand function is modeled as \\(D_1 (p) = a + b p\\), the optimal price will be \\(p^\\star_1 = - \\frac{a + b p^\\star}{b}\\) which can be solved as \\(p^\\star_1 = - a/2b\\).\n\\(p^\\star_1\\) is just an estimate of the optimum price. Still, the monopolist can try out that price, giving a third data point for the demand function from which a better model of the demand function can be constructed. With the better estimate, find a new a argmax \\(p^\\star_2\\). This sort of iterative process for finding an argmax of a real-world function is very common in practice."
  },
  {
    "objectID": "Differentiation/23-optim.html#sec-flat-on-top",
    "href": "Differentiation/23-optim.html#sec-flat-on-top",
    "title": "24  Optimization",
    "section": "24.4 Be practical!",
    "text": "24.4 Be practical!\nDecision making is about choosing among alternatives. In some engineering or policy contexts, this can mean finding a value for an input that will produce the “best” outcome. For those who have studied calculus, it’s natural to believe that calculus-based techniques for optimization are the route to making the decision.\nWe emphasize that the optimization techniques covered in this chapter are only part of a broader set of techniques for real-world decision-making problems. In particular, most policy contexts involve multiple objectives. For example, in designing a car one goal is to make it cheap to manufacture, another to make it attractive, and still another to make it safe. These different objectives are often at odds with one another. In Block 4 of this text, we’ll discuss some calculus techniques that help policy-makers in multi-objective settings.\nFor now, sticking with the idealized (and often unrealistic) setting of maximizing a single objective, with one or more inputs. Recall the setting for calculus-type maximization. You have a function with one or more inputs, say, \\(f(x)\\) or \\(g(x,y)\\) or, often, \\(h(x, y, z, \\ldots)\\) where \\(\\ldots\\) might be standing for tens or hundreds or thousands of inputs or more.\nIf you can graph the function (feasible for one- or two-input functions), you can often easily scan the graph by eye to find the peak. The calculus-based techniques were developed for situations where such graphing is not possible and, instead, you have a formula for the function. (Such occasions are of great theoretical interest but not all that common in practice.) The basis of the calculus techniques is the observation that, at the argmax of a smooth function, the derivative of the function is 0.\nAs an example, consider a style problem that often appears in calculus textbooks. You have been tasked to design a container for a large volume V of liquid. It is desired to make the weight of the container as little as possible. (This is a minimization problem, then.) In classical textbook fashion, you are told that the container is to be a cylinder made out of a particular metal of a particular thickness.\nThis is a lovely geometry/calculus problem. Whether it is relevant to any genuine, real-world problem is another question.\n\n\n\n\n\n\n\n\n\nUsing the notation in the diagram, the volume and surface area of the cylinder is \\[V(r, h) \\equiv \\pi r^2 h \\ \\ \\ \\text{and}\\ \\ \\ A(r, h) \\equiv 2 \\pi r^2 + 2 \\pi r h\\]\nMinimizing the weight of the cylinder is our objective (according to the problem statement) and the weight is proportional to the surface area. Since the volume \\(V\\) is given (according to the problem statement), we want to re-write the area function to use volume:\n\\[h(r, V) \\equiv V / \\pi r^2 \\ \\ \\ \\implies\\ \\ \\ A(r, V) = 2 \\pi r^2 + 2 \\pi r V/\\pi r^2 = 2 \\pi r^2 + 2 V / r\\] Suppose \\(V\\) were specified as 1000 liters. A good first step is to choose appropriate units for \\(r\\) to make sure the formula for \\(A(r, V)\\) is dimensionally consistent. Suppose we choose \\(r\\) in cm. Then we want \\(V\\) in cubic centimeters (cc). 1000 liters is 1,000,000 cc. Now we can plot a slice of the area function:\n\nA <- makeFun(2*pi*r^2 + 2*V/r ~ r, V=1000000)\nslice_plot(A(r) ~ r, domain(r=c(10, 100))) %>%\n  gf_labs(x = \"radius (cm)\", y = \"Surface area of container (square cm)\")\n\n\n\n\n\n\n\n\nAs always, the function’s derivative is zero at the optimal \\(r\\). In the graph, the argmin is near \\(r=50\\) cm at which point the minimum is about 50,000 cm\\(^2\\). Since \\(h(r,V) = V/\\pi r^2\\), the required height of cylinder will be near \\(10^6 / \\pi 50^2 = 127\\)cm.\nIn calculus courses, the goal is often to find a formula for the optimal radius as a function of \\(V\\). So we differentiate the objective function—that is, the area function for any \\(V\\) and \\(r\\) with respect to \\(r\\), \\[\\partial_r A(r, V) = 4 \\pi r - 2 V / r^2\\] Setting this to zero (which will be true at the optimal \\(r^\\star\\)) we can solve for \\(r^\\star\\) in terms of \\(V\\): \\[4 \\pi r^\\star - 2 \\frac{V}{\\left[r^\\star\\right]^2} = 0 \\ \\ \\ \\Longrightarrow\\ \\ \\ 4\\pi r^\\star = 2\\frac{V}{\\left[r^\\star\\right]^2} \\Longrightarrow\\ \\ \\ \\left[r^\\star\\right]^3 = \\frac{1}{2\\pi} V \\ \\ \\ \\Longrightarrow\\ \\ \\  r^\\star = \\sqrt[3]{V/2\\pi}\\]\nFor \\(V = 1,000,000\\) cm\\(^3\\), this gives \\(r^\\star = 54.1926\\) cm which in turn implies that the corresponding height \\(h^\\star = V/\\pi (r^\\star)^2 = 108.3852\\) cm.\nWe’ve presented the optimum \\(r^\\star\\) and \\(h^\\star\\) to the nearest micron. (Does that make sense to you? Think about it for a moment before reading on.)\nA good rule of thumb in modeling is this: “If you don’t know what a sensible precision is for reporting your result, you don’t have a complete grasp of the problem.” Here are two reasonable ways to sort out a suitable precision.\n\nSolve a closely related problem which for many practical purposes would have been equivalent.\nLook at how big a change in the output of the objective function is produced by a change from the argmax.\n\nApproach (2) is always at hand, since you already know the objective function. Let’s graph the objective function near \\(r = 54.1926\\) …\n\n\n\n\n\n\n\n\n\nLook carefully at the axes scales. Deviating from the mathematical optimum by about 5cm (that is, 50,000 microns) produces a change in the output of the objective function by about 400 units out of 55,000. In other words, about 0.7%.\nIt’s true that \\(r^\\star = 54.1926\\) cm gives the “best” outcome. And sometimes such precision is warranted. For example, improving the speed of an elite marathon racer by even 0.1% would give her a 7 second advantage: often the difference between silver and gold!\nWhat’s different is that you know exactly what is the ultimate objective of a marathon: finish faster. But you may not know the ultimate objective of the system your “optimal” tank will be a part of. For instance, your tank may be part of an external fuel pod on an aircraft. Certainly the designers of the aircraft want the tank to be as light as possible. But they also want to reduce drag as much as possible. A 54 cm diameter tube has about 17% more drag than a 50 cm tube. To save that much drag, it’s probably well worth increasing weight by 0.7%.\nIn reporting the results from an optimization problem, you ought to give the decision maker all relevant information. Here, that might be as simple as including the above graph in your report.\nWe mentioned another technique for getting a handle on what precision is meaningful: (1) solve a closely related problem. This often requires some insight and creativity to frame the new problem. Here, we note that large capacity tanks often are shaped like a lozenge: a cylinder with hemi-spherical ends.\n\n\n\n\n\n\n\n\n\nUsing \\(h\\) for the length of the cylindrical portion of the tank, and \\(r\\) for the radius, the volume and surface area are: \\[V(r, h) = \\pi r^2 h + \\frac{4}{3} \\pi r^3 \\ \\ \\ \\text{and}\\ \\ \\ A(r,h) = 2 \\pi r h + 4 \\pi r^2\\] Again, \\(V\\) was specified as 1000 liters. As detailed in Exercise 23.18, the surface area of this 1000-liter tank is about 48,400 cm\\(^2\\). This is more than 10% less than for the cylindrical tank."
  },
  {
    "objectID": "Differentiation/23-optim.html#exercises",
    "href": "Differentiation/23-optim.html#exercises",
    "title": "24  Optimization",
    "section": "24.5 Exercises",
    "text": "24.5 Exercises"
  },
  {
    "objectID": "Differentiation/24-partial.html",
    "href": "Differentiation/24-partial.html",
    "title": "25  Partial change and the gradient vector",
    "section": "",
    "text": "This is a good time to point out something we have been doing all along, but which has likely been such a persistent component of your mathematics education that you may not have realized that it is a construction.\nWe have two ways by which we represent functions:\nThese two modes are sometimes intertwined, as when we use the name “line” to refer to a computational object: \\(\\line(x) \\equiv a x + b\\).\nUnfortunately for functions of two inputs, a surface is hard to present in the formats that are most easily at hand: a piece of paper, a printed page, a computer screen. That’s because a curved surface is naturally a 3-dimensional object, while paper and screens provide two-dimensional images. Consequently, the graphics mode we prefer for presenting functions of two inputs is the contour plot, which is not a single geometrical object but a set of many objects: contours, labels, colored tiles.\nWe’ve been doing calculus on functions with one input because it is so easy to exploit both the computational mode and the graphical mode. And it might fairly be taken as a basic organizing theme of calculus that\nWhen figuring out the derivative function \\(\\partial_x f(x)\\) from a graph of \\(f(x)\\), we find the tangent to the graph at each of many input values, record the slope of the line (and throw away the intercept) and then write down the series of slopes as a function of the input, typically by representing the slope by position along the vertical axis and the corresponding input by position along the horizontal axis. Figure 25.1 shows the process.\nPanel (A) in Figure 25.1 shows a smooth function \\(f(x)\\) (thin black curve). To find the function \\(\\partial_x f(x)\\), we take the slope of \\(f(x)\\) at many closely spaced inputs. In Panel (A), we’ve highlighted short, tangent line segments at the closely-spaced points labeled A through V. The slope of each tangent line segment can be calculated by the usual rise-over-run method; the numerical value of the slope is written underneath the segment. To plot the derivative \\(\\partial_x f(x)\\), I have taken the slope information from (A) and plotted it as a function of \\(x\\).\nTo restate what you already know, in the neighborhood of any input value \\(x\\), the slope of any local straight-line approximation to \\(f(x)\\) is given by the value of of \\(\\partial_x f(x)\\)."
  },
  {
    "objectID": "Differentiation/24-partial.html#calculus-on-two-inputs",
    "href": "Differentiation/24-partial.html#calculus-on-two-inputs",
    "title": "25  Partial change and the gradient vector",
    "section": "25.1 Calculus on two inputs",
    "text": "25.1 Calculus on two inputs\nAlthough we use contour plots for good practical reasons, the graph of a function \\(g(x,y)\\) with two inputs is a surface, as described in Section @ref(surface-plot). The derivative of \\(g(x,y)\\) should encode the information needed to approximate the surface at any input \\((x,y)\\). In particular, we want the derivative of \\(g(x,y)\\) to tell us the orientation of the tangent plane to the surface.\nA tangent plane is infinite in extent. Let’s use the word facet to refer to a little patch of the tangent plane centered at the point of contact. Each facet is flat. (It’s part of a plane!) Figure 25.2 shows some facets tangent to a familiar curved surface. No two of the facets are oriented the same way.\n\n\n\n\n\n\nFigure 25.2: A melon as a model of a curved surface such as the graph of a function of two inputs. Each tangent facet has its own orientation. (Disregard the slight curvature of the small pieces of paper. Summer humidity has interfered with my attempt to model a flat facet with a piece of Post-It paper!\n\n\n\nBetter than a picture of a summer melon, pick up a hardcover book and place it on a curved surface such as a basketball. The book cover is a flat surface: a facet. The orientation of the cover will match the orientation of the surface at the point of tangency. Change the orientation of the cover and you will find that the point of tangency will change correspondingly.\nIf melons and basketballs are not your style, you can play the same game on an interactive graph of a function with two inputs. The snapshot below is a link to an applet that shows the graph of a function as a blue surface. You can specify a point on the surface by setting the value of the (x, y) input using the sliders. Display the tangent plane (which will be green) at that point by check-marking the “Tangent plane” input. (Acknowledgments to Alfredo Sánchez Alberca who wrote the applet using the GeoGebra math visualization system.)\n::: {asis eval=knitr::is_html_output()}  :::\n\n\n\nFor the purposes of computation by eye, a contour graph of a surface can be easier to deal with. Figure 25.3 shows the contour graph of a smoothly varying function. Three points have been labeled A, B, and C.\n\n\n\n\n\n\n\n\nFigure 25.3: A function of 2 inputs with 3 specific inputs marked A, B, and C\n\n\n\n\nZooming in on each of the marked points presents a simpler picture for each of them, although one that is different for each point. Each zoomed-in plot contains almost parallel, almost evenly spaced contours. If the surface had been exactly planar over the entire zoomed-in domain, the contours would be exactly parallel and exactly evenly spaced. We can approach such exact parallelness by zooming in more closely around the labeled point.\n\n\n\n\n\nFigure 25.4: Zooming in on the neighborhoods of A, B, and C in Figure 25.3 shows a simple, almost planar, local landscape. The bottom row shows the contours of the tangent plane near each of the neighborhoos in the top row.\n\n\n\n\nJust as the function \\(\\line(x) \\equiv a x + b\\) describes a straight line, the function \\(\\text{plane}(x, y) \\equiv a + b x + c y\\) describes a plane whose orientation is specified by the value of the parameters \\(b\\) and \\(c\\). (Parameter \\(a\\) is about the vertical location of the plane, not it’s orientation.)\nIn the bottom row of Figure 25.4, the facets tangent to the original surface at A, B, and C are displayed. Comparing the top and bottom rows of Figure 25.4) you can see that each facet has the same orientation as the surface; the contours face in the same way.\nRemember that the point of constructing such facets is to generalize the idea of a derivative from a function of one input \\(f(x)\\) to functions of two or more inputs such as \\(g(x,y)\\). Just as the derivative \\(\\partial_x f(x_0)\\) reflects the slope of the line tangent to the graph of \\(f(x)\\) at \\(x=x_0\\), our plan for the “derivative” of \\(g(x_0,y_0)\\) is to represent the orientation of the facet tangent to the graph of \\(g(x,y)\\) at \\((x=x_0, y=y_0)\\). The question for us now is what information is needed to specify an orientation.\nOne clue comes from the formula for a function whose graph is a plane oriented in a particular direction:\n\\[\\text{plane}(x,y) \\equiv a + b x + cy\\]\n\nTo explore the roles of the parameters \\(b\\) and \\(c\\) in setting the orientation of the line, open a SANDBOX. The scaffolding code generates a particular instance of \\(\\text{plane}(x,y)\\) and plots it in two ways: a contour plot and a surface plot. Change the numerical values of \\(b\\) and \\(c\\) and observe how the orientation of the planar surface changes in the graphs. You can also see that the value of \\(a\\) is irrelevant to the orientation of the plane, just as the intercept of a straight-line graph is irrelevant to the slope of that line.\n\nplane <- makeFun(a + b*x + c*y ~ x + y, a = 1, b = -2.5, c = 1.6)\nif (knitr::is_html_output()) {\n  interactive_plot(plane(x, y) ~ x + y, domain(x=c(-2, 2), y=c(-2, 2)))\n} else {\n  knitr::include_graphics(\"www/plane-3d.png\")\n}\n\n\n\n\ncontour_plot(plane(x, y) ~ x + y, domain(x=c(-2, 2), y=c(-2, 2))) %>%\n  gf_refine(coord_fixed())\n\n\n\n\n\n\n\n\nAs always it can be difficult to extract quantitative information from a surface plot. For the example here, you can see that the high-point on the surface is when \\(x\\) is most negative and \\(y\\) is most positive. Compare that to the contour plot to verify that two modes are displaying the same surface.\n(Note: The gf_refine(coord_fixed()) part of the contour-plot command makes numerical intervals on the horizontal and vertical axes have the same length.)\n\nAn instructive experience is to pick up a rigid, flat object, for instance a smartphone or hardcover book. Hold the object level with pinched fingers at the mid-point of each of the short ends, as shown in ?fig-hold-book (left).\n\n\n\n\n\nFigure 25.5: Combining two simple movements can tip a plane to all sorts of different orientations.\n\n\n\n\n\n\n\nFigure 25.6: Combining two simple movements can tip a plane to all sorts of different orientations.\n\n\n\n\n\n\n\nFigure 25.7: Combining two simple movements can tip a plane to all sorts of different orientations.\n\n\n\n\nYou can tip the object in one direction by raising or lowering one hand. (middle picture) And you can tip the object in the other coordinate direction by rotating the object around the line joining the points grasped by the left and right hands. (right picture) By combining these two motions, you can orient the surface of the object in a wide range of directions.1\nThe purpose of this lesson is to show that two-numbers are sufficient to dictate the orientation of a plane. In terms of ?fig-hold-book these are 1) the amount that one hand is raised relative to the other and 2) the angle of rotation around the hand-to-hand axis.\nSimilarly, in the formula for a plane, the orientation is set by two numbers, \\(b\\) and \\(c\\) in \\(\\text{plane}(x, y) \\equiv a + b x + c y\\).\nHow do we find the right \\(b\\) and \\(c\\) for the tangent facet to a function \\(g(x,y)\\) at a specific input \\((x_0, y_0)\\)? Taking slices of \\(g(x,y)\\) provides the answer. In particular, these two slices: \\[\\text{slice}_1(x) \\equiv g(x, y_0) = a + b\\, x + c\\, y_0 \\\\ \\text{slice}_2(y) \\equiv g(x_0, y) = a + b x_0 + c\\, y\\]\nLook carefully at the formulas for the slices. In \\(\\text{slice}_1(x)\\), the value of \\(y\\) is being held constant at \\(y=y_0\\). Similarly, in \\(\\text{slice}_2(y)\\) the value of \\(x\\) is held constant at \\(x=x_0\\).\nThe parameters \\(b\\) and \\(c\\) can be read out from the derivatives of the respective slices: \\(b\\) is equal to the derivative of the slice\\(_1\\) function with respect to \\(x\\) evaluated at \\(x=x_0\\), while \\(c\\) is the derivative of the slice\\(_2\\) function with respect to \\(y\\) evaluated at \\(y=y_0\\). Or, in the more compact mathematical notation:\n\\[b = \\partial_x \\text{slice}_1(x)\\left.\\strut\\right|_{x=x_0} \\ \\ \\text{and}\\ \\ c=\\partial_y \\text{slice}_2(y)\\left.\\strut\\right|_{y=y_0}\\] These derivatives of slice functions are called partial derivatives. The word “partial” refers to examining just one input at a time. In the above formulas, the \\({\\large |}_{x=x_0}\\) means to evaluate the derivative at \\(x=x_0\\) and \\({\\large |}_{y=y_0}\\) means something similar.\nYou don’t need to create the slices explicitly in order to calculate the partial derivatives. Simply differentiate \\(g(x, y)\\) with respect to \\(x\\) in order to get parameter \\(b\\) and differentiate \\(g(x, y)\\) with respect to \\(y\\) to get parameter \\(c\\). To demonstrate, we’ll make use of the sum rule: \\[\\partial_x g(x, y) = \\underbrace{\\partial_x a}_{=0} + \\underbrace{\\partial_x b x}_{=b} + \\underbrace{\\partial_x cy}_{=0} = b\\] Similarly, \\[\\partial_y g(x, y) = \\underbrace{\\partial_y a}_{=0} + \\underbrace{\\partial_y b x}_{=0} + \\underbrace{\\partial_y cy}_{=c} = c\\]\n\nGet in the habit of noticing the subscript on the differentiation symbol \\(\\partial\\). When taking, for instance, \\(\\partial_y f(x,y,z, \\ldots)\\), all inputs other than \\(y\\) are to be held constant. Some examples:\n\\[\\partial_y 3 x^2 = 0\\ \\ \\text{but}\\ \\ \\\n\\partial_x 3 x^2 = 6x\\\\\n\\ \\\\\n\\partial_y 2 x^2 y = 2x^2\\ \\ \\text{but}\\ \\ \\\n\\partial_x 2 x^2 y = 4 x y\n\\]"
  },
  {
    "objectID": "Differentiation/24-partial.html#all-other-things-being-equal",
    "href": "Differentiation/24-partial.html#all-other-things-being-equal",
    "title": "25  Partial change and the gradient vector",
    "section": "25.2 All other things being equal …",
    "text": "25.2 All other things being equal …\nRecall that the derivative of a function with one input, say, \\(\\partial_x f(x)\\) tells you, at each possible value of the input \\(x\\), how much the output will change proportional to a small change in the value of the input.\nNow that we are in the domain of multiple inputs, writing \\(h\\) to stand for “a small change” is not entirely adequate. Instead, we’ll write \\(dx\\) for a small change in the \\(x\\) input and \\(dy\\) for a small change in the \\(y\\) input.\nWith this notation, we write the first-order polynomial approximation to a function of a single input \\(x\\) as \\[f(x+dx) = f(x) + \\partial_x f(x) \\times dx\\] Applying this notation to functions of two inputs, we have: \\[g(x + \\color{magenta}{dx}, y) = g(x,y) + \\color{magenta}{\\partial_x} g(x,y) \\times \\color{magenta}{dx}\\] and \\[g(x, y+\\color{brown}{dy}) = g(x,y) + \\color{brown}{\\partial_y} g(x,y) \\times \\color{brown}{dy}\\]\nEach of these statements is about changing one input while holding the other input(s) constant. Or, as the more familiar expression goes, “The effect of changing one input all other things being equal or all other things held constant.2\nEverything we’ve said about differentiation rules applies not just to functions of one input, \\(f(x)\\), but to functions with two or more inputs, \\(g(x,y)\\), \\(h(x,y,z)\\) and so on."
  },
  {
    "objectID": "Differentiation/24-partial.html#gradient-vector",
    "href": "Differentiation/24-partial.html#gradient-vector",
    "title": "25  Partial change and the gradient vector",
    "section": "25.3 Gradient vector",
    "text": "25.3 Gradient vector\nFor functions of two inputs, there are two partial derivatives. For functions of three inputs, there are three partial derivatives. We can, of course, collect the partial derivatives into Cartesian coordinate form. This collection is called the gradient vector.\nJust as our notation for differences (\\(\\cal D\\)) and derivatives (\\(\\partial\\)) involves unusual typography on the letter “D,” the notation for the gradient involves such unusual typography although this time on \\(\\Delta\\), the Greek version of “D.” For the gradient symbol, turn \\(\\Delta\\) on its head: \\(\\nabla\\). That is, \\[\\nabla g(x,y) \\equiv \\left(\\stackrel\\strut\\strut\\partial_x g(x,y), \\ \\ \\partial_y g(x,y)\\right)\\]\nNote that \\(\\nabla g(x,y)\\) is a function of both \\(x\\) and \\(y\\), so in general the gradient vector differs from place to place in the function’s domain.\nThe graphics convention for drawing a gradient vector for a particular input, that is, \\(\\nabla g(x_0, y_0)\\), puts an arrow with its root at \\((x_0, y_0)\\), pointing in direction \\(\\nabla g(x_0, y_0)\\), as in Figure 25.8.\n\n## Warning in makeFun.formula(g(x, y) ~ x, suppress.warnings = FALSE): Implicit\n## variables without default values (dangerous!): y\n\n## Warning in makeFun.formula(g(x, y) ~ x, suppress.warnings = FALSE): Implicit\n## variables without default values (dangerous!): y\n## Warning in makeFun.formula(g(x, y) ~ y, suppress.warnings = FALSE): Implicit\n## variables without default values (dangerous!): x\n\n## Warning in makeFun.formula(g(x, y) ~ y, suppress.warnings = FALSE): Implicit\n## variables without default values (dangerous!): x\n\n\n\n\nFigure 25.8: The gradient vector \\(\\nabla g(x=1,y=2)\\). The vector points in the steepest uphill direction. Consequently, it is perpendicular to the contour passing through its root.\n\n\n\n\nA gradient field (see Figure 25.9) is the value of the gradient vector at each point in the function’s domain. Graphically, in order to prevent over-crowding, the vectors are drawn at discrete points. The lengths of the drawn vectors are set proportional to the numerical length of \\(\\nabla g(x, y)\\), so a short vector means the surface is relatively level, a long vector means the surface is relatively steep.\n\n\n\n\n\nFigure 25.9: A plot of the gradient field \\(\\nabla g(x,y)\\)."
  },
  {
    "objectID": "Differentiation/24-partial.html#total-derivative-optional",
    "href": "Differentiation/24-partial.html#total-derivative-optional",
    "title": "25  Partial change and the gradient vector",
    "section": "25.4 Total derivative (optional)",
    "text": "25.4 Total derivative (optional)\nThe name “partial derivative” suggests the existence of some kind of derivative that’s not just a part, but the whole thing. The total derivative is such a whole and gratifyingly made up of it’s parts, that is, the partial derivatives.\nSuppose you are modeling the temperature of some volume of the atmosphere, given as \\(T(t, x, y, z)\\). This merely says that the temperature depends on both time and location, something that is familiar from everyday life.\nThe partial derivatives have an easy interpretation: \\(\\partial_t T()\\) tells how the temperature is changing over time at a given location, perhaps because of the evaporation or condensation of water vapor. \\(\\partial_x T()\\) tells how the temperature changes in the \\(x\\) direction, and so on.\nThe total derivative gives an overall picture of the changes in a parcel of air, which you can thnk of as a tiny balloon-like structure but without the balloon membrane. The temperature inside the “balloon” may change with time (e.g. condensation or evaporation of water), but as the ballon drifts along with the motion of the air (that is, the wind), the evolving location can change the temperature as well. Think of a balloon caught in an updraft: the temperature goes down as the balloon ascends.\nFor an imaginary observer located in the balloon, the temperature is changing with time. Part of this change is the instrinsic change measured by \\(\\partial_t T\\) but we need to add to that the changes induces by the evolving location of the balloon. The partial change in temperature due to a change in altitude is \\(\\partial_z T\\), but it’s important to realize that the coordinates of the location are themselves functions of time: \\(x(t), y(t), z(t)\\). Seeing the function \\(T()\\) for the observer in the balloon as a function of \\(t\\), we have \\(T(t, x(t), y(t), z(t))\\). This is a function composition: \\(T()\\) composed with each of \\(x()\\), \\(y()\\), and \\(z()\\). Recall in the chain rule \\(\\partial_v f(g(v)) = \\partial_v f(g(v)) \\partial_v g(v)\\) that the derivative of the composed quantity is the product of two derivatives.\nLikewise, the total derivative of temperature with respect to the observer riding in the balloon will be add together the parts due to changes in time (holding position constant), x-coordinate (holding time and the other space coordinates constant), and the like. Signifying the total differentiation with a capital \\(D\\), we have \\[D\\, T(t) = \\partial_t T() + \\partial_x T() \\cdot\\partial_t x + \\partial_y T()\\cdot \\partial_t y + \\partial_z T() \\cdot\\partial_t z\\] Note that \\(\\partial_t x\\) is the velocity of the balloon in the x-direction, and similarly for the other coordinate directions. Writing these velocities as \\(v_x, v_y, v_z\\), the total derivative for temperature of a parcel of air embedded in a moving atmosphere is\n\\[D\\ T(t) = \\partial_t T + v_x\\, \\partial_x T + v_y\\, \\partial_y T + v_z\\, \\partial_z T\\] Formulations like this, which put the parts of change together into a whole, are often seen in the mathematics of fluid flow as applied in meteorology and oceanology."
  },
  {
    "objectID": "Differentiation/24-partial.html#sec-differential-skier",
    "href": "Differentiation/24-partial.html#sec-differential-skier",
    "title": "25  Partial change and the gradient vector",
    "section": "25.5 Differentials",
    "text": "25.5 Differentials\n\nA little bit of this, a little bit of that. — Stevie Wonder, “The Game of Love”\n\nWe have framed calculus in terms of functions: transformations that take one (or more!) quantities as input and return a quantity as output. This was not the original formulation. In this section, we will use the original style in order to demonstrate how you can sometimes skip the step of constructing a function before differentiating to answer a question of the sort: “If this quantity changes by a little bit, how much will another, related quantity change?”\nAs an example, consider the textbook-style problem of a water skier being pulled along the water by a rope pulled in from the top of a tower of height \\(H\\). The skier is distance \\(x\\) from the tower. As the rope is winched in at a constant rate, does the skier go faster or slower as she approaches the tower.\n\n\n\n\n\n\n\n\n\nIn the function style of approach, we can write the position function \\(x(t)\\) with input the length of the rope \\(L(t)\\). Using the diagram, you can see that \\[x(t) = \\sqrt{\\strut L(t)^2 - H^2}\\ .\\]\nDifferentiate both sides with respect to \\(t\\) to get the velocity of the skier: \\(\\partial_t x(t)\\) through the chain rule: \\[\\underbrace{\\partial_t x(t)}_{\\partial_t f(g(t))} = \\underbrace{\\frac{1}{2\\sqrt{\\strut L(t)^2 - H^2}}}_{\\left[ \\partial_t f \\right](g(t)) } \\times \\underbrace{\\left[2 \\partial_t L(t)\\right]}_{\\partial_t g(t)} = \\frac{\\partial_t L(t)}{\\strut\\sqrt{L(t)^2 - H^2}}\\]\nNow to reformulate the problem without defining a function.\nNewton referred to “flowing quantities” or “fluents” and to what today is universally called derivatives as “fluxions.” Newton did not have a notion of inputs and output.3\nAt about the same time as Newton’s inventions, very similar ideas were being given very different names by mathematicians on the European continent. There, an infinitely small change in a quantity was called a “differential” and the differential of \\(x\\) was denoted \\(dx\\).\nThe first calculus textbook was subtitled, Of the Calculus of Differentials, in other words, how to calculate differentials. (See Figure 25.10.) Section I of this 1696 text is entitled, “Where we give the rules of this calculation,” those rules being recognizably the same as presented in Section 23 of this book.\n\n\n\n\n\n\nFigure 25.10: From the start of the first calculus textbook, by le marquis de l’Hôpital, 1696.\n\n\n\nDefinition I of Section I states,\n\n“We call quantities variable* that grow or decrease continuously; and to the contrary constant quantities are those that remain the same while the others change. … The infinitely small amount by which a continuous quantity increases or decreases is called the differential.*”\n\nThe differential is not a derivative. The differential is an infinitely small change in a quantity and a derivative is a rate of change. The differential of a quantity \\(x\\) is written \\(dx\\) in the textbook.4\nThe point of Section I of de l’Hôpital’s textbook is to present the rules by which the differentials of complex quantities can be calculated. You’ll recognize the product rule in de l’Hôpital’s notation:\n\n\n\n\n\n\nThe differential of \\(x\\,y\\) is \\(y\\,dx + x\\,dy\\)\n\n\n\nThe Pythagorean theorem relates the various quantities this way:\n\\[L^2 = x^2 + H^2\\]\nThe differential of each side of the equation refers to “a little bit” of increase in the quantity on that side of the equation: \\[d(L^2) = d(x^2)\\ \\ \\ \\implies\\ \\ \\ 2 L\\, dL = 2 x\\, dx\\] where we’ve used one of the “rules” for calculating differentials. This gives us \\[dx = \\frac{L}{x} dL\\] Think of this as a recipe for calculating \\(dx\\). If you tell me \\(L\\), \\(x\\), and \\(dL\\) then you can calculate the value of \\(dx\\). For instance, suppose the tower is 52 feet tall and that there is \\(L=173\\) feet of tow-rope extending to the skier. The Pythagorean theorem tells us the skier is \\(x=165\\) feet from the base of the tower. The rope is, let us suppose, being pulled in at the top of the tower at \\(dL = 10\\) feet per second. How fast is \\(x\\) changing? \\[dx = \\frac{173\\ \\text{ft}}{165\\ \\text{ft}} \\times 10 \\text{ft s}^{-2} = 10.05\\ \\text{ft s}^{-1}\\]\nWe’ll return to “a little bit of this” when we explore how to add up little bits to get the whole in Section 38."
  },
  {
    "objectID": "Differentiation/24-partial.html#exercises",
    "href": "Differentiation/24-partial.html#exercises",
    "title": "25  Partial change and the gradient vector",
    "section": "25.6 Exercises",
    "text": "25.6 Exercises\n<!– Drill\n\n\nPart i What is \\(\\partial_x x\\)?\n\\(0\\)\\(1\\)\\(x\\)\\(y\\)\n\n\n\n\nPart ii What is \\(\\partial_x y\\)?\n\\(0\\)\\(1\\)\\(x\\)\\(y\\)\n\n\n\n\nPart iii What is \\(\\partial_x a\\, x\\)?\n\\(0\\)\\(a\\)\\(x\\)\\(y\\)\n\n\n\n\nPart iv What is \\(\\partial_x x\\, y\\)?\n\\(0\\)\\(1\\)\\(x\\)\\(y\\)\n\n\n\n\nPart v What is \\(\\partial_y x\\, y\\)?\n\\(0\\)\\(1\\)\\(x\\)\\(y\\)\n\n\n\n\nPart vi What is \\(\\partial_x A e^{kt}\\)?\n\\(0\\)\\(A k e^{kx}\\)\\(t\\)\n\n\n\n\nPart vii What is \\(\\partial_t A e^{kt}\\)?\n\\(0\\)\\(k A e^{kt}\\)\\(k A e^{kx}\\)\\(t A e^{kt}\\)\n\n\n\n\nPart viii What is \\(\\partial_x A x e^{kt}\\)?\n\\(A e^{kt}\\)\\(A x e^{kt}\\)\\(0\\)\\(A k x e^{kt}\\)\n\n\n\n\nPart ix What is \\(\\partial_t A x e^{kt}\\)?\n\\(A e^{kt}\\)\\(A k e^{kt}\\)\\(0\\)\\(A k x e^{kt}\\)\n\n\n\n\nPart x What is \\(\\partial_x \\left[\\strut a_0 + a_1 x + a_2 x^2 \\right]\\)?\n0\\(a_1 + 2 a_2 x\\)\\(a_1 + a_2 x\\)\\(a_0 + a_1 x\\)\n\n\n\n\nPart xi What is \\(\\partial_y \\left[\\strut a_0 + a_1 x + a_2 x^2 \\right]\\)?\n0\\(a_1 + 2 a_2 x\\)\\(a_1 + a_2 x\\)\\(a_1 + 2 a_2 y\\)\n\n\n\n\nPart xii What is \\(\\partial_x \\left[\\strut a_0 + a_1 y + a_2 y^2 \\right]\\)?\n0\\(a_1 + 2 a_2 x\\)\\(a_1 + a_2 x\\)\\(a_1 + 2 a_2 y\\)\n\n\n\n\nPart xiii What is \\(\\partial_x \\left[\\strut a_0 + a_1 x + b_1 y + c x y \\right]\\)?\n\\(a_1 + c\\)\\(a_1\\)\\(a_1 + cy\\)\\(a_1 + b1 + c\\)\n\n\n\n\nPart xiv What is \\(\\partial_y \\left[\\strut a_0 + a_1 x + b_1 y + c x y \\right]\\)?\n\\(b_1 + c\\)\\(b_1\\)\\(b_1 + cx\\)\\(a_1 + b1 + c\\)\n\n\n\n\nPart xv What is \\(\\partial_x \\partial_y \\left[\\strut a_0 + a_1 x + b_1 y + c x y \\right]\\)? (Usually we would write \\(\\partial_{xy}\\) instead of \\(\\partial_x \\partial_y\\), but they amount to the same thing.)\n\\(0\\)\\(a_1\\)\\(c\\)\\(b_1\\)\n\n\n\n\nPart xvi What is \\(\\partial_x \\partial_x \\left[\\strut a_0 + a_1 x + b_1 y + c x y \\right]\\)? (Usually we would write \\(\\partial_{xx}\\) instead of \\(\\partial_x \\partial_x\\), but they amount to the same thing.)\n\\(0\\)\\(a_1\\)\\(c\\)\\(b_1\\)\n\n\n\n\nPart xvii What is \\(\\partial_x \\partial_x \\left[\\strut a_0 + a_1 x + b_1 y + c x y + a_2 x^2 + b_2 y^2 \\right]\\)? (Usually we would write \\(\\partial_{xx}\\) instead of \\(\\partial_x \\partial_x\\), but they amount to the same thing.)\n\\(0\\)\\(a_2\\)\\(2 a_2\\)\\(c + a_2\\)\n\n\n\n\nPart xviii What is \\(\\partial_y \\partial_x \\left[\\strut a_0 + a_1 x + b_1 y + c x y + a_2 x^2 + b_2 y^2 \\right]\\)? (Usually we would write \\(\\partial_{yx}\\) instead of \\(\\partial_y \\partial_x\\), but they amount to the same thing.)\n\\(0\\)\\(2 a_2\\)\\(c\\)\\(2 b_2\\)\n\n\n\n\nPart xix What is \\(\\partial_x \\left[\\strut A x^n y^m \\right]\\)?\n\n\\(A y^m\\)\n\\(A n m x^{n-1} y^{m-1}\\)\n\\(A n x^{n-1} y^m\\)\n\\(A m x^{n} y^{m-1}\\)\n\n\n\n\n\nPart xx What is \\(\\partial_y \\left[\\strut A x^n y^m \\right]\\)?\n\n\\(A m y^{m-1}\\)\n\\(A n m x^{n-1} y^{m-1}\\)\n\\(A n x^{n-1} y^m\\)\n\\(A m x^{n} y^{m-1}\\)\n\n\n\n\n\nPart xxi What is \\(\\partial_{xy} \\left[\\strut A x^n y^m \\right]\\)?\n\n\\(A m x^{n-1} y^{m-1}\\)\n\\(A n m x^{n-1} y^{m-1}\\)\n\\(A n x^{n-1} y^{m-1}\\)\n\\(A m x^{n} y^{m-1}\\)\n\n\n\n\n\nPart xxii What is \\(\\partial_x \\left[\\strut f(x) + y\\right]\\)?\n\n\\(0\\)\n\\(\\partial_x f(x) + 1\\)\n\\(\\partial_x f(x)\\)\n\\(\\partial_x f(x) + y\\)\n\n\n\n\n\nPart xxiii What is \\(\\partial_x \\left[\\strut f(x) + g(y)\\right]\\)?\n\n\\(0\\)\n\\(\\partial_x f(x) + \\partial_x g(y)\\)\n\\(\\partial_x f(x)\\)\n\\(\\partial_x f(x) + \\partial_y g(y)\\)\n\n\n\n\n\nPart xxiv What is \\(\\partial_y \\left[\\strut f(x) + g(y)\\right]\\)?\n0\\(\\partial_x g(y)\\)\\(\\partial_x f(x)\\)\\(\\partial_y g(y)\\)\n\n\n\n\nPart xxv What is \\(\\partial_x \\partial_y \\left[\\strut f(x) + g(y)\\right]\\)?\n\n0\n\\(\\partial_x \\partial_y g(y)\\)\n\\(\\partial_x f(x)\\)\n\\(\\partial_y g(y)\\)\n\n\n\n\n\nPart xxvi What is \\(\\partial_y \\partial_y \\left[\\strut f(x) + g(y)\\right]\\)?\n01\\(\\partial_y g(y)\\)\\(\\partial_{yy} g(y)\\)\n\n\n\n\nPart xxvii What is \\(\\partial_y f(x) g(y)\\)?\n\n\\(g(y)\\ \\partial_y f(x) + f(x) \\ \\partial_y g(y)\\)\n\\(f(x)\\ \\partial_{y} g(y)\\)\n\\(\\partial_y g(y)\\)\n0\n\n\n\n\n\nPart xxviii What is \\(\\partial_y h(x,y) g(y)\\)?\n\n$ g(y) _y h(x,y) + h(x,y) _y g(y)$\n\\(g(y) \\partial_y h(x, y)\\)\n\\(\\partial_y g(y)\\)\n0\n\n\n\n\n\nPart xxix What is \\(\\partial_x h(x,y) g(y)\\)?\n\n\\(g(y) \\partial_y h(x, y)\\)\n\\(g(y)\\ \\partial_x h(x,y) + h(x,y)\\ \\partial_x g(y)\\)\n\\(\\partial_x h(x, y)\\)\n\\(g(y) \\partial_x h(x, y)\\)\n\n\n\n\n\nPart xxx What is \\(\\partial_{yx} h(x,y) g(y)\\)?\n\n\\((\\partial_x g(y))\\  (\\partial_x h(x, y)) + g(y) (\\partial_{xx} h(x, y) )\\)\n\\(g(y) \\partial_{yx} h(x,y) + h(x,y)\\ \\partial_y g(y)\\)\n\\(\\partial_{yx} h(x, y)\\)\n\\((\\partial_y g(y)) \\ (\\partial_x h(x, y)) + g(y)\\ (\\partial_{yx} h(x, y))\\)\n\n\n\n\n\nPart xxxi What is the “with-respect-to” input in \\(\\partial_y xy\\)?\n\\(y\\)\\(x\\)\\(1\\)\n\n\n\n\nPart xxxii What is the “with-respect-to” input in \\(\\partial_x y\\)?\n\\(y\\)\\(x\\)\\(1\\)\n\n\n\n\nPart xxxiii What is the “with-respect-to” input in \\(\\partial_t y\\)?\n\\(y\\)\\(t\\)\\(1\\)\n\n\n\n\nPart xxxiv At which of these inputs is the function steepest in the x-direction?\n\\((x=0, y=1)\\)\\((x=1, y=5)\\)\\((x=0, y=6)\\)\\((x=-2, y=6)\\)\n\n\n\n\nPart xxxv At which of these inputs is the function practically flat?\n\\((x=0, y=1)\\)\\((x=1, y=2)\\)\\((x=0, y=6)\\)\\((x=-2, y=3)\\)\n\n\n\n\nPart xxxvi You are standing on the input point \\((x=-1,y=4)\\). In terms of the compass points (where north would be up and east to the right), which direction points most steeply uphill from where you are standing.\nNESESWNW\n\n\n\n\nPart xxxvii You are standing on the input point \\((x=2,y=1)\\). In terms of the compass points (where north would be up and east to the right), which direction points most steeply uphill from where you are standing.\nNESESWNW\n\n\n\n\nPart xxxviii You have been hiking all day and have reached map coordinate (x=2, y=2). You are completely exhausted. Time for a break. You want to walk along the hill, without any change of elevation. Which compass direction should you head in to get started?\nNE or SWSE but not NWNW or SENW but not SE"
  },
  {
    "objectID": "Differentiation/25-approximation.html",
    "href": "Differentiation/25-approximation.html",
    "title": "26  Local approximations [DRAFT]",
    "section": "",
    "text": "NOTE NOTE NOTE\nThe material in this first section has been moved to the new Block 1 chapter 5. CHANGE THIS CHAPTER TO FOCUS ON THE ANALYSIS OF LOW-ORDER POLYNOMIALS BY differentiation.\nThe information that you have about the relationship often takes the form of a data table. Each row records one trial in which the values of the inputs have been measured and the corresponding output value recorded. We’ll discuss the methods of constructing functions to match such data in Block 5 of this course.\nAnother common form for the information about the relationship is about derivatives. That is, you know something about the derivative of a relationship even though you don’t (yet) have a form for the function describing the relationship. As an example, think about building a model of the sustainable speed of a bicycle as a function of the gear selected and the grade of the road—up or down.\nConsider these three questions that any experienced bicyclist can likely answer:\nUsing the methods in this chapter, the answers to those three questions let you choose an appropriate form for the speed(gear, grade) function. Then, using methods in Block 5 of this text, you can make a few measurements for any given rider and construct a model customized to that rider.\nNote that the three questions all have to do with derivatives. An “optimal gear” is a gear at which \\(\\partial_\\text{gear} \\text{speed}(\\text{gear}, \\text{grade}) = 0\\). That you ride slower the higher the numerical value of the slope means that \\(\\partial_\\text{grade} \\text{speed}(\\text{gear}, \\text{grade}) < 0\\). And we know that \\(\\partial_\\text{gear} \\text{speed}(\\text{gear}, \\text{grade})\\) depends on the grade; that’s why there’s a different optimal gear at each grade.\nEND OF MATERIAL COPIED From modeling/05-low-order-polynomials.Rmd\nWe have focused in this book on a small set of basic modeling functions and three operations for assembling new functions out of old ones: linear combination, multiplication, and composition. All of these have a domain that is the whole number line, or the positive half of the number line, or perhaps the whole number line leaving out zero or some other isolated point. Consider such domains to be global.\nWe also discussed the components of piecewise functions. Each component is a function defined on a limited domain, an interval \\(a \\leq x \\leq b\\). In contrast to the global domains, we’ll call the limited domains local.\nIn this chapter, we’ll explore a simple and surprisingly powerful method to approximate any function locally, that is, over a small domain.\nThe information that you have about the relationship often takes the form of a data table. Each row records one trial in which the values of the inputs have been measured and the corresponding output value recorded. We’ll discuss the methods of constructing functions to match such data in Block 5 of this course.\nAnother common form for the information about the relationship is about derivatives. That is, you know something about the derivative of a relationship even though you don’t (yet) have a form for the function describing the relationship. As an example, think about building a model of the sustainable speed of a bicycle as a function of the gear selected and the grade of the road—up or down.\nConsider these three questions that any experienced bicyclist can likely answer:\nUsing the methods in this chapter, the answers to those three questions let you choose an appropriate form for the speed(gear, grade) function. Then, using methods in Block 5 of this text, you can make a few measurements for any given rider and construct a model customized to that rider.\nNote that the three questions all have to do with derivatives. An “optimal gear” is a gear at which \\(\\partial_\\text{gear} \\text{speed}(\\text{gear}, \\text{grade}) = 0\\). That you ride slower the higher the numerical value of the slope means that \\(\\partial_\\text{grade} \\text{speed}(\\text{gear}, \\text{grade}) < 0\\). And we know that \\(\\partial_\\text{gear} \\text{speed}(\\text{gear}, \\text{grade})\\) depends on the grade; that’s why there’s a different optimal gear at each grade."
  },
  {
    "objectID": "Differentiation/25-approximation.html#eight-simple-shapes",
    "href": "Differentiation/25-approximation.html#eight-simple-shapes",
    "title": "26  Local approximations [DRAFT]",
    "section": "26.1 Eight simple shapes",
    "text": "26.1 Eight simple shapes\nIn many modeling situations with a single input, you can get very close to a good modeling function \\(f(x)\\) by selecting one of eight simple shapes, shown in Figure 26.1.\n\n\n\n\n\nFigure 26.1: The eight simple shapes, locally, of functions with one input. (See Section 26.)\n\n\n\n\n\n\n\n\n\nFigure 26.2: The eight simple shapes, locally, of functions with one input. (See Section 26.)\n\n\n\n\nTo choose among these shapes, consider your modeling context:\n\nis the relationship positive (slopes up) or negative (slopes down)\nis the relationship monotonic or not\nis the relationship concave up, concave down, or neither\n\nSome examples, scenarios where the modeler knows about the derivative and concavity of the relationship being modeled. It’s often the case that your knowledge of the system comes in this form.\n\nThe incidence of an out-of-control epidemic versus time is concave up, but shallow-then-steep. As the epidemic is brought under control, the decline is steep-then-shallow and concave up. Over the whole course of an epidemic, there is a maximum incidence. Experience shows that epidemics can have a phase where incidence reaches a local minimum: a decline as people practice social distancing followed by an increase as people become complacent.\nHow many minutes can you run as a function of speed? Concave down and shallow-then-steep; you wear out faster if you run at high speed. How far can you walk as a function of time? Steep-then-shallow and concave down; your pace slows as you get tired.\nHow does the stew taste as a function of saltiness. The taste improves as the amount of salt increases … up to a point. Too much salt and the stew is unpalatable.\nThe temperature of cooling water or the emission of radioactivity as functions of time are concave up and steep-then-shallow.\nHow much fuel is consumed by an aircraft as a function of distance? For long flights the function is concave up and shallow-then-steep; fuel use increases with distance, but the amount of fuel you have to carry also increases with distance and heavy aircraft use more fuel per mile.\nIn micro-economic theory there are production functions that describe how much of a good is produced at any given price, and demand functions that describe how much of the good will be purchased as a function of price.\n\nAs a rule, production increases with price and demand decreases with price. In the short term, production functions tend to be concave down, since it’s hard to squeeze increased production out of existing facilities.\n\nFor demand in the short term, functions will be concave up when there is some group of consumers who have no other choice than to buy the product. An example is the consumption of gasoline versus price: it’s hard in the short term to find another way to get to work. In the long term, consumption functions can be concave down as consumers find alternatives to the high-priced good. For example, high prices for gasoline may, in the long term, prompt a switch to more efficient cars, hybrids, or electric vehicles. This will push demand down steeply."
  },
  {
    "objectID": "Differentiation/25-approximation.html#low-order-polynomials",
    "href": "Differentiation/25-approximation.html#low-order-polynomials",
    "title": "26  Local approximations [DRAFT]",
    "section": "26.2 Low-order polynomials",
    "text": "26.2 Low-order polynomials\nThere is a simple, familiar functional form that, by selecting parameters appropriately, can take on each of the eight simple shapes: the second-order polynomial. \\[g(x) \\equiv a + b x + c x^2\\] As you know, the graph of \\(g(x)\\) is a parabola.\n\nThe parabola opens upward if \\(0 < c\\). That’s the shape of a local minimum.\nThe parabola opens downward if \\(c < 0\\). That’s the shape of a local maximum\n\nConsider what happens if \\(c = 0\\). The function becomes simply \\(a + bx\\), the straight-line function.\n\nWhen \\(0 < b\\) the line slopes upward.\nWhen \\(b < 0\\) the line slopes downward.\n\nWith the appropriate choice of parameters, the form \\(a + bx + cx^2\\) is capable of representing four of the eight simple shapes. What about the remaining four? This is where the idea of local becomes important. Those remaining four shapes are the sides of parabolas, as in Figure 26.3.\n\n\n\n\n\nFigure 26.3: Four of the eight simple shapes correspond to the sides of the parabola. The labels refer to the graphs in Figure 26.2."
  },
  {
    "objectID": "Differentiation/25-approximation.html#sec-low-order-two",
    "href": "Differentiation/25-approximation.html#sec-low-order-two",
    "title": "26  Local approximations [DRAFT]",
    "section": "26.3 The low-order polynomial with two inputs",
    "text": "26.3 The low-order polynomial with two inputs\nFor functions with two inputs, the low-order polynomial approximation looks like this:\n\\[g(x, y) \\equiv a_0 + a_x x + a_y y + a_{xy} x y + a_{yy} y^2 + a_{xx} x^2\\] In reading this form, note the system being used to name the polynomial’s coefficients. First, we’ve used \\(a\\) as the root name of all the coefficients. Sometimes we might want to compare two or more low-order polynomials, so it’s convenient to be able to use \\(a\\) for one, \\(b\\) for another, and so on.\nThe subscripts on the coefficients describes exactly which term in the polynomial involves each coefficient. For instance, the \\(a_{yy}\\) coefficient applies to the \\(y^2\\) term, while \\(a_x\\) applies to the \\(x\\) term.\nEach of \\(a_0, a_x,\\) \\(a_y,\\) \\(a_{xy}, a_{yy}\\), and \\(a_{xx}\\) will, in the final model, be a constant quantity. Don’t be confused by the use of \\(x\\) or \\(y\\) in the name of the coefficients. Each coefficient is a constant and not a function of the inputs. Often, your prior knowledge of the system being modeled will tell you something about one or more of the coefficients, for example, whether it is positive or negative. Finding a precise value is often based on quantitative data about the system.\nIt helps to have different names for the various terms. It’s not too bad to say something like, “the \\(a_{xy}\\) term.” (Pronounciation: “a sub x y” or “a x y”) But the proper names are: linear terms, quadratic terms, and interaction term. And a shout out to \\(a_0\\), the constant term.\n\\[g(x, y) \\equiv a_0 + \\underbrace{a_x x + a_y y}_\\text{linear terms} \\ \\ \\ +\n\\underbrace{a_{xy} x y}_\\text{interaction term} +\\ \\ \\  \\underbrace{a_{yy} y^2 + a_{xx} x^2}_\\text{quadratic terms}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 26.4: A saddle\n\n\n\n\nIf you’re like many people, you find it harder to walk uphill than down, and find it takes more out of you to walk longer distances than shorter. Let’s build a model of this, using nothing more than your intuition and the method of low-order polynomial approximations.\nLet’s call the map distance walked \\(d\\). (“Map distance” is the horizontal change in position, disregarding vertical changes.) The steepness of the hill will be the “grade” \\(g\\), which is measured as the horizontal distance covered divided by the vertical climb. If you’re going downhill, the grade is negative.\nThe key ingredient in the model: We’ll measure the “difficulty” or “exertion” to walking as the energy consumed during the walk: \\(E(d, g)\\).\nSome assumptions about walking and energy consumed:\n\nIf you don’t walk, you consume zero energy walking.\nThe energy consumed should be proportional to the length of the walk. This is an assumption, and is probably valid, only for walks of short to medium distances, as opposed to forced marches over tens of miles.\n\nWe’ll start with the full 2nd-order polynomial in two inputs, and then seek to eliminate terms that aren’t needed.\n\\[E_{big}(d, g) \\equiv a_0 + a_d\\, d + a_g\\, g + a_{dg}\\, d\\, g + a_{dd}\\,d^2 + a_{gg}\\,g^2\\] According to assumption (1), when \\(E(d=0, g) = 0\\). Of course, if you are walking zero distance, it doesn’t matter what the grade is; the energy consumed is still zero.\nConsequently, we know that all terms that don’t include a \\(d\\) should go away. This leaves us with\n\\[E_{medium}(d, g) \\equiv  a_d\\, d + a_{dg}\\, d\\, g + a_{dd}\\,d^2 = d \\left[\\strut a_d + a_{dg}\\, g + a_{dd}\\,d\\right]\\] Assumption (2) says that energy consumed is proportional to \\(d\\). The multiplier on \\(d\\) in \\(E_{medium}()\\) is \\(\\left[\\strut a_d + a_{dg}\\, g + a_{dd}\\,d\\right]\\) which is itself a function of \\(d\\). A proportional relationship implies a multiplier that doesn’t depend on the quantity itself. This means that \\(a_{dd} = 0\\).\nThis leaves us with a very simple model: \\[E(d, g) \\equiv \\left[\\strut a_1 + a_2\\, g\\right]\\, d\\] where we have simplified the labeling on the coefficients since there are only two in the model.\nPerhaps assumption (2) is mis-placed and that the energy consumed per unit distance in a walk increases with the length of the walk. If so, we would need to return to the question of \\(a_{dd}\\). This is typical of the modeling cycle. Trying to be economical with model terms highlights the question of which terms are so small they can be ignored.\n\n\nIn selecting cadets for pilot training, two criteria are the cadet’s demonstrated flying aptitude and the leadership potential of the cadet. Let’s assume that the overall merit \\(M\\) of a candidate is a function of flying aptitude \\(F\\) and leadership potential \\(L\\).\nCurrently, the merit score is a simple function of the \\(F\\) and \\(L\\) scores: \\[M_{current}(F, L) \\equiv F + L\\]\nThe general in charge of the training program is not satisfied with the current merit function. “I’m getting too many cadets who are great leaders but poor pilots, and too many pilot hot-shots who are not good leaders. I would rather have an good pilot who is a good leader than have a great pilot who is a poor leader or a poor pilot who is a great leader.” (You might reasonably agree or disagree with this point of view, but the general is in charge.)\nThe general has tasked you to revise the formula to better match her views about the balance betwen flying ability and leadership potential.\nHow should you go about constructing \\(M_{improved}(F, L)\\)?\nYou recognize that \\(F + L\\) is a low-order polynomial: just the linear terms are present without a constant or interaction term or quadratic terms. Low-order polynomials are a good way to approximate any formula locally, so you have decided to follow that route.\nQuadratic terms are appropriate when a model needs to feature a locally optimal level of the of the inputs. But it will never be the case that a lower flying score will be more favored than a higher score, and the same thing for the leadership score. So your model doesn’t need quadratic terms.\nThat leaves the interaction term as the way forward. The low-order polynomial model will be \\[M_{improved}(F, L) \\equiv d_0 + F + L + d_{FL} FL\\] Should \\(d_{FL}\\) be positive or negative?\nImagine a cadet Drew with acceptable and equal F and L scores. Another cadet, Blake, has scores that are \\(F+\\epsilon\\) and \\(L-\\epsilon\\), where \\(\\epsilon\\) might be positive or negative. Under the original formula for merit, Drew and Blake have equal merit. Under the new criteria, Drew should have a higher merit than Blake. In other words: \\[M_{improved}(F, L) - M_{improved}(F+\\epsilon, L-\\epsilon) > 0\\]\nReplace \\(M_{improved}(F, L)\\) with the low-order polynomial approximation given earlier. \\[\\underbrace{d_0 + F + L + d_{FL} FL}_{M_{improved}(F, L)} - \\underbrace{\\left[{\\large\\strut} d_0 + \\left[ F + \\epsilon\\right] + \\left[ L - \\epsilon\\right] + d_{FL} (FL -\\epsilon L + \\epsilon F -  \\epsilon^2)\\right]}_{M_{improved}(F+\\epsilon, L-\\epsilon)} > 0\\] Collecting and cancelling terms in the above gives \\[- d_{FL}(\\epsilon(F-L) + \\epsilon^2) > 0\\] Since \\(F\\) and \\(L\\) were assumed equal, this results in \\[M_{improved}(F, L) - M_{improved}(F+\\epsilon, L-\\epsilon) = d_{FL}\\, \\epsilon^2 > 0\\] Thus, \\(d_{FL}\\) will have to be positive."
  },
  {
    "objectID": "Differentiation/25-approximation.html#sec-partial-thought",
    "href": "Differentiation/25-approximation.html#sec-partial-thought",
    "title": "26  Local approximations [DRAFT]",
    "section": "26.4 Thinking partially",
    "text": "26.4 Thinking partially\nThe expression for a general low-order polynomial in two inputs can be daunting to think about all at once: \\[g(x, y) \\equiv a_0 + a_x x + a_y y + a_{xy} x y + a_{xx} x^2 + a_{yy} y^2\\] As with many complicated settings, a good approach can be to split things up into simpler pieces. With a low-order polynomial, one such splitting up involves partial derivatives. There are six potentially non-zero partial derivatives for a low-order polynomial, of which two are the same; so only five quantities to consider.\n\n\\(\\partial_x g(x,y) = a_x + a_{xy}y + 2 a_{xx} x\\)\n\\(\\partial_y g(x,y) = a_y + a_{xy}x + 2 a_{yy} y\\)\n\\(\\partial_{xy} g(x,y) = \\partial_{yx} g(x,y) = a_{xy}\\). These are the so-called mixed partial derivatives. It doesn’t matter whether you differentiate by \\(x\\) first or by \\(y\\) first. The result will always be the same for any smooth function.\n\\(\\partial_{xx} g(x,y) = 2 a_{xx}\\)\n\\(\\partial_{yy} g(x,y) = 2 a_{yy}\\)\n\nThe above list states neutral mathematical facts that apply generally to any low-order polynomial whatsoever.3 Those facts, however, shape a way of asking questions of yourself that can help you shape the model of a given phenomenon based on what you already know about how things work.\nTo illustrate, consider the situation of modeling the effect of study \\(S\\) and of tutoring \\(T\\) (a.k.a. office hours, extended instruction) on performance \\(P(S,T)\\) on an exam. In the spirit of partial derivatives, we’ll assume that all other factors (student aptitude, workload, etc.) are held constant.\nTo start, pick fiducial values for \\(S\\) and \\(T\\) to define the local domain for the model. Since \\(S=0\\) and \\(T=0\\) are easy to envision, we’ll use those for the fiducial values.\nNext, ask five questions, in this order, about the system being modeled.\n\nDoes performance increase with study time? Don’t over-think this. Remember that the approximation is around a fiducial point. Here, a reasonable answer is, “yes.” We’ll take\\(\\partial_S P(S, T) > 0\\) to imply that \\(a_S > 0\\). This is appropriate because close to the fiducial point, the other contributors to \\(\\partial_S P(S, T)\\), namely \\(a_{ST}T + 2 a_{SS} S\\) will be vanishingly small.\nDoes performance increase with time spent being tutored? Again, don’t over-think this. Don’t worry (yet) that your social life is collapsing because of the time spent studying and being tutored, and the consequent emotional depression will cause you to fail the exam. We’re building a model here and the heuristic being used is to consider factors in isolation. Since (as we expect you’ll agree) \\(\\partial_T P(S, T) > 0\\), we have that \\(a_T > 0\\).\n\nNow the questions get a little bit harder and will exercise your calculus-intuition since you’ll have to think about changes in the rates of change.\n\nThis question has to do with the mixed partial derivative, which we’ve written variously as \\(\\partial_{ST} P(S,T)\\) or \\(\\partial_{TS} P(S,T)\\) and which it might be better to think about as \\(\\partial_S \\left[\\partial_T P(S,T) \\right]\\) or \\(\\partial_T \\left[\\partial S P(S,T)\\right]\\). Although these are mathematically equal, often your intuition will favor one form or the other. Recall that we’re working on the premise that \\(\\partial_S P(S,T) > 0\\), or, in other words, study will help you do better on the exam. Now for \\(\\partial_T \\left[\\partial S P(S,T)\\right]\\). This is a the matter of whether some tutoring will make your study more effective. Let’s say yes here, since tutoring can help you overcome a misconception that’s a roadblock to effective study. So \\(\\partial_{TS} P(S,T) > 0\\) which implies \\(a_{ST} > 0\\).\n\nThe other way round, \\(\\partial_S \\left[\\partial_T P(S,T) \\right]\\) is a matter of whether increasing study will enhance the positive effect of tutoring. We’ll say yes here again, because a better knowledge of the material from studying will help you follow what the tutor is saying and doing. From pure mathematics, we already know that the two forms of mixed partials are equivalent, but to the human mind they sometimes (and incorrectly) appear to be different in some subtle, ineffable way.\nIn some modeling contexts, there might be no clear answer to the question of \\(\\partial_{xy}\\, g(x,y)\\). That’s also a useful result, since it tells us that the \\(a_{xy}\\) term may not be important to understanding that system.\n\nOn to the question of \\(\\partial_{SS} P(S,T)\\), that is, whether \\(a_{SS}\\) is positive, negative, or negligible. We know that \\(a_{SS} S^2\\) will be small whenever \\(S\\) is small, so this is our opportunity to think about bigger \\(S\\). So does the impact of a unit of additional study increase or decrease the more you study? One point of view is that there is some moment when “it all comes together” and you understand the topic well. But after that epiphany, more study might not accomplish as much as before the epiphany. Another bit of experience is that “cramming” is not an effective study strategy. And then there’s your social life … So let’s say, provisionally, that there is an argmax to study, beyond which point you’re not helping yourself. This means that \\(a_{SS} < 0\\).\nFinally, consider \\(\\partial_{TT} P(S, T)\\). Reasonable people might disagree here, which is itself a reason to suspect that \\(a_{TT}\\) is negligible.\n\nAnswering these questions doesn’t provide a numerical value for the coefficients on the low-order polynomial, and says nothing at all about \\(a_0\\), since all the questions are about change.\nAnother step forward in extracting what you know about the system you are modeling is to construct the polynomial informed by questions 1 through 5. Since you don’t know the numerical values for the coefficients, this might seem impossible. But there is a another modeler’s trick that might help.\nLet’s imagine that the domain of both \\(S\\) and \\(T\\) or the interval zero to one. This is not to say that we think one hour of study is the most possible but simply to defer the question of what are appropriate units for \\(S\\) and \\(T\\). Very much in this spirit, for the coefficients we’ll use \\(+0.5\\) when are previous answers indicated that the coefficient should be greater than zero, \\(-0.5\\) when the answers pointed to a negative coefficient, and zero if we don’t know. Using this technique, here’s the model, which mainly serves as a basis for checking whether our previous answers are in line with our broader intuition before we move on quantitatively.\n\nP <- makeFun(0.5*S + 0.5*T + 0.5*S*T - 0.5*S^2 ~ S & T)\ncontour_plot(P(S, T) ~ S & T, domain(S=0:1, T=0:1))\n\n\n\n\nFigure 26.5: The result of our intuitive investigation of the effects of study and tutoring on exam performance. The units are not yet assigned.\n\n\n\n\nNotice that for small values of \\(T\\), the horizontal spacing between adjacent contours is large. That is, it takes a lot of study to improve performance a little. At large values of \\(T\\) the horizontal spacing between contours is smaller."
  },
  {
    "objectID": "Differentiation/25-approximation.html#finding-coefficients-from-data",
    "href": "Differentiation/25-approximation.html#finding-coefficients-from-data",
    "title": "26  Local approximations [DRAFT]",
    "section": "26.5 Finding coefficients from data",
    "text": "26.5 Finding coefficients from data\nLow-order polynomials are often used for constructing functions from data. In this section, I’ll demonstrate briefly how this can be done. The full theory will be introduced in Block 5 of this text.\nThe data I’ll use for the demonstration is a set of physical measurements of height, weight, abdominal circumference, etc. on 252 human subjects. These are contained in the Body_fat data frame, shown below. ::: {.cell layout-align=“center” fig.showtext=‘false’} ::: {.cell-output-display}\n\n\n::: :::\nOne of the variables records the body-fat percentage, that is, the fraction of the body’s mass that is fat. This is thought to be an indicator of fitness and health, but it is extremely hard to measure and involves weighing the person when they are fully submerged in water. This difficulty motivates the development of a method to approximation body-fat percentage from other, easier to make measurements such as height, weight, and so on.\nFor the purpose of this demonstration, we’ll build a local polynomial model of body-fat percentage as a function of height (in inches) and weight (in pounds).\nThe polynomial we choose will omit the quadratic terms. It will contain the constant, linear, and interaction terms only. That is \\[\\text{body.fat}(h, w) \\equiv c_0 + c_h h + c_w w + c_{hw} h w\\] The process of finding the best coefficients in the polynomial is called linear regression. Without going into the details, we’ll use linear regression to build the body-fat model and then display the model function as a contour plot.\n\nmod <- lm(bodyfat ~ height + weight + height*weight,\n          data = Zcalc::Body_fat)\nbody_fat_fun <- makeFun(mod)\ncontour_plot(body_fat_fun(height, weight) ~ height + weight,\n             domain(weight=c(100, 250), height = c(60, 80))) %>%\n  gf_labs(title = \"Body fat percentage\")\n\n\n\n\nFigure 26.6: A low order polynomial model of body fat percentage as a function of height (inches) and weight (lbs).\n\n\n\n\nThat we can build such a model doesn’t mean that it’s useful for anything. In Block 5 of the text we’ll return to the question of how well a model constructed from data represents the real-world relationships that the model attempts to describe."
  },
  {
    "objectID": "Differentiation/25-approximation.html#exercises",
    "href": "Differentiation/25-approximation.html#exercises",
    "title": "26  Local approximations [DRAFT]",
    "section": "26.6 Exercises",
    "text": "26.6 Exercises"
  },
  {
    "objectID": "Differentiation/26-taylor.html",
    "href": "Differentiation/26-taylor.html",
    "title": "27  Polynomials",
    "section": "",
    "text": "A big part of the high-school algebra curriculum is about polynomials. In some ways, this is appropriate since polynomials played an outsized part in the historical development of mathematical theory. Indeed, the so-called “Fundamental theorem of algebra” is about polynomials.1\nFor modelers, polynomials are a mixed bag. They are very widely used in modeling. Sometimes this is entirely appropriate, for instance the low-order polynomials that are the subject of Section 26. The problems come when high-order polynomials are selected for modeling purposes. Building a reliable model with high-order polynomials requires a deep knowledge of mathematics, and introduces serious potential pitfalls. Modern professional modelers learn the alternatives to high-order polynomials, but newcomers often draw on their experience in high-school and give unwarranted credence to polynomials. This chapter attempts to guide you to the ways you are likely to see polynomials in your future work and to help you avoid them when better alternatives are available."
  },
  {
    "objectID": "Differentiation/26-taylor.html#sec-polynomial-basics",
    "href": "Differentiation/26-taylor.html#sec-polynomial-basics",
    "title": "27  Polynomials",
    "section": "27.1 Basics of polynomials with one input",
    "text": "27.1 Basics of polynomials with one input\nA polynomial is a linear combination of a particular class of functions: power-law functions with non-negative, integer exponents: 1, 2, 3, …. The individual functions are called monomials, a word that echoes the construction of chemical polymers out of monomers; for instance, the material polyester is constructed by chaining together a basic chemical unit called an ester.\nIn one input, say \\(x\\), the monomials are \\(x^1, x^2, x^3\\), and so on. (There’s also \\(x^0\\), but that’s better thought of as the constant function.) An n-th order polynomial has monomials up to exponent \\(n\\). For example, the form of a third-order polynomial is \\[a_0 + a_1 x^1 + a_2 x^2 + a_3 x^3\\]\nThe domain of polynomials, like the power-law functions they are assembled from, is the real numbers, that is, the entire number line \\(-\\infty < x < \\infty\\). But for the purposes of understanding the shape of high-order polynomials, it’s helpful to divide the domain into three parts: a wriggly domain at the center and two tail domains to the right and left of the center.\n\n\n\n\n\nFigure 27.1: A \\(n\\)th-order polynomial can have up to \\(n-1\\) critical points that it wriggles among. A 7-th order polynomial is shown here in which there are six local maxima or minima alternatingly.\n\n\n\n\nFigure 27.1 shows a 7th order polynomial—that is, the highest-order term is \\(x^7\\). In one of the tail domains the function value heads off to \\(\\infty\\), in the other to \\(-\\infty\\). This is a necessary feature of all odd-order polynomials: 1, 3, 5, 7, …\nIn contrast, for even-order polynomials (2, 4, 6, …) the function value in the two tail domains go in the same direction, either both to \\(\\infty\\) (Hands up!) or both to \\(-\\infty\\).\nIn the wriggly domain in Figure 27.1, there are six argmins or argmaxes.\nAn \\(n\\)th-order polynomial can have up to \\(n-1\\) extrema.\nNote that the local polynomial approximations in Section 26) are at most 2nd order and so there is at most 1 wriggle: a unique argmax. If the approximation does not include the quadratic terms (\\(x^2\\) or \\(y^2\\)) then there is no argmax for the function."
  },
  {
    "objectID": "Differentiation/26-taylor.html#multiple-inputs",
    "href": "Differentiation/26-taylor.html#multiple-inputs",
    "title": "27  Polynomials",
    "section": "27.2 Multiple inputs?",
    "text": "27.2 Multiple inputs?\nHigh-order polynomials are rarely used with multiple inputs. One reason is the proliferation of coefficients. For instance, here is the third-order polynomial in two inputs, \\(x\\), and \\(y\\). \\[\\underbrace{b_0 + b_x x + b_y y}_\\text{first-order terms} + \\underbrace{b_{xy} x y + b_{xx} x^2 + b_{yy} y^2}_\\text{second-order terms} + \\underbrace{b_{xxy} x^2 y + b_{xyy} x y^2 + b_{xxx} x^3 + b_{yyy} y^3}_\\text{third-order terms}\\]\nThis has 10 coefficients. With so many coefficients it’s hard to ascribe meaning to any of them individually. And, insofar as some feature of the function does carry meaning in terms of the modeling situation, that meaning is spread out and hard to quantify."
  },
  {
    "objectID": "Differentiation/26-taylor.html#sec-high-order-approx",
    "href": "Differentiation/26-taylor.html#sec-high-order-approx",
    "title": "27  Polynomials",
    "section": "27.3 High-order approximations",
    "text": "27.3 High-order approximations\nThe potential attraction of high-order polynomials is that, with their wriggly interior, they can take on a large number of appearances. This chameleon-like behavior has historically made them the tool of choice for understanding the behavior of approximations. That theory has motivated the use of polynomials for modeling patterns in data, but, paradoxically, has shown that high-order polynomials should not be the tool of choice for modeling data.2\nPolynomial functions lend themselves well to calculations, since the output from a polynomial function can be calculated using just the basic arithmetic functions: addition, subtraction, multiplication, and division. To illustrate, consider this polynomial: \\[g(x) \\equiv x - \\frac{1}{6} x^3\\] Since the highest-order term is \\(x^3\\) this is a third-order polynomial. (As you’ll see, we picked these particular coefficients, 0, 1, 0, -1/6, for a reason.) With such simple coefficients the polynomial is easy to handle by mental arithmetic. For instance, for \\(g(x=1)\\) is \\(5/6\\). Similarly, \\(g(x=1/2) = 23/48\\) and \\(g(x=2) = 2/3\\). A person of today’s generation would use an electronic calculator for more complicated inputs, but the mathematicians of Newton’s time were accomplished human calculators. It would have been well within their capabilities to calculate, using paper and pencil, \\(g(\\pi/4) = 0.7046527\\).3\nOur example polynomial, \\(g(x) \\equiv x - \\frac{1}{6}x^3\\), graphed in color in Figure 27.2, doesn’t look exactly like the sinusoid. If we increased the extent of the graphics domain, the disagreement would be even more striking, since the sinusoid’s output is always in \\(-1 \\leq \\sin(x) \\leq 1\\), while the polynomial’s tails are heading off to \\(\\infty\\) and \\(-\\infty\\). But, for a small interval around \\(x=0\\), exactly aligns with the sinusoid.\n\n\n\n\n\nFigure 27.2: The polynomial \\(g(x) \\equiv x -x^3 / 6\\) is remarkably similar to \\(\\sin(x)\\) near \\(x=0\\).\n\n\n\n\nIt’s clear from the graph that the approximation is excellent near \\(x=0\\) and gets worse as \\(x\\) gets larger. The approximation is poor for \\(x \\approx \\pm 2\\). We know enough about polynomials to say that the approximation will not get better for larger \\(x\\); the sine function has a range of \\(-1\\) to \\(1\\), while the left and right tails of the polynomial are heading off to \\(\\infty\\) and \\(-\\infty\\) respectively.\nOne way to measure the quality of the approximation is the error \\({\\cal E}(x)\\) which gives, as a function of \\(x\\), the difference between the actual sinusoid and the approximation: \\[{\\cal E}(x) \\equiv |\\strut\\sin(x) - g(x)|\\] The absolute value used in defining the error reflects our interest in how far the approximation is from the actual function and not so much in whether the approximation is below or above the actual function. Figure 27.3 shows \\({\\cal E}(x)\\) as a function of \\(x\\). Since the error is the same on both sides of \\(x=0\\), only the positive \\(x\\) domain is shown.\n\n\n\n\n\nFigure 27.3: The error \\({\\cal E}(x)\\) of \\(x - x^3/6\\) as an approximation to \\(\\sin(x)\\). Top panel: linear scale. Bottom panel: on a log-log scale.\n\n\n\n\nFigure 27.3 shows that for \\(x < 0.3\\), the error in the polynomial approximation to \\(\\sin(x)\\) is in the 5th decimal place. For instance, \\(\\sin(0.3) = 0.2955202\\) while \\(g(0.3) = 0.2955000\\).\nThat the graph of \\({\\cal E}(x)\\) is a straight-line on log-log scales diagnoses \\({\\cal E}(x)\\) as a power law. That is: \\({\\cal E}(x) = A x^p\\). As always for power-law functions, we can estimate the exponent \\(p\\) from the slope of the graph. It’s easy to see that the slope is positive, so \\(p\\) must also be positive.\nThe inevitable consequence of \\({\\cal E}(x)\\) being a power-law function with positive \\(p\\) is that \\(\\lim_{x\\rightarrow 0} {\\cal E}(x) = 0\\). That is, the polynomial approximation \\(x - \\frac{1}{6}x^3\\) is exact as \\(x \\rightarrow 0\\).\nThroughout this book, we’ve been using straight-line approximations to functions around an input \\(x_0\\). \\[g(x) = f(x_0) + \\partial_x f(x_0) [x-x_0]\\] One way to look at \\(g(x)\\) is as a straight-line function. Another way is as a first-order polynomial. This raises the question of what a second-order polynomial approximation should be. Rather than the polynomial matching just the slope of \\(f(x)\\) at \\(x_0\\), we can arrange things so that the second-order polynomial will also match the curvature of the \\(f()\\). Since the curvature involves only the first and second derivatives of a function, the polynomial constructed to match both the first and the second derivative will necessarily match the slope and curvature of \\(f()\\). This can be accomplished by setting the polynomial coefficients appropriately.\nStart with a general, second-order polynomial centered around \\(x_0\\): \\[g(x) \\equiv a_0 + a_1 [x-x_0] + a_2 [x - x_0]^2\\] The first- and second-derivatives, evaluated at \\(x=x_0\\) are: \\[\\partial_x g(x)\\left.{\\Large\\strut}\\right|_{x=x_0} = a_1 + 2 a_2 [x  - x_0] \\left.{\\Large\\strut}\\right|_{x=x_0} = a_1\\] \\[\\partial_{xx} g(x)\\left.{\\Large\\strut}\\right|_{x=x_0} =  2 a_2\\] Notice the 2 in the above expression. When we want to write the coefficient \\(a_2\\) in terms of the second derivative of \\(g()\\), we’ll end up with\n\\[a_2 = \\frac{1}{2} \\partial_{xx} g(x)\\left.{\\Large\\strut}\\right|_{x=x_0}\\]\nTo make \\(g(x)\\) approximate \\(f(x)\\) at \\(x=x_0\\), we need merely set \\[a_1 = \\partial_x f(x)\\left.{\\Large\\strut}\\right|_{x=x_0}\\] and \\[a_2 = \\frac{1}{2} \\partial_{xx} f(x) \\left.{\\Large\\strut}\\right|_{x=x_0}\\] This logic can also be applied to higher-order polynomials. For instance, to match the third derivative of \\(f(x)\\) at \\(x_0\\), set \\[a_3 = \\frac{1}{6} \\partial_{xxx} f(x)  \\left.{\\Large\\strut}\\right|_{x=x_0}\\] Remarkably, each coefficient in the approximating polynomial involves only the corresponding order of derivative. \\(a_1\\) involves only \\(\\partial_x f(x) \\left.{\\Large\\strut}\\right|_{x=x_0}\\); the \\(a_2\\) coefficient involves only \\(\\partial_{xx} f(x) \\left.{\\Large\\strut}\\right|_{x=x_0}\\); the \\(a_3\\) coefficient involves only \\(\\partial_{xx} f(x) \\left.{\\Large\\strut}\\right|_{x=x_0}\\), and so on.\nNow we can explain where the polynomial that started this section, \\(x - \\frac{1}{6} x^3\\) came from and why those coefficients make the polynmomial approximate the sinusoid near \\(x=0\\).\n\n\n\n\n\n\n\n\nOrder\n\\(\\sin(x)\\) derivative\n\\(x - \\frac{1}{6}x^3\\) derivative\n\n\n\n\n0\n\\(\\sin(x) \\left.{\\Large\\strut}\\right|_{x=0} = 0\\)\n\\(\\left( 1 - \\frac{1}{6}x^3\\right)\\left.{\\Large\\strut}\\right|_{x=0} = 0\\)\n\n\n1\n\\(\\cos(x) \\left.{\\Large\\strut}\\right|_{x=0} = 1\\)\n\\(\\left(1 - \\frac{3}{6} x^2\\right) \\left.{\\Large\\strut}\\right|_{x=0}= 1\\)\n\n\n2\n\\(-\\sin(x) \\left.{\\Large\\strut}\\right|_{x=0} = 0\\)\n\\(\\left(- \\frac{6}{6} x\\right) \\left.{\\Large\\strut}\\right|_{x=0} = 0\\)\n\n\n3\n\\(-\\cos(x) \\left.{\\Large\\strut}\\right|_{x=0} = -1\\)\n\\(- 1\\left.{\\Large\\strut}\\right|_{x=0} = -1\\)\n\n\n4\n\\(\\sin(x) \\left.{\\Large\\strut}\\right|_{x=0} = 0\\)\n\\(0\\left.{\\Large\\strut}\\right|_{x=0} = 0\\)\n\n\n\nThe first four derivatives of \\(x - \\frac{1}{6} x^3\\) exactly match, at \\(x=0\\), the first four derivatives of \\(\\sin(x)\\).\nThe polynomial constructed by matching successive derivatives of a function \\(f(x)\\) at some input \\(x_0\\) is called a Taylor polynomial.\n\nLet’s construct a 3rd-order Taylor polynomial approximation to \\(f(x) = e^x\\) around \\(x=0\\).\nWe know it will be a 3rd order polynomial: \\[g_{\\exp}(x) \\equiv a_0 + a_1 x + a_2 x^2 + a_3 x^3\\] The exponential function is particularly nice for examples because the function value and all it’s derivatives are identical: \\(e^x\\). So \\[f(x= 0) = 1\\]\n\\[ \\partial_x f(x=0) = 1\\] \\[\\partial_{xx} f(x=0) = 1\\] \\[\\partial_{xxx} f(x=0) = 1\\] and so on.\nThe function value and derivatives of \\(g_{\\exp}(x)\\) at \\(x=0\\) are: \\[g_{\\exp}(x=0) = a_0\\] \\[\\partial_{x}g_{\\exp}(x=0) = a_1\\] \\[\\partial_{xx}g_{\\exp}(x=0) = 2 a_2\\] \\[\\partial_{xxx}g_{\\exp}(x=0) = 2\\cdot3\\cdot a_3 = 6\\, a_3\\] Matching these to the exponential evaluated at \\(x=0\\), we get \\[a_0 = 1\\] \\[a_1 = 1\\] \\[a_2 = \\frac{1}{2}\\] \\[a_3 = \\frac{1}{2 \\cdot 3} = \\frac{1}{6}\\]\nResult: the 3rd-order Taylor polynomial approximation to the exponential at \\(x=0\\) is \\[g_{\\exp}(x) = 1 + x + \\frac{1}{2} x^2 +  \\frac{1}{2\\cdot 3} x^3 +\\frac{1}{2\\cdot 3\\cdot 4} x^4\\]\nFigure 27.4 shows the exponential function \\(e^x\\) and its 3th-order Taylor polynomial approximation near \\(x=0\\):\n\n\n\n\n\nFigure 27.4: The 3th-order Taylor polynomial approximation to \\(e^x\\) arount \\(x=0\\)\n\n\n\n\nThe polynomial is exact at \\(x=0\\). The error \\({\\cal E}(x)\\) grows with increasing distance from \\(x=0\\):\n\n\n\n\n\nFigure 27.5: The error from a 3rd-order Taylor polynomial approximation to \\(e^x\\) around \\(x=0\\) is a power-law function with exponent \\(4\\).\n\n\n\n\n\n\n\nFigure 27.6: The error from a 3rd-order Taylor polynomial approximation to \\(e^x\\) around \\(x=0\\) is a power-law function with exponent \\(4\\).\n\n\n\n\nThe plot of \\(\\log_{10} {\\cal E}(x)\\) versus \\(\\log_{10} | x |\\) in ?fig-taylor-exp-5 shows that the error grows from zero at \\(x=0\\) as a power-law function. Measuring the exponent of the power-law from the slope of the graph on log-log axes give \\({\\cal E}(x) = a |x-x_0|^5\\). This is typical of Taylor polynomials: for a polynomial of degree \\(n\\), the error will grow as a power-law with exponent \\(n+1\\). This means that the higher is \\(n\\), the faster \\(\\lim_{x\\rightarrow x_0}{\\cal E}(x) \\rightarrow 0\\). On the other hand, since \\({\\cal E}_x\\) is a power law function, as \\(x\\) gets further from \\(x_0\\) the error grows as \\(\\left(x-x_0\\right)^{n+1}\\).\n\n\nBrooke Taylor (1685-1731), a near contemporary of Newton, published his work on approximating polynomials in 1715. Wikipedia reports: “[T]he importance of [this] remained unrecognized until 1772, when Joseph-Louis Lagrange realized its usefulness and termed it ‘the main [theoretical] foundation of differential calculus’.”Source\n\n\n\n\n\nFigure 27.7: Brook Taylor\n\n\n\n\nDue to the importance of Taylor polynomials in the development of calculus, and their prominence in many calculus textbooks, many students assume their use extends to constructing models from data. They also assume that third- and higher-order monomials are a good basis for modeling data. Both these assumptions are wrong. Least squares is the proper foundation for working with data.\nTaylor’s work preceded by about a century the development of techniques for working with data. One of the pioneers in these new techniques was Carl Friedrich Gauss (1777-1855), after whom the gaussian function is named. Gauss’s techniques are the foundation of an incredibly important statistical method that is ubiquitous today: least squares. Least squares provides an entirely different way to find the coefficients on approximating polynomials (and an infinite variety of other function forms). The R/mosaic fitModel() function for polishing parameter estimates is based on least squares. In Block 5, we’ll explore least squares and the mathematics underlying the calculations of least-squares estimates of parameters."
  },
  {
    "objectID": "Differentiation/26-taylor.html#indeterminate-forms",
    "href": "Differentiation/26-taylor.html#indeterminate-forms",
    "title": "27  Polynomials",
    "section": "27.4 Indeterminate forms",
    "text": "27.4 Indeterminate forms\nLet’s return to an issue that has bedeviled calculus students since Newton’s time. The example we’ll use is the function \\[\\text{sinc}(x)  \\equiv \\frac{\\sin(x)}{x}\\]\nThe sinc() function (pronounced “sink”) is still important today, in part because of its role in converting discrete-time measurements (as in an mp3 recording of sound) into continuous signals.\nWhat is the value of \\(\\text{sinc}(0)\\)? One answer, favored by arithmetic teachers is that \\(\\text{sinc}(0)\\) is meaningless, because it involves division by zero.\nOn the other hand, \\(\\sin(0) = 0\\) as well, so the sinc function evaluated at zero involves 0/0. This quotient is called an indeterminant form. The logic is this: Suppose we assume that \\(0/0 = b\\) for some number \\(b\\). then \\(0 = 0 \\times b = 0\\). So any value of \\(b\\) would do; the value of \\(0/0\\) is “indeterminant.”\nStill another answer is suggested by plotting out sinc(\\(x\\)) near \\(x=0\\) and reading the value off the graph: sinc(0) = 1.\n\nslice_plot(sin(x) / x ~ x, domain(x=c(-10,10)), npts=500)\n\n\n\n\nFigure 27.8: To judge from this plot, \\(\\sin(0) = 1\\).\n\n\n\n\nThe graph of sinc() looks smooth and the shape makes sense. Even if we zoom in very close to \\(x=0\\), the graph continues to look smooth. We call such functions well behaved.\nCompare the well-behaved sinc() to a very closely related function (which doesn’t seem to be so important in applied work): \\(\\frac{\\sin(x)}{x^3}\\).\nBoth \\(\\sin(x)/x\\) and \\(\\sin(x) / x^3\\), evaluated at \\(x=0\\) involve a divide by zero. Both are indeterminate forms 0/0 at \\(x=0\\). But the graph of \\(\\sin(x) / x^3\\) (see ?fig-sinc2) is not we’ll behaved. \\(\\sin(x) / x^3\\) does not have any particular value at \\(x=0\\); instead, it has an asymptote.\n\nslice_plot(sin(x) / x ~ x, domain(x=c(-0.1, 0.1)), npts=500) %>%\n  gf_refine(scale_y_log10())\nslice_plot(sin(x) / x^3 ~ x, domain(x=c(-0.1, 0.1)), npts=500) %>%\n  gf_refine(scale_y_log10())\n\n\n\n\nFigure 27.9: Zooming in around the division by zero. Left: The graph of \\(\\sin(x)/x\\) versus \\(x\\). Right: The graph of \\(\\sin(x)/x^2\\). The vertical scales on the two graphs are utterly different.\n\n\n\n\n\n\n\nFigure 27.10: Zooming in around the division by zero. Left: The graph of \\(\\sin(x)/x\\) versus \\(x\\). Right: The graph of \\(\\sin(x)/x^2\\). The vertical scales on the two graphs are utterly different.\n\n\n\n\nSince both \\(\\sin(x)/x\\left.{\\Large\\strut}\\right|_{x=0}\\) and \\(\\sin(x)/x^3\\left. {\\Large\\strut}\\right|_{x=0}\\) involve a divide-by-zero, the answer to the utterly different behavior of the two functions is not to be found at zero. Instead, it’s to be found near zero. For any non-zero value of \\(x\\), the arithmetic to evaluate the functions is straight-forward. Note that \\(\\sin(x) / x^3\\) starts its mis-behavior away from zero. The slope of \\(\\sin(x) / x^3\\) is very large near \\(x=0\\), while the slope of \\(\\sin(x) / x\\) smoothly approaches zero.\nSince we’re interested in behavior near \\(x=0\\), a useful technique is to approximate the numerator and denominator of both functions by polynomial approximations.\n\n\\(\\sin(x) \\approx x - \\frac{1}{6} x^3\\) near \\(x=0\\)\n\\(x\\) is already a polynomial.\n\\(x^3\\) is already a polynomial.\n\nRemember, these approximations are exact as \\(x\\) goes to zero. So sufficiently close to zero,\n\\[\\frac{\\sin(x)}{x} = \\frac{x - \\frac{1}{6} x^3}{x} = 1 + \\frac{1}{6} x^2\\] Even at \\(x=0\\), there’s nothing indeterminant about \\(1 + x^2/6\\); it’s simply 1.\nCompare this to the polynomial approximation to \\(\\sin(x) / x^3\\): \\[\\frac{\\sin(x)}{x^3} = \\frac{x - \\frac{1}{6} x^3}{x^3} = \\frac{1}{x^2} - \\frac{1}{6}\\]\nEvaluating this at \\(x=0\\) involves division by zero. No wonder it’s badly behaved.\nThe procedure for checking whether a function involving division by zero behaves well or poorly is described in the first-ever calculus textbook, published in 1697. The title (in English) is: The analysis into the infinitely small for the understanding of curved lines. In honor of the author, the Marquis de l’Hospital, the procedure is called l’Hopital’s rule.4\nConventionally, the relationship is written \\[\\lim_{x\\rightarrow x_0} \\frac{u(x)}{v(x)} = \\lim_{x\\rightarrow x_0} \\frac{\\partial_x u(x)}{\\partial_x v(x)}\\]\nLet’s try this out with our two example functions around \\(x=0\\):\n\\[\\lim_{x\\rightarrow 0} \\frac{\\sin(x)}{x} = \\frac{\\lim_{x\\rightarrow 0} \\cos(x)}{\\lim_{x \\rightarrow 0} 1} = \\frac{1}{1} = 1\\]\n\\[\\lim_{x\\rightarrow 0} \\frac{\\sin(x)}{x^3} = \\frac{\\lim_{x\\rightarrow 0} \\cos(x)}{\\lim_{x \\rightarrow 0} 3x^2} = \\frac{1}{0} \\ \\ \\text{indeterminate}!\\]"
  },
  {
    "objectID": "Differentiation/26-taylor.html#computing-with-indeterminate-forms",
    "href": "Differentiation/26-taylor.html#computing-with-indeterminate-forms",
    "title": "27  Polynomials",
    "section": "27.5 Computing with indeterminate forms",
    "text": "27.5 Computing with indeterminate forms\nIn the early days of electronic computers, division by zero would cause a fault in the computer, often signaled by stopping the calculation and printing an error message to some display. This was inconvenient, since programmers did not always forsee division-by-zero situations and avoid them.\nAs you’ve seen, modern computers have adopted a convention that simplifies programming considerably. Instead of stopping the calculation, the computer just carries on normally, but produces as a result one of two indeterminant forms: Inf and NaN.\nInf is the output for the simple case of dividing zero into a non-zero number, for instance:\n\n17/0\n## [1] Inf\n\nNaN, standing for “not a number,” is the output for more challenging cases: dividing zero into zero, or multiplying Inf by zero, or dividing Inf by Inf.\n\n0/0\n## [1] NaN\n0 * Inf\n## [1] NaN\nInf / Inf\n## [1] NaN\n\nThe brilliance of the idea is that any calculation that involves NaN will return a value of NaN. This might seem to get us nowhere. But most programs are built out of other programs, usually written by other people interested in other applications. You can use those programs (mostly) without worrying about the implications of a divide by zero. If it’s important to respond in some particularly way, you can always check the result for being NaN in your own programs. (Much the same is true for Inf, although dividing a non-Inf number by Inf will return 0.)\nPlotting software will often treat NaN values as “don’t plot this.” That’s why it’s possible to make a sensible plot of \\(\\sin(x)/x\\) even when the plotting domain includes zero."
  },
  {
    "objectID": "Differentiation/26-taylor.html#exercises",
    "href": "Differentiation/26-taylor.html#exercises",
    "title": "27  Polynomials",
    "section": "27.6 Exercises",
    "text": "27.6 Exercises\n\n<!– Drill\n\n\nPart i Here is a function \\(f(x)\\):  In the Taylor polynomial approximation to \\(f(x)\\) centered at \\(x=-2\\), what will be the sign of the coefficient on the first-order term. Choose the best answer.\n\npositive\nzero\nnegative\nno such coefficient exists in a Taylor polynomial\n\n\n\n\n\nPart ii Here is a function \\(f(x)\\):  In the Taylor polynomial approximation to \\(f(x)\\) centered at \\(x=1\\), what will be the sign of the coefficient on the first-order term. Choose the best answer.\n\npositive\nzero\nnegative\nno such coefficient exists in a Taylor polynomial\n\n\n\n\n\nPart iii Here is a function \\(f(x)\\):  In the Taylor polynomial approximation to \\(f(x)\\) centered at \\(x=1\\), what will be the sign of the coefficient on the second-order term. Choose the best answer.\n\npositive\nzero\nnegative\nno such coefficient exists in a Taylor polynomial\n\n\n\n\n\nPart iv Here is a function \\(f(x)\\):  In the Taylor polynomial approximation to \\(f(x)\\) centered at \\(x=-4\\), what will be the sign of the coefficient on the first-order term. Choose the best answer.\n\npositive\nzero\nnegative\nno such coefficient exists in a Taylor polynomial\n\n\n\n\n\nPart v Here is a function \\(f(x)\\):  In the Taylor polynomial approximation to \\(f(x)\\) centered at \\(x=4\\), what will be the sign of the coefficient on the second-order term. Choose the best answer.\n\npositive\nzero\nnegative\nno such coefficient exists in a Taylor polynomial\n\n\n\n\n\nPart vi Here is a function \\(f(x)\\):  In the Taylor polynomial approximation to \\(f(x)\\) centered at \\(x=4\\), what will be the sign of the coefficient on the constant (zeroth-order) term. Choose the best answer.\n\npositive\nzero\nnegative\nno such coefficient exists in a Taylor polynomial\n\n\n\n\n\nPart vii Here is a function \\(f(x)\\):  In the Taylor polynomial approximation to \\(f(x)\\) centered at \\(x=3\\), what will be the sign of the coefficient on the second-order term. Choose the best answer.\n\npositive\nzero\nnegative\nno such term exists in a Taylor polynomial\n\n\n\n\n\nPart viii Here is a function \\(f(x)\\):  In the Taylor polynomial approximation to \\(f(x)\\) centered at \\(x=0\\), what will be the sign of the coefficient on the reciprocal term. Choose the best answer.\n\npositive\nzero\nnegative\nno such term exists in a Taylor polynomial\n\n\n\n\n\nPart ix Here is a function \\(g(x)\\):  Two Taylor polynomials, centered on the same \\(x\\) are shown. One is fifth-order, the other is third-order. Which is which?\n\nThe third-order polynomial is brown.\nThe third-order polynomial is magenta.\n\n\n\n\n\nPart x Here is a function \\(g(x)\\):  with a Taylor polynomial shown in magenta. What is the order of the polynomial?\nzeroonetwothreefour"
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html",
    "href": "Linear-combinations/B5-Vectors.html",
    "title": "28  Vectors",
    "section": "",
    "text": "Until now, our presentation of calculus has featured functions, sometimes expressed as formulas involving combinations of the basic modeling functions, sometimes generated directly from data by splines. Now we turn to a new framework for expressing functions, the inputs on which they operate, and the kind of outputs they generate.\nThis framework is central to technical work in a huge range of fields. The usual name given to it by mathematicians is linear algebra, although only the word “linear” conveys useful information about the subject. The physicists developing the first workable quantum theory called it matrix mechanics. The framework is fundamental to scientific computation and is often the approach of choice even to non-linear problems. Application of the framework to problems of information access was the spark that ignited the modern era of search engines.\nAlthough the words “algebra” and “quantum” may suggest that conceptual difficulties are in store, in fact human intuition is well suited to establishing a useful understanding. We will use two formats to introduce linear algebra: (1) geometric and visual; (2) via simple arithmetic, numbers, and algorithms."
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#length-direction",
    "href": "Linear-combinations/B5-Vectors.html#length-direction",
    "title": "28  Vectors",
    "section": "28.1 Length & direction",
    "text": "28.1 Length & direction\nA vector is a mathematical idea that is deeply rooted in everyday physical experience. Geometrially, a vector is simply an object consisting only of length and direction.\nA pencil is a good physical metaphor for a vector, but a pencil has other, non-vector qualities such as diameter, color, and an eraser. And, being a physical object, a pencil always has position: the place it’s at.\n\n\n\n\n\nFigure 28.1: Three pencils, but just two vectors. The yellow and blue pencils have the same length and direction, so they are the same vector. Pencils have position, but vectors don’t. The green pencil shares the same direction, but it has a different length, so it is a different vector from the blue/yellow vector.\n\n\n\n\nYou can move in a given direction either forward or in reverse. To eliminate this ambiguity, it’s helpful to imagine vectors having a tip and a tail. For the pencil illustrations, the writing end it the tip and the eraser is the tail.\n\n\n\n\n\nFigure 28.2: Two different vectors. They have the same length and are parallel, but they point in opposite directions.\n\n\n\n\nVectors are always embedded in a vector space. Our physical stand-ins for vectors, the pencils, were photographed on a table top: a two-dimensional space. Naturally, the pencil-vectors are also embedded in our everyday three-dimensional space. The table-top can be thought of as a representation of a two-dimensional subspace of three-dimensional space.\nOften, we will use vectors to represent a change in position, that is, a step or displacement in the sense of “step to the left” or “step forward.” An individual vector describes a step of a specific length in a particular direction. Much of the useful mathematics of vectors can be understood as constructing instructions for reaching a target: “take three and a half steps along the green vector, then turn and take two steps backwards along the yellow vector.”\nVectors embedded in three-dimensional space are central to physics and engineering. Quantities such as force, acceleration, and velocity are properly represented not as simple numerical quantities but as vectors with magnitude (that is, length) and direction. The statement, “The plane’s velocity is 450 miles per hour to the north-north-west” is perfectly intelligible to most people, describing magnitude and direction. Note that the vector velocity can be understood without having to know where the plane is located; vectors have only the two qualities of magnitude and direction. Position is irrelevant to describing velocity, or, for that matter, force or acceleration.\nThe gradients that we studied with partial differentiation (Chapter 24) are vectors. A gradient’s direction points directly uphill from a given point; it’s magnitude tells how steep the hill is at that point.\nVectors are a practical tool in many situations such as relative motion. Consider the problem of finding an aircraft heading and speed to intercept another plane that’s also moving. The US Navy training movie from the 1950s shows how such calculations used to be done with paper and pencil.\n\n\nNowadays such relative motion calculations are computerized. You may well wonder how the computer is able to represent vectors, since pencils aren’t part of computer hardware. The answer is disappointingly simple: the properties of direction and magnitude can also be represented by a set of numbers. Two numbers will do for a vector embedded in two-dimensional space, three for a vector embedded in three-dimensional space.\nRepresenting a vector as a set of numbers requires the imposition of a framework: a coordinate system. In Figure 28.3, the vector (that is, the green pencil) has been placed in a coordinate system. Usually you would expect there to be labels for each of the coordinate lines, but this labeling is not necessarily to show a vector (even if it is needed to specify a position). The two coordinates to be assigned to the vector are the difference between the tip and the tail. In the figure, there are 20 units horizontally and 16 units vertically, so the vector is \\((20, 16)\\).\n\n\n\n\n\nFigure 28.3: Representing a vector as a set of numbers requires reference to a coordinate system, shown here as graph paper.\n\n\n\n\nBy convention, when we write a vector as a set of coordinate numbers, we write the numbers in a column. For instance, the vector in Figure @ref(fig:vector-graph-paper), which we’ll call \\(\\vec{green}\\), is written numerically as:\n\\[\\vec{green} \\equiv \\left[\\begin{array}{c}20\\\\16\\end{array}\\right]\\] In more advanced linear algebra, the distinction between a column vector (like \\(\\vec{green}\\)) and a row vector (like \\(\\left[20 \\ 16\\right]\\)) is important. For our purposes in this block, we will only have need of column vectors.\n\nColumn vectors can be constructed with the rbind() function, as in\n\nrbind(1,3,-4)\n##      [,1]\n## [1,]    1\n## [2,]    3\n## [3,]   -4\n\nNote that the elements are separated by commas in the same way as any other R function.\nLater in this block, we will be using data frames to define vectors. We’ll introduce the R syntax for that when we need it.\n\n\nIf you have previous experience with R, say in a statistics course, or if you regard yourself as an expert, please note the following. The R language has a data structure called a “vector,” which is a set of elements without the information needed to consider it a row or column vector. As such, the native R “vector” is not suited for linear-algebra computations in R.\nMany people construct mathematical vectors using the matrix() function. Such a matrix() command to produce a column vector would look like matrix(c(1, 3, -4), ncol=1). This is a professional practice, but we regard it as too verbose for our purposes in this book. We will use rbind() instead. Note that combining rbind() with c() or other preconstructed R “vectors” will not produce a mathematical row vector\n\nrbind(c(1,2,3))\n##      [,1] [,2] [,3]\n## [1,]    1    2    3\n\nrbind(1:5)\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    2    3    4    5\n\nEventually, we will be constructing matrices. We’ll do this by concatenating column vectors, e.g.\n\ncbind(\n    rbind( 1,  2,  3),\n    rbind(10, 11, 12)\n)\n##      [,1] [,2]\n## [1,]    1   10\n## [2,]    2   11\n## [3,]    3   12\n\n\nIn physics and engineering vectors are used to describe positions, velocities, acceleration, forces, momentum, and other such functions of time or space. In mathematical notation, such a velocity can be written \\(\\vec{v}(t)\\). It’s common to perform calculus operations such a differentiation, writing it as \\(\\partial_t \\vec{v}(t)\\).\nThe vector-valued function of time \\(\\vec{v}(t)\\) can also be written in terms of scalar-valued components assembled into a vector. For instance, a subscript is often used to identify which component is which, so that \\[\\vec{v}(t) = \\left[\\begin{array}{c}v_x(t)\\\\v_y(t)\\\\v_z(t)\\end{array}\\right]\\] where the \\(x\\), \\(y\\), and \\(z\\) refer to the axes of the coordinate system.\nSince the physics and engineering vectors are typically 2- or 3-dimensional, when working numerically there’s not much lost by keeping track of the components with a set of scalar quantities rather than as a vector. You saw this already in Chapter 33 when we represented the instantaneous vector position of a robot arm as a pair of scalar-valued functions \\(x(t)\\) and \\(y(t)\\).\nIn linear algebra, vectors often have many more than 3 components. In this book, we will work with vectors with hundreds of components. Services like Google search rely on vector calculations with millions of components. When programming such systems, representing the vectors as individual scalar components is unwieldy. The programming must rely on handling the whole vector as a single entity."
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#the-nth-dimension",
    "href": "Linear-combinations/B5-Vectors.html#the-nth-dimension",
    "title": "28  Vectors",
    "section": "28.2 The nth dimension",
    "text": "28.2 The nth dimension\nLiving as we do in a palpably three-dimensional space, and being part of a species whose senses and brains developed in three dimensions, it’s hard and maybe even impossible to get a grasp on what higher-dimensional spaces would be like.\nA lovely 1884 book, Flatland features the inhabitants of a two-dimensional world. The central character, Square, receives a visitor, Sphere, from the three-dimensional world in which Flatland is embedded. Only with difficulty can Square assemble a conception of Sphere from the appearing, growing, and vanishing of Sphere’s intersection with the flat world. Square’s attempt to convince Sphere that his three-dimensional world might be embedded in a four-dimensional one leads to rejection and disgrace.\n\n\n\n\n\n\n\n\n\nEven if the spatial extent of higher dimensions is not accessible, the one-dimensional vector inhabitants of any such space can be readily perceived and constructed as a list of numbers. With this device, allow us to introduce vectors from 4, 5, and 6 dimensions, and even \\(n\\) dimensional space.\n\\[\\left[\\begin{array}{r}6.4\\\\3.0\\\\-2.5\\\\17.3\\end{array}\\right]\\ \\ \\ \\left[\\begin{array}{r}-14.2\\\\-6.9\\\\18.0\\\\1.5\\\\-0.3\\end{array}\\right]\\ \\ \\ \\left[\\begin{array}{r}5.3\\\\-9.6\\\\84.1\\\\5.7\\\\-11.3\\\\4.8\\end{array}\\right]\\ \\ \\ \\cdots\\ \\ \\ \\left.\\left[\\begin{array}{r}7.2\\\\-4.4\\\\0.6\\\\-4.1\\\\4.7\\\\\\vdots\\ \\ \\\\-7.3\\\\8.3\\end{array}\\right]\\right\\} n\\]\nSensible people may consider it mathematical ostentation to promote an everyday column of numbers into a vector in high-dimensional space. The utility of doing so is to help us think about the arithmetic we are about to do on vectors in terms of familiar geometrical concepts: lengths, angles, alignment, and so on. Perhaps unexpectedly, it also guides us to think about data—which consists of columns of numbers in a data frame—using our powerful geometrical intuition.\nThere’s nothing science-fiction-like about so-called “high-dimensional” spaces; they are not usually intended to correspond to a physical space. Vectors with many components are often used in advanced physics to represent the state of a particle. For instance, the state vector could contain both the position and velocity and might be written \\((x, y, z, v_x, v_y, v_z)\\), but you can easily see this as the concatenation of a position vector and a velocity vector, each of which is 3-dimensional. In statistics, engineering, and statistical mechanics, the term degrees of freedom is used as an alternative to “dimension.” Another example: computer-controlled machine tools are often described as having 5 degrees of freedom (or more). There is a cutting head whose \\(x, y, z\\) position can be set as well as the head’s orientation (tilt) as an azimuth and inclination. If ever you start to freak out about the idea of a 10-dimensional space, just close your eyes and remember that this is only shorthand for the set of arrays with 10 elements."
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#geometry-arithmetic",
    "href": "Linear-combinations/B5-Vectors.html#geometry-arithmetic",
    "title": "28  Vectors",
    "section": "28.3 Geometry & arithmetic",
    "text": "28.3 Geometry & arithmetic\nThere are three common mathematical tasks involving vectors that can be understood with simple geometry. Given a set of vectors drawn on paper, you can carry out these tasks by pencil assisted by a simple ruler and a protractor.\n\nMeasure the length of a vector.\nMeasure the angle between two vectors.\nCreate a new vector by scaling a vector. Scaling makes the new vector longer or shorter or point in the opposite orientation, but the direction remains identical to the original.\n\nThe geometrical perspective is helpful for many purposes, but often we need to work with vectors using computers. For this, we use the numerical representation of vectors.\nThis section introduces the arithmetic of vectors. With this arithmetic in hand, we can carry out the above tasks (and more!) on vectors that consist of a column of numbers. Especially noteworthy is that the arithmetic enables to to apply simple geometrical concepts to vectors in three or more dimensions.\nTo scale a vector \\(\\vec{w}\\) means more or less to change the vector’s length. A good mental image for scaling is based on thinking about the vector as a step or displacement in the direction of \\(\\vec{w}\\). Scaling means to go on a simple walk, taking one step after the other in the same direction as the \\(\\vec{w}\\). We write a scaled vector by placing a number in front of the name of the vector. \\(3 \\vec{w}\\) is a short walk of three steps; \\(117 \\vec{w}\\) is a considerably longer walk; \\(-5 \\vec{w}\\) means to take five steps backwards. You can also take fraction steps: \\(0.5 \\vec{w}\\) is half a step, \\(19.3 \\vec{w}\\) means to take 19 steps followed by a 30% step. Scaling a vector by \\(-1\\) means flipping the vector tip-for-tail; this doesn’t change the length, just the orientation.\nArithmetically, scaling a vector is accomplished simply by multiplying each of the vector’s components by the same number. Suppose that we are working with a vector \\(\\vec{v}\\) that has \\(n\\) components. (We’ll also define another vector \\(\\vec{w}\\) to use in examples.)\n\\[\\vec{v} \\equiv \\left[\\begin{array}{r}6\\\\2\\\\-4\\\\\\vdots\\\\1\\\\8\\end{array}\\right]\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\vec{w} \\equiv \\left[\\begin{array}{r}-3\\\\1\\\\-5\\\\\\vdots\\\\2\\\\5\\end{array}\\right]\\] To scale a vector by 3 is accomplished by multiplying each component by 3\n\\[3\\, \\vec{v} = 3\\left[\\begin{array}{r}6\\\\2\\\\-4\\\\\\vdots\\\\1\\\\8\\end{array}\\right] = \\left[\\begin{array}{r}18\\\\6\\\\-12\\\\\\vdots\\\\3\\\\24\\end{array}\\right]\\] This is perfectly ordinary multiplication applied component by component, that is, componentwise.\nScaling involves a number (the “scalar”) and a single vector. There are other sorts of multiplication however, that involve two or more vectors.\nThe dot product is one approach to multiplication of one vector with another. The dot product between \\(\\vec{v}\\) and \\(\\vec{w}\\) is written \\[\\vec{v} \\bullet \\vec{w}\\].\nThe arithmetic of the dot product involves two steps:\n\nMultiply the two vectors component-wise. For instance: \\[\\underset{\\Large \\vec{v}}{\\left[\\begin{array}{r}6\\\\2\\\\-4\\\\\\vdots\\\\1\\\\8\\end{array}\\right]}\\  \\underset{\\Large \\vec{w}}{\\left[\\begin{array}{r}-3\\\\1\\\\-5\\\\\\vdots\\\\2\\\\5\\end{array}\\right]} = \\left[\\begin{array}{r}-18\\\\2\\\\20\\\\\\vdots\\\\2\\\\40 \\end{array}\\right]\\]\nSum the elements in the component-wise product. For the component-wise product of \\(\\vec{v}\\) and \\(\\vec{w}\\), this will be \\(-18 + 2 + 20 + \\cdots +2 + 40\\). The resulting sum, which is an ordinary quantity, that is, a scalar, is the output of the dot product. That is, the dot product takes two vectors as inputs and produces a scalar as an output.\n\n\nR/mosaic provides a beginner-friendly function for computing a dot product. To mimic the use of the dot, as in \\(\\vec{v} \\bullet \\vec{w}\\), the function will be invoked using infix notation. You have a huge amount of experience with infix notation, even if you never heard the term. Some examples:\n3 + 2       7 / 4      6 - 2      9 * 3     2 ^ 4\nInfix notation is distinct from the functional notation that you are also familiar with, for instance sin(2) or makeFun(x^2 ~ x).\nIn principle, you could invoke the +, -, *, /, and ^ operations using functional notation. Nobody does this because the commands are so ugly:\n\n\n`+`(3, 2)\n\n\n## [1] 5\n\n\n\n`/`(7, 4)\n\n\n## [1] 1.75\n\n\n\n`-`(6, 2)\n\n\n## [1] 4\n\n\n\n`*`(9, 3)\n\n\n## [1] 27\n\n\n\n`^`(2, 4)\n\n\n## [1] 16\n\n\n\n \nThe R language makes it possible to define new infix operators, but there is a catch. The new operators must always have a name that begins and ends with the % symbol, for example %in% or %*% or %dot%. You’ll be using %*% and %dot% a lot in this block and the next.\nHere’s an example of using %dot% to calculate the dot product of two vectors:\n\na <- rbind(1, 2, 3, 5, 8, 13)\nb <- rbind(1, 4, 2, 3, 2, -1)\na %dot% b\n## [1] 33\n\nThe vectors being combined with %dot% must both have the same number of elements. Otherwise, an error message will result:\n\nrbind(2, 1) %dot% rbind(3, 4, 5)\n## Error in rbind(2, 1) %dot% rbind(3, 4, 5): Vector <u> must have the same number of elements as vector <b>.\n\n\nTo the student encountering the dot product for the first time, a natural response is to wonder what such a two-step operation might be good for. As we progress through this block, you’ll see the dot product playing a central role.\n\nYou will be seeing a lot of the dot product, so it’s important to have it firmly in mind that a dot product is not ordinary multiplication."
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#sec-vector-length",
    "href": "Linear-combinations/B5-Vectors.html#sec-vector-length",
    "title": "28  Vectors",
    "section": "28.4 Vector lengths",
    "text": "28.4 Vector lengths\nThe arithmetic used to calculate the length of a vector is based on the Pythagorean theorem. For a vector \\(\\vec{u} = \\left[\\begin{array}{c}4\\\\3\\end{array}\\right]\\) the vector is the hypotenuse of a right triangle with legs of length 4 and 3 respectively. Therefore, \\[\\|\\vec{u}\\| = \\sqrt{4^2 + 3^2} = 5\\ .\\] For vectors with more than two components, follow the same pattern: sum the squares of the components then take the square root.\nThe length of a vector \\(\\vec{u}\\) can also be computed using the dot product: \\[\\|\\vec{u}\\| = \\sqrt{\\strut\\vec{u} \\bullet \\vec{u}}\\ .\\] Although length has an obvious physical interpretation, in many areas of science including statistics and quantum physics, the square length is a more fundamental quantity. The square length of \\(\\vec{u}\\) is simply \\(\\|\\vec{u}\\|^2 = \\vec{u}\\bullet \\vec{u}\\).\n\nConsider the two vectors \\[\\vec{u} \\equiv \\left(\\begin{array}{c}3\\\\4\\end{array}\\right) \\  \\  \\ \\mbox{and}  \\ \\ \\ \\vec{w} \\equiv \\left(\\begin{array}{c}1\\\\1\\\\1\\\\1\\end{array}\\right)\n\\]\nThe length of \\(\\vec{u}\\) is \\(|| \\vec{u} || = \\sqrt{\\strut 3^2 + 4^2} = \\sqrt{\\strut 25} = 5\\).\nThe length of \\(\\vec{w}\\) is \\(|| \\vec{w} || = \\sqrt{\\strut 1^2 + 1^2 + 1^2 + 1^2} = \\sqrt{\\strut 4} = 2\\).\n\n\nIn statistics, the many applications of linear algebra often involve a simple constant vector, which we’ll write \\(\\vec{1}\\). It is simply a column vector of 1s, \\[\\vec{1} \\equiv \\left[\\begin{array}{c}1\\\\1\\\\1\\\\\\vdots\\\\1\\\\1\\\\ \\end{array}\\right]\\ .\\] Common statistical calculations can be expressed compactly in vector notation. For example, if \\(\\vec{x}\\) is an \\(n\\)-dimensional vector, then the mean of the components of \\(\\vec{x}\\), which is often written \\(\\bar{x}\\), is \\[\\bar{x} \\equiv \\frac{1}{n}\\  \\vec{x} \\bullet \\vec{1}\\ .\\] The symbol \\(\\bar{}\\) is pronounced “bar”, and \\(\\bar{x}\\) is pronounced “x-bar.”.\nAnother commonly used statistic is the variance of the components of a vector \\(\\vec{x}\\). This is only slightly more complicated than the mean: \\[\\text{var}(x) \\equiv \\frac{1}{n-1}\\  (\\vec{x} - \\bar{x}) \\bullet (\\vec{x} - \\bar{x})\\ .\\] The quantity \\(\\vec{x} - \\bar{x}\\) is an example of scalar subtraction, which is done on a component-wise basis. For instance, with \\[\\vec{x} = \\left[\\begin{array}{r}1\\\\2\\\\3\\\\4\\\\\\end{array}\\right]\\] then \\(\\bar{x} = 2.5\\). This being the case, \\[\\vec{x} - \\bar{x} = \\left[\\begin{array}{c}-1.5\\\\-0.5\\\\\\ 0.5\\\\\\ 1.5\\\\\\end{array}\\right]\\ ,\\] with the variance of \\(\\vec{x}\\) being \\[\\frac{1}{4-1} \\left[\\begin{array}{r}-1.5\\\\-0.5\\\\0.5\\\\1.5\\\\\\end{array}\\right] \\bullet \\left[\\begin{array}{r}-1.5\\\\-0.5\\\\0.5\\\\1.5\\\\\\end{array}\\right] = \\frac{5}{3}\\ .\\]"
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#angles",
    "href": "Linear-combinations/B5-Vectors.html#angles",
    "title": "28  Vectors",
    "section": "28.5 Angles",
    "text": "28.5 Angles\nAny two vectors of the same dimension have a distinct angle between them. This is easily seen for two-dimensional vectors. Draw two vectors on a sheet of paper. Since vectors have only two properties, length and direction, in your mind’s eye you can pick up one of the vectors and relocate its “tail” to meet the tail of the other vector.\nMeasure the angle between two vectors the short way round: between 0 and 180 degrees. Any larger angle, say 260 degrees, will be identified with its circular complement: 100 degrees is the complement of a 260 degree angle.\nIn 2- and 3-dimensional spaces, we can measure the angle between two vectors using a protractor: arrange the vectors so they are tail to tail, align the baseline of the protractor with one of the vectors and read off the angle marked by the second vector.\nIt’s also possible to measure the angle using arithmetic. Suppose we have vectors \\(\\vec{v}\\) and \\(\\vec{w}\\) that are in the same dimensional space. That is, \\(\\vec{v}\\) and \\(\\vec{w}\\) have the same number of components:\n\\[\\vec{v} = \\left[\\begin{array}{c}v_1\\\\v_2\\\\\\vdots\\\\v_n\\\\\\end{array}\\right]\\ \\ \\ \\text{and}\\ \\ \\ \\vec{w} = \\left[\\begin{array}{c}w_1\\\\w_2\\\\\\vdots\\\\w_n\\\\\\end{array}\\right]\\ ,\\]\nUsing the dot-product and length notation, we can write the formula for the cosine of the angle between two vectors as \\[\\cos(\\theta) \\equiv \\frac{\\vec{v}\\cdot\\vec{w}}{\\|\\vec{v}\\|\\ \\|\\vec{w}\\|}\\ .\\]\n\nRemember that the dot-product-based formula above gives the cosine of the angle between the two vectors. It turns out that in many applications, the cosine is exactly what’s needed. If you insist on knowing the angle \\(\\theta\\) rather than \\(\\cos(\\theta)\\), the trigonometric function \\(\\arccos()\\) will do the job. For instance, if \\(\\theta\\) is such that \\(\\cos(\\theta) = 0.6\\), compute the angle in degrees with ::: {.cell layout-align=“center” fig.showtext=‘false’}\nacos(0.6)*180/pi\n## [1] 53.1301\n\nThe trigonometric functions in R (and in most other languages) do calculations with angles in units of radians. The 180/pi is the factor that converts radians to degrees. Figure @ref(fig:cosine-conversion) shows a graph of converting \\(\\cos(\\theta)\\) to \\(\\theta\\) in degrees.\n\n\n\n\n\nFigure 28.4: The \\(\\arccos()\\) function (acos() in R) converts \\(\\cos(\\theta)\\) to \\(\\theta\\).\n\n\n\n\n:::\n\nWhat does the angle \\(\\theta\\) between two vectors tell us?\nIn geometrical terms, the angle tells us how strongly aligned the vectors are. An angle of 0 tells us the vectors point in the same direction, and angle of 180 degrees means that the vectors point in exactly opposing directions. Either of these—0 or 180 degrees—indicates that the two vectors are perfectly aligned. Such alignment means that by appropriate scalar multiplication, the two vectors could be made exactly equal to one another and, consequently, that the scaled vectors would be one and the same.\nAngles such as 5 or 175 degrees indicate that the two vectors are mostly aligned, but imperfectly. When the angle is 90 degrees of course—a right angle—the two vectors are perpendicular.\nThe vector alignment has a particularly important meaning in terms of data. Suppose the two vectors are two columns in a data frame: two different variables. In statistics there is an important quantity called the correlation coefficient, denoted \\(r\\). To say that two variables are correlated means that the variables are connected to one another in some way. For instance, among children, height and age are correlated. Since height tends to increase along with age (for children), the two variables are said to be positively correlated. The largest possible correlation is \\(r=1\\).\nA negative correlation means that as one variable increases the other tends to decrease. Temperature and elevation are negatively correlated, as are the pressure and volume of a gas at a given temperature. The most negative possible correlation is \\(r=-1\\).\nA zero correlation indicates that there is no simple relationship between the two variables. This occurs when the variables are orthogonal, a term described in Section 28.6.\nIn terms of vectors, that is, the columns in the data frame, the correlation coefficient \\(r\\) is the same quantity as the cosine of the angle between the vectors. At the time the correlation coefficient was invented in the 1880s, it was not widely appreciated that \\(r\\) is simply the cosine of an angle. Perhaps the several generations of statistics students who have studied correlation would have had a better grasp on the subject if it had been called alignment and measured in degrees."
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#sec-orthogonality",
    "href": "Linear-combinations/B5-Vectors.html#sec-orthogonality",
    "title": "28  Vectors",
    "section": "28.6 Orthogonality",
    "text": "28.6 Orthogonality\nTwo vectors are said to be orthogonal when the angle between them is 90 degrees. In everyday speech we call a 90 degree angle a “right angle.” The word “orthogonal” is really just a literal translation of “right angle.” (The syllable “gon” indicates an angle, as in the five-angled pentagon or six angled hexagon. “Ortho” means “right” or “correct,” as in “orthodox” (right beliefs) or “orthodontics” (right teeth) or “orthopedic” (right feet).)\nTwo vectors are at right angles—we prefer “orthogonal” since “right” has many meanings not related to angles—when the dot product between them is zero.\n\n\n \n\nFind a vector that is orthogonal to \\(\\left[\\strut\\begin{array}{r}1\\\\2\\end{array}\\right]\\).\nThe arithmetic trick is to reverse the order of the components and put a minus sign in front of one of them, so \\(\\left[\\strut\\begin{array}{r}-2\\\\1\\end{array}\\right]\\).\nWe can confirm the orthogonality by calculating the dot product: \\(\\left[\\begin{array}{c}-2\\\\\\ 1\\end{array}\\right] \\cdot \\left[\\strut\\begin{array}{r}1\\\\2\\end{array}\\right] = -2\\times1 + 1 \\times 2 = 0\\).\nIn R, this can be written\n\nu <- rbind( 1, 2)\nv <- rbind(-2, 1)\nu %dot% v\n## [1] 0\n\n\n\n\n \n\nFind a vector orthogonal to \\(\\left[\\strut\\begin{array}{r}1\\\\2\\\\3\\end{array}\\right]\\).\nWe have a little more scope here. A simple approach is to insert a zero component in the new vector and then use the two-dimensional trick to fill in the remaining components.\nFor instance, starting with \\(\\left[\\strut\\begin{array}{r}0\\\\\\_\\\\ \\_\\end{array}\\right]\\) the only non-zero components of the dot product will involve the 2 and 3 of the original vector. So \\(\\left[\\strut\\begin{array}{r}0\\\\ -3\\\\ 2\\end{array}\\right]\\) is orthogonal. Or, if we start with \\(\\left[\\strut\\begin{array}{r}\\_\\\\0\\\\\\_\\end{array}\\right]\\) we would construct \\(\\left[\\strut\\begin{array}{r}-3\\\\ 0\\\\ 1\\end{array}\\right]\\)."
  },
  {
    "objectID": "Linear-combinations/B5-Vectors.html#exercises",
    "href": "Linear-combinations/B5-Vectors.html#exercises",
    "title": "28  Vectors",
    "section": "28.7 Exercises",
    "text": "28.7 Exercises"
  },
  {
    "objectID": "Linear-combinations/B5-linear-combinations.html",
    "href": "Linear-combinations/B5-linear-combinations.html",
    "title": "29  Linear combinations of vectors",
    "section": "",
    "text": "In this chapter, we introduce linear combinations of vectors. As you recall, a linear combination is a sum of basic elements each of which has been scaled. For instance, in Block 1 we looked at linear combinations of functions such as \\[g(t) = A + B e^{kt}\\] which involves the basic functions \\(\\text{one}(t)\\) and \\(e^{kt}\\) scaled respectively by \\(A\\) and \\(B\\).\nLinear combinations of vectors involve scaling and addition, which are simple seen either as numerical operations or a geometric ones. A useful concept will be the set of all vectors that can be constructed as linear combinations of given vectors. This set of all possibilities, called the subspace spanned by the given vectors is key to understanding how to find the “best” scalars for a given purpose."
  },
  {
    "objectID": "Linear-combinations/B5-linear-combinations.html#scaling-vectors",
    "href": "Linear-combinations/B5-linear-combinations.html#scaling-vectors",
    "title": "29  Linear combinations of vectors",
    "section": "29.1 Scaling vectors",
    "text": "29.1 Scaling vectors\nTo scale a vector means to change its length without altering its direction. Scaling by a negative number flips the vector tip-for-tail. Figure 29.1 shows two vectors \\(\\vec{v}\\) and \\(\\vec{w}\\) together with several scaled versions of each.\n\n\n\n\n\nFigure 29.1: Vectors \\(\\vec{v}\\) and \\(\\vec{w}\\) and some scaled versions of them.\n\n\n\n\nThe vectors we create by scalar multiplication can be placed anywhere we like.\nArithmetically, scaling a vector is accomplished by multiplying each component of the vector by the scalar, e.g.\n\\[\\vec{u} = \\left[\\begin{array}{r}1.5\\\\-1\\end{array}\\right]\\ \\ \\ \\ 2\\vec{u} = \\left[\\begin{array}{r}3\\\\-2\\end{array}\\right]\\ \\ \\ \\\n-\\frac{1}{2}\\vec{u} = \\left[\\begin{array}{r}-0.75\\\\0.5\\end{array}\\right]\\ \\ \\ \\ \\]\nEvery vector is associated with a subspace that is one-dimensional; you can only reach the points on a line by stepping in the direction of a vector."
  },
  {
    "objectID": "Linear-combinations/B5-linear-combinations.html#adding-vectors",
    "href": "Linear-combinations/B5-linear-combinations.html#adding-vectors",
    "title": "29  Linear combinations of vectors",
    "section": "29.2 Adding vectors",
    "text": "29.2 Adding vectors\nTo add two vectors, choose either one of the vectors as a start, then move the tail of the second vector to the tip of the first, as in Figure 29.2.\n\n\n\n\n\nFigure 29.2: Adding two vectors, yellow and green, by placing them tail to tip. The result is the vector going from the tail of yellow to the tip of green. This resultant is equivalent to the blue vector.\n\n\n\n\nAdding vectors in this way takes advantage of the rootlessness of a vector. So long as we keep the direction and length the same, we can move a vector to whatever place is convenient. For adding vectors, the convenient arrangement is to place the tail of the second vector at the tip of the first. The result—the blue pencil in the picture above—has the length and direction from the tail of the first pencil (yellow) to the tip of the second (green). But so long as we maintain this length and direction, we can put the result (blue) anywhere we want.\nArithmetically, vector addition is simply a matter of applying addition component-by-component, that is, componentwise. For instance, consider adding two vectors \\(\\vec{v}\\) and \\(\\vec{w}\\):\nTHIS MATH MARKUP DOESN’T COMPILE TO PDF\n<!--\\underbrace{\\left[\\begin{array}{r}1.5\\\\-1\\\\2\\\\6\\end{array}\\right]}_\\vec{v} + \\underbrace{\\left[\\begin{array}{r}2\\\\4\\\\-2\\\\-3.2\\end{array}\\right]}_\\vec{w} = \\underbrace{\\left[\\begin{array}{r}3.5\\\\3\\\\0\\\\2.8\\end{array}\\right]}_{\\vec{v} + \\vec{w}}-->\nUnlike our pencil exemplars of vectors, which must of physical necessity always be in the three-dimensional space we inhabit, mathematical vectors can be embedded in any-dimensional space. Addition is applicable to vectors embedded in the same space. Arithmetically, this means that the two vectors to be added must have the same number of components.\nArithmetic subtraction of one vector from another is a simple component-wise operation. For example:\n$$\\underbrace{\\left[\\begin{array}{r}1.5\\\\-1\\\\2\\\\6\\end{array}\\right]}_\\vec{v} {\\Large -} \\underbrace{\\left[\\begin{array}{r}2\\\\4\\\\-2\\\\-3.2\\end{array}\\right]}_\\vec{w} = \\underbrace{\\left[\\begin{array}{r}-0.5\\\\-5\\\\4\\\\9.2\\end{array}\\right]}_{\\vec{v} - \\vec{w}}\\ .$$\nFrom a geometrical point of view, many people like to think of \\(\\vec{v} - \\vec{w}\\) in terms of placing the two vectors tail to tail as in Figure 29.3. Read out the result as the vector running from the tip of \\(\\vec{v}\\) to the tip of \\(\\vec{w}\\). In Figure 29.3, the yellow vector is \\(\\vec{v}\\), the blue vector is \\(\\vec{w}\\). The result of the subtraction is the green vector.\n\n\n\n\n\nFigure 29.3: Subtracting blue from yellow gives green."
  },
  {
    "objectID": "Linear-combinations/B5-linear-combinations.html#linear-combinations",
    "href": "Linear-combinations/B5-linear-combinations.html#linear-combinations",
    "title": "29  Linear combinations of vectors",
    "section": "29.3 Linear combinations",
    "text": "29.3 Linear combinations\nIn the previous chapter, we suggested that you think of a vector as a “step” or displacement in a given direction and of a given magnitude as in, “1 foot to the northeast.” This interpretation highlights the mathematical structure of vectors: just a direction and a length, nothing else.\nThe “step”-interpretation is also faithful to an important reason why vectors are useful. We use steps to get from one place to another. Similarly, a central use for the formalism of vectors is to guide our thinking and our algorithms for figuring out how best to get from one “place” to another. We’ve used quotation marks around “place” because we are not necessarily referring to a physical destination. We’ll get to what else we might mean by “place” later in this Block.\nAs a fanciful example of getting to a “place,” consider a treasure hunt. You are given these instructions to get there:\n\n\nOn June 1, go to the flagpole before sunrise.\nAt 6:32, walk 213 paces away from the sun.\nAt 12:19, walk 126 paces toward the sun.\n\n\nThe sun position varies over the day, so the direction to the sun on June 1 at 6:32 will be different than at 12:19. Figure 29.4 the Sun vectors at 6:32 and 12:19 on June 1.\n\n\n\n\n\nFigure 29.4: For June 1: \\(\\color{magenta}{ ext{Sun's direction at 6:32}}\\) and $$. (Location: latitude 38.0091, /longitude -104.8871). Source: suncalc.org\n\n\n\n\nThe treasure-hunt directions are in the form of a linear combination of vectors. For each of the two vectors described in the treasure instructions, the length of the vector is 1 pace. (Admittedly, not a scientific unit of length.) Scaling \\(\\color{magenta}{\\text{the magenta vector}}\\) by -213 and \\(\\color{blue}{\\text{the blue vector}}\\) by 126, then adding the two scaled vectors gives a vector that takes you from the flagpole to the treasure.\nA stickler for details might point out tht the “direction of the sun” has an upward component. Common sense will guide you to walk in the direction of the Sun as projected onto Earth’s surface. Section 30 deals with projections of vectors."
  },
  {
    "objectID": "Linear-combinations/B5-linear-combinations.html#functions-as-vectors",
    "href": "Linear-combinations/B5-linear-combinations.html#functions-as-vectors",
    "title": "29  Linear combinations of vectors",
    "section": "29.4 Functions as vectors",
    "text": "29.4 Functions as vectors\nThis is a calculus book, and calculus is about functions. So you can imagine that there is going to be some connection between functions and vectors.\nWe’ll start with the idea that a vector is a column of numbers. Recall from Block 1 (Section 4.002) the idea of representing a function as a table of inputs and the corresponding outputs.\nHere is such a table with some of our pattern-book functions.\n\n\n\n \n  \n    t \n    one(t) \n    identity(t) \n    exp(t) \n    sin(t) \n    pnorm(t) \n  \n \n\n  \n    0.0 \n    1 \n    0.0 \n    1.000000 \n    0.0000000 \n    0.5000000 \n  \n  \n    0.1 \n    1 \n    0.1 \n    1.105171 \n    0.0998334 \n    0.5398278 \n  \n  \n    0.2 \n    1 \n    0.2 \n    1.221403 \n    0.1986693 \n    0.5792597 \n  \n  \n    0.3 \n    1 \n    0.3 \n    1.349859 \n    0.2955202 \n    0.6179114 \n  \n  \n    0.4 \n    1 \n    0.4 \n    1.491825 \n    0.3894183 \n    0.6554217 \n  \n  ... and so on ...\n  \n  \n  \n    4.6 \n    1 \n    4.6 \n    99.48432 \n    -0.9936910 \n    0.9999979 \n  \n  \n    4.7 \n    1 \n    4.7 \n    109.94717 \n    -0.9999233 \n    0.9999987 \n  \n  \n    4.8 \n    1 \n    4.8 \n    121.51042 \n    -0.9961646 \n    0.9999992 \n  \n  \n    4.9 \n    1 \n    4.9 \n    134.28978 \n    -0.9824526 \n    0.9999995 \n  \n  \n    5.0 \n    1 \n    5.0 \n    148.41316 \n    -0.9589243 \n    0.9999997 \n  \n\n\n\n\n\nIn this representation, each of the pattern-book functions is a column of numbers, that is, a vector.\nFunctions that we construct by linear combination are, in this vector format, just a linear combination of the vectors. For instance, the function \\(g(t) \\equiv 3 - 2 t\\) is \\(3\\cdot \\text{one}(t) - 2 \\cdot \\text{identity}(t)\\)\n\n\n\n \n  \n    t \n    one(t) \n    identity(t) \n    g(t) \n  \n \n\n  \n    0.0 \n    1 \n    0.0 \n    3.0 \n  \n  \n    0.1 \n    1 \n    0.1 \n    2.8 \n  \n  \n    0.2 \n    1 \n    0.2 \n    2.6 \n  \n  \n    0.3 \n    1 \n    0.3 \n    2.4 \n  \n  \n    0.4 \n    1 \n    0.4 \n    2.2 \n  \n  ... and so on ...\n  \n  \n  \n    4.6 \n    1 \n    4.6 \n    -6.2 \n  \n  \n    4.7 \n    1 \n    4.7 \n    -6.4 \n  \n  \n    4.8 \n    1 \n    4.8 \n    -6.6 \n  \n  \n    4.9 \n    1 \n    4.9 \n    -6.8 \n  \n  \n    5.0 \n    1 \n    5.0 \n    -7.0 \n  \n\n\n\n\n\nThe table above is a collection of four vectors: \\(\\vec{\\mathtt t}\\), \\(\\vec{\\mathtt{ one(t)}}\\), \\(\\vec{\\mathtt{identity(t)}}\\), and \\(\\vec{\\mathtt{g(t)}}\\). Each of those vectors has 51 components. In math-speak, we can say that the vectors are “embedded in a 51-dimensional space.”\nThe functions in the table are being represented as discrete values. Still, a table, combined with interpolation (Chapter 33) can produce a continuum."
  },
  {
    "objectID": "Linear-combinations/B5-linear-combinations.html#matrices-and-linear-combinations",
    "href": "Linear-combinations/B5-linear-combinations.html#matrices-and-linear-combinations",
    "title": "29  Linear combinations of vectors",
    "section": "29.5 Matrices and linear combinations",
    "text": "29.5 Matrices and linear combinations\nA collection of vectors, such as the one displayed in the previous table, is called a matrix. Each of the vectors in a matrix must have the same number of components.\nAs mathematical notation, we will use bold-faced, capital letters to stand for matrices, for example \\(\\mathit{M}\\). The symbol \\(\\rightleftharpoons\\) is a reminder that a matrix can contain multiple vectors, just as the symbol \\(\\rightharpoonup\\) in \\(\\vec{v}\\) reminds us that the name “\\(v\\)” refers to a vector.\nIn the conventions for data, we give a name to each column of a data frame so that we can refer to it individually. In the conventions used in vector mathematics, single letter are used to refer to the individual vectors.\nAs a case in point, let’s look at a matrix \\(\\mathit{M}\\) containing the two vectors which we’ve previously called \\(\\vec{\\mathtt{one(t)}}\\) and \\(\\vec{\\mathtt{identity(t)}}\\): \\[\\mathit{M} \\equiv \\left[\\begin{array}{rr}1 & 0\\\\\n1 & 0.1\\\\\n1 & 0.2\\\\\n1 & 0.3\\\\\n\\vdots & \\vdots\\\\\n1 & 4.9\\\\\n1 & 5.0\\\\\n\\end{array}\\right]\\ .\\] The linear combination which we might previous have called \\(3\\cdot \\vec{\\mathtt{t}} - 2\\,\\vec{\\mathtt{identity(t)}}\\) can be thought of as\n$$\\left[\\overbrace{\\begin{array}{r}\n1\\\\\n1 \\\\\n1 \\\\\n1 \\\\\n\\vdots &\\\\\n1 \\\\\n1 \n\\end{array}}^{3 \\times}\n\\stackrel{\\begin{array}{r}\n\\\\\n\\\\\n\\\\\n\\\\\n\\\\\n\\\\\n\\\\\n\\\\\n\\end{array}}{\\Large + \\ }\n\\overbrace{\\begin{array}{r}\n0\\\\\n0.1 \\\\\n0.2 \\\\\n0.3 \\\\\n\\vdots\\\\\n4.9 \\\\\n5.0 \n\\end{array}}^{-2 \\times}\\right] = \\left[\\begin{array}{r}\n\\\\ \\\\ 3\\\\\n2.8\\\\2.6\\\\2.4\\\\\\vdots\\\\-6.8\\\\-7.0\\\\ \\\\ \\\\\n\\end{array}\\right]\\ ,$$ but this is not conventional notation. Instead, we would write this more concisely as \n$$\\stackrel{\\Large\\mathit{M}}{\\left[\\begin{array}{rr}1 & 0\\\\\n1 & 0.1\\\\\n1 & 0.2\\\\\n1 & 0.3\\\\\n\\vdots & \\vdots\\\\\n1 & 4.9\\\\\n1 & 5.0\\\\\n\\end{array}\\right]} \\ \n\\stackrel{\\Large\\vec{w}}{\\left[\\begin{array}{r}2\\\\-3\\end{array}\\right]}$$\nIn symbolic form, the linear combination of the columns of \\(\\mathit{M}\\) using respectively the scalars in \\(\\vec{w}\\) is simply \\(\\mathit{M} \\, \\vec{w}\\). This is called matrix multiplication.\nNaturally, the operation only makes sense if there are as many components to \\(\\vec{w}\\) as there are columns in \\(\\mathit{M}\\).\n\n“Matrix multiplication” might better have been called “\\(\\mathit{M}\\) linearly combined by \\(\\vec{w}\\).” But “matrix multiplication” is the standard term for such linear combinations.\n\n\nIn R, you can make vectors with the rbind() command, short for “bind rows,” as in ::: {.cell layout-align=“center” fig.showtext=‘false’}\nrbind(2, 5, -3)\n##      [,1]\n## [1,]    2\n## [2,]    5\n## [3,]   -3\n\nwith the components of the vector presented as successive arguments to the function.\nOne way to make a matrix is with the cbind() command, short for “bind columns”. The arguments to cbind() will typically be vectors created by rbind(). For instance, the matrix \\[\\mathit{A} \\equiv \\left[\\vec{u}\\ \\ \\vec{v}\\right]\\ \\ \\text{where}\\ \\ \\vec{u} \\equiv \\left[\\begin{array}{r}2\\\\5\\\\-3\\end{array}\\right]\\ \\ \\text{and}\\ \\ \\vec{v} \\equiv \\left[\\begin{array}{r}1\\\\-4\\\\0\\end{array}\\right]\\] can be constructed in R with these commands.\n\nu <- rbind(2, 5, -3)\nv <- rbind(1, -4, 0)\nA <- cbind(u, v)\nA\n##      [,1] [,2]\n## [1,]    2    1\n## [2,]    5   -4\n## [3,]   -3    0\n\nTo compute the linear combination \\(3 \\vec{u} + 1 \\vec{v}\\), that is, \\(\\mathit{A} \\cdot \\left[\\begin{array}{r}3\\\\1\\end{array}\\right]\\) you use the matrix multiplication operator %*%. For instance, the following defines a vector \\[\\vec{x} \\equiv \\left[\\begin{array}{r}3\\\\1\\end{array}\\right]\\] to do the job in a way that’s easy to read:\n\nx <- rbind(3, 1)\nA %*% x\n##      [,1]\n## [1,]    7\n## [2,]   11\n## [3,]   -9\n\n:::\n\nIt’s a mistake to use * instead of %*% for matrix multiplication. Remember that * is for componentwise multiplication which is different from matrix multiplication. Componentwise multiplication with vectors and matrices will usually give an error message as with:\n\nA * x\n## Error in A * x: non-conformable arrays\n\nThe phrase “non-conformable arrays” is R-speak for saying “I don’t know how to do component-wise multiplication with two differently shaped objects.\n\nIn chapters to come, we will sometimes make several different linear combinations of the vectors in a matrix. Of course the result of each individual linear combination will be a vector, so the “several different linear combinations” can be thought of as a collection of vectors, that is, a matrix.\nFor example, consider the possible linear combinations of the two vectors in a matrix \\[\\mathit{A} = \\left[\\begin{array}{r}2\\\\5\\\\-3\\end{array}\\ \\begin{array}{r}1\\\\-4\\\\0\\end{array}\\right]\\ .\\]\nThe combinations we have in mind are: \\[\n\\mathit{A}\\left[\\begin{array}{r}3\\\\1\\end{array}\\right]=\n\\left[\\begin{array}{r}7\\\\11\\\\-9\\end{array}\\right]\n\\ \\ \\ \\ \\ \\ \\ \\ \\ \\\n\\mathit{A} \\left[\\begin{array}{r}-0\\\\2\\end{array}\\right]= \\left[\\begin{array}{r}2\\\\-8\\\\0\\end{array}\\right]\n\\ \\ \\ \\ \\ \\ \\  \\ \\ \\\n\\mathit{A} \\left[\\begin{array}{r}-1\\\\0\\end{array}\\right] = \\left[\\begin{array}{r}-2\\\\-5\\\\3\\end{array}\\right]\n\\] A more concise way to write this collects the vectors with the values for the scalars into a matrix, which we’ll call \\[\\mathit{X} \\equiv \\left[\\begin{array}{rrr}3 & 0 & -1\\\\1 & 2 & 0\\end{array}\\right]\\ .\\]\n\\[\\mathit{A} \\ \\mathit{X}  = \\left[\\begin{array}{rrr}7 &2 &-2\\\\11 & -8 & -5\\\\-9 & 0 & 3\\end{array}\\right]\\]\n\nIn R, to create the set of linear combinations, we create the matrices \\(\\mathit{A}\\) and \\(\\mathit{X}\\) and combine them with matrix multiplication. ::: {.cell layout-align=“center” fig.showtext=‘false’}\nA <- cbind(\n       rbind( 2,  5, -3),\n       rbind( 1, -4,  0)\n     )\n\nA is a collection of two vectors. Therefore, each vector in X must have two components: one for each vector in A\n\nX <- cbind(\n       rbind( 3, 1),\n       rbind( 0, 2),\n       rbind(-1, 0)\n)\n\nThe overall result will be a new matrix, containing three vectors, one for each vector in X:\n\nA %*% X\n##      [,1] [,2] [,3]\n## [1,]    7    2   -2\n## [2,]   11   -8   -5\n## [3,]   -9    0    3\n\n:::"
  },
  {
    "objectID": "Linear-combinations/B5-linear-combinations.html#sub-spaces",
    "href": "Linear-combinations/B5-linear-combinations.html#sub-spaces",
    "title": "29  Linear combinations of vectors",
    "section": "29.6 Sub-spaces",
    "text": "29.6 Sub-spaces\nRecall that a vector with \\(n\\) components can be said to be embedded in an \\(n\\)-dimensional space. You might like to think of the embedding space as a kind of club with restricted membership. A vector with 2 elements is entitled to join the 2-dimensional club, but a vector with more or fewer than 2 elements cannot be admitted to the club. Similarly, there are clubs for 3-component vectors, 4-component vectors, and so on.\nThe clubhouse itself is a kind of space, the space in which any and all of the vectors that are eligible for membership can be embedded.\nNow imagine the clubhouse arranged into meeting rooms. Each meeting room is just part of the clubhouse space. Which part? That depends on a set of vectors who sponsor the meeting. For instance, in the ten-dimensional clubhouse, a few members, let’s say \\(\\color{blue}{\\vec{u}}\\) and \\(\\color{magenta}{\\vec{v}}\\) decide to sponsor a meeting. That meeting room, part of the whole clubhouse space, is called a subspace.\nA subspace has its own rules for admission. Vectors belong to the subspace only if they can be constructed as a linear combination of the sponsoring members. Mathematically, although the subspace is defined by the founding vectors, the subspace itself consists f all the possible vectors can be constructed by a linear combination of the sponsors.\nAs an example, consider the clubhouse that is open to any and all vectors with three components. The diagram in ?fig-two-vecs shows the clubhouse with just two members present, \\(\\color{blue}{\\vec{u}}\\) and \\(\\color{magenta}{\\vec{v}}\\).\nAny vector can sponsor its own subspace. In ?fig-two-vecs the subspace sponsored by \\(\\color{blue}{\\vec{u}}\\) is the extended line through \\(\\color{blue}{\\vec{u}}\\), that is, all the possible scaled versions of \\(\\color{blue}{\\vec{u}}\\). Similarly, the subspace sponsored by \\(\\color{magenta}{\\vec{v}}\\) is the extended line through \\(\\color{magenta}{\\vec{v}}\\). Each of these subspaces is one-dimensional.\n\n\n\n\n\n\n\n\n\nTwo vectors \\(\\color{blue}{\\vec{u}}\\) and \\(\\color{magenta}{\\vec{v}}\\) embedded in 3-dimensional space. The subspace spanned by each vector, individually, is shown as a line. NEED TO PROVIDE PRINTABLE LINK FOR PDF version\n\n\n\n\nMultiple vectors can sponsor a subspace. The subspace sponsored by both \\(\\color{blue}{\\vec{u}}\\) and \\(\\color{magenta}{\\vec{v}}\\) contains all the vectors that can be constructed as linear combinations of \\(\\color{blue}{\\vec{u}}\\) and \\(\\color{magenta}{\\vec{v}}\\). In Figure 29.5, this subspace is shown in gray.\n\n\n\n\n\n\n\n\n\nFigure 29.5: Two vectors \\(\\vec{u}\\) and \\(\\vec{w}\\). The subspace spanned by two vectors is a plane, shown as a gray surface. NEED TO PROVIDE LINK for PDF version\n\n\n\n\nOn the other hand, the subspace sponsored by \\(\\color{magenta}{\\vec{v}}\\) and \\(\\color{blue}{\\vec{u}}\\) is not the entire clubhouse. \\(\\color{magenta}{\\vec{v}}\\) and \\(\\color{blue}{\\vec{u}}\\) lie in a common plane, but not all the vectors in the 3-dimensional clubhouse lied in that plane. In fact, if you rotate ?fig-two-vecs-plane to “look down the barrel” of either \\(\\color{magenta}{\\vec{v}}\\) or \\(\\color{blue}{\\vec{u}}\\), the plane will entirely disappear from view. A subspace is an infinitesimal slice of the embedding space.\n“Sponsored a subspace” is metaphorical. In technical language we speak of the subspace spanned by a set of vectors in the same embedding space. Usually, we refer to a “set of vectors” as a matrix. For instance, letting \\[\\mathit{M} \\equiv \\left[{\\Large \\strut}\\color{blue}{\\vec{u}}\\ \\ \\color{magenta}{\\vec{v}}\\right]\\ ,\\] the gray plane in Figure 29.5 is the subspace spanned by \\(\\mathit{M}\\) or, more concisely, \\(span(\\mathit{M})\\).\nFor a more concrete, everyday representation of the subspace spanned by two vectors, a worthwhile experiment is to pick up two pencils pointing in different directions. Place the eraser ends together, pinched between thumb and forefinger. You can point the whole rigid assembly in any direction you like. The angle between them will remain the same.\nPlace a card on top of the pencils, slipping it between your pressed fingers to hold it tightly in place. The card is another kind of geometrical object: a planar surface. The orientation of two vectors together determine the orientation of the surface. This simple fact will be extremely important later on.\nYou could replace the pencils with line segments drawn on the card underneath each pencil. Now you have the angle readily measurable in two dimensions. The angle between two vectors in three dimensions is the same as the angle drawn on the two-dimension surface that rests on the vectors.\nNotice that you can also lay a card along a single vector. What’s different here is that you can roll the card around the pencil; there are many different orientations for such a card even while the vector stays fixed. So a single fixed vector does not determine uniquely the orientation of the planar surface in which the two vectors can reside. But with two fixed vectors, there is only one such surface."
  },
  {
    "objectID": "Linear-combinations/B5-linear-combinations.html#exercises",
    "href": "Linear-combinations/B5-linear-combinations.html#exercises",
    "title": "29  Linear combinations of vectors",
    "section": "29.7 Exercises",
    "text": "29.7 Exercises"
  },
  {
    "objectID": "Linear-combinations/B5-projection.html",
    "href": "Linear-combinations/B5-projection.html",
    "title": "30  Projection & residual",
    "section": "",
    "text": "Many problems in physics and engineering involve the task of decomposing a vector \\(\\vec{b}\\) into two perpendicular component vectors \\(\\hat{b}\\) and \\(\\vec{r}\\), such that \\(\\hat{b} + \\vec{r} = \\vec{b}\\) and \\(\\hat{b} \\cdot \\vec{r} = 0\\). There is an infinite number of ways to accomplish such a decomposition, one for each way or orienting \\(\\hat{b}\\) relative to \\(\\vec{b}\\). Figure 30.1 shows a few examples.\nThe task of decomposition is important also outside of physics and engineering. Our particular interest will be in finding how best to take a linear combination of the columns of a matrix \\(\\mathit{A}\\) in order to make the best approximation to a given vector \\(\\vec{b}\\). This problem solves all sorts of problems: finding a linear combination of functions to match a relationship laid out in data, constructing statistical models such as those found in machine learning, effortlessly solving sets of simultaneous linear equations with any number of equations and any number of unknowns."
  },
  {
    "objectID": "Linear-combinations/B5-projection.html#projection-terminology",
    "href": "Linear-combinations/B5-projection.html#projection-terminology",
    "title": "30  Projection & residual",
    "section": "30.1 Projection terminology",
    "text": "30.1 Projection terminology\nThe problem of decomposition can be considered to be a special case of projection. The word “projection” may bring to mind the casting of shadows on a screen in the same manner as an old-fashioned slide projector or movie projector. The light source is arranged to generate parallel rays which arrive perpendicularly to the screen. A movie screen is two-dimensional, a subspace defined by two vectors. Imagining those two vectors to be collected into matrix \\(\\mathit{A}\\), the idea is to decompose \\(\\vec{b}\\) into a component that lies in the subspace defined by \\(\\mathit{A}\\) and another component that is perpendicular to the screen. That perpendicular component is what we have been calling \\(\\vec{r}\\) while the vector \\(\\hat{b}\\) is the projection of \\(\\vec{b}\\) onto the screen. To make it easier to keep track of the various roles played by \\(\\vec{b}\\), \\(\\hat{b}\\), \\(\\vec{r}\\) and \\(\\mathit{A}\\), we’ll give these vectors English-language names. The motivation for these names will become apparent in later chapters, but for now, here they are. You will want to memorize them.\n\n\\(\\vec{b}\\) the target vector\n\\(\\hat{b}\\) the model vector\n\\(\\vec{r}\\) the residual vector\n\\(\\mathit{A}\\) the model space (or “model subspace”)\n\nProjection is the process of finding the model vector that is as close as possible to the target vector \\(\\vec{b}\\). Another way to see this is as finding the model vector that makes the residual vector as short as possible.\n\nFigure 30.2 shows a a solved projection problem in 3-dimensional space. The figure can be rotated or set spinning, which makes it much easier to interpret the diagram as a three dimensional object. In addition to \\(\\vec{b}\\) and the vectors \\(\\vec{u}\\) and \\(\\vec{b}\\) that constitute the matrix \\(\\mathit{A}\\), the diagram includes a translucent plane marking \\(span(\\mathit{A})\\). The goal of projection is, from these givens, to find the model vector (shown in light green). Once the model vector \\(\\vec{x}\\) is known, the residual vector is easy to calculate \\[\\vec{r} \\equiv \\vec{b} - \\hat{b}\\ .\\] Another approach to the problem is to find the residual vector \\(r\\) first, then use that to find the model vector as \\[\\hat{b} \\equiv \\vec{b} - \\vec{r}\\ .\\]\n\n\n\n\nNEED TO PROVIDE LINK AND IMAGE FOR PDF version\n\n\n\n\n\nFigure 30.2: A three-dimensional diagram showing the target vector \\(\\vec{b}\\) and the vectors \\(\\vec{u}\\) and \\(\\vec{v}\\). The subspace spanned by \\(\\vec{u}\\) and \\(\\vec{v}\\) is indicated with a translucent plane. The model vector (green) is the result produced in solving the projection problem.\n\n\n\n\nInterpreting such three dimensional diagrams can be difficult. But there are tricks involving watching the diagram as it is rotated. For instance, how do we know that the translucent plane in Figure 30.2 contains \\(\\vec{u}\\) and \\(\\vec{v}\\)? As the diagram rotates, from time to time you will be looking edge on at the plane, so that the plane appears as a line on the screen. At such times, you can see that vectors \\(\\vec{u}\\) and \\(\\vec{v}\\) disappear. There is no component to \\(\\vec{u}\\) and \\(\\vec{v}\\) that sticks out from the plane."
  },
  {
    "objectID": "Linear-combinations/B5-projection.html#projection-onto-a-single-vector",
    "href": "Linear-combinations/B5-projection.html#projection-onto-a-single-vector",
    "title": "30  Projection & residual",
    "section": "30.2 Projection onto a single vector",
    "text": "30.2 Projection onto a single vector\nAs we said, projection involves a vector \\(\\vec{b}\\) and a matrix \\(\\mathit{A}\\) that defines the model space. We’ll start with the simplest case, where \\(\\mathit{A}\\) has only one column. That column is, of course, a vector. We’ll call that vector \\(\\vec{a}\\), so the projection problem is to project \\(\\vec{b}\\) onto the subspace spanned by \\(\\vec{a}\\).\nGeometrically, the situation of projecting the target vector \\(\\vec{b}\\) onto the model space \\(\\vec{a}\\) is diagrammed in Figure 30.3.\n\n\n\n\n\nFigure 30.3: The geometry of projecting \\(\\vec{b}\\) onto \\(\\vec{a}\\) to produce the model vector \\(\\hat{b}\\).\n\n\n\n\nThe angle between \\(\\vec{a}\\) and \\(\\vec{b}\\) is labelled \\(\\theta\\). You already know how to calculate \\(\\theta\\) from \\(\\vec{b}\\) and \\(\\vec{a}\\) by using the dot product:\n\\[\\cos(\\theta) = \\frac{\\vec{b} \\bullet \\vec{a}}{\\len{b}\\, \\len{a}}\\ .\\] Knowing \\(\\theta\\) and \\(\\len{b}\\), you can calculate the length of the model vector \\(\\hat{b}\\): \\[\\len{s} = \\len{b} \\cos(\\theta) = \\vec{b} \\bullet \\vec{a} / \\len{a}\\ .\\]\nScaling \\(\\vec{a}\\) by \\(\\len{a}\\) would produce a vector oriented in the model subspace, but it would have the wrong length: length \\(\\len{a} \\len{s}\\). So we need to divide \\(\\vec{a}\\) by \\(\\len{a}\\) to get a unit length vector oriented along \\(\\vec{a}\\):\n\\[\\text{model vector:}\\ \\ \\hat{b} = \\left[\\vec{b} \\bullet \\vec{a}\\right] \\,\\vec{a} / {\\len{a}^2} = \\frac{\\vec{b} \\bullet \\vec{a}}{\\vec{a} \\bullet \\vec{a}}\\  \\vec{a}.\\] . \n\nIn R/mosaic, you can calculate the projection of \\(\\vec{b}\\) onto \\(\\vec{a}\\) using %onto%. For instance ::: {.cell layout-align=“center” fig.showtext=‘false’}\nb <- rbind(-1, 2)\na <- rbind(-2.5, -0.8)\ns <- b %onto% a\ns\n##            [,1]\n## [1,] -0.3265602\n## [2,] -0.1044993\n\nHaving found \\(\\hat{b}\\), the residual vector \\(\\vec{r}\\) can be calculated as \\(\\vec{b}- \\hat{b}\\).\n\nr <- b - s\nr\n##            [,1]\n## [1,] -0.6734398\n## [2,]  2.1044993\n\nThe two properties that a projection satisfies are:\n\nThe residual vector is perpendicular to each and every vector in \\(\\mathit{A}\\). Since in this example, \\(\\mathit{A}\\) contains only the one vector \\(\\vec{a}\\), we need only look at \\(\\vec{r} \\cdot \\vec{a}\\) and confirm that it’s zero. ::: {.cell layout-align=“center” fig.showtext=‘false’}\n\nr %dot% a\n## [1] -2.220446e-16\n::: 2. The residual vector plus the model vector exactly equal the target vector. Since we computed r <- b - s, we know this must be true, but still … ::: {.cell layout-align=“center” fig.showtext=‘false’}\n(r+s) - b\n##      [,1]\n## [1,]    0\n## [2,]    0\n:::\nIf the difference between two vectors is zero for every coordinate, the two vectors must be identical. :::"
  },
  {
    "objectID": "Linear-combinations/B5-projection.html#projection-onto-a-set-of-vectors",
    "href": "Linear-combinations/B5-projection.html#projection-onto-a-set-of-vectors",
    "title": "30  Projection & residual",
    "section": "30.3 Projection onto a set of vectors",
    "text": "30.3 Projection onto a set of vectors\nAs we have just seen, projecting a target \\(\\vec{b}\\) onto a single vector is a matter of arithmetic. Now we will expand the technique to project the target vector \\(\\vec{b}\\) onto multiple vectors collected into a matrix \\(\\mathit{A}\\). Whereas in the chapter we used trigonometry to find the component of \\(\\vec{b}\\) aligned with the single vector \\(\\vec{a}\\), now we have to deal with multiple vectors at the same time. The result will be the component of \\(\\vec{b}\\) aligned with the subspace sponsored by \\(\\mathit{A}\\).\nThere is one situation where the projection is easy: when the vectors in \\(\\mathit{A}\\) are mutually orthogonal. In this situation, carry out several one-vector-at-a-time projections: \\[\\vec{p_1} = \\modeledby{\\vec{b}}{\\vec{v_1}}\\\\\n\\vec{p_2} = \\modeledby{\\vec{b}}{\\vec{v_2}}\\\\\n\\vec{p_3} = \\modeledby{\\vec{b}}{\\vec{v_3}}\\\\\n\\text{and so on}\\] The projection of \\(\\vec{b}\\) onto \\(\\mathit{A}\\) will be the sum \\(\\vec{p_1} + \\vec{p2} + \\vec{p3}\\).\n\nTo illustrate the method of projection when the vectors in \\(\\mathit{A}\\) are mutually orthogonal, we can construct such a matrix. ::: {.cell layout-align=“center” fig.showtext=‘false’}\nb  <- rbind( 1,  1,  1, 1)\nv1 <- rbind( 1,  2,  0, 0)\nv2 <- rbind(-2,  1,  3, 1)\nv3 <- rbind( 0,  0, -1, 3)\nA <- cbind(v1, v2, v3)\n\nYou can verify using a dot product that v1, v2, and v3 are mutually orthogonal.\nNow construct the one-at-a-time projections: ::: {.cell layout-align=“center” fig.showtext=‘false’}\np1 <- b %onto% v1\np2 <- b %onto% v2\np3 <- b %onto% v3\n:::\nTo find the projection of \\(\\vec{b}\\) onto the subspace spanned by \\(\\mathit{A}\\), add up the one-at-a-time projections:\n\nb_on_A <- p1 + p2 + p3\n\nNow we’ll confirm that b_on_A really is the projection of b onto A. The strategy is to construct the residual from the projection. ::: {.cell layout-align=“center” fig.showtext=‘false’}\nresid <- b - b_on_A\n::: All that’s needed is to confirm that the residual is perpendicular to each and every vector in A: ::: {.cell layout-align=“center” fig.showtext=‘false’}\nresid %dot% v1\n## [1] 7.771561e-16\nresid %dot% v2\n## [1] -2.220446e-16\nresid %dot% v3\n## [1] 6.661338e-16\n::: :::"
  },
  {
    "objectID": "Linear-combinations/B5-projection.html#a-becomes-q",
    "href": "Linear-combinations/B5-projection.html#a-becomes-q",
    "title": "30  Projection & residual",
    "section": "30.4 A becomes Q",
    "text": "30.4 A becomes Q\nNow that we have a satisfactory method for projecting \\(\\vec{b}\\) onto a matrix \\(\\mathit{A}\\) consisting of mutually orthogonal vectors, we need to develop a method for the projection when the vectors in \\(\\mathit{A}\\) are not mutually orthogonal. The big picture here is that we will construct a new matrix \\(\\mathit{Q}\\) that spans the same space as \\(\\mathit{A}\\) but whose vectors are mutually orthogonal. We’ll construct \\(\\mathit{Q}\\) out of linear combinations of the vectors in \\(\\mathit{A}\\), so we can be sure that \\(span(\\mathit{Q}) = span(\\mathit{A})\\).\nWe introduce the process with an example, involving a vectors in a 4-dimensional space. \\(\\mathit{A}\\) will be a matrix with two columns, \\(\\vec{v_1}\\) and \\(\\vec{v_2}\\). Here’s the setup for the example vectors and model matrix:\n\nb <- rbind(1,1,1,1)\nv1 <- rbind(2,3,4,5)\nv2 <- rbind(-4,2,4,1)\nA <- cbind(v1, v2)\n\nWe start the construction of the \\(\\mathit{Q}\\) matrix by pulling in the first vector in \\(\\mathit{A}\\). We’ll call that vector \\(\\vec{q_1}\\)\n\nq1 <- v1\n\nThe next \\(\\mathit{Q}\\) vector will be constructed to be perpendicular to \\(\\vec{q_1}\\) but still in the subspace spanned by \\(\\left[{\\Large\\strut}\\vec{v_1}\\ \\ \\vec{v_2}\\right]\\). We can guarantee this will be the case by making the \\(\\mathit{Q}\\) vector entirely as a linear combination of \\(\\vec{v_1}\\) and \\(\\vec{v_2}\\).\n\nq2 <- v2 %perp% v1\n\nsince \\(\\vec{q_1}\\) and \\(\\vec{q_2}\\) are orthogonal and define the same subspace as \\(\\mathit{A}\\), we can construct the projection of \\(\\vec{b}\\) onto \\(\\vec{A}\\) by adding up the projections of \\(\\vec{b}\\) onto the individual vectors in \\(\\mathit{Q}\\), like this:\n\nbhat <- (b %onto% q1) + (b %onto% q2)\n\nTo confirm that this calculation of \\(\\hat{\\vec{b}}\\) is correct, construct the residual vector and confirm that it is perpendicular to every vector in \\(\\mathit{Q}\\) (and therefore in \\(\\mathit{A}\\), which spans the same space).\n\nr <- b - bhat\nr %dot% v1\n## [1] 1.110223e-15\nr %dot% v2\n## [1] 2.220446e-16\n\nNote that we defined \\(\\vec{r} = \\vec{b} - \\hat{\\mathbf{b}}\\), so it’s guaranteed that \\(\\vec{r} + \\hat{\\mathbf{b}}\\) will equal \\(\\vec{b}\\).\nThis process can be extended to any number of vectors in \\(\\mathit{A}\\). Here’s the algorithm for constructing \\(\\mathit{Q}\\):\n\nTake the first vector from \\(\\mathit{A}\\) and call it \\(\\vec{q_1}\\).\nTake the second vector from \\(\\mathit{A}\\) and find the residual from projecting it onto \\(\\vec{q_1}\\). This residual will be \\(\\vec{q_2}\\). At this point, the matrix \\(\\left[\\strut \\vec{q_1}, \\ \\ \\vec{q_2}\\right]\\) consists of mutually orthogonal vectors.\nTake the third vector from \\(\\mathit{A}\\) and project it onto \\(\\left[\\strut \\vec{q_1}, \\ \\ \\vec{q_2}\\right]\\). We can do this because we already have an algorithm for projecting a vector onto a matrix with mutually orthogonal columns. Call the residual from this projection \\(\\mathit{q_3}\\). It will be orthogonal to the vectors in \\(\\left[\\strut \\vec{q_1}, \\ \\ \\vec{q_2}\\right]\\), so all three of the q vectors we’ve created are mutually orthogonal.\nContinue onward, taking the next vector in \\(\\mathit{A}\\), projecting it onto the q-vectors already assembled, and finding the residual from that projection.\nRepeat step (iv) until all the vectors in \\(\\mathit{A}\\) have been handled.\n\n\nProject a \\(\\vec{b}\\) that lives in 10-dimensional space onto the subspace sponsored by five vectors that are not mutually orthgonal:\n\nb <- rbind(3,2,7,3,-6,4,1,-1, 8, 2) # or any set of 10 numbers\nv1 <- rbind(4, 7, 1, 0, 3, 0, 6, 1, 1, 2)\nv2 <- rbind(8, 8, 4, -3, 3, -2, -4, 9, 6, 0)\nv3 <- rbind(12, 0, 4, -2, -6, -4, -1, 4, 6, -7)\nv4 <- rbind(0, 3, 9, 6, -4, -5, 4, 0, 5, -4)\nv5 <- rbind(-2, 5, -4, 8, -9, 3, -5, 0, 11, -4)\nA  <- cbind(v1, v2, v3, v4, v5)\n\nYou can confirm using dot products that the v-vectors are not mutually orthogonal.\nNow to construct the vectors in \\(\\mathit{Q}\\).\n\nq1 <- v1\nq2 <- v2 %perp% q1\nq3 <- v3 %perp% cbind(q1, q2)\nq4 <- v4 %perp% cbind(q1, q2, q3)\nq5 <- v5 %perp% cbind(q1, q2, q3, q4)\nQ <- cbind(q1, q2, q3, q4, q5)\n\nSince Q consists of mutually orthogonal vectors, the projection of b onto Q can be done one vector at a time. ::: {.cell layout-align=“center” fig.showtext=‘false’}\np1 <- b %onto% q1\np2 <- b %onto% q2\np3 <- b %onto% q3\np4 <- b %onto% q4\np5 <- b %onto% q5\n# put together the components\nb_on_A <- p1 + p2 + p3 + p4 + p5\n# check the answer: resid should be perpendicular to A\nresid <- b - b_on_A\nresid %dot% v1\n## [1] 1.065814e-14\nresid %dot% v2\n## [1] 4.973799e-14\nresid %dot% v3\n## [1] 7.105427e-15\nresid %dot% v4\n## [1] 0\nresid %dot% v5\n## [1] 1.776357e-14\n\n:::"
  },
  {
    "objectID": "Linear-combinations/B5-projection.html#exercises",
    "href": "Linear-combinations/B5-projection.html#exercises",
    "title": "30  Projection & residual",
    "section": "30.5 Exercises",
    "text": "30.5 Exercises"
  },
  {
    "objectID": "Linear-combinations/B5-target-problem.html",
    "href": "Linear-combinations/B5-target-problem.html",
    "title": "31  The target problem",
    "section": "",
    "text": "“In theory there is no difference between theory and practice, while in practice there is.”\nIn this chapter, we ask you to reconsider a mathematical theory that is universally taught in high-school and to consider augmenting it with newer computational ideas that address the same kind of problems, but which produce useful results even when the mathematical theory insists the “a solution does not exist.”\nThe time-honored theory is that taught in high-school algebra. There’s nothing wrong with that theory except that it is incomplete. It doesn’t address the needs of present-day practice, particularly in data science, statistics, and machine learning.\nAlgebra, in its basic sense, is about generalizing arithmetic to handle situations where some quantities are not yet known numerically and so are represented by symbols. The algebra student learns rules for symbolic expressions that allow the expressions to be re-arranged into other forms that would clearly be valid if replaced by numbers. Some examples of these rules:\ni. \\(ax = b\\) is equivalent to \\(x = a/b\\).\nii. \\(a + x = b\\) is equivalent to \\(x=b-a\\).\niii. \\(a x^2 + b x + c = 0\\) is equivalent to \\(x = \\frac{-b\\pm \\sqrt{\\strut b^2 - 4ac}}{2a}\\).\niv. \\(\\ln(ax) = b\\) is equivalent to \\(x = \\frac{1}{a}\\ln(b)\\).\nA major challenge to the algebra student is to use such rules to re-arrange expressions into a form \\(x=\\) that enables \\(x\\) to be calculated from the numerical values of the other symbols. Unfortunately, students are given little or no insight to the historical origins of algebra techniques and why they are not necessarily appropriate for all tasks.\nIn English, the word “algebra” is seen as early as 1551. It comes from a book written by the Persian Muhammad ibn Musa al-Khwarizmi (780-850), The Compendious Book on Calculation by Completion and Balancing. The book introduced the use of rules familiar to every algebra student. In the original Arabic, the title includes the word “al-jabr,” meaning “completion” or “rejoining.” According to some sources, the literal meaning of “al-jabr” was resetting and rejoining broken bones. That literal meaning correctly conveys the importance of the subject, but also the pain endured by many algebra students. (Incidentally, the “algorithm” comes from the name of the book’s author: al Khwarizmi. He is a major figure in the history of mathematics.)\nThis history may not be of immediate interest to every reader, but there is a good point to it. The roots of algebra are ancient and developed in an era very different from our own. Today’s student learns algebra in order to facilitate the study and practice of physics, chemistry, statistics, engineering, and other fields. None of these fields existed when algebra was being conceived. That is, the theory was developed before the recognition of the problems and calculations that arise in modern practice. Thus, “in practice, theory and practice are different.”\nThis chapter is about re-expressing some basic algebraic theory in order to align it better to today’s practice."
  },
  {
    "objectID": "Linear-combinations/B5-target-problem.html#sec-linear-equations",
    "href": "Linear-combinations/B5-target-problem.html#sec-linear-equations",
    "title": "31  The target problem",
    "section": "31.1 Linear equations",
    "text": "31.1 Linear equations\nThe focus of interest will be the familiar task\n\\[\\ \\ \\ \\ \\ \\ \\text{given}\\ \\ a x = b\\,,\\ \\ \\text{find}\\ \\ x\\ .\\] All algebra students learn that \\(x = b/a\\), with the proviso that if \\(a = 0\\), “there is no solution.”\nA somewhat more advanced algebra task is to work with “simultaneous linear equations,” for example: \\[\\ \\ \\ \\text{given}\\ \\ \\ \\begin{array}{rrrcr}\n3 x & + & 2 y & = & 7\\\\\n-1&+&y&=&4\\end{array}\n\\ \\ \\ \\ \\text{find}\\ \\ x\\,\\&\\,y\\ .\n\\]\nSolving simultaneous linear equations is hard. It involves more arithmetic than \\(ax = b\\) and requires the student to make good choices how to take linear combinations of the two equations to reduce the problem to two equations, one with \\(x\\) as the only unknown and one with \\(y\\). Also, the “there is no solution” proviso is not easy to state, so you can’t know at a glance whether there is indeed a solution.\nThe simultaneous linear equation problem can be more compactly written using matrix and vector notation. \\[\\begin{array}{rrrcr}3x & + &2y & = & 7\\\\-1&+&y&=&4\\end{array} \\ \\ \\text{is the same as}\\ \\ \\left[\\begin{array}{r}3\\\\-1\\end{array}\\right] x + \\left[\\begin{array}{r}2\\\\1\\end{array}\\right] y =\n\\left[\\begin{array}{r}7\\\\4\\end{array}\\right] \\] You can see the vector form as a linear combination of two vectors. Collecting these two vectors into a matrix \\(\\mathit{A}\\), and similarly writing \\(x\\, \\text{and}\\, y\\) as the scalar components of a vector \\(\\vec{x}\\) gives \\[\\left[\\begin{array}{rr}3&2\\\\-1&1\\end{array}\\right]\\ \\vec{x} = \\left[\\begin{array}{r}7\\\\4\\end{array}\\right]\\] Which can be expressed as \\(\\mathit{A} \\vec{x} = \\vec{b}\\).\nA student, recognizing the similarity of \\(\\mathit{A}\\vec{x} = \\vec{b}\\) to \\(a x = b\\) would reasonably suggest the solution \\(\\vec{x} = \\vec{b}/ \\mathit{A}\\). Such a student might be instructed, “No, you can’t do this.” A better response would be, “Good. Now tell me what you mean by \\(\\vec{b}/\\mathit{A}\\)?”\nModern practice often calls for solving \\(\\mathit{A}\\vec{x} = \\vec{b}\\) in settings where a traditional algebra teacher might say, as for \\(0 x = b\\) that “there is no solution.”\nTo illustrate such a setting, recall the problems from Section Section 11.3 of finding the linear combination of the functions \\(f(\\mathtt{time})=1\\) and \\(g(\\mathtt{time}) = e^{-0.019 \\mathtt{time}}\\) that best matches the CoolingWater data:\n\n\n\n \n  \n    time \n    temp \n  \n \n\n  \n    0 \n    98.2 \n  \n  \n    1 \n    94.4 \n  \n  \n    2 \n    91.4 \n  \n  ... and so on ...\n  \n  \n  \n    220 \n    25.9 \n  \n  \n    221 \n    25.8 \n  \n\n\n\n\n\nWe seek scalars \\(C\\) and \\(D\\) such that the function \\(C f(\\mathtt{time}) + D g(\\mathtt{time})\\) gives the best possible match to temp.\nWe can compactly write the problem of finding the best linear combination into matrix form by evaluating \\(f()\\) and \\(g()\\) at the values listed in the time column: \\[\\underbrace{\\left[\\begin{array}{rr}1&1.0000\\\\1&0.9812\\\\1&0.9627\\\\\\vdots\\\\1&0.0153\\\\1&0.0150\\end{array}\\right]}_{\\!\\!\\!\\!\\!\\!\\!\\!{\\large\\mathit{A}} = \\left[\\strut f(\\mathtt{time})\\,,\\ \\ \\ g(\\mathtt{time})\\right]} \\underbrace{\\left[\\begin{array}{r}C\\\\D\\end{array}\\right]}_{\\large\\vec{x}} \\ \\text{is the best match to}\\  \\underbrace{\\left[\\begin{array}{r}\\mathtt{98.2}\\\\\\mathtt{94.4}\\\\\\mathtt{91.4}\\\\\\vdots\\\\\\mathtt{25.9}\\\\\\mathtt{25.8}\\end{array}\\right]}_{\\large\\vec{b}}\\]\nRegrettably, the classical algebraicists did not propose a rule for “is the best match to.” Replacing “is the best match to” with \\(=\\) is not literally correct since “there is no solution” that makes the equality literally true.\nWe’ll use the term target problem to name the task of finding \\(\\vec{x}\\) such that \\(\\mathit{A} \\vec{x}\\) is the best possible match to \\(\\vec{b}\\). This term is motivated by the idea that \\(\\vec{b}\\) is a target, and we seek to use the resources in \\(\\mathit{A}\\) to get as close as possible to the target: choose \\(\\vec{x}\\) such that \\(\\mathit{A} \\vec{x}\\) falls as closely as possible to the target.\nTo address the practical problem in the notation of algebra theory, people write \\[\\mathit{A} \\vec{x} = \\vec{b} - \\vec{r}\\] where \\(\\vec{r}\\) is a vector specially selected to path up \\(\\mathit{A} \\vec{x} = \\vec{b}\\) so that when the best-matching \\(C\\) and \\(D\\) are found, there will be a literal equality solution to \\(\\mathit{A} \\vec{x} = \\vec{b} - \\vec{r}\\).\nAt first glance, \\(\\mathit{A} \\vec{x} = \\vec{b} - \\vec{r}\\) might seem intractable: How are we to find \\(\\vec{r}\\). The answer is that \\(\\vec{r}\\) will be the solution to the projection problem \\(\\vec{b}\\sim\\mathit{A}\\). When \\(\\vec{r}\\) is selected this way, \\(\\vec{r}\\) will be the shortest possible vector that can do the matching up. In other words, by choosing \\(\\vec{r} = \\vec{b} \\sim \\mathit{A}\\) we are implementing the following definition of “is the best match to”: “the best match is the one with the smallest length \\(\\vec{r}\\).”\nIt’s remarkable that one can find \\(\\vec{r}\\) even without knowing \\(\\vec{x}\\). That’s why we introduced and solved the projection problem before taking on the target problem.\nThe part of the target problem that we have still to figure out is how, given \\(\\vec{r}\\), to find \\(\\vec{x}\\). But even at this point you can see that \\(\\mathit{A}\\vec{x} = \\vec{b} - \\vec{r}\\) must have a solution, since \\(\\vec{b} - \\vec{r}\\) is exactly the model vector \\(\\hat{b}\\) which, as we saw in Section 30), must lie in \\(span{\\mathit{A}}\\)."
  },
  {
    "objectID": "Linear-combinations/B5-target-problem.html#visualization-in-a-two-dimensional-subspace",
    "href": "Linear-combinations/B5-target-problem.html#visualization-in-a-two-dimensional-subspace",
    "title": "31  The target problem",
    "section": "31.2 Visualization in a two-dimensional subspace",
    "text": "31.2 Visualization in a two-dimensional subspace\nTo help you create a mental model of the geometry of the target problem, we’ll solve it graphically for a two dimensional subspace. That is, we’ll solve \\(\\left[\\vec{u}, \\vec{v}\\right] \\vec{x} = \\vec{b}\\). For simplicity, the vectors \\(\\vec{u}\\), \\(\\vec{v}\\) and \\(\\vec{b}\\) will have two components. This means that there is no need to project \\(\\vec{b}\\) onto the subspace; it’s already there (so long as \\(\\vec{u}\\) and \\(\\vec{v}\\) have different directions. )\nYou may already have encountered the step (ii) technique in your childhood reading. The problem appears in Robert Louis Stevenson’s famous novel, Treasure Island. The story is about the discovery of a treasure map indicating the location of buried treasure on the eponymous Island. There is a red X on the map labelled “bulk of treasure here,” but that is hardly sufficient to guide the dig for treasure. After all, every buried treasure needs some secret to protect it. On the back of the map is written a cryptic clue to the precise location:\n\nTall tree, Spy-glass shoulder, bearing a point to the N. of N.N.E.\nSkeleton Island E.S.E. and by E.\nTen feet.\n\nSkeleton Island is clearly marked on the map, as is Spy-glass Hill. The plateau marked by the red X “was dotted thickly with pine-trees of varying height. Every here and there, one of a different species rose forty or fifty feet clear above its neighbors.” But which of these was the “tall tree” mentioned in the clue?\n\n\n\n\n\nFigure 31.1: The map of Treasure Island. The heading ‘E.S.E. and by E.’ is marked with a solid black line starting at Skeleton Island. The heading ‘N. of N.N.E.’ is marked by dotted lines, one of which is positioned to point at the shoulder of Spy-glass Hill. Where the bearing from Skeleton Island meets the bearing to Spy-glass Hill will be the Tall tree.\n\n\n\n\nWith your new-found background in vectors, you will no doubt recognize that “N. of N.N.E” is the direction of a vector as is “E.S.E. and by E.” Pirate novels seem always to use the length unit of “pace,” which we’ll use here as well. The target is the shoulder of Spy-glass Hill. Or, in vector terms, \\(\\vec{b}\\) is the vector with Skeleton Island as the tail and the should of Spy-glass Hill as the tip. The vectors are \\(\\vec{u} = \\text{N. of N.N.E.}\\) and \\(\\vec{v} = \\text{E.S.E. and by E.}\\) We need to \\[\\text{solve} \\ \\ \\underbrace{\\left[\\vec{u}, \\vec{v}\\right]}_{\\Large\\strut\\mathit{A}} \\underbrace{\\small\\left[\\begin{array}{c}C\\\\D\\end{array}\\right]}_{\\Large\\vec{x}} = \\vec{b}\\ \\ \\text{for}\\ \\ {\\small\\left[\\begin{array}{c}C\\\\D\\end{array}\\right]}\\ .\\]\nLong John Silver, obviously an accomplished mathematician, starts near Skeleton Island, moving on along the vector that keeps Skeleton Island to the compass bearing one point east of east-south-east. While on the march, he keeps a telescope trained on the shoulder of Spy-glass Hill. When that telescope points one point north of north-north-east, they are in the vicinity of a tall tree. That’s the tree matching the clue.\nThe vectors in Treasure Island were perpendicular to one another, that is, mutually orthogonal. The more general situation is that the vectors in \\(\\mathit{A}\\) will be somewhat aligned with one another: not mutually orthogonal. Figure 31.2 illustrates the situation: \\(\\vec{v}\\) is not perpendicular to \\(\\vec{u}\\). The task, still, is to find a linear combination of \\(\\vec{u}\\) and \\(\\vec{v}\\) that will match \\(\\vec{b}\\). The diagram shows the \\(\\vec{u}\\) vector and the subspace aligned with \\(\\vec{u}\\), and similarly for \\(\\vec{v}\\)\n\n\n\n\n\nFigure 31.2: The telescope method of solving projection onto two vectors.\n\n\n\n\nThe algorithm is based in Long John Silver’s technique. Pick either \\(\\vec{u}\\) or \\(\\vec{v}\\), it doesn’t matter which. In the diagram, we’ve picked \\(\\vec{v}\\). Align your telescope with that vector. Now march along the other vector, \\(\\vec{u}\\), carefully keeping the telescope on the bearing aligned with \\(\\vec{v}\\). From the diagram, you can see that when you’ve marched to \\(\\frac{1}{2} \\vec{u}\\), the telescope does not yet have \\(\\vec{b}\\) in view. Similarly, at \\(1 \\vec{u}\\), the target \\(\\vec{b}\\) isn’t yet visible. Marching a little further, to about \\(1.6 \\vec{u}\\) brings you to the point in the \\(\\vec{u}\\)-subspace where the target falls into view. This tells us that the coefficient on \\(\\vec{u}\\) will be 1.6.\nTo find the coefficient on \\(\\vec{v}\\), you’ll need to march along the line of the telescope, taking steps of size \\(\\|\\vec{v}\\|\\). In the diagram, we’ve marked the march with copies of \\(\\vec{v}\\) to make the counting easier. We’ll need to march opposite the direction of \\(\\vec{v}\\), so the coefficient will be negative. Taking 2.8 steps of size \\(\\|\\vec{v}\\|\\) brings us to the target. Thus:\n\\[\\vec{b} = 1.6 \\vec{u} - 2.8 \\vec{v}\\ .\\]\nTo handle vectors in spaces where telescopes are not available, we need an arithmetic algorithm. In R, that algorithm is packaged up as qr.solve(). We will pick this up again the next section.\n\nIn 3-dimensional space, visualization of the solution to the target problem is possible, at least for those who have the talent of rotating three-dimensional objects in their head. For the rest of us, a physical model can help; take three pencils labeled \\(\\vec{u}\\), \\(\\vec{v}\\), and \\(\\vec{b}\\) and bury their tails in a small ball of putty. (Chemistry molecular construction kits are a good alternative.)\nIn case putty, pencils, or a molecular model kit are not available, use the interactive diagram in Figure 31.3. This diagram also includes \\(\\hat{b}\\) and \\(\\vec{r}\\) with the hope that this will guide you into orienting the diagram appropriately to see where the solution comes from.\n\n\n\n\nNEED TO PROVIDE A SHORT LINK for PDF version\n\n\n\n\n\nFigure 31.3: Showing the relative orientation of the three vectors \\(\\vec{u}\\), \\(\\vec{v}\\) and \\(\\vec{b}\\). Drag the image to rotate it.\n\n\n\n\n\\(\\vec{u}\\) and \\(\\vec{v}\\) are fixed in length. However, their lengths will appear to change as you rotate the space. This might be called the “gun-barrel” effect; a tube looks very short when you look down it’s longitudinal axis, but looks longer when you look at it from the side. Rotate the space until both \\(\\vec{u}\\) and \\(\\vec{v}\\) reach their maximum apparent length. The viewpoint that accomplishes this is looking downward perpendicularly onto the \\(\\left[\\vec{u},\\vec{v}\\right]\\)-plane. In this orientation, you will be looking down the barrel of the \\(\\vec{r}\\) gun. Vector \\(\\vec{b}\\) is not in that plane, as you can confirm by rotating the plot a bit out of the \\(\\left[\\vec{u},\\vec{v}\\right]\\)-plane. Returning to the perspective looking down perpendicularly on the place, you can see how \\(\\vec{b}\\) corresponds to \\(\\hat{b}\\), the point in the plane where the projection of \\(\\vec{b}\\) will fall.\nTo find the scalar multiplier on \\(\\vec{v}\\), rotate the space until the vector \\(\\vec{u}\\) is pointing straight toward you. You’ll see only the arrowhead of \\(\\vec{u}\\). Vectors \\(\\vec{v}\\) and \\(\\hat{b}\\) will appear parallel to each other, but that’s because you are looking at the plane edge on. In this orientation, \\(\\hat{b}\\) will appear just a little longer than \\(\\vec{v}\\), perhaps 1.2 times longer. So 1.2 is the scalar multiplier on \\(\\vec{v}\\).\nTo figure out the scalar multiplier on \\(\\vec{u}\\), follow the same procedure as in the previous paragraph, but looking down the barrel of \\(\\vec{v}\\). From this perspective, \\(\\vec{u}\\) appears longer than \\(\\hat{b}\\); the scalar multiplier on \\(\\vec{u}\\) will be about 0.9. In terms of \\(\\mathit{A} \\vec{x} = \\hat{b}\\), the solution is \\[\\vec{x} = \\left[\\begin{array}{r}0.9\\\\1.2\\end{array}\\right]\\ .\\]"
  },
  {
    "objectID": "Linear-combinations/B5-target-problem.html#properties-of-the-solution",
    "href": "Linear-combinations/B5-target-problem.html#properties-of-the-solution",
    "title": "31  The target problem",
    "section": "31.3 Properties of the solution",
    "text": "31.3 Properties of the solution\nAs you might expect, there is a known solution to the target problem. We’ll start by using a computer implementation of this solution to demonstrate some simple properties of the solution. As an example, we’ll use three vectors \\(\\vec{u}\\), \\(\\vec{v}\\), and \\(\\vec{w}\\) in a 5-dimensional space as the “screen” to be projected onto, and another vector \\(\\vec{b}\\) as the object being projected.\nThe matrix \\(\\mathit{A}\\) is: \\[{\\mathbf A} \\equiv \\left[\\strut \\begin{array}{ccc}|&|&|\\\\\\vec{u} & \\vec{v} & \\vec{w}\\\\|&|&|\\end{array}\\right]\\]\nFor the sake of example, we’ll make up some vectors. In your own explorations, you can change them to anything you like.\n\n# the three vectors\nu <- rbind(6, 4, 9, 3, 1)\nv <- rbind(1, 5,-2, 0, 7)\nw <- rbind(3,-5, 2, 8, 4)\nA <- cbind(u, v, w)\n# the target\nb <- rbind(8, 2,-5, 7, 0)\n\nThe operator %onto% model vector and from that we can calculate the residual vector.\n\ns <- b %onto% A \nr <- b - s\n\nThose two simple commands constitute a complete solution to the projection problem, where see seek to model vector and the residual vector.\nIn the target problem we want more: How to express \\(\\hat{b}\\) as a linear combination of the columns in \\(\\mathit{A}\\). At the risk of being repetitive, this means finding \\(\\color{magenta}{\\vec{x}}\\) in \\[\\mathit{A}\\ \\color{magenta}{\\large\\vec{x}} = \\vec{b}\\] where \\(\\mathit{A}\\) and \\(\\vec{b}\\) are given.\nThe function qr.solve() finds \\(\\vec{x}\\). ::: {.cell layout-align=“center” fig.showtext=‘false’}\nx <- qr.solve(A, b)\n::: ::: {.cell layout-align=“center” fig.showtext=‘false’}\n##            [,1]\n## [1,] 0.03835171\n## [2,] 0.33478133\n## [3,] 0.48849968\n:::\nHow can we confirm that this really is the solution to the target problem for this set of vectors? Easy! Just multiply \\(\\mathit{A}\\) by the \\(\\vec{x}\\) that we found. The result should be the target vector \\(\\hat{b}\\):\n\nA %*% x\n##            [,1]\n## [1,]  2.0303906\n## [2,] -0.6151849\n## [3,]  0.6526021\n## [4,]  4.0230526\n## [5,]  4.3358197\ns\n##            [,1]\n## [1,]  2.0303906\n## [2,] -0.6151849\n## [3,]  0.6526021\n## [4,]  4.0230526\n## [5,]  4.3358197\n\n\nYou should add qr.solve() to your computational toolbox of R functions."
  },
  {
    "objectID": "Linear-combinations/B5-target-problem.html#application-of-the-target-problem",
    "href": "Linear-combinations/B5-target-problem.html#application-of-the-target-problem",
    "title": "31  The target problem",
    "section": "31.4 Application of the target problem",
    "text": "31.4 Application of the target problem\nIn Section 31.1 we translated into vector/matrix form the problem, originally stated in Block 1, of finding the best linear combination of \\(f(\\mathtt{time}) \\equiv 1\\) and \\(g(\\mathtt{time}) \\equiv e^{-0.019 \\mathtt{time}}\\). Let’s solve that problem now.\n\nEarlier we introduced rbind() for the purpose of making column vectors, as in ::: {.cell layout-align=“center” fig.showtext=‘false’}\nrbind(3,7,-1)\n##      [,1]\n## [1,]    3\n## [2,]    7\n## [3,]   -1\n\nNow we are going to work with columns of data stored in the CoolingWater data frame. A good way to extract a column from a data frame is using the with() function. For instance,\n\nb <- with(CoolingWater, temp)\ntime <- with(CoolingWater, time)\nA <- cbind(1, exp(-0.019 * time))\nhead(A)\n##      [,1]      [,2]\n## [1,]    1 1.0000000\n## [2,]    1 0.9811794\n## [3,]    1 0.9627129\n## [4,]    1 0.9445941\n## [5,]    1 0.9268162\n## [6,]    1 0.9093729\n\nNotice that cbind() automatically translated 1 into the vector of all ones.\nWe’re all set up to solve the target problem:\n\nx <- qr.solve(A, b)\n\n\n## [1] 25.92024 61.26398\n\nHow good an answer is the x calculated by qr.solve()? Judge for yourself!\n\ngf_point(temp ~ time, data = CoolingWater, size=0) %>%\n  slice_plot(25.92 + 61.26*exp(-0.019*time) ~ time,\n             color=\"blue\")\n\n\n\n\n\n\n\n\nYou may recall from Block 1 the explanation for the poor match between the model and the data for early times: that the water cooled quickly when poured into the cool mug, but the mug-with-water cooled much slower into the room air.\nLet’s augment the model by adding another vector with a much faster exponential cooling, say, \\(e^{-0.06 \\mathtt{time}}\\).\n\nnewA <- cbind(A, exp(-0.06*time))\nqr.solve(newA, b)\n## [1] 26.82297 53.27832 12.67486\n\n\ngf_point(temp ~ time, data = CoolingWater, size=0) %>%\n  slice_plot(26.82 + 53.28*exp(-0.019*time) +\n               12.67*exp(-0.06*time) ~ time,\n             color=\"green\")\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "Linear-combinations/B5-target-problem.html#exercises",
    "href": "Linear-combinations/B5-target-problem.html#exercises",
    "title": "31  The target problem",
    "section": "31.5 Exercises",
    "text": "31.5 Exercises"
  },
  {
    "objectID": "Linear-combinations/B5-stat-modeling.html",
    "href": "Linear-combinations/B5-stat-modeling.html",
    "title": "32  Statistical modeling and R2",
    "section": "",
    "text": "So far, we’ve been looking at linear combinations from a distinctively mathematical point of view: vectors, collections of vectors (matrices), projection, angles and orthogonality. We’ve show a few applications of the techniques for working with linear combinations, but have always expressed those techniques using mathematical terminology. In this Chapter, we will take a detour to get a sense of the perspective and terminology of another field: statistics.\nIn the quantitative world, including fields such as biology and genetics, the social sciences, business decision making, etc. there are far more people working with linear combinations with a statistical eye than there are people working with the mathematical form of notation. Statistics is a far wider field than linear combination, so this chapter is not an attempt to replace the need to study statistics and data science. The purpose is merely to show you how a mathematical process can be used as part of a broader framework to provide useful information to decision-makers.\nIt often happens that a model is needed to help organize complex, multivariate data for purposes such as prediction. As a case in point, consider the data available in the Body_fat data frame, which consists of measurements of characteristics such as height, weight, chest circumference, and body fat on 252 men.\nBody fat, the percentage of total body mass consisting of fat, is thought by some to be a good measure of general fitness. To what extent this theory is merely a reflection of general societal attitudes toward body shape is unknown.\nWhatever its actual utility, body fat is hard to measure directly; it involves submerging a person in water to measure total body volume, then calculating the persons mass density and converting this to a reading of body-mass percentage. For those who would like to see body fat used more broadly as a measure of health and fitness, this elaborate procedure stands in the way. And so they seek easier ways to estimate body fat along the lines of the Body Mass Index (BMI), which is a simple arithmetic combination of easily measured height and weight. (Note that BMI is also controversial as anything other than a rough description of body shape. In particular, the label “overweight,” officially \\(25 \\leq \\text{BMI}\\leq 30\\) has at best little connection to actual health.)\nHow can we construct a model, based on the available data, of body fat as a function of the easy-to-measure characteristics such as height and weight? You can anticipate that this will be a matter of applying what we know about the target problem \\[\\text{Given}\\ \\mathit{A}\\  \\text{and}\\ \\vec{b}\\text{, solve } \\mathit{A} \\vec{x} = \\vec{b}\\ \\text{for}\\ \\vec{x}\\]where \\(\\vec{b}\\) is the column of body-mass measurements and \\(\\mathit{A}\\) is the matrix of all the other columns in the data frame.\nIn statistics, the target \\(\\vec{b}\\) is called the response variable and \\(\\mathit{A}\\) is the set of explanatory variables. You can also think of the response variable as the output of the model we will build and the explanatory variables as the inputs to that model.\nAlthough application of the target problem is an essential part of constructing a statistical model, it is far from the only part. For instance, statisticians find is useful to think about “how much” of the response variable is explained by the explanatory variables. Measuring this requires a definition for “how much.” In defining “how much,” statisticians focus not on how much variation there is among the values in the response variable. The standard way to measure this is with the variance, which was introduce in Section 28.4 and can be thought of as the average of pair-wise differences among the elements in \\(\\vec{b}\\).\nIn order to support this focus on the variance of \\(\\vec{b}\\), statisticians typically augment \\(\\vec{A}\\) with a column of ones, which they call the intercept.\nTo move forward, we’re going to extract the response variable from the data and construct \\(\\vec{A}\\), adding in the vector of ones. We’ll show the vector/matrix commands for doing this, but you don’t have to remember them because statisticians have a more user-friendly interface to the calculations.\nOnce we have b and A, we find the coefficients on the linear model in the usual way, with qr.solve().\nHaving applied qr.solve(), \\(\\vec{x}\\) now contains the coefficients on the “best” linear combination of the columns in \\(\\vec{A}\\). One of the ways in which the R language is designed to support statistics, is that it keeps track of names of columns, so the elements of \\(\\vec{x}\\) are labelled with the name of the column the element applies to.\nBased on the above, the model for body fat as a function of the explanatory variables is: \\[\\text{body fat} = -40.5 + 0.253\\, \\mathtt{wrist} - 0.818\\, \\mathtt{thigh} - 0.223\\, \\mathtt{forearm}\\ .\\] ::: {.Rmosaic data-latex=““} In invoking qr.solve(A, b) we have created a vector x containing the solution to the target problem. We can use that vector x in the usual ways, for example to construct the model vector (A %*% x) or the residual vector (b - A %*% x).\nSometimes you will want to create a function that implements the linear combination described by x. For convenience, the R/mosaic makeFun() knows how to accept a vector input and create the corresponding function. For example:\n:::"
  },
  {
    "objectID": "Linear-combinations/B5-stat-modeling.html#how-good-a-model",
    "href": "Linear-combinations/B5-stat-modeling.html#how-good-a-model",
    "title": "32  Statistical modeling and R2",
    "section": "32.1 How good a model?",
    "text": "32.1 How good a model?\nThere are so many ways to construct a linear-combination model from a data frame—all the different combinations of columns plus possibly interaction terms and other transformations—that it’s natural to ask, “What’s the best model?”\nAs always, “best” depends on the purpose for your model is to be used. This requires thought on the part of the modeler.\nBut there is a far more limited way to address “best” that doesn’t require any substantial thought. Consequently—and perhaps unfortunately—this method is often used in practice. It’s called R-squared and usually written R2. There’s nothing wrong with the R2 method, so long as the correct statistical interpretation is given it. We’ll mention it here without going into the statistics, just so that you will have seen the relevant names and the mathematics (but not statistics!) behind them.\nThe basic question addressed by R2 is: How much of the variation in the response variable b is accounted for by the columns of the matrix A.\nThe standard way to measure the “amount of variation” in a variable is the variance. In R, you calculate that with\n\nvar(b)\n##          bodyfat\n## bodyfat 70.03582\n\n\nHow good is the model?\nCould we make a better model?\n\nTo answer these questions, we’ll have to develop a measure of how good the model is. And this depends on the purpose for which we’ll be using the model.\nWe can also look at the variation in the model vector, \\(\\hat{b}\\).\n\nbhat <- A %*% x\nvar(bhat)\n##          bodyfat\n## bodyfat 22.16637\n\nR2 is simply the ratio of these two variances:\n\nvar(bhat) / var(b)\n##           bodyfat\n## bodyfat 0.3165004\n\nThis result, 31.7%, is interpreted as the fraction of the variance in the response variable that is accounted for by the model. Near synonyms for “accounted for” is explained by or can be attributed to.\nIn the same spirit, we can ask how much of the variance in the response variable is unexplained by, or unaccounted by the explanatory variables. To answer this, look at the size of the residual:\n\nvar(b - bhat) / var(b)\n##           bodyfat\n## bodyfat 0.6834996\n\nNotice that the amount of variance explained, 68.3%, plus the amount remaining unexplained, 31.7%, add up to 100%. This is no accident. It is the reason why statisticians use the variance as a measure of variability."
  },
  {
    "objectID": "Linear-combinations/B5-stat-modeling.html#machine-learning",
    "href": "Linear-combinations/B5-stat-modeling.html#machine-learning",
    "title": "32  Statistical modeling and R2",
    "section": "32.2 Machine learning",
    "text": "32.2 Machine learning\nIf you pay attention to trends, you will know about advances in artificial intelligence and the many claims—some hype, some not—about how it will change everything from animal husbandry to warfare. Services such as Google Translate are based on artificial intelligence, as are many surveillance technologies. (Whether the surveillance is for good or ill is a serious matter.)\nSkills in artificial intelligence are currently a ticket to lucrative employment.\nLike so many things, “artificial intelligence” is a branding term. In fact, what all the excitement is about is not mostly artificial intelligence at all. The advances, by and large, have come over 50 years of development in a field called “statistical learning” or “machine learning,” depending on whether the perspective is from statistics or computer science.\nA major part of the mathematical foundation of statistical (or “machine”) learning is linear algebra. Many workers in “artificial intelligence” are struggling to catch up because they never took linear algebra in college or, if they did, they took a proof-oriented course that didn’t cover the elements of linear algebra that are directly applicable. We’re trying to do better in this course.\nSo if you’re diligent, and continue your studies to take actual statistical/machine learning courses, you’ll find yourself at the top of the heap. Even xkcd, the beloved techno-comic, gets in on the act, as this cartoon reveals:\n\n\n\n\n\n\n\n\n\nLook carefully below the paddle and you’ll see the Greek letter “lambda”, \\(\\lambda\\). You’ll meet the linear algebra concept signified by \\(\\lambda\\)—eigenvalues and eigenvectors—in Block 6.\n\nWe’ve been using the R/mosaic function df2matrix() to construct the A and b matrices used in linear model from data. This is mainly for convenience: we need a way to carry out the calculations that lets you see the x vector, and calculate the model vector and the residual in the way described in Section 31.\nIn practice, statistical modelers use other software. The most famous of these in R is the lm() family of functions. This does all the work of creating the b vector and the A matrix, QR solving, etc. We call it a “family” of functions because the output of lm() is not simply the vector of coefficients x but includes many other features that support statistical inference on the models created.\nIn a statistics course using R, you are very likely to encounter lm(). You’ll never hear about df2matrix() outside of this book."
  },
  {
    "objectID": "Linear-combinations/B5-stat-modeling.html#exercises",
    "href": "Linear-combinations/B5-stat-modeling.html#exercises",
    "title": "32  Statistical modeling and R2",
    "section": "32.3 Exercises",
    "text": "32.3 Exercises"
  },
  {
    "objectID": "Linear-combinations/B5-functions.html",
    "href": "Linear-combinations/B5-functions.html",
    "title": "33  Functions as vectors",
    "section": "",
    "text": "Starting with ?sec-vectors, we have been working with the dot product, an operation that combines two vectors to produce a scalar. \\[\\vec{b}\\bullet\\vec{a} \\equiv\n\\left[\\begin{array}{c}b_1\\\\b_2\\\\\\vdots\\\\b_n\\end{array}\\right] \\bullet\n\\left[\\begin{array}{c}a_1\\\\a_2\\\\\\vdots\\\\a_n\\end{array}\\right] \\equiv b_1 a_1 + b_2 a_2 + \\cdots b_n a_n\\] The dot product enables us to use arithmetic to calculate geometric properties of vectors, even in high dimensional spaces that are out of reach of a ruler or protractor. For instance\nWe used such operations to solve the target problem: finding the best approximation of a vector \\(\\vec{b}\\) as a linear combination of a set of vectors in a matrix \\(\\mathit{A}\\).\nAs early as Block 1, we constructed functions as a linear combination of other functions, for example: \\[g(t) \\equiv A + B \\sin\\left(\\frac{2 \\pi}{P} t\\right)\\] where \\(A\\) is the scalar multiplier for the function \\(\\text{one}(t) \\equiv 1\\) and \\(B\\) the scalar multiplier for the sinusoid of period \\(P\\).\nWe’re going to revisit the idea of linear combinations of functions using our new tools of length, included angle, and projection. To do this, we need to have a definition of the dot product suitable for application to functions."
  },
  {
    "objectID": "Linear-combinations/B5-functions.html#dot-product-for-functions",
    "href": "Linear-combinations/B5-functions.html#dot-product-for-functions",
    "title": "33  Functions as vectors",
    "section": "33.1 Dot product for functions",
    "text": "33.1 Dot product for functions\nGiven two functions, \\(f(t)\\) and \\(g(t)\\) defined over some domain \\(D\\), we’ll compute the dot product of the functions as a sum of the product of the two functions, that is: \\[f(t) \\bullet g(t) \\equiv \\int_{D} f(t)\\,g(t)\\,dt\\ .\\] ::: {.example data-latex=““} Suppose that our two functions are \\(\\text{one}(t) \\equiv 1\\) and \\(\\text{identity}(t) \\equiv t\\) on the domain \\(0 \\leq t \\leq 1\\). Find the length of each function and the included angle between them.\n\nLength: \\(\\|\\text{one}(t)\\| = \\left[\\int_0^1 1 \\cdot 1\\,dt\\right]^{1/2} = \\left[\\ \\strut t\\left.{\\large\\strut}\\right|_0^1\\ \\right]^{1/2} = 1\\)\nLength: \\(\\|\\text{identity}(t)\\| = \\left[\\int_0^1 t \\cdot t\\,dt\\right]^{1/2} = \\left[\\ \\strut \\frac{1}{2}t^2\\left.{\\large\\strut}\\right|_0^1\\ \\right]^{1/2} = \\frac{1}{\\sqrt{2}}\\)\nIncluded angle: \\[\\cos(\\theta) = \\frac{\\text{one}(t) \\bullet \\text{identity}(t)}{\\|\\strut\\text{one}(t)\\| \\, \\|\\text{identity}(t)\\|}  =\n\\sqrt{2}\\ \\int_0^1 t\\, dt = \\sqrt{\\strut 2} \\left.{\\Large\\strut}\\frac{1}{2} t^2\\right|_0^1 = \\sqrt{\\frac{1}{2}}\\] Since \\(\\cos(\\theta) = \\sqrt{1/2}\\), the angle \\(\\theta\\) is 45 degrees. :::\n\n\nProject \\(f(t) \\equiv t^2\\) onto \\(g(t) = \\text{one}(t)\\) over the domain \\(-1 \\leq t \\leq 1\\).\nThe projection of \\(f(t)\\) onto \\(g(t)\\) will be \\[\\widehat{f(t)} = \\frac{f(t) \\bullet g(t)}{g(t) \\bullet g(t)}\\ g(t)\\]\n\n\\(f(t) \\bullet g(t) \\equiv \\int_{-1}^{1} t^2 dt = \\frac{1}{3} \\left.{\\Large \\strut}t^3\\right|_{-1}^{1} = \\frac{2}{3}\\)\n\\(g(t) \\bullet g(t) \\equiv \\int_{-1}^1 \\ dt = 2\\)\n\nThus, \\[\\widehat{f(t)} = \\frac{1}{3} \\text{one(t)} = \\frac{1}{3}\\ .\\]\n\nThe left panel of Figure 33.1 shows the functions \\(f(t) \\equiv t^2\\) and \\(\\color{magenta}{\\widehat{f(t)} \\equiv 1/3}\\) on the domain. The center panel shows the residual function, that is \\(f(t) - \\widehat{f(t)}\\). The right panel gives the square of the length of the residual function, which is \\(\\int_{-1}^1 \\left[f(t) - \\widehat{f(t)}\\right]^{1/2}\\, dt\\) as indicated by the area shaded in \\(\\color{blue}{\\text{blue}}\\).\n\n\n\n\n\nFigure 33.1: Projecting \\(f(t) \\equiv t^2\\) onto \\(g(t) \\equiv \\text{one}(t)\\).\n\n\n\n\n\nThe table links to audio files recorded by a human speaker voicing various vowels. Play the sounds to convince yourself that they really are the vowels listed. (It may help to use the controls to slow down the playback.)\nVowel | Player\n------|-------\n\"o\" as in \"stone\" | <audio controls><source src = \"https://linguistics.ucla.edu/people/hayes/103/Charts/VChart/o.wav\" type = \"audio/wav\"></audio>\n\"e\" as in \"eel\" | <audio controls><source src = \"https://linguistics.ucla.edu/people/hayes/103/Charts/VChart/y.wav\" type = \"audio/wav\"></audio>\nAs you may know, the physical stimuli involved in sound are rapid oscillations in air pressure. Our standard model for oscillations is the sinusoid function, which is parameterized by its period and it’s amplitude. The period of a sound oscillation is short: between 0.3 and 10 milliseconds. The amplitude is small. To get a sense for how small, consider the change in air pressure when you take an elevator up 10 stories in a building. The pressure amplitude of sound at a conversational level of loudness corresponds to taking that elevator upward by 1 to 10 mm.\nThe shapes of the “e” (as in “eel”) and “o” (as in “stone”) sound waves—in short, the waveforms—are drawn in ?fig-sound-waves.\n\n\n\n\n\nThe waveforms of two vowel sounds. Only about five hundredths of a second is shown.\n\n\n\n\nThe function resembles none of our small set of pattern-book functions. It is more complicated, more detailed, more irregular than any of the basic modeling functions featured in this book.\nFor many tasks it’s helpful to have a modeling approach that’s well suited to such detailed and irregular functions. For example, we might want to identify the speaker from a recording, or to play the recording slower or faster without changing the essence of the sound, or to tweak the function to have additional properties such as being exactly on tune while maintaining its individuality as a sound.\nA remarkable aspect of the waveforms in ?fig-sound-waves is their periodicity. The 0.05 sec graphics domain shown includes roughly seven repetitions of a basic waveform. That is, each cycle lasts about \\(\\frac{0.05 \\text{s}}{7} \\approx 7 \\text{ms}\\). what distinguishes the “e” waveform from the “o” waveform is the shape of the waveform that’s being repeated. The individual cycle of the “o” has three peaks of diminishing amplitude. The “e” cycle has two main peaks, high then low. It also has a very fast wiggle superimposed on the two peaks.\nAn important strategy for modeling such complicated oscillations is to decompose (synonym: analyze) them into a linear combination of simpler parts."
  },
  {
    "objectID": "Linear-combinations/B5-functions.html#sinusoids-as-vectors",
    "href": "Linear-combinations/B5-functions.html#sinusoids-as-vectors",
    "title": "33  Functions as vectors",
    "section": "33.2 Sinusoids as vectors",
    "text": "33.2 Sinusoids as vectors\nThe sinusoid is our fundamental model of periodic phenomena. To get started with using sinusoids as vectors, we’ll start with a simple setting: a single sinusoid of a specified frequency.\nFigure 33.2 shows three sinusoids all with the same frequency, but shifted somewhat in time:\n\n\n\n\n\nFigure 33.2: Three sinusoids with a frequency of \\(\\omega=3\\) cycles per second.\n\n\n\n\nSince we have a dot product for functions, we can treat each of the three sinusoids as a vector. For instance, consider the length of waveforms A and B and the included angle between them.\n\n\n## vector lengths \nlengthA <- Integrate(waveA(t) * waveA(t) ~ t, domain(t=0:1)) %>% sqrt() \nlengthA\n## [1] 0.7071068\nlengthB <- Integrate(waveB(t) * waveB(t) ~ t, domain(t=0:1)) %>% sqrt()\nlengthB\n## [1] 0.7071068\nlengthC <- Integrate(waveC(t) * waveC(t) ~ t, domain(t=0:1)) %>% sqrt()\nlengthC\n## [1] 0.7071068\n## dot products\ndotAB   <- Integrate(waveA(t) * waveB(t) ~ t, domain(t=0:1)) \ndotAB\n## [1] -3.984443e-18\ndotAC   <- Integrate(waveA(t) * waveC(t) ~ t, domain(t=0:1))\ndotAC\n## [1] -0.1545085\ndotBC   <- Integrate(waveB(t) * waveC(t) ~ t, domain(t=0:1))\ndotBC\n## [1] -0.4755283\n\n\nThe cosine of the included angle \\(\\theta\\) between functions A and B is calculated using the the dot product formula: \\[\\cos(\\theta) = \\frac{A\\bullet B}{\\|A\\|\\, \\|B\\|}\\] or, computationally\n\ndotAB / (lengthA * lengthB)\n## [1] -7.968886e-18\n\nSince \\(\\cos(\\theta) = 0\\), wave A and B are orthogonal. Admittedly, there is no right angle to be perceived from the graph, but the mathematics of angles gives this result.\nThe graphical presentation of orthogonality between waveforms A and B is easier to appreciate if we plot out the dot product itself: the integral of waveform A times waveform B. Figure 33.3 shows this integral using colors, blue for positive and orange for negative. The integral is zero, since the positive (blue) areas exactly equal the negative (orange) areas.\n\n\n\n\n\nFigure 33.3: The dot product between waveforms A and B, graphically.\n\n\n\n\nIn contrast, waveform A is not orthogonal to waveform C, and similarly for waveform B. ?fig-AC-BC shows this graphically: the positive and negative areas in the two integrals do not cancel out to zero.\n\n\n\n\n\nThe dot products between waveforms A and C (top panel) and between B and C (bottom panel).\n\n\n\n\nWe can project waveform C onto the 2-dimensional subspace spanned by A and B. Since waveforms A and B are orthogonal, This can be done simply by projecting C onto each of A and B one at a time. Here’s a calculation of the scalar multipliers for A and for B and the model vector (that is, the component of C in the A-B subspace):\n\nA_coef <- dotAC / lengthA^2\nB_coef <- dotBC / lengthB^2\nmod_vec <- makeFun(A_coef*waveA(t) + B_coef*waveB(t) ~ t)\n# length of mod_vec\nIntegrate(mod_vec(t)*mod_vec(t) ~ t, domain(t=0:1)) %>% sqrt()\n## [1] 0.7071068\n\nYou can see that the length of the model vector is the same as the length of the vector being projected. This means that waveform C lies exactly in the subspace spanned by waveforms A and B.\nA time-shifted sinusoid of frequency \\(\\omega\\) can always be written as a linear combination of \\(\\sin(2\\pi\\omega t)\\) and \\(\\cos(2\\pi\\omega t)\\). The coefficients of the linear combination tell us both the amplitude of the time-shifted sinusoid and the time shift.\n\nConsider the function \\(g(t) \\equiv 17.3 \\sin(2*pi*5*(t-0.02)\\) on the domain \\(0 \\leq t \\leq 1\\) seconds. The amplitude is 17.3. The time shift is 0.02 seconds. Let’s confirm this using the coefficients on the linear combination of sine and cosine of the same frequency.\n\ng <- makeFun(17.3 * sin(2*pi*5*(t-0.02)) ~ t)\nsin5 <- makeFun(sin(2*pi*5*t) ~ t)\ncos5 <- makeFun(cos(2*pi*5*t) ~ t)\nA_coef <- Integrate(g(t) * sin5(t) ~ t, domain(t=0:1)) /\n  Integrate(sin5(t) * sin5(t) ~ t, domain(t=0:1))\nA_coef\n## [1] 13.99599\nB_coef <- Integrate(g(t)*cos5(t) ~ t, domain(t=0:1)) /\n  Integrate(cos5(t) * cos5(t) ~ t, domain(t=0:1))\nB_coef\n## [1] -10.16868\n\nThe amplitude of \\(g(t)\\) is the Pythagorean sum of the two coefficients: ::: {.cell layout-align=“center” fig.showtext=‘false’}\nsqrt(A_coef^2 + B_coef^2)\n## [1] 17.3\n\nThe time delay involves the ratio of the two coefficients:\n\natan2(B_coef, A_coef) / (2*pi*5) \n## [1] -0.02\n\nFor our purposes here, we’ll need only the Pythagorean sum and will ignore the time delay. :::\n?fig-cello-seg (top) shows the waveform of a note played on a cello. The note lasts about 1 second. The bottom panel zooms in on the waveform, showing 82 ms (that is, 0.082 s).\n\n\n\n\n\nWaveform recorded from a cello.\n\n\n\n\nThe whole note starts with a sharp “attack,” followed by a long period called a “sustain,” and ending with a “decay.” Within the sustain and decay, the waveform is remarkably repetitive, seen best in the bottom panel of the figure.\nIf you count carefully in the bottom panel, you’ll see that the waveform completes 9 cycles in the 0.082 s graphical domain. This means that the period is 0.082 / 9 = 0.0091 s. The frequency \\(\\omega\\) is the reciprocal of this: 1/0.0091 = 109.76 Hz. That is, the cello is vibrating about 110 times per second.\nIn modeling the cello waveform as a linear combination of sinusoids, the frequencies we use ought to respect the period of the cello vibration. Figure 33.4 shows the original waveform as well as the projection of the waveform onto a sinusoid with a frequency of 109.76 Hz. The figure also shows the residual from the projection, which is simply the original waveform minus the projected version.\n\n\n\n\n\nFigure 33.4: Top: The cello waveform and its projection onto a sinusoid with frequency \\(\\omega = 109.76\\) Hz. Bottom: The residual from the projection.\n\n\n\n\nThe sinusoid with \\(\\omega = 109.76\\) is not the only one that will repeat every 0.0091 s. So will a sinusoid with frequency \\(2\\omega = 219.52\\), one with frequency \\(3\\omega = 329.28\\) and so on. These multiples of \\(\\omega\\) are called the harmonics of that frequency. In Figure 33.5 (top) the cello waveform is projected onto \\(\\omega\\) and its first harmonic \\(2\\omega\\). In the middle panel, the projection is made onto \\(\\omega\\) and its first three harmonics. In the bottom panel, the projection is onto \\(\\omega\\) and its first eight harmonics.\n\n\n\n\n\nFigure 33.5: ?(caption)\n\n\n\n\nAs the number of harmonics increases, the approximation gets better and better.\nUntil now, all the plots of the cello waveform have been made in what’s called the time domain. That is, the horizontal axis of the plots has been time, as seems natural for a function of time.\nThe decomposition into sinusoids offers another way of describing the cello waveform: the frequency domain. In the frequency domain, we report the amplitude and phase of the projection onto each frequency, plotting that versus frequency. Figure 33.6 shows the waveform in the frequency domain.\n\n\n\n\n\nFigure 33.6: The frequency domain description of the cello waveform.\n\n\n\n\nFrom the amplitude graph in Figure 33.6, you can see that only a handful of frequencies account for almost all of the signal. Thus, the frequency domain representation is in many ways much more simple and compact than the time domain representation.\nThe frequency domain description is an important tool in many fields. As you’ll see in Block 6, models of many kinds of systems, from the vibrations of buildings during an earthquake, aircraft wings in response to turbulence, and the bounce of a car moving over a rutted road have a very simple form when stated in the frequency domain. Each sinusoid in the input (earthquake shaking, air turbulence, rutted road) gets translated into the same frequency sinusoid in the output (building movement, wing bending, car bound): just the amplitude and phase of the sinusoid is altered.\nThe construction of the frequency domain description from the waveform is called a Fourier Transform, one of the most important techiques in science.\n\nAn important tool in chemistry is molecular vibrational spectroscopy in which a sample of the material is illuminated by an infrared beam of light. The frequency of infrared light ranges from about \\(300 \\times 10^7\\) Hz to \\(400 \\times 10^{10}\\) Hz, about 30 million to 40 billion times faster than the cello frequency.\nInfrared light is well suited to trigger vibrations in the various bonds of a molecule. By measuring the light absorbed at each frequency, a frequency domain picture can be drawn of the molecules in the sample. This picture can be compared to a library of known molecules to identify the makeup of the sample.\nThe analogous procedure for stringed musical instruments such as the cello or violin would be to rap on the instrument and record the hum of the vibrations induced. The Fourier transform of these vibrations effectively paint a picture of the tonal qualities of the instrument."
  },
  {
    "objectID": "Linear-combinations/B5-functions.html#exercises",
    "href": "Linear-combinations/B5-functions.html#exercises",
    "title": "33  Functions as vectors",
    "section": "33.3 Exercises",
    "text": "33.3 Exercises"
  },
  {
    "objectID": "accumulation-part.html",
    "href": "accumulation-part.html",
    "title": "Accumulation",
    "section": "",
    "text": "This is where I’ll explain what the block is about and the overall goals."
  },
  {
    "objectID": "Accumulation/27-intro.html",
    "href": "Accumulation/27-intro.html",
    "title": "34  Change & accumulation",
    "section": "",
    "text": "Every 10 years, starting in 1790, the US Census Bureau carries out a constitutionally mandated census: a count of the current population. The overall count as a function of year is shown in Figure 34.1. [Source]\nIn the 230 years spanned by the census data, the US population has grown 100-fold, from about 4 million in 1790 to about 330,000,000 in 2020.\nIt’s tempting to look for simple patterns in such data. Perhaps the US population has been growing exponentially. A semi-log plot of the same data suggests that the growth is only very roughly exponential. A truly exponential process would present as a curve with a constant derivative, but the derivative of the function in the graph is decreasing over the centuries.\nInsofar as the slope over the semi-log graph is informative, it amounts to this quantity: \\[\\partial_t \\ln(\\text{pop}(t)) = \\frac{\\partial_t\\, \\text{pop}(t)}{\\text{pop}}\\] This is the per-capita rate of growth, that is, the rate of change in the population divided by the population. Conventionally, this fraction is presented as a percentage: percentage growth in the population per year, as in Figure 34.2.\nThe dots in the graph are a direct calculation from the census data. There’s a lot of fluctuation, but an overall trend stands out: the population growth rate has been declining since the mid-to late 1800s. The deviations from the trend are telling and correspond to historical events. There’s a relatively low growth rate seen from 1860 to 1870: that’s the effect of the US Civil War. The Great depression is seen in the very low growth from 1930 to 1940. Baby Boom: look at the growth from 1950-1960. The bump from 1990 to 2000? Not coincidentally, the 1990 Immigration Act substantially increased the yearly rate of immigration.\nIf the trend in the growth rate continues, the US will reach zero net growth about 2070, then continue with negative growth. Of course, negative growth is just decline. A simple prediction from Figure 34.2 is that the argmax of the US population—that is, the year that the growth rate reaches zero—will occur around 2070.\nHow large will the population be when it reaches its maximum?\nIn Block 2, we dealt with situations where we know the function \\(f(t)\\) and want to find the rate of change \\(\\partial_t f(t)\\). Here, we know the rate of change of the population and we need to figure out the population itself, in other words to figure out from a known \\(\\partial_t f(t)\\) what is the unknown function \\(f(t)\\).\nThe process of figuring out \\(f(t) \\longrightarrow \\partial_t f(t)\\) is, of course, called differentiation. The opposite process, \\(\\partial_t f(t) \\longrightarrow f(t)\\) is called anti-differentiation.\nIn this block we’ll explore the methods for calculating anti-derivatives and some of the settings in which anti-derivative problems arrive."
  },
  {
    "objectID": "Accumulation/27-intro.html#accumulation",
    "href": "Accumulation/27-intro.html#accumulation",
    "title": "34  Change & accumulation",
    "section": "34.1 Accumulation",
    "text": "34.1 Accumulation\nImagine a simple setting: water flowing out of a tap into a basin or tank. The amount of water in the basin will be measured in a unit of volume, say liters. Measurement of the flow \\(f(t)\\) of water from the tap into the tank has different units, say liters per second. If volume \\(V(t)\\) is the volume of water in the tank as a function of time, \\(f(t)\\) at any instant is \\(f(t) = \\partial_t V(t)\\).\nClearly there is a relationship between the two functions \\(f(t)\\) and \\(V(t)\\). With derivatives, we can give a good description of that relationship: \\[f(t) = \\partial_t V(t)\\] This description will be informative if we have measured the volume of water in the basin as a function of time and want to deduce the rate of flow from the tap. Now suppose we have measured the flow \\(f(t)\\) and want to figure out the volume. The volume at any instant is the past flow accumulated to that instant. As a matter of notation, we write this view of the relationship as \\[V(t) = \\int f(t) dt,\\] which you can read as “volume is the accumulated flow.”\nOther examples of accumulation and change:\n\nvelocity is the rate of change of position with respect to time. Likewise, position is the accumulation of velocity over time.\nforce is the rate of energy with respect to position. Likewise energy is the accumulation of force as position changes.\ndeficit is the rate of change of debt with respect to time. Likewise, debt is the accumulation of deficit over time."
  },
  {
    "objectID": "Accumulation/27-intro.html#notation-for-anti-differentiation",
    "href": "Accumulation/27-intro.html#notation-for-anti-differentiation",
    "title": "34  Change & accumulation",
    "section": "34.2 Notation for anti-differentiation",
    "text": "34.2 Notation for anti-differentiation\nFor differentiation we are using the notation \\(\\partial_x\\) as in \\(\\partial_x f(x)\\). Remember that the subscript on \\(\\partial\\) names the with-respect-to input. There are three pieces of information this notation:\n\nThe \\(\\color{magenta}{\\partial}\\) symbol which identifies the operation as partial differentiation.\nThe name of the with-respect-to input \\(\\partial_{\\color{magenta}{x}}\\) written as a subscript to \\(\\partial\\).\nThe function to be differentiated, \\(\\partial_x \\color{magenta}{f(x)}\\).\n\nFor anti-differentiation, our notation must also specify the three pieces of information. It might be tempting to use the same notation as differentiation but replace the \\(\\partial\\) symbol with something else, perhaps \\(\\eth\\) or \\(\\spadesuit\\) or \\(\\forall\\), giving us something like \\(\\spadesuit_x f(x)\\).\nConvention has something different in store. The notation for anti-differentiation is \\[\\large \\int f(x) dx\\] 1. The \\(\\color{magenta}{\\int}\\) is the marker for anti-differentiation. 2. The name of the with-respect-to input is contained in the “dx” at the end of the notation: \\(\\int f(x) d\\color{magenta}{x}\\) 3. The function being anti-differentiated is in the middle \\(\\int \\color{magenta}{f(x)} dx\\).\nFor those starting out with anti-differentiation, the conventional notation can be confusing, especially the \\(dx\\) part. It’s easy confuse \\(d\\) for a constant and \\(x\\) for part of the function being anti-differentiated.\nThink of the \\(\\int\\) and the \\(dx\\) as brackets around the function. You need both brackets for correct notation, the \\(\\int\\) and the \\(dx\\) together telling you what operation to perform.\nRemember that just as \\(\\partial_x f(x)\\) is a function, so is \\(\\int f(x) dx\\)."
  },
  {
    "objectID": "Accumulation/27-intro.html#rmosaic-notation",
    "href": "Accumulation/27-intro.html#rmosaic-notation",
    "title": "34  Change & accumulation",
    "section": "34.3 R/mosaic notation",
    "text": "34.3 R/mosaic notation\nRecall that the notation for differentiation in R/mosaic is D(f(x) ~ x). The R/mosaic notation for anti-differentiation is very similar:\nD(f(x) ~ x)\nThis has the same three pieces of information as \\(\\partial_x f(x)\\)\n\nD() signifies differentiation whereas antiD() signifies anti-differentiation.\n~ x identifies the with-respect-to input.\nf(x) ~ is the function on which the operation is to be performed.\n\nRemember that just as D(f(x) ~ x) creates a new function out of f(x) ~ x, so does antiD(f(x) ~ x)."
  },
  {
    "objectID": "Accumulation/27-intro.html#dimension-and-anti-differentiation",
    "href": "Accumulation/27-intro.html#dimension-and-anti-differentiation",
    "title": "34  Change & accumulation",
    "section": "34.4 Dimension and anti-differentiation",
    "text": "34.4 Dimension and anti-differentiation\nThis entire block will be about anti-differentiation, its properties and its uses. You already know that anti-differentiation (as the name suggests) is the inverse of differentiation. There is one consequence of this that is helpful to keep in mind as we move on to other chapters. This being calculus, the functions that we construct and operate upon have inputs that are quantities and outputs that are also quantities. Every quantity has a dimension, as discussed in Chapter 16. When you are working with any quantity, you should be sure that you know its dimension and its units.\nThe dimension of the input to a function does not by any means have to be the same as the dimension of the output. For instance, we have been using many functions where the input has dimension time and the output is position (dimension L) or velocity (dimension L/T) or acceleration (dimension L/T\\(^2\\)).\nImagine working with some function \\(f(y)\\) that’s relevant to some modeling project of interest to you. Returning to the bracket notation that we used in Chapter 16, the dimension of the input quantity will be [\\(y\\)]. The dimension of the output quantity is [\\(f(y)\\)]. (Remember from 16 that [\\(y\\)] means “the dimension of quantity \\(y\\)” and that [\\(f(y)\\)] means “the dimension of the output from \\(f(y)\\).”)\nThe function \\(\\partial_y f(y)\\) has the same input dimension \\([y]\\) but the output will be \\([f(y)] / [y]\\). For example, suppose \\(f(y)\\) is the mass of fuel in a rocket as a function of time \\(y\\). The output of \\(f(y)\\) has dimension M. The input dimension \\([y]\\) is T.\nThe output of the function \\(\\partial_y f(y)\\) has dimension \\([f(y)] / [y]\\), which in this case will be M / T. (Less abstractly, if the fuel mass is given in kg, and time is measured in seconds, then \\(\\partial_y f(y)\\) will have units of kg-per-second.)\nHow about the dimension of the anti-derivative \\(F(y) = \\int f(y) dy\\)? Since \\(F(y)\\) is the anti-derivative of \\(f(y)\\) (with respect to \\(y\\)), we know that \\(\\partial_y F(y) = f(y)\\). Taking the dimension of both sides \\[[\\partial_y F(y)] = \\frac{[F(y)]}{[y]} = \\frac{[F(y)]}{\\text{T}} = [f(y)] = \\text{M}\\] Consequently, \\([F(y)] = \\text{M}\\).\nTo summarize:\n\nThe dimension of derivative \\(\\partial_y f(y)\\) will be \\([f(y)] / [y]\\).\nThe dimension of the anti-derivative \\(\\int f(y) dy\\) will be \\([f(y)]\\times [y]\\).\n\nOr, more concisely:\n\nDifferentiation is like division, anti-differentiation is like multiplication.\n\nPaying attention to the dimensions (and units!) of input and output can be a boon to the calculus student. Often students have some function \\(f(y)\\) and they are wondering which of the several calculus operations they are supposed to do: differentiation, anti-differentiation, finding a maximum, finding an argmax or a zero. Start by figuring out the dimension of the quantity you want. From that, you can often figure out which operation is appropriate.\nTo illustrate, imagine that you have constructed \\(f(y)\\) for your task and you know, say, \\[[f(y)] = \\text{M       and} \\  \\ \\ \\ \\ [y] = \\text{T}\\ .\\] Look things up in the following table:\n\n\n\nDimension of result\nCalculus operation\n\n\n\n\nM / T\ndifferentiate\n\n\nM T\nanti-differentiate\n\n\nM\nfind max or min\n\n\nT\nfind argmax/argmin or a function zero\n\n\nM T\\(^2\\)\nanti-differentiate twice in succession\n\n\nM / T\\(^2\\)\ndifferentiate twice in succession\n\n\n\nFor example, suppose the output of the accelerometer on your rocket has dimension L / T\\(^2\\). You are trying to figure out from the accelerometer reading what is your altitude. Altitude has dimension L. Look up in the table to see that you want to anti-differentiate acceleration twice in succession."
  },
  {
    "objectID": "Accumulation/27-intro.html#sec-preliminary-terrors",
    "href": "Accumulation/27-intro.html#sec-preliminary-terrors",
    "title": "34  Change & accumulation",
    "section": "34.5 From Calculus Made Easy",
    "text": "34.5 From Calculus Made Easy\nCalculus Made Easy, by Silvanus P. Thompson, is a classic, concise, and elegant textbook from 1910. It takes a common-sense approach, sometimes lampooning the traditional approach to teaching calculus.\n\nSome calculus-tricks are quite easy. Some are enormously difficult. The fools who write the textbooks of advanced mathematics—and they are mostly clever fools—seldom take the trouble to show you how easy the easy calculations are. On the contrary, they seem to desire to impress you with their tremendous cleverness by going about it in the most difficult way. — From the preface\n\nThompson’s first chapter starts with the notation of accumulation, which he calls “the preliminary terror.”\n\nThe preliminary terror … can be abolished once for all by simply stating what is the meaning—in common-sense terms—of the two principal symbols that are used in calculating.\nThese dreadful symbols are:\n\n\\(\\Large\\  d\\) which merely means “a little bit of.”\n\nThus \\(dx\\) means a little bit of \\(x\\); or \\(du\\) means a little bit of \\(u\\). Ordinary mathematicians think it more polite to say “an element of,” instead of “a little bit of.” Just as you please. But you will find that these little bits (or elements) may be considered to be indefinitely small.\n\n\\(\\ \\ \\large\\int\\) which is merely a long \\(S\\), and may be called (if you like) “the sum of.”\n\nThus \\(\\ \\int dx\\) means the sum of all the little bits of \\(x\\); or \\(\\ \\int dt\\) means the sum of all the little bits of \\(t\\). Ordinary mathematicians call this symbol “the integral of.” Now any fool can see that if \\(x\\) is considered as made up of a lot of little bits, each of which is called \\(dx\\), if you add them all up together you get the sum of all the \\(dx\\)’s, (which is the same thing as the whole of \\(x\\)). The word “integral” simply means “the whole.” If you think of the duration of time for one hour, you may (if you like) think of it as cut up into \\(3600\\) little bits called seconds. The whole of the \\(3600\\) little bits added up together make one hour.\nWhen you see an expression that begins with this terrifying symbol, you will henceforth know that it is put there merely to give you instructions that you are now to perform the operation (if you can) of totaling up all the little bits that are indicated by the symbols that follow.\n\n\nThe next chapter shows what it means to “total up all the little bits” of a function."
  },
  {
    "objectID": "Accumulation/27-intro.html#exercises",
    "href": "Accumulation/27-intro.html#exercises",
    "title": "34  Change & accumulation",
    "section": "34.6 Exercises",
    "text": "34.6 Exercises"
  },
  {
    "objectID": "Accumulation/28-visualizing.html",
    "href": "Accumulation/28-visualizing.html",
    "title": "35  Totaling the little bits",
    "section": "",
    "text": "Many students wonder how it is possible to reconstruct a function \\(F(x)\\) from its derivative \\(f(x)\\). The point of this short chapter is to help you develop some intuition about anti-differentiation.\nYou already know the notation meaning “\\(F(x)\\) is the anti-derivative of \\(f(x)\\)”: \\[\\large \\int f(x)\\, dx\\ .\\] In drawing a graph of \\(F(x)\\), we will of course want to use coordinate axes where the quantity \\(x\\) is represented on the horizontal axis and the quantity of the output \\(F(x)\\) is on the vertical axis:\nIt’s premature to have drawn a segment of \\(F(x)\\) because we haven’t yet undertaken to compute \\(F(x) = \\int f(x)\\, dx\\). At this point in the process, all we know is \\(f(x)\\), not \\(F(x)\\). Still, since we know \\(f(x)\\), we do know the slope of the little segment of \\(F(x)\\). We just don’t know where that segment should be located vertically in each of the \\(dx\\) regions that make up the whole domain.\nWe can’t draw \\(f(x)\\) in the ordinary way as a curve wending its way across the domain of the graph. Why not? Because the vertical axis of the graphics frame is in terms of \\(F(x)\\) and has a different dimension than the output of \\(f(x)\\).\nBut we can draw \\(f(x)\\) in terms of the slope of a segment of horizontal extent \\(dx\\), so long as we accept that the vertical position of that segment means nothing: \\(f(x)\\) gives information only about the slope of the segment. The best we can do at this point is to graph \\(f(x)\\) in terms of sloping segments, as in Figure 35.2.\nEach of the segments in Figure 35.2 has the same horizontal extent, namely \\(dx\\). When we draw a sloping segment over the tiny bit \\(dx\\) of the domain, the vertical extent of the segment will be the product of the width \\(dx\\) and the slope \\(f(x)\\). That is, the vertical extent will be the product \\(f(x) dx\\).\nWhenever we know a function \\(f(x)\\) and have chosen a size for \\(dx\\) we can draw a graph of \\(f(x)\\) in the form shown in Figure 35.2. We’re drawing it in this unusual way because we want the graphics frame to be all ready for drawing the graph of \\(F(x)\\) in the normal fashion after we have figured out what \\(F(x)\\) results from accumulating/summing-up all the little \\(f(x) dx\\) segments. When we write \\(\\large\\int\\) in the notation \\[\\large \\int f(x)\\, dx\\] we mean, “sum up all the \\(f(x) dx\\) segments.”\nLet’s now consider how to “sum up all the segments.” We’ll start in Figure 35.3 with an example where we already know \\(F(x)\\). That way, we can see of our sum of the \\(f(x) dx\\) segments really does reconstruct \\(F(x)\\).\nNow imagine that we sliced up \\(F(x)\\) over small sub-domains of \\(x\\), as in Figure 35.3 (bottom). That is, we approximated \\(F()\\) piecewise locally. But we’ve broken the continuity of \\(F(x)\\) by moving each slice up or down so that the left-most point has value 0.\nCan you reconstruct \\(F(x)\\) from the local segments?\nStart by reading off the function value from the last point in the left-most segment. That’s been marked in Figure 35.3 with a blue dot. The function value at that dot is 7.072.\nNow take the second segment. The idea is to move that segment upward until it joins the first segment at the blue dot. You can do that by adding 7.072 to the second segment. The result is shown in Figure 35.4(top).\nNow read off the new value at the end of the second segment, it’s 4.198. Add this amount to the third segment as in Figure 35.4(bottom).\nContinue this process until you have reconstructed \\(F(x)\\) from the local segments.\nYou may object: “Of course you can reconstruct \\(F(x)\\) from the local segments, but this isn’t the same as reconstructing \\(F(x)\\) from its derivative \\(\\partial_x F(x)\\).” My answer: “That depends on how many segments you use.”\nWhen we make the segment width \\(h\\) smaller and smaller, the individual segments become more and more like straight lines. Figure 35.5 shows the segments for smaller and smaller \\(h\\).\nNotice that many of the segments are straight lines. That’s understandable, since any function looks like a straight line over a small enough domain.\nEach of those straight-line segments is drawn over a domain \\(x_i < x < x_i+dx\\) that has width \\(dx\\). For \\(dx\\) small enough, the segment is well approximated by a straight line with slope \\(\\partial_x F(x_i)\\). Multiplying slope by width \\(dx\\) gives the segment height: \\(\\left[{\\large\\strut}\\partial_x F(x_i)\\right]\\ dx\\). Of course, remember that \\(\\partial_x F(x) = f(x)\\) helps us see that each of the little segments is \\(f(x_i)\\ dx\\).\nLets review. The standard notation for anti-differentiation can be interpreted in terms of putting together segments, or, in the words of Prof. Thompson in Calculus Made Easy, “totaling up all the little bits.” (See Section 34.5.)\nAltogether, we have:\n\\[\\large \\underbrace{\\underbrace{\\Large\\color{magenta}{\\int}}_{\\color{magenta}{\\text{assemble}}} \\underbrace{\\Large \\overbrace{f(x)}^{\\small\\text{slope of F(x)}}\\ \\  \\overbrace{\\strut dx}^{\\small \\text{bits of}\\ x}}_{\\color{blue}{\\text{the slope segments}}}}_{\\text{giving}\\ {\\Large F(x)+C}\\ \\text{altogether.}}\\]"
  },
  {
    "objectID": "Accumulation/28-visualizing.html#exercises",
    "href": "Accumulation/28-visualizing.html#exercises",
    "title": "35  Totaling the little bits",
    "section": "35.1 Exercises",
    "text": "35.1 Exercises"
  },
  {
    "objectID": "Accumulation/29-integration.html",
    "href": "Accumulation/29-integration.html",
    "title": "36  Integration",
    "section": "",
    "text": "Anti-derivatives are useful when you know how a quantity is changing but don’t yet know the quantity itself.\nIt’s important, of course, to keep track of which is the “quantity itself” and which is the “rate of increase in that quantity.” This always depends on context and your point of view. It’s convenient, then, to set some fixed examples to make it easy to keep track of which quantity is which.\nWe’ll also adopt a convention to make it simpler to recognize which quantity is the “quantity itself” and which is the “rate of increase in that quantity.” We will use CAPITAL LETTERS to name functions that are the quantity itself, and lower-case letters for the rate of increase in that quantity. For example, if talking about motion, an important quantity is momentum and how it changes over time. The momentum itself will be \\({\\mathbf M}(t)\\) while the rate of increase of momentum will be \\(m(t)\\).1 The amount of money a business has on hand at time \\(t\\) is \\({\\mathbf S}(t)\\) measured, say, in dollars. The rate of increase of that money is \\(s(t)\\), in, say, dollars per day.\nNotice that we’re using the phrase “rate of increase” rather than “rate of change.” That’s because we want to keep straight the meaning of the sign of the lower-case function. If \\(m(t)\\) is positive, the momentum is increasing. If \\(m(t)\\) is negative then it’s a “negative rate of increase,” which is, of course, just a “decrease.”\nFor a business, money coming in means that \\(s(t)\\) is positive. Expenditures of money correspond to \\(s(t)\\) being negative. In the fuel example. \\({\\mathbf F}(t)\\) is the amount of fuel in the tank. \\(f(t)\\) is the rate of increase in the amount of fuel in the tank. Of course, engines burn fuel, removing it from the tank. So we would write the rate at which fuel is burned as \\(-f(t)\\): removing fuel is a negative increase in the amount of fuel, an expenditure of fuel.\nThe objective of this chapter is to introduce you to the sorts of calculations, and their notations, that let you figure out how much the CAPITAL LETTER quantity has changed over an interval of \\(t\\) based on what you already know about the value over time of the lower-case function.\nThe first step in any such calculation is to find or construct the lower-case function \\(f(t)\\) or \\(c(t)\\) or \\(m(t)\\) or whatever it might be. This is a modeling phase. In this chapter, we’ll ignore detailed modeling of the situation and just present you with the lower-case function.\nThe second step in any such calculation is to compute the anti-derivative of the lower-case function, giving as a result the CAPITAL LETTER function. You’ve already seen the notation for this, e.g. \\[{\\Large  F(t) = \\int f(t) dt}\\ \\ \\ \\ \\ \\text{or}\\ \\ \\ \\ \\ {\\Large G(t) = \\int g(t) dt}\\ \\ \\ \\ \\text{and so on.}\\] In this chapter, we will not spend any time on this step; we will assume that you already have at hand the means to compute the anti-derivative. (Indeed, you already have antiD() available which will do the job for you.) Later chapters will look at the issues around and techniques for doing the computations by other means.\nThe remaining steps in such calculations are to work with the CAPITAL LETTER function to compute such things as the amount of that quantity, or the change in that quantity as it is accumulated over an interval of \\(t\\)."
  },
  {
    "objectID": "Accumulation/29-integration.html#net-change",
    "href": "Accumulation/29-integration.html#net-change",
    "title": "36  Integration",
    "section": "36.1 Net change",
    "text": "36.1 Net change\nPerhaps it goes without saying, but once you have the CAPITAL LETTER function, e.g. \\(F(t)\\), you can evaluate that function at any input that falls into the domain of \\(F(t)\\). If you have a graph of \\(F(t)\\) versus \\(t\\), just position your finger on the horizontal axis at input \\(t_1\\), then trace up to the function graph, then horizontally to the vertical axis where you can read off the value \\(F(t_1)\\). If you have \\(F()\\) in the form of a computer function, just apply \\(F()\\) to the input \\(t_1\\).\nIn this regard, \\(F(t)\\) is like any other function.\nHowever, in using and interpreting the \\(F(t)\\) that we constructed by anti-differentiating \\(f(t)\\), we have to keep in mind the limitations of the anti-differentiation process. In particular, any function \\(f(t)\\) does not have a unique anti-derivative function. If we have one anti-derivative, we can always construct another by adding some constant: \\(F(t) + C\\) is also an anti-derivative of \\(f(t)\\).\nBut we have a special purpose in mind when calculating \\(F(t_1)\\). We want to figure out from \\(F(t)\\) how much of the quantity \\(f(t)\\) has accumulated up to time \\(t_1\\). For example, if \\(f(t)\\) is the rate of increase in fuel (that is, the negative of fuel consumption), we want \\(F(t_1)\\) to be the amount of fuel in our tank at time \\(t_1\\). That cannot happen. All we can say is that \\(F(t_1)\\) is the amount of fuel in the tank at \\(t_1\\) give or take some unknown constant C.\nInstead, the correct use of \\(F(t)\\) is to say how much the quantity has changed over some interval of time, \\(t_0 \\leq t \\leq t_1\\). This “change in the quantity” is called the net change in \\(F()\\). To calculate the net change in \\(F()\\) from \\(t_0\\) to \\(t_1\\) we apply \\(F()\\) to both \\(t_0\\) and \\(t_1\\), then subtract:\n\\[\\text{Net change in}\\ F(t) \\ \\text{from}\\ t_0 \\ \\text{to}\\ t_1 :\\\\= F(t_1) - F(t_0)\\]\n\nSuppose you have already constructed the rate-of-change function for momentum \\(m()\\) and implemented it as an R function m(). For instance, \\(m(t)\\) might be the amount of force at any instant \\(t\\) of a car, and \\({\\mathbf M}(t)\\) is the accumulated force, better known as momentum. We’ll assume that the input to m() is in seconds, and the output is in kg-meters-per-second-squared, which has the correct dimension for force.\nYou want to find the amount of force accumulated between time \\(t=2\\) and \\(t=5\\) seconds.\n\n\n\n\n# You've previous constructed m(t)\nM <- antiD(m(t) ~ t)\nM(5) - M(2)\n## [1] -1.392131\n\nTo make use of this quantity, you’ll need to know it’s dimension and units. For this example, where the dimension [\\(m(t)\\)] is M L T\\(^{-2}\\), and [\\(t\\)] = T, the dimension [\\({\\mathbf M}(t)\\)] will be M L T\\(^{-1}\\). In other words, if the output of \\(m(t)\\) is kg-meters-per-second-squared, then the output of \\(V(t)\\) must be kg- meters-per-second."
  },
  {
    "objectID": "Accumulation/29-integration.html#the-definite-integral",
    "href": "Accumulation/29-integration.html#the-definite-integral",
    "title": "36  Integration",
    "section": "36.2 The “definite” integral",
    "text": "36.2 The “definite” integral\nWe have described the process of calculating a net change from the lower-case function \\(f(t)\\) in terms of two steps:\n\nConstruct \\(F(t) = \\int f(t) dt\\).\nEvaluate \\(F(t)\\) at two inputs, e.g. \\(F(t_2) - F(t_1)\\), giving a net change, which we’ll write as \\({\\cal F}(t_1, t_2) = F(t_2) - F(t_1)\\).\n\nAs a matter of notation, the process of going from \\(f(t)\\) to the net change is written as one statement. \\[{\\cal F}(t_1, t_2) = F(t_2) - F(t_1) = \\int_{t_1}^{t_2} f(t) dt\\]\nThe punctuation \\[\\int_{t_1}^{t_2} \\_\\_\\_\\_ dt\\] captures in one construction both the anti-differentiation step (\\(\\int\\_\\_dt\\)) and the evaluation of the anti-derivative at the two bound \\(t_2\\) and \\(t_1\\).\nSeveral names are used to describe the overall process. It is important to become familiar with these.\n\n\\(\\int_a^b f(t) dt\\) is called a definite integral of \\(f(t)\\).\n\\(a\\) and \\(b\\) are called, respectively, the lower bound of integration and the upper bound of integration, although given the way we draw graphs it might be better to call them the “left” and “right” bounds, rather than lower and upper.\nThe pair \\(a, b\\) is called the bounds of integration.\n\nAs always, it pays to know what kind of thing is \\({\\cal F}(t_1, t_2)\\). Assuming that \\(t_1\\) and \\(t_2\\) are fixed quantities, say \\(t_1 = 2\\) seconds and \\(t_2 = 5\\) seconds, then \\({\\cal F}(t_1, t_2)\\) is itself a quantity. The dimension of that quantity is [\\(F(t)\\)] which in turn is [\\(f(t)\\)]\\(\\cdot\\)[\\(t\\)]. So if \\(f(t)\\) is fuel consumption in liters per second, then \\(F(t)\\) will have units of liters, and \\({\\cal F}(t_1, t_2)\\) will also have units of liters.\nRemember also an important distinction:\n\n\\(F(t) = \\int f(t) dt\\) is a function whose output is a quantity.\n\\(F(t_2) - F(t_1) = \\int_{t_1}^{t_2} f(t) dt\\) is a quantity, not a function.\n\nOf course, \\(f(t)\\) is a function whose output is a quantity. In general, the two functions \\(F(t)\\) and \\(f(t)\\) produce outputs that are different kinds of quantities. For instance, the output of \\(F(t)\\) is liters of fuel while the output of \\(f(t)\\) is liters per second: fuel consumption. Similarly, the output of \\(S(t)\\) is dollars, while the output of \\(s(t)\\) is dollars per day.\nThe use of the term definite integral suggests that there might be something called an indefinite integral, and indeed there is. “Indefinite integral” is just a synonym for “anti-derivative.” In this book we favor the use of anti-derivative because it’s too easy to leave off the “indefinite” and confuse an indefinite integral with a definite integral. Also, “anti-derivative” makes it completely clear what is the relationship to “derivative.”\nSince 1700, it’s common for calculus courses to be organized into two divisions:\n\nDifferential calculus, which is the study of derivatives and their uses.\nIntegral calculus, which is the study of anti-derivatives and their uses.\n\nMathematical notation having been developed for experts rather than for students, very small typographical changes are often used to signal very large changes in meaning. When it comes to anti-differentiation, there are two poles of fixed meaning and then small changes which modify the meaning. The poles are:\n\nAnti-derivative: \\(\\int f(t) dt\\), which is a function whose output is a quantity.\nDefinite integral \\(\\int_a^b f(t) dt\\), which is a quantity, plain and simple.\n\nBut you will also see some intermediate forms:\n\n\\(\\int_a^t f(t) dt\\), which is a function with input \\(t\\).\n\\(\\int_a^x f(t) dt\\), which is the same function as in (a) but with the input name \\(x\\) being used.\n\\(\\int_t^b f(t) dt\\), which is a function with input \\(t\\).\nLess commonly, \\(\\int_x^t f(t) dt\\) which is a function with two inputs, \\(x\\) and \\(t\\). The same is true of \\(\\int_x^y f(t) dt\\) and similar variations."
  },
  {
    "objectID": "Accumulation/29-integration.html#initial-value-of-the-quantity",
    "href": "Accumulation/29-integration.html#initial-value-of-the-quantity",
    "title": "36  Integration",
    "section": "36.3 Initial value of the quantity",
    "text": "36.3 Initial value of the quantity\nRecall that we’re interested in a real quantity \\({\\mathbf F}(t)\\), but we only know \\(f(t)\\) and from that can calculate an anti-derivative \\(F(t)\\). The relationship between them is \\[{\\mathbf F}(t) = F(t) + C\\] where \\(C\\) is some fixed quantity that we cannot determine directly from \\(f(t)\\).\nStill, even if we cannot determine \\(C\\), there’s one way we can use \\(F(t)\\) to make definite statements about \\({\\mathbf F}(t)\\). Consider the net change from \\(t_1\\) to \\(t_2\\) in the real quantity \\({\\mathbf F}\\). This is \\[{\\mathbf F}(t_2) - {\\mathbf F}(t_1) =  \\left[F(t_2) + C\\right] - \\left[F(t_1) + C\\right] = F(t_2) - F(t_1)\\] In other words, just knowing \\(F(t)\\), we can make completely accurate statements about net changes in the value of \\({\\mathbf F}(t)\\).\nLet’s develop our understanding of this unknown constant \\(C\\), which is called the constant of integration. To do so, watch the movie in Figure 36.1 showing the process of constructing the anti-derivative \\[F(t) = \\int_2^t f(t) dt\\ .\\]\n\n\n\n\n\nFigure 36.1: Constructing the anti-derivative \\(F(t)\\) by reading the slope from \\(f(t)\\) and using that slope to extend the picture of \\(F()\\)\n\n\n\n\n\nFocus first on the top graph. The function we are integrating, \\(f(t)\\), is known before we carry out the integration, so it is shown in the top graph.\n\n\\(f(t)\\) is the rate of increase in \\(F(t)\\) (or \\({\\mathbf F}(t)\\) for that matter). From the graph, you can read using the vertical axis the value of \\(f(t)\\) for any input \\(t\\). But since \\(f(t)\\) is a rate of increase, we can also depict \\(f(t)\\) as a slope. That slope is being drawn as a \\(\\color{magenta}{\\text{magenta}}\\) arrow. Notice that when \\(f(t)\\) is positive, the arrow slopes upward and when \\(f(t)\\) is negative, the arrow slopes downward. The steepness of the arrow is the value of \\(f(t)\\), so for inputs where the value of \\(f(t)\\) is far from zero the arrow is steeper than for values of \\(f(t)\\) that are near zero.\n\nNow look at both graphs, but concentrate just on the arrows in the two graphs. They are always the same: carbon copies of one another.\nFinally the bottom graph. We’re starting the integral at \\(t_1=2\\). Since nothing has yet been accumulated, the value \\(F(t_1 = 2) = 0\\). From (1) and (2), you know the arrow shows the slope of \\(F(t)\\). So as \\(F(t>2)\\) is being constructed the arrow guides the way. When the slope arrow is positive, \\(F(t)\\) is growing. When the slope arrow is negative, \\(F(t)\\) is going down.\n\nIn tallying up the accumulation of \\(f(t)\\), we started at time \\(t=2\\) and with \\(F(t=2) = 0\\). This makes sense, since nothing can be accumulated over the mere instant of time from \\(t=2\\) to \\(t=2\\). On the other hand, it was our choice to start at \\(t=2\\). We might have started at another value of \\(t\\) such as \\(t=0\\) or \\(t=-5\\) or \\(t=-\\infty\\). If so, then the accumulation of \\(f(t)\\) up to \\(t=2\\) would likely have been something other than zero.\nBut what if we knew an actual value for \\({\\mathbf F}(2)\\). This is often the case. For instance, before taking a trip you might have filled up the fuel tank. The accumulation of fuel consumption only tells you how much fuel has been used since the start of the trip. But if you know the starting amount of fuel, by adding that to the accumulation you’ll know instant by instant how much fuel is in the tank. In other words, \\[{\\mathbf F}(t) = {\\mathbf F}(2) + \\int_2^t f(t) dt\\ .\\] This is why, when we write an anti-derivative, we should always include mention of some constant \\(C\\)—the so-called constant of integration—to remind us that there is a difference between the \\(F(t)\\) we get from anti-differentiation and the \\({\\mathbf F}(t)\\) of the function we’re trying to reconstruct. That is, \\[{\\mathbf F}(t) = F(t) + C = \\int f(t) dt + C\\ .\\] We only need to know \\({\\mathbf F}(t)\\) at one point in time, say \\(t=0\\), to be able to figure out the value of \\(C\\): \\[C = {\\mathbf F}(0) - F(0)\\ .\\]\nAnother way to state the relationship between the anti-derivative and \\({\\mathbf F}(t)\\) is by using the anti-derivative to accumulate \\(f(t)\\) from some starting point \\(t_0\\) to time \\(t\\). That is: \\[{\\mathbf F}(t) \\ =\\  {\\mathbf F}(t_0) + \\int_{t_0}^t f(t)\\, dt\\  = \\\n{\\mathbf F}(t_0) + \\left({\\large\\strut}F(t) - F(t_0)\\right)\\]\n\nA famous legend has Galileo at the top of the Tower of Pisa around 1590. The legend illustrates Galileo’s finding that a light object (e.g. a marble) and a heavy object (e.g. a ball) will fall at the same speed. Galileo published his mathematical findings in 1638 in Discorsi e Dimostrazioni Matematiche, intorno a due nuove scienze. (English: Discourses and Mathematical Demonstrations Relating to Two New Sciences)\nIn 1687, Newton published his world-changingPhilosophiae Naturalis Principia Mathematica. (English: Mathematical Principles of Natural Philosophy)\nLet’s imagine the ghost of Galileo returned to Pisa in 1690 after reading Newton’s Principia Mathematica. In this new legend, Galileo holds a ball still in his hand, releases it, and figures out the position of the ball as a function of time.\nAlthough Newton famously demonstrated that gravitational attraction is a function of the distance between to objects, he also knew that at a fixed distance—the surface of the Earth—gravitational acceleration was constant. So Galileo was vindicated by Newton. But, although gravitational acceleration is constant from top to bottom of the Tower of Pisa, Galileo’s ball was part of a more complex system: a hand holding the ball still until release. Acceleration of the ball versus time is therefore approximately a Heaviside function:\n\\[\\text{accel}(t) \\equiv \\left\\{\\begin{array}{rl}0 & \\text{for}\\ t \\leq 3\\\\\n{-9.8}  & \\text{otherwise}\\end{array}\\right.\\]\n\naccel <- makeFun(ifelse(t <= 3, 0, -9.8) ~ t)\n\nAcceleration is the derivative of velocity. We can construct a function \\(V(t)\\) as the anti-derivative of acceleration, but the real-world velocity function will be \\[{\\mathbf V}(t) = {\\mathbf V}(0) + \\int_0^t \\text{accel}(t) dt\\]\n\nV_from_antiD <- antiD(accel(t) ~ t)\nV <- makeFun(V0 + (V_from_antiD(t) - V_from_antiD(0)) ~ t, V0 = 0)\n\nIn the computer expression, the parameter V0 stands for \\({\\mathbf V}(0)\\). We’ve set it equal to zero since, at time \\(t=0\\), Galileo was holding the ball still.\nVelocity is the derivative of position, but the real-world velocity function will be the accumulation of velocity from some starting time to time \\(t\\), plus the position at that starting time: \\[x(t) \\equiv x(0) + \\int_0^t V(t) dt\\] We can calculate \\(\\int V(t) dt\\) easily enough with antiD(), but the function \\(x(t)\\) involves evaluating that anti-derivative at times 0 and \\(t\\):\n\nx_from_antiD <- antiD(V(t) ~ t)\nx <- makeFun(x0 + (x_from_antiD(t) - x_from_antiD(0)) ~ t, x0 = 53)\n\nWe’ve set the parameter x0 to be 53 meters, the height above the ground of the top balcony on which Galileo was standing for the experiment.\n\n\n\n\n\nFigure 36.2: The acceleration, velocity, and position of the ball as a function of time in Galileo’s Tower of Pisa experiment. The ball is released at time \\(t_0\\).\n\n\n\n\n\nIn the (fictional) account of the 1690 experiment, we had Galileo release the ball at time \\(t=0\\). That’s a common device in mathematical derivations, but in a physical sense it’s entirely arbitrary. Galileo might have let go of the ball at any other time, say, \\(t=3\\) or \\(t=14:32:05\\).\nA remarkable feature of integrals is that it doesn’t matter what we use as the lower bound of integration, so long as we set the initial value to correspond to that bound.\n\nFor a while you were writing integrals like this: \\(\\int_a^b f(t) dt\\). Then you replaced \\(b\\) with the input name \\(t\\) to get \\(\\int_a^t f(t) dt\\). But then you switched everything up by writing \\(\\int_a^t f(x) dx\\). Is that the same as \\(\\int_a^t f(t) dt\\)? If so, why do you get to replace the \\(t\\) with \\(x\\) in some places but not in others?\nRecall from Chapter 5 that the names used for inputs to a function definition don’t matter so long as they are used consistently on the left and right sides of \\(\\equiv\\). For instance, all these are the same function:\n\n\\(f(x) \\equiv m x + b\\)\n\\(g(t) \\equiv m t + b\\)\n\\(h(\\text{wind}) \\equiv m \\text{wind} + b\\)\n\nNow think about the integral \\(\\int_a^b f(t) dt\\): \\[\\int_a^b f(t) dt = F(b) - F(a)\\ .\\]\nOn the left-hand side, the input name \\(t\\) is prominant, appearing in two places: \\(f(\\color{magenta}{t}) d\\color{magenta}{t}\\). But \\(t\\) is nowhere on the right-hand side. We could have equally well written this as \\(\\int_a^b f(x) dx\\) or \\(\\int_a^b f(\\text{wind}) d\\text{wind}\\). The name we use for the input to \\(f()\\) doesn’t matter so long as it is consistent with the name used in the \\(d\\_\\_\\) part of the notation. Often, the name placed in the blanks in \\(\\int f(\\_\\_) d\\_\\_\\) is called a dummy variable.\nWriting \\(\\int_a^t f(t) dt\\) is perfectly reasonable, but many authors dislike the multiple appearance of \\(t\\). So they write something like \\(\\int_a^t f(x) dx\\) instead."
  },
  {
    "objectID": "Accumulation/29-integration.html#integrals-from-bottom-to-top",
    "href": "Accumulation/29-integration.html#integrals-from-bottom-to-top",
    "title": "36  Integration",
    "section": "36.4 Integrals from bottom to top",
    "text": "36.4 Integrals from bottom to top\nThe bounds of integration appear in different arrangements. None of these are difficult to derive from the basic forms:\n\nThe relationship between an integral and its corresponding anti-derivative function: \\[\\int_a^b f(x) dx = F(b) - F(a)\\] This relationship has a fancy-sounding name: the second fundamental theorem of calculus.\nThe accumulation from an initial-value \\[{\\mathbf F}(b)\\  =\\  {\\mathbf F}(a) + \\int_a^b f(x) dx\\  = \\ {\\mathbf F}(a) + F(b) - F(a)\\] For many modeling situations, \\(a\\) and \\(b\\) are fixed quantities, so \\(F(a)\\) and \\(F(b)\\) are also quantities; the output of the anti-derivative function at inputs \\(a\\) and \\(b\\). But either the lower-bound or the upper-bound can be input names, as in \\[\\int_0^t f(x) dx = F(t) - F(0)\\]\n\nNote that \\(F(t)\\) is not a quantity but a function of \\(t\\).\nOn occasion, you will see forms like \\(\\int_t^0 f(x)dx\\). You can think of this in either of two ways:\n\nThe accumulation from a time \\(t\\) less than 0 up until 0.\nThe reverse accumulation from 0 until time \\(t\\).\n\nReverse accumulation can be a tricky concept because it violates everyday intuition. Suppose you were harvesting a row of ripe strawberries. You start at the beginning of the row—position zero. Then you move down the row, picking strawberries and placing them in your basket. When you have reached position \\(B\\) your basket holds the accumulation \\(\\int_0^B s(x)\\, dx\\), where \\(s(x)\\) is the lineal density of strawberries—units: berries per meter of row.\nBut suppose you go the other way, starting with an empty basket at position \\(B\\) and working your way back to position 0. Common sense says your basket will fill to the same amount as in the forward direction, and indeed this is the case. But integrals work differently. The integral \\(\\int_B^0 s(x) dx\\) will be the negative of \\(\\int_0^B s(x) dx\\). You can see this from the relationship between the integral and the anti-derivative: \\[\\int_B^0 s(x) dx \\ = \\ S(0) - S(B) \\ =\\ -\\left[{\\large\\strut}S(B) - S(0)\\right]\\ = \\ -\\int_0^B s(x) dx\\]\nThis is not to say that there is such a thing as a negative strawberry. Rather, it means that harvesting strawberries is similar to an integral in some ways (accumulation) but not in other ways. In farming, harvesting from 0 to \\(B\\) is much the same as harvesting from \\(B\\) to 0, but integrals don’t work this way.\nAnother property of integrals is that the interval between bounds of integration can be broken into pieces. For instance:\n\\[\\int_a^c f(x) dx \\ = \\ \\int_a^b f(x) dx + \\int_b^c f(x) dx\\] You can confirm this by noting that \\[\\int_a^b f(x) dx + \\int_b^c f(x) dx \\ = \\ \\left[{\\large\\strut}F(b) - F(a)\\right] + \\left[{\\large\\strut}F(c) - F(b)\\right] = F(c) - F(a) \\ = \\ \\int_a^c f(x) dx\\ .\\]\nFinally, consider this function of \\(t\\): \\[\\partial_t \\int_a^t f(x) dx\\ .\\] First, how do we know it is a function of \\(t\\)? \\(\\int_a^t f(x) dx\\) is a definite integral and has the value \\[\\int_a^t f(x) dx = F(t) - F(a)\\  .\\] Following our convention, \\(a\\) is a parameter and stands for a specific numerical value, so \\(F(a)\\) is the output of \\(F()\\) for a specific input. But according to convention \\(t\\) is the name of an input. So \\(F(t)\\) is a function whose output depends on \\(t\\). Differentiating the function \\(F(t)\\), as with every other function, produces a new function.\nSecond, there is a shortcut for calculating \\(\\partial_t \\int_a^t f(x) dx\\): \\[\\partial_t \\int_a^t f(x) dx\\ =\\ \\partial_t \\left[{\\large\\strut}F(t) - F(a)\\right]\\ .\\] Since \\(F(a)\\) is a quantity and not a function, \\(\\partial_t F(a) = 0\\). That simplies things. Even better, we know that the derivative of \\(F(t)\\) is simply \\(f(t)\\): that’s just the nature of the derivative/anti-derivative relationship between \\(f(t)\\) and \\(F(t)\\). Put together, we have: \\[\\partial_t \\int_a^t f(x) dx\\ =\\ f(t)\\ .\\]\nThis complicated-looking identity has a fancy name: the first fundamental theorem of calculus.\n\nBacktracking the stars.\nIn the 1920s, astronomers and cosmologists questioned the idea that the large-scale universe is static and unchanging. This traditional belief was undermined both by theory (e.g. General Relativity) and observations. The most famous of these were collected and published by Edwin Hubble, starting in 1929 and continuing over the next decade as improved techniques and larger telescopes became available. In recent years, with the availability of the space telescope named in honor of Hubble data has expanded in availability and quality. Figure 36.3 shows a version of Hubble’s 1929 graph based on contemporary data.\n\n\n\n\n\nFigure 36.3: The relationship between velocity and distance of stars, using contemporary data in the same format at Edwin Hubble’s 1929 publication.\n\n\n\n\nEach dot in Figure 36.3 is an exploding star called a supernova. The graph shows the relationship between the distance of the star from our galaxy and the outward velocity of that star. The velocities are large, \\(3 \\times 10^4 = 30,000\\) km/s is about one-tenth the speed of light. Similarly, the distances are big; 600 Mpc is the same as 2 billion light years or \\(1.8 \\times 10^{22} \\text{km}\\). The slope of the line in Figure 36.3 is \\(\\frac{3.75 \\times 10^4\\, \\text{km/s}}{1.8 \\times 10^{22}\\, \\text{km}} = 2.1 \\times 10^{-18}\\, \\text{s}^{-1}\\). For ease of reading, we’ll call this slope \\(\\alpha\\) and therefore the velocity of a start distance \\(D\\) from Earth is \\[v(D) \\equiv \\alpha D\\ .\\]\nEarlier in the history of the universe each star was a different distance from Earth. We’ll call this function \\(D(t)\\), distance as a function of time in the universe.\nThe distance travelled by each star from time \\(t\\) (billions of years ago) to the present is \\[\\int_t^\\text{now} v(t) dt  = D_\\text{now} - D(t)\\] which can be re-arranged to give \\[D(t) = D_\\text{now} - \\int_t^\\text{now} v(t) dt .\\] Assuming that \\(v(t)\\) for each star has remained constant at \\(\\alpha D_\\text{now}\\), the distance travelled by each star since time \\(t\\) depends on it’s current distance like this: \\[\\int_t^\\text{now} v(t) dt = \\int_t^\\text{now} \\left[ \\alpha D_\\text{now}\\right]\\, dt = \\alpha D_\\text{now}\\left[\\text{now} - t\\right]\\] Thus, the position of each star at time \\(t\\) is \\[D(t) = D_\\text{now} - \\alpha D_\\text{now}\\left[\\text{now} - t\\right] = D(t)\\] or, \\[D(t) = D_\\text{now}\\left({\\large\\strut} 1-\\alpha \\left[\\text{now} - t\\right]\\right)\\]\nAccording to this model, there was a common time \\(t_0\\) when when all the stars were at the same place: \\(D(t_0) = 0\\). This happened when \\[\\text{now} - t_0 = \\frac{1}{\\alpha} = \\frac{1}{2.1 \\times 10^{-18}\\, \\text{s}^{-1}} = 4.8 \\times 10^{17} \\text{s}\\ .\\] It seems fair to call such a time, when all the stars where at the same place at the same time, as the origin of the universe. If so, \\(\\text{now} - t_0\\) corresponds to the age of the universe and our estimate of that age is \\(4.8\\times 10^{17}\\text{s}\\). Conventionally, this age is reported in years. To get that, we multiply by the flavor of one that turns seconds into years: \\[\\frac{60\\, \\text{seconds}}{1\\, \\text{minute}} \\cdot \\frac{60\\, \\text{minutes}}{1\\, \\text{hour}} \\cdot \\frac{24\\, \\text{hours}}{1\\, \\text{day}} \\cdot \\frac{365\\, \\text{days}}{1\\, \\text{year}} = 31,500,000 \\frac{\\text{s}}{\\text{year}}\\] The grand (but hypothetical) meeting of the stars therefore occurred \\(4.8 \\times 10^{17} \\text{s} / 3.15 \\times 10^{7} \\text{s/year} = 15,000,000,000\\) years ago. Pretty crowded to have all the mass in the universe in one place at the same time. No wonder they call it the Big Bang!"
  },
  {
    "objectID": "Accumulation/29-integration.html#exercises",
    "href": "Accumulation/29-integration.html#exercises",
    "title": "36  Integration",
    "section": "36.5 Exercises",
    "text": "36.5 Exercises"
  },
  {
    "objectID": "Accumulation/30-euler.html",
    "href": "Accumulation/30-euler.html",
    "title": "37  Integrals step-by-step",
    "section": "",
    "text": "The setting for anti-differentiation (and it’s close cousin, integration) is that we have a function \\(F(t)\\) which we do not yet know, but we do have access to some information about it: its slope as a function of time \\(f(t) \\equiv \\partial_t F(t)\\) and, perhaps, its value \\(F(t_0)\\) at some definite input value.\nSection 35 showed some ways to visualize the construction of an \\(F(t)\\) by accumulating short segments of slope. The idea is that we know \\(f(t)\\) which tells us, at any instant, the slope of \\(F(t)\\). So, in drawing a graph of \\(F(t)\\), we put our pen to paper at some input value \\(t_0\\) and then move forward in \\(t\\), setting the instantaneous slope of our curve according to \\(f(t)\\).\nIn Section 36, we dealt with one of the limitations of finding \\(F(t)\\) by anti-differentiation of \\(f(t)\\); the anti-derivative is not unique. This is because to start drawing \\(F(t)\\) we need pick a \\(t_0\\) and an initial value of \\(F(t_0)\\). If we had picked a a different starting point \\(t_1\\) or a different initial value \\(F(t_1)\\), the new curve would be different than the one drawn through \\((t_0, F(t_0))\\), although it would have the same shape, just shifted up or down according to our choice. We summarize this situation algebraically by writing \\[\\int f(t) dt = F(t) + C\\ ,\\] where \\(C\\) is the constant of integration, that is, the vertical shift of the curve.\nThe non-uniqueness of \\(F(t)\\) does not invalidate its usefulness. In particular, the quantity \\(F(b) - F(a)\\), will be the same regardless of which starting point we used to draw \\(F(t)\\). We have two names for \\(F(b) - F(a)\\)\nThese two things, the net change and the definite integral, are really one and the same, a fact we describe by writing \\[\\int_a^b f(t) dt = F(b) - F(a)\\ .\\]\nIn this chapter, we’ll introduce a simple numerical method for calculating from \\(f()\\) the net change/definite integral. This will be a matter of trivial but tedious arithmetic: adding up lots of little bits of \\(f(t)\\). Later, in Section 38, we’ll see how to avoid the tedious arithmetic by use of algebraic, symbolic transformations. This symbolic approach has great advantages, and is the dominant method of anti-differentiation found in college-level science textbooks. However, there are many common \\(f(t)\\) for which the symbolic approach is not possible, whereas the numerical method works for any \\(f(t)\\). Even more important, the numerical technique has a simple natural extension to some commonly encountered accumulation problems that look superficially like they can be solved by anti-differentiation but rarely can be in practice. We’ll meet one such problem and solve it numerically, but a broad approach to the topic, called dynamics or differential equations, will have to wait until Block 6."
  },
  {
    "objectID": "Accumulation/30-euler.html#euler-method",
    "href": "Accumulation/30-euler.html#euler-method",
    "title": "37  Integrals step-by-step",
    "section": "37.1 Euler method",
    "text": "37.1 Euler method\nThe starting point for this method is the definition of the derivative of \\(F(t)\\). Reaching back to Chapter 8,\n\\[\\partial_t F(t) \\equiv \\lim_{h\\rightarrow 0} \\frac{F(t+h) - F(t)}{h}\\] To translate this into a numerical method for computing \\(F(t)\\), let’s write things a little differently.\n\nFirst, since the problem setting is that we don’t (yet) know \\(F(t)\\), let’s refer to things we do know. In particular, we know \\(f(t) = \\partial_t F(t)\\).\nAgain, recognizing that we don’t yet know \\(F(t)\\), let’s re-write the expression using something that we do know: \\(F(t_0)\\). Stated more precisely, \\(F(t_0)\\) is something we get to make up to suit our convenience. (A common choice is \\(F(t_0)=0\\).)\nLet’s replace the symbol \\(h\\) with the symbol \\(dt\\). Both of them mean “a little bit of” and \\(dt\\) makes explicit that we mean “a little bit of \\(t\\).”\nWe’ll substitute the limit \\(\\lim_{h\\rightarrow 0}\\) with an understanding that \\(dt\\) will be something “small.” How small? We’ll deal with that question when we have to tools to answer it.\n\nWith these changes, we have \\[f(t_0) = \\frac{F(t_0+dt) - F(t_0)}{dt}\\ .\\] The one quantity in this relationship that we do not yet know is \\(F(t_0 + dt)\\). So re-arrange the equation so that we can calculate the unknown in terms of the known. \\[F(t_0 + dt) = F(t_0) + f(t_0)\\, dt\\ .\\]\n\nLet’s consider finding the anti-derivative of \\(\\dnorm()\\), that is, \\(\\int_0^t \\dnorm(x) dx\\). In one sense, you already know the answer, since \\(\\partial_x \\pnorm(x) = \\dnorm(x)\\). In reality, however, we know \\(\\pnorm()\\) only because it has been numerically constructed by integrating \\(\\dnorm()\\). The \\(\\pnorm()\\) function is so important that the numerically constructed answer has been memorized by software."
  },
  {
    "objectID": "Accumulation/30-euler.html#area",
    "href": "Accumulation/30-euler.html#area",
    "title": "37  Integrals step-by-step",
    "section": "37.2 Area",
    "text": "37.2 Area\nThe quantity \\[\\Large \\color{magenta}{f(t_0)}\\, \\color{orange}{dt}\\] gives rise to a visualization that has been learned by generations of calculus students. The visualization is so compelling and powerful that many students (and teachers, and textbook authors) mistake the visualization for integration and anti-differentiation themselves.\nWe’ll start the visualization with a simple graph of \\(f(t)\\), which is called the integrand in the integral \\(\\int_a^b f(t) dt\\). Figure 37.1 shows the graph of \\(f(t)\\). A specific point \\(t_0\\) has been marked on the horizontal axis. Next to it is another mark at \\(t_0 + dt\\). Of course, the distance between these marks is \\(\\color{orange}{dt}\\).\n\n\n\n\n\nFigure 37.1: Illustrating the interpretation of \\(f(t_0) dt\\) as an “area”.\n\n\n\n\nPer the usual graphical convention, a position along the vertical axis corresponds to a possible output of \\(f(t)\\). The output for \\(t=t_0\\) is \\(\\color{magenta}{f(t_0)}\\). That same quantity corresponds to the length of the vertical orange segment connecting \\((t_0, 0)\\) to \\((t_0, f(t_0))\\).\nThe \\(\\color{orange}{dt}\\) line segment and the \\(\\color{magenta}{f(t_0)}\\) segment constitute two sides of a rectangle, shown as a shaded zone. The “area” of that rectangle is the product \\(\\color{magenta}{f(t_0)}\\ \\color{orange}{dt}\\).\nIn this sort of visualization, an integral is the accumulation of many of these \\(f(t) dt\\) rectangles. For instance, Figure 37.2 the visualization of the integral \\[\\int_{0}^3 f(t) dt\\ .\\]\n\n## Warning in is.na(x): is.na() applied to non-(list or vector) of type\n## 'expression'\n\n## Warning in is.na(x): is.na() applied to non-(list or vector) of type\n## 'expression'\n\n## Warning in is.na(x): is.na() applied to non-(list or vector) of type\n## 'expression'\n\n\n\n\nFigure 37.2: Visualizing the integral \\(\\int_0^3 f(t) dt\\) as the total “area” of several \\(f(t) dt\\) bars. The width of each of the bars is \\(dt\\). The height depends on the value of the function \\(f(t)\\) at the bar. For illustration, two of the bars are marked with vertical and horizontal line segments.\n\n\n\n\nAs always in calculus, we imagine \\(dt\\) as a “small” quantity. In ?fig-bars-0-3B you can see that the function output changes substantially over the sub-domain spanned by a single rectangle. Using smaller and smaller \\(dt\\), as in ?fig-bars-0-3-small brings the visualization closer and closer to the actual meaning of an anti-derivative.\n\n\n\n\n\nVisualizing the integral \\(\\int_0^3 f(t) dt\\) as the total “area” of several \\(f(t) dt\\) bars. The width of each of the bars is \\(dt\\). The height depends on the value of the function \\(f(t)\\) at the bar. For illustration, two of the bars are marked with vertical and horizontal line segments.\n\n\n\n\n\nWhy do you keep putting “area” in quotes?\nWhen \\(f(t_i) < 0\\), then \\(f(t_i) dt\\) will be negative. There is no such thing as a negative area, but in constructing an integral the \\(f(t_i)dt\\), being negative, diminishes the accumulated area.\n\n\n\n\n\nFigure 37.3: The \\(\\int_{-2}^3 g(t) dt\\) covers subdomains where \\(g(t) > 0\\) and where \\(g(t) < 0\\). In those latter subdomains, the “area” is negative, and shown in light orange here.\n\n\n\n\nAnother problem is that area is a physical quantity, with dimension L\\(^2\\). The quantity produced by integration will have physical dimension \\([f(t)][t]\\), the product of the dimension of the with-respect-to quantity and the output of the function.\n“Area” is an effective metaphor for visualizing integration, but the goal of integration is not to calculate an area but, typically, some other kind of quantity."
  },
  {
    "objectID": "Accumulation/30-euler.html#the-euler-step",
    "href": "Accumulation/30-euler.html#the-euler-step",
    "title": "37  Integrals step-by-step",
    "section": "37.3 The Euler Step",
    "text": "37.3 The Euler Step\nThe previous section a visualization of an integral in terms of an area on a graph. As you know, a definite integral \\(\\int_a^b f(t) dt\\) can also be computed by constructing the anti-derivative \\(F(t) \\equiv \\int f(t) dt\\) and evaluating it at the upper and lower bounds of integration: \\(F(b) - F(a)\\). In this section, we’ll look at the numerical process of constructing an anti-derivative function, which uses many of the same concepts as those involved in finding an integral by combining areas of rectangles.\nA definite integral produces a quantity, not a function. The anti-derivative function constructed by using quantities like \\(f(t) dt\\) will be a series of quantities rather than a formula. In particular, it will have the form of a data table, something like this:\n\n\n\n\n\n\\(t\\)\n\\(F(t)\\)\n\n\n\n\n-2\n10.62\n\n\n-1.5\n6.47\n\n\n-1\n3.51\n\n\n-0.5\n2.02\n\n\n0\n2.4\n\n\n0.5\n3.18\n\n\n1.0\n5.14\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\nTo start, we’ll need to create a series of \\(t\\) values. We’ll do this by specifying a starting value for \\(t\\) and then creating successive values by adding a numerical increment \\(dt\\) to the entries one after the other until we reach a terminating value. For instance, in the above table, the starting value for \\(t\\) is \\(-2\\), the numerical increment is \\(dt=0.5\\), and the terminating value is \\(1\\).\nIn previous chapters of this book we have worked with data tables, but always the data table was given to us, we did not have to construct it.1 Now we need to construct the data frame with the \\(t\\) column containing appropriate values. Computer languages provide many ways to accomplish this task. We’ll use a simple R/mosaic function Picket(), which constructs a data table like the one shown above. You provide two arguments: the domain for \\(t\\), that is, the desired upper and lower bounds of integration; the interval size \\(dt\\) (which is called h in the argument list). For instance, to construct the \\(t\\) column of the table shown above, you can use Picket() this way:\n\nPts <- Picket(domain(t = -2:1), h=0.5)\nPts\n## # A tibble: 6 × 3\n##       t preweight weight\n##   <dbl>     <dbl>  <dbl>\n## 1  -2           1    0.5\n## 2  -1.5         1    0.5\n## 3  -1           1    0.5\n## 4  -0.5         1    0.5\n## 5   0           1    0.5\n## 6   0.5         1    0.5\n\nAs you can see, the data table produced by Picket() has the \\(t\\) column, as well as a second column named weight. We haven’t explained weight yet, but you can see that it is the same value we specified as h.\nThe name Picket() is motivated by the shape of a picket fence. The pickets are evenly spaced, which keeps things simple but is not a requirement.\nNote that the picket does not say anything at all about the function \\(f(t)\\) being anti-differentiated. The picket can be applied to any function although precision might require a smaller \\(dt\\) for functions that have a lot going on in a small domain.\nThe next step in using the picket to perform anti-differentiation is to apply the function \\(f()\\) to the pickets. That is, we’ll add a new column, perhaps called vals to the data table.\nAdding a new column is a common task when dealing with data. We’ll do this with a new function, mutate(), whose specific function is adding new columns (or modifying old ones). Here’s the command to apply \\(f()\\) to t and call the new column vals:\n\n# Find the height of the pickets\nPts <- Pts %>%\n  mutate(vals = f(t))\n\nWith this modification, the data table looks like:\n\n## # A tibble: 6 × 4\n##       t preweight weight  vals\n##   <dbl>     <dbl>  <dbl> <dbl>\n## 1  -2           1    0.5 -9.12\n## 2  -1.5         1    0.5 -7.27\n## 3  -1           1    0.5 -4.50\n## 4  -0.5         1    0.5 -1.46\n## 5   0           1    0.5  1.28\n## 6   0.5         1    0.5  3.31\n\nNow that we know the value of the function at each of the pickets, the next step is to multiply the value by the spacing between pickets. That spacing, which we set with the argument h = 0.5 in our original call to Picket() is in the column called weight. We’ll call the result of the multiplication step. Note that the following R command incorporates the previous calculation of vals; we’re looking to build up a single command that will do all the work.\n\n# Multiply the height by the picket spacing\nPts <- Pts %>%\n  mutate(vals = f(t),\n         step = vals * weight)\n\n\nPts\n## # A tibble: 6 × 5\n##       t preweight weight  vals   step\n##   <dbl>     <dbl>  <dbl> <dbl>  <dbl>\n## 1  -2           1    0.5 -9.12 -4.56 \n## 2  -1.5         1    0.5 -7.27 -3.63 \n## 3  -1           1    0.5 -4.50 -2.25 \n## 4  -0.5         1    0.5 -1.46 -0.732\n## 5   0           1    0.5  1.28  0.639\n## 6   0.5         1    0.5  3.31  1.66\n\nWe used the name step to identify the product of the height and spacing of the pickets to help you think about the overall calculation as accumulating a series of steps. Each step provides a little more information about the anti-derivative that we will now calculate. In terms of the area metaphor for integration, each step is the area of one vertical bar of the sort presented in the previous section.\nWe’ll call these Euler steps, a term that will be especially appropriate when, in Block 6, we use integration to calculate the trajectories of systems—such as a ball in flight—that change in time.\nThe final step in constructing the anti-derivative is to add up the steps. This is simple addition. But we’ll arrange the addition one step at a time. That is, for the second row, the result will be the sum of the first two steps. For the third row, the result will be the sum of the first three steps. And so on. The name for this sort of accumulation of the previous steps is called a cumulative sum. Another name for a cumulative sum is a “running sum”: the sum-so-far as we move down the column of steps. Cumulative sums are computed in R by using cumsum(). Here, we’re calling the result of the cumulative sum F to emphasize that it is the result of anti-differentiating \\(f()\\). But keep in mind that the anti-derivative is not just the F column, but the table with both t and F columns. That is, the table has a column for the input as well as the output. That’s what it takes to be a function.\n\n# Doing everything in one command\nPts <- \n  Picket(domain(t = -2:1), h=0.5) %>%\n  mutate(vals = f(t),\n         step = vals * weight,\n         F = cumsum(step))\n\n\n## # A tibble: 6 × 6\n##       t preweight weight  vals   step      F\n##   <dbl>     <dbl>  <dbl> <dbl>  <dbl>  <dbl>\n## 1  -2           1    0.5 -9.12 -4.56   -4.56\n## 2  -1.5         1    0.5 -7.27 -3.63   -8.19\n## 3  -1           1    0.5 -4.50 -2.25  -10.4 \n## 4  -0.5         1    0.5 -1.46 -0.732 -11.2 \n## 5   0           1    0.5  1.28  0.639 -10.5 \n## 6   0.5         1    0.5  3.31  1.66   -8.88\n\nWe can summarize the steps in this Euler approach to numerical integration graphically:\n\n\n\n\n\n{#fig-euler-integration1, fig-align=‘center’ width=90%}\n\n\n\n\n\n\n\nFigure 37.4: Steps in a numerical construction of an anti-derivative. (1) Create a set of picket locations over the domain of interest. The locations are spread horizontally by amount dt, so each picket will be dt units wide. (2) evaluate the original function at the picket points to give picket heights. (3) Multiply the picket height by the picket width to create an “area”. (4) Starting at zero for the left-most picket, add in successive picket areas to construct the points on the anti-derivative function (green). Note that the vertical axis in (4) has a different dimension and units than in steps (1)-(3). In (4) the vertical scale is in the units of the anti-derivative function output.\n\n\n\n\nFigure 37.5 shows a dynamic version of the process of constructing an anti-derivative by Euler steps. The integrand \\(f(t)\\) is shown in the top panel, the anti-derivative \\(F(t)\\) is shown being built up in the bottom panel. The \\(\\color{magenta}{\\text{magenta}}\\) bar in the top plot is the current Euler step. That step is added to the previously accumulated steps to construct \\(F(t)\\).\n\nPROVIDE LINK TO MOVIE IN PDF version.\n\n\n\n\n\n\nFigure 37.5: A dynamic view of building \\(F(t)\\) from \\(f(t)\\) by accumulating Euler steps.\n\n\n\n\n\nThe following graphic from a well-respected news magazine, The Economist, shows the reported number of cases and deaths from Covid-19 during a two-year period in Russia. (“Sputnik” is the name given to a Russian-developed vaccine, named after the first man-made satellite in Earth orbit, launched by the Soviet Union on Oct. 4, 1957 and precipitating a Cold-War crisis of confidence in in the US.)\n\n\n\n\n\n\n\n\n\nThe figure caption gives information about the units of the quantities being graphed. Notice the word “daily,” which tells us, for example, that in mid-2021 there were about 10,000 new cases of Covid-19 each day and correspondingly about 350 daily deaths.\nHow many total cases and total deaths are reported in the graphic?\nThere are, of course, two distinct ways to present such data which can be easily confused by the casual reader. One important way to present data is as cumulative cases and deaths as a function of date. We’ll call these \\(C(t)\\) and \\(D(t)\\). Another prefectly legitimate presentation is of the rate of change \\(\\partial_t C(t)\\) and \\(\\partial_t D(t)\\) which, following our informal capital/lower-case-letter convention, we could write \\(c(t)\\) and \\(d(t)\\). Since there is no such thing as a “negative” case or death, we know that \\(C(t)\\) and \\(D(t)\\) are monotonic functions, never decreasing. So the graphs cannot possibly be of \\(C(t)\\) and \\(D(t)\\), since the graphs are far from monotonic. Consequently, the displayed graphs are \\(c(t)\\) and \\(d(t)\\), as confirmed by the word “daily” in the caption.\nTo find \\(C(t)\\) and \\(D(t)\\) requires integrating \\(c(t)\\) and \\(d(t)\\). The value of \\(C(t)\\) and \\(D(t)\\) at the right-most extreme of the graph can be found by calculating the “area” under the \\(c(t)\\) and \\(d(t)\\) curves. But care needs to be taken in reading the horizontal axis. Although the axes are labelled with the year, the tick marks are spaced by one month. (Notice “month” does not appear in the caption.) The far right end of the graph is in early July 2021. The far left end, when the graph moves away from zero cases and deaths, is early April 2020.\nYou can do a reasonable job estimating the “area” by extending the tick marks on the horizontal axis and counting the resulting rectangles that fall under the curve.\n\n\n\n\n\n\n\n\n\nFor the graph of cases, the “area” of each rectangle is \\(\\frac{5000\\, \\text{cases}}{\\text{ day}}\\cdot \\text{1 month}\\). This has the right dimension, “cases,” but the units are screwy. So replace 1 month with 30.5 days (or thereabouts) to get an “area” of each rectangle of 172,500 cases. Similarly, the “area” of the rectangles on the right graph is 3050 deaths."
  },
  {
    "objectID": "Accumulation/30-euler.html#better-numerics-optional",
    "href": "Accumulation/30-euler.html#better-numerics-optional",
    "title": "37  Integrals step-by-step",
    "section": "37.4 Better numerics (optional)",
    "text": "37.4 Better numerics (optional)\nExcept as a textbook exercise, you will likely never have to compute a numerical anti-derivative from scratch as we did in the previous section. This is a good thing. To understand why, you have to know one of the important features of modern technical work. That feature is: We never work alone in technical matters. There is always a set of people whose previous work we are building on, even if we never know the names of those people. This is because technology is complicated and it is evidently beyond the reach of any human to master all the salient aspects of each piece of technology being incorporated into the work we consider our own.\nOf course this is true for computers, since no individual can build a useful computer from first principles. It’s also true for software. One detail in particular is relevant to us here. Computer arithmetic of the sort used in the previous section—particularly addition—is prone to error when adding up lots and lots of small bits. This means that it is not always sensible to choose very small \\(dt\\) in order to get a very accurate approximation to the anti-derivative.\nFortunately, there are specialists in numerical mathematics who work on ways to improve the accuracy of calculations for mid-sized \\(dt\\). Their work has been incorporated into the results of antiD() and Integrate() and so the details are, for us, unimportant. But they are only unimportant because they have been taken care of.\nTo illustrate how considerably more accuracy can be gained in calculating an anti-derivative, consider that the rectangular bars drawn in the previous sections are intended to approximate the “area” under the function. With this in mind, we can replace the rectangular bars with more suitable shapes that stay closer to the function over the finite extend of each \\(dt\\) domain. The rectangular bars model the function as piecewise constant. A better job can be done with piecewise linear approximations or piecewise quadratic approximations. Often, such refinements can be implemented merely by changing the weight column in the picket data frame used to start off the process.\nOne widely used method, called Gauss-Legendre quadrature can calculate a large segment of an integral accurately (under conditions that are common in practice) with just five evaluations of the integrand \\(f(t)\\).\n\n\n\nPicket locations and weights For the integral \\(\\int_a^b f(t) dt\\) where \\(c = \\frac{a+b}{2}\\) and \\(w = (b-a)/2\\).\n\n\n\n\n\n\nlocation\nweight\n\n\n\n\n\\(c - 0.90618 w\\)\n\\(0.236927 \\times w\\)\n\n\n\\(c - 0.53847 w\\)\n\\(0.478629 \\times w\\)\n\n\n\\(c\\)\n\\(0.568889 \\times w\\)\n\n\n\\(c + 0.53847 w\\)\n\\(0.478629 \\times w\\)\n\n\n\\(c + 0.90618 w\\)\n\\(0.236927 \\times w\\)\n\n\n\n\n\nThe locations and weights may seem like a wizard parody of mathematics, but those precise values are founded in an advanced formulation of polynomials rooted in the theory of linear combinations to which you’ll be introduced in Block 5. Needless to say, you can hardly be expected to have any idea where they come from. That’s why it’s useful to build on the work of experts in specialized areas. It’s particularly helpful when such expertise is incorporated into software that faithfully and reliably implements the methods. The lesson to take to heart: Use professional software systems that have been extensively vetted."
  },
  {
    "objectID": "Accumulation/30-euler.html#exercises",
    "href": "Accumulation/30-euler.html#exercises",
    "title": "37  Integrals step-by-step",
    "section": "37.5 Exercises",
    "text": "37.5 Exercises"
  },
  {
    "objectID": "Accumulation/31-symbolic.html",
    "href": "Accumulation/31-symbolic.html",
    "title": "38  Symbolic anti-differentiation",
    "section": "",
    "text": "You have already learned how to write down, by sight, the anti-derivative of the many of the pattern-book functions. As a reminder, here is an (almost) complete list of the derivatives and anti-derivatives of the pattern-book functions.\nYou can see that the derivatives and anti-derivatives of the pattern-book functions can be written in terms of the pattern-book functions. The left column contains the symbolic derivatives of the pattern book functions.1 The right column contains the symbolic anti-derivatives. We call them “symbolic,” because they are written down with the same kind of symbols that we use for writing the pattern-book functions themselves.2\nWe’re stretching things a bit by including \\(\\dnorm(x)\\) and \\(\\pnorm(x)\\) among the functions that can be integrated symbolically. As you’ll see later, \\(\\dnorm(x)\\) is special when it comes to integration.\nThink of the above table as the “basic facts” of differentiation and anti-differentiation. It’s well worth memorizing the table since it shows many of the relationships among the functions that are central to this book. For the sinusoids, we’ve used the traditional name \\(\\cos(x)\\) to refer to \\(\\sin(x + \\pi/2)\\) and \\(-\\cos(x)\\) instead of \\(\\sin(x - \\pi/2)\\) since generations of calculus students have been taught to name “cosine” as the derivative of “sine,” and don’t always remember the relationship that \\(\\cos(x) =\\sin(x + \\pi/2)\\).\nFor differentiation, any function that can be written using combinations of the pattern-book functions by multiplication, composition, and linear combination has a derivative that can be written using the pattern-book functions. So a complete story of symbolic differentiation is told by the above table and the differentiation rules:\nThis chapter is about the analogous rules for anti-differentiation. The anti-differentiation rule for linear combination is simple: essentially the same as the rule for differentiation.\n\\[\\int \\left[\\strut a\\, f(x) + b\\, g(x)\\right] dx = a\\!\\int\\! f(x) dx + b\\!\\int\\! g(x) dx\\] How about the rules for function products and for composition? The surprising answer is that there are no such rules. There is no template analogous to the product and chain rules for derivatives, that can consistently be used for anti-derivatives. What we have instead are techniques of integration, somewhat vague rules that will sometimes guide a successful search for the anti-derivative, but often will lead you astray.\nIndeed, there are many functions for which a symbolic anti-derivative cannot be constructed from compositions and/or multiplication of pattern-book functions that can be written using pattern-book functions.3\nFortunately, we already know the symbolic anti-derivative form of many functions. We’ll call those the cataloged functions, but this is not a term in general use in mathematics. For functions not in the catalog, it is non-trivial to find out whether the function has a symbolic anti-derivative or not. This is one reason why the techniques of integration do not always provide a result.\nThe following sections provide an overview of techniques of integration. We start with a description of the cataloged functions and direct you to computer-based systems for looking up the catalog. (These are almost always faster and more reliable than trying to do things by hand.) Then we introduce a new interpretation of the notation for anti-differentiation: differentials. This interpretation makes it somewhat easier to understand the major techniques of integration: substitution and integration by parts. We’ll finish by returning to a setting where symbolic integration is easy: polynomials.\nRemember that, even if we cannot always find a symbolic anti-derivative, that we can always construct a numerical anti-derivative that will be precise enough for almost any genuine purpose."
  },
  {
    "objectID": "Accumulation/31-symbolic.html#sec-cataloged-functions",
    "href": "Accumulation/31-symbolic.html#sec-cataloged-functions",
    "title": "38  Symbolic anti-differentiation",
    "section": "38.1 The cataloged functions",
    "text": "38.1 The cataloged functions\nIn a traditional science or mathematics education, students encounter (almost exclusively) basic functions from a mid-sized catalog. For instance: \\(\\sqrt{\\strut\\_\\_\\_\\ }\\), \\(\\sin()\\), \\(\\cos()\\), \\(\\tan()\\), square(), cube(), recip(), \\(\\ln()\\), \\(\\exp()\\), negate(), gaussian(), and so on. This catalog also includes some functions that take two arguments but are traditionally written without using parentheses. For instance, \\(a+b\\) doesn’t look like a function but is entirely equivalent to \\(+(a, b)\\). Others in this class are \\(\\times(\\ ,\\ )\\), \\(\\div(\\ , \\ )\\), \\(-(\\ ,\\ )\\), and ^( , ).\nThe professional applied mathematician’s catalog is much larger. You can see an example published by the US National Institute of Standards and Technology as the Digital Library of Mathematical Functions. (Almost all of the 36 chapters in this catalog, important though they be, are highly specialized and not of general interest across fields.)\nThere is a considerable body of theory for these cataloged functions, which often takes the form of relating them to one another. For instance, \\(\\ln(a \\times b) = \\ln(a) + \\ln(b)\\) demonstrates a relationship among \\(\\ln()\\), \\(+\\) and \\(\\times\\). Along the same lines of relating the cataloged functions to one another is \\(\\partial_x \\sin(x) = \\cos(x)\\) and other statements about derivatives such as those listed in Chapter Section 20.\nSimply to illustrate what a function catalog looks like, Figure 38.1 shows a page from an 1899 handbook entitled A Short Table of Integrals.\n\n\n\n\n\n\nFigure 38.1: Entries 124-135 from A Short Table of Integrals (1899) by Benjamin Osgood Pierce. The book includes 938 such entries.\n\n\n\nThe use of cataloged functions is particularly prevalent in textbooks, so the quantitatively sophisticated student will encounter symbolic anti-derivatives of these functions throughout his or her studies.\nThe cataloged functions were assembled with great effort by mathematicians over the decades. The techniques and tricks they used to find symbolic anti-derivatives are not part of the everyday experience of technical workers, although many mathematically minded people find them a good source of recreation.\nCalculus textbooks that include extensive coverage of the techniques and tricks should be understood as telling a story of the historical construction of catalogs, rather than conveying skills that are widely used today. In a practical sense, when the techniques are needed, it’s more reliable to access them via computer interface such as WolframAlpha, as depicted in Figure 38.2.\n\n\n\n\n\n\nFigure 38.2: Pierce’s entry 125 as computed by the WolframAlpha system.\n\n\n\nThe systems can do a good job identifying cases where the techniques will not work. In such systems, they provide the anti-derivative as constructed by numerical integration. The R/mosaic antiD() function works in this same way, although its catalog contains only a tiny fraction of the functions found in professional systems. (But then, only a tiny fraction of the professional cataloged function are widely used in applied work.)"
  },
  {
    "objectID": "Accumulation/31-symbolic.html#differentials",
    "href": "Accumulation/31-symbolic.html#differentials",
    "title": "38  Symbolic anti-differentiation",
    "section": "38.2 Differentials",
    "text": "38.2 Differentials\nBreathing some life into the symbol \\(dx\\) will help in understanding the algebra of techniques for anti-differentiating function compositions and products. We’ve thus far presented \\(dx\\) as a bit of notation: punctuation for identifying the with-respect-to input in anti-derivatives. That is, in interpreting a sequence of symbols like \\(\\int f(x,t) dx\\), we’ve parsed the sequence of symbols into three parts:\n\\[\\underbrace{\\int}_{\\text{integral sign}} \\overbrace{f(x, t)}^{\\text{function to be anti-differentiated}} \\underbrace{dx}_{\\text{'with respect to'}}\\]\nBy analogy, the English sentence\n\\[\\text{We loaded up on snacks.}\\]\nconsists of five parts: the five words in the sentence.\nBut you can also see “We loaded up on snacks” as having three parts:\n\\[\\underbrace{\\text{We}}_{\\text{subject}}\\  \n\\overbrace{\\text{loaded up on}}^{\\text{verb}}\\ \\ \\\n\\underbrace{\\text{snacks}}_{\\text{object}}\\]\nLikewise, the integrate sentence can be seen as consisting of just two parts:\n\\[\\underbrace{\\int}_{\\text{integral sign}} \\overbrace{f(x, t) dx}^{\\text{differential}}\\]\nA differential corresponds to the little sloped segments that we add up when calculating a definite integral numerically using the slope function visualization. That is \\[\\underbrace{\\int}_{\\text{Sum}} \\underbrace{\\overbrace{f(x,t)}^\\text{slope of segment}\\ \\  \\overbrace{dx}^\\text{run}}_\\text{rise}\\]\nA differential is a genuine mathematical object and is used, for example, in analyzing the geometry of curved spaces, as in the Theory of General Relativity. But this is well beyond the scope of this introductory calculus course.\nOur use here for differentials will be to express rules for anti-differentiation of function compositions and products.\nYou should be thinking in terms of differentials when you see a sentence like the following:\n\n“In \\(\\int \\sin(x) \\cos(x) dx\\), make the substitution \\(u = \\sin(x)\\), implying that \\(du = \\cos(x) dx\\) and getting \\(\\int u du\\), which is simple to integrate.”\n\nThe table gives some examples of functions and their differentials. “w.r.t” means “with respect to.”\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\nFunction\nderivative\nw.r.t.\ndifferential\n\n\n\n\n\\(v(x) \\equiv x\\)\n\\(\\partial_x v(x) = 1\\)\nx\n\\(dv = dx\\)\n\n\n\\(u(x) \\equiv x^2\\)\n\\(\\partial_x u(x) = 2x\\)\nx\n\\(du = 2x dx\\)\n\n\n\\(f(x) \\equiv \\sin(x)\\)\n\\(\\partial_x f(x) = \\cos(x)\\)\nx\n\\(df = \\cos(x)dx\\)\n\n\n\\(u(x) \\equiv e^{3 x}\\)\n\\(\\partial_x u(x) = 3 e^{3 x}\\)\nx\n\\(du = 3 e^{3 x} dx\\)\n\n\n\\(g(x) \\equiv t^3\\)\n\\(\\partial_t v(t) = 3 t^2\\)\nt\n\\(dg = 3 t^2 dt\\)\n\n\n\n\n\n\nAs you can see, the differential of a function is simply the derivative of that function followed by the little \\(dx\\) or \\(dt\\) or whatever is appropriate for the “with respect to” input.\nNotice that the differential of a function is not written with parentheses: The function \\(u(x)\\) corresponds to the differential \\(du\\).\n\nWhat is the differential of \\(\\sin(x)\\)?\nAs we’ve seen, \\(\\partial_x \\sin(x) = cos(x)\\). For form the differential of \\(\\sin()\\), take the derivative and suffix it with a \\(dx\\) (since \\(x\\) is the name of the input):\n\\[\\cos(x)\\ dx\\]"
  },
  {
    "objectID": "Accumulation/31-symbolic.html#u-substitution",
    "href": "Accumulation/31-symbolic.html#u-substitution",
    "title": "38  Symbolic anti-differentiation",
    "section": "38.3 U-substitution",
    "text": "38.3 U-substitution\nThere is little reason to use \\(\\partial_t\\) and \\(\\int \\left[\\right]dt\\) to cancel each other out, but it is the basis of an often successful strategy—u-substitution—for finding anti-derivatives symbolically. Here’s the differentiate/integrate algorithm behind u-substitution.\n\nPick a function \\(f()\\) and another function \\(g()\\). Typically \\(f()\\) and \\(g()\\) belong to the family of basic modeling functions, e.g. \\(e^x\\), \\(\\sin(t)\\), \\(x^n\\), \\(\\ln(x)\\), and so on. For the purpose of illustration, we’ll use \\(f(x) = \\ln(x)\\) and \\(g(t) = \\cos(t)\\).\nCompose \\(f()\\) with \\(g()\\) to produce a new function \\(f(g())\\) which, in our case, will be \\(\\ln(\\cos(t))\\).\nUse the chain rule to find \\(\\partial_t f(g(t))\\). In the example, the derivative of \\(\\ln(x)\\) is \\(1/x\\), the derivative of \\(g(t)\\) is \\(-\\sin(t)\\). By the chain rule, \\[\\partial_t f\\left(\\strut g(t)\\right) = \\partial_t \\underbrace{\\Large\\ln}_{f()}\\left(\\underbrace{\\large\\cos(t)}_{g(t)}\\right) = \\underbrace{\\left[- \\frac{1}{\\cos(t)}\\right]}_{f'(g(t))} \\underbrace{\\left[{\\LARGE\\strut}\\sin(t)\\right]}_{g'(t)} = -  \\frac{\\sin(t)}{\\cos(t)} = - \\tan(t)\\]\n\nIn a sense, we have just watched a function give birth to another through the straightforward process of differentiation. Having witnessed the birth, we know who is the integration parent of \\(\\tan(t)\\), namely \\(\\int \\tan(t) dt = \\ln\\left(\\cos(t)\\right)\\). For future reference, we might write this down in our diary of integrals: \\[\\int \\tan(t) dt = - \\ln(\\cos(t)) + C\\] Saving this fact in your diary is helpful. The next time you need to find \\(\\int \\tan(x) dx\\), you can look up the answer (\\(-\\ln(\\cos(x)) + C\\)) from your diary. If you use \\(\\int \\tan(x) dx\\) a lot, you will probably come to memorize the answer, just as you have already memorized that \\(\\int \\cos(t) dt = \\sin(t)\\) (a fact that you will use a lot in the rest of this course).\nNow for the u-substitution game. The trick is to take a problem of the form \\(\\int h(t) dt\\) and extract from \\(h(t)\\) two functions, an \\(f()\\) and a \\(g()\\). You’re going to do this so that \\(h(t) = \\partial_t F(g(t))\\), where \\(\\partial_x F(x) = f(x)\\) Once you’ve done this, you have an answer to the original integration question: \\(\\int h(t) dt = F(g(t)) + C\\).\n\nTask: Evaluate the definite integral \\(\\int \\frac{\\sin(\\ln(x))}{x} dx\\).\nYou don’t know ahead of time that this is an integral amenable to solution by u-substitution. For all you know, it’s not. So before you start, look at the function to see if it one of those for which you already know the anti-derivative, for example any of the pattern-book functions or their parameterized cousins the basic modeling functions.\n\nIf so, you’ve already memorized the answer and you are done. If not …\n\nAssume for a moment—without any guarantee that this will work, mind you—that the answer can be built using u-substitution. You will therefore look hard at \\(h()\\) and try to see in it a plausible form that looks like the derivative of some \\(f(g(x))\\).\nIn the problem at hand, we can readily see something of the form \\(f(g(x))\\) in the \\(\\sin(\\ln(x))\\). This immediately gives you a candidate for \\(g(x)\\), namely \\(g(x)\\equiv \\ln(x)\\) We don’t know \\(f()\\) yet, but if \\(g()\\) is the right guess, and if u-substitution is going to work, we know that \\(f()\\) has to be something that produces \\(\\sin()\\) when you differentiate it. That’s \\(-\\cos()\\). So now we have a guess \\[h_\\text{guess}(x) = -\\cos(\\ln(x)) \\partial_x \\ln(x) = - \\cos(\\ln(x)) \\frac{dx}{x}\\]\n\nIf this guess matches the actual \\(h()\\) then you win. The answer to \\(\\int h(x) dx\\) will be \\(f(g(x)) = -\\cos(\\ln(x))\\). If not, see if there is any other plausible guess for \\(g(x)\\) to try. If you can’t find one that works, try integration by parts."
  },
  {
    "objectID": "Accumulation/31-symbolic.html#integration-by-parts-standard-presentation",
    "href": "Accumulation/31-symbolic.html#integration-by-parts-standard-presentation",
    "title": "38  Symbolic anti-differentiation",
    "section": "38.4 Integration by parts (standard presentation)",
    "text": "38.4 Integration by parts (standard presentation)\nIf you do a lot of symbolic anti-differentation, you will often come across functions that you don’t recognize as being the derivative of an already known function. Consider, for instance, \\[\\int x \\cos(x) dx\\ .\\]\nEven though the integrand \\(x \\cos(x)\\) is a simple product of two pattern book functions it is likely not a function that you have previously produced by differentiation. Thus, it’s not yet in your diary of anti-derivatives. The purpose of integration by parts is to provide a standard way to re-organize anti-derivatives like \\(\\int x \\cos(x) dx\\), where the integrand is a product of two simple functions, into another form. Being able to do this is no guarantee that the other form will be something you can anti-differentiate, but it’s worth rolling the dice to see if you get lucky.\nThe re-organization rule is based on two fundamental properties of differentiation and anti-differentiation.\n\n\\(\\int f'(x) dx = f(x)\\). This is saying nothing more than if \\(f'(x)\\) is the derivative of \\(f(x)\\), then \\(f(x)\\) must be an anti-derivative of \\(f'(x)\\).\n\\(\\partial_x \\left[\\strut u(x)\\cdot v(x) \\right] = u'(x)\\cdot v(x) + v'(x)\\cdot u(x)\\): the product rule of differentiation.\n\nLet’s integrate both sides of the statement of the product rule. For the left side, applying rule (i), we get a simple result:\n\\[\\int\\left[\\strut\\partial_x \\left[\\strut u(x)\\cdot v(x) \\right]\\right] dx = u(x) \\cdot v(x)\\]\nAs for the right side, all we get is two anti-derivatives: \\[\\int\\left[\\strut u'(x)\\cdot v(x) + v'(x)\\cdot u(x)\\right]dx =\n\\int\\left[\\strut u'(x)\\cdot v(x)\\right]dx + \\int\\left[\\strut u(x)\\cdot v'(x)\\right]dx\\] Putting together the previous two expressions and re-arranging gives: \\[\\int u(x)\\cdot v'(x)\\, dx = u(x) \\cdot v(x) - \\int  v(x)\\cdot u'(x)dx\\ \\ \\ \\mathbf{ \\text{parts re-arrangment}}\\] Now, consider a problem like \\(\\int x \\cdot \\cos(x) dx\\) that we don’t yet know how to solve. Let’s associate this problem with the left side of the parts re-arrangement equation. With luck, we will recognize a problem that we’ll know how to do on the right-hand side.\nTo implement the re-arrangement, we need to split our as yet unknown anti-derivative into two pieces: \\(u(x)\\) and \\(v'(x) dx\\). There are many possible ways to do this but the most obvious is \\[\\int \\underbrace{\\strut x}_{u(x)} \\cdot \\underbrace{\\cos(x) dx}_{v'(x) dx}\\] According to this proposed splitting, we have \\(u(x) = x\\) and \\(v'(x) dx = \\cos(x) dx\\). To plug things into the right side of the parts re-arrangement we’ll need to find \\(v(x)\\) and \\(u'(x) dx\\). Since we know \\(u(x) = x\\) it’s easy to take the differential, \\(du = dx\\). Similarly, we know \\(v'(x) dx = \\cos(x) dx\\) so we can integrate both sides: \\[v(x) = \\underbrace{\\int v'(x) dx = \\int \\cos(x) dx}_{\\text{from }\\ v'(x)\\,dx\\ =\\ \\cos(x)\\,dx} = \\sin(x)\\] Now that we know the \\(v(x)\\) that’s consistent with our original splitting of the anti-derivative into \\(\\int u(x) \\cdot v'(x) dx\\) we can plug in our results to the right side of the parts re-arrangement equation:\n\\[\\int x \\cdot \\cos(x)dx = x \\sin(x) - \\int \\underbrace{\\sin(x)}_{v(x)}\\  \\underbrace{\\ 1\\ dx\\ \\strut}_{u'(x) dx}\\] We’re in luck! We already know the anti-derivative \\(\\int \\sin(x) dx = -\\cos(x)\\). Substituting this result for the \\(\\int v(x) u'(x) dx\\) term, we arrive at \\[\\int x \\cdot \\cos(x)dx = x \\sin(x) + \\cos(x)\\ .\\]\nThe key creative step in using integration by parts effectively is to choose a helpful split of the original integral into the \\(u(x)\\) and \\(v'(x) dx\\) parts. This is usually based on a solid knowledge of derivatives and anti-derivatives of basic functions as well as insight into the downstream consequences of any choice. In this sense, picking \\(u(x)\\) and \\(v'(x)dx\\) is like making a move in chess. Some players can see two or three moves ahead and so can pick the first move to improve their position. Without such foresight, the best most people can do is to pick a first move that seems attractive and accept that their fate might be either victory or checkmate.\nFor the calculus student learning integration by parts, there is an irony. Gaining enough experience to make good choices of \\(u(x)\\) and \\(v'(x)dx\\) means that you will solve, or read about solving, many anti-differentiation problems. You can, of course, enter the solutions into your diary of anti-derivatives, obviating to that extent the need to perform integration by parts in the future.\n\nIn demonstrating that \\[\\int x \\cdot \\cos(x)dx = x \\sin(x) + \\cos(x)\\] we followed a number of steps each of which might be subject to error. Best to confirm our solution before accepting it. This can be done by differentiating both sides of our solution: \\[\\partial_x \\int x \\cdot \\cos(x)dx = x \\cos(x) = \\partial_x \\left[\\strut x \\sin(x) + \\cos(x)\\right] = \\underbrace{\\sin(x) + x \\cos(x)}_{\\partial_x \\left[x\\cdot\\sin(x)\\right]}\\  \\underbrace{- \\sin(x)}_{\\partial_x \\cos(x)}= x\\cos(x)\\]\n\n\nWhat would happen in the previous example if we had made a bad choice for \\(u(x)\\) and \\(v'(x) dx\\)? For instance, we might have split \\(x \\cos(x) dx\\) into \\(u(x) = \\cos(x)\\) and \\(v'(x)\\,dx = x\\, dx\\). Working out \\(u'(x)\\,dx\\) and \\(v(x)\\) is easy: \\(u'(x)\\, dx = -\\sin(x)\\, dx\\) and \\(v(x) = \\frac{1}{2} x^2\\). Plugging into the re-arrangement formula gives:\n\\[\\int x \\cdot \\cos(x)\\,dx = \\frac{1}{2} x^2 \\cos(x) - \\int \\frac{1}{2} x^2 \\left[\\strut - \\sin(x)\\right]\\,dx = \\frac{1}{2} x^2 \\cos(x) + \\int \\frac{1}{2} x^2  \\sin(x)\\,dx\\] Unless you know \\(\\int x^2 \\sin(x) dx\\), this re-arrangement leaves you no better off than at the beginning.\nOn the other hand … if you are in the business of compiling diaries of anti-derivatives, you could use this situation to chalk up another entry based on already knowing \\(\\int x \\cdot \\cos(x) dx\\): \\[\\int x^2 \\sin(x) dx = 2 \\int x\\cdot \\cos(x)dx - x^2\\cos(x) = 2x\\sin(x) + 2\\cos(x) - x^2 \\cos(x)\\]\n\n\nFind \\(\\int x \\ln(x) dx\\).\nLet \\(u(x) = \\ln(x)\\) and \\(v'(x)dx = x dx\\).\nThen, \\(u'(x)dx = \\frac{1}{x} dx\\) and \\(v(x) = \\frac{1}{2} x^2\\).\nUsing the parts re-arrangement formula …\n\\[\\int x \\ln(x) dx = \\frac{1}{2} x^2 \\cdot \\ln(x) - \\int \\frac{1}{2} x^2\\cdot \\frac{1}{x}\\, dx \\\\\n\\frac{1}{2} x^2 \\cdot \\ln(x) - \\frac{1}{4} x^2\\] And don’t forget, after all this work, to add the constant of integration \\(C\\)!"
  },
  {
    "objectID": "Accumulation/31-symbolic.html#integration-by-parts-optional-alternative-presentation",
    "href": "Accumulation/31-symbolic.html#integration-by-parts-optional-alternative-presentation",
    "title": "38  Symbolic anti-differentiation",
    "section": "38.5 Integration by parts (optional alternative presentation)",
    "text": "38.5 Integration by parts (optional alternative presentation)\nIntegration by parts applies to integrals that are recognizably of the form \\[\\int f(x) g(x) dx\\] Step 1: Split up the integrand into an \\(f(x)\\) and a \\(g(x)\\) multiplied together. That is, split the integrand into parts that are multiplied together. The way we wrote the integrand, this was trivial.\nStep 2: Pick one of \\(f(x)\\) or \\(g(x)\\). Typically, you pick the one that has a dead-easy anti-derivative. For our general description, let’s suppose this is \\(g(x)\\) which has anti-derivative \\(G(x)\\) (where we know \\(G()\\)).\nStep 3: Construct a helper function \\(h(x) \\equiv f(x) G(x)\\). This requires no work, since we’ve already identified \\(f(x)\\) and \\(G(x)\\) in step (2).\nStep 4: Find \\(\\partial_x h(x)\\). It’s always easy to find derivatives, and here we just use the product rule: \\[\\partial_x h(x) = \\partial_x f(x) \\cdot G(x) + f(x)\\cdot\\partial_x G(x)\\] We know from the way we constructed \\(G(x)\\) that \\(\\partial_x G(x) = g(x)\\), so the equation is \\[\\partial_x h(x) = \\partial_x f(x) \\cdot G(x) + f(x)\\cdot g(x)\\]\nStep 5: Anti-differentiate both sides of the previous equation. From the fundamental theorem of calculus, we know how to do the left side of the equation. \\[\\int \\partial_x h(x) = h(x) \\equiv f(x)g(x)\\] The right side of the equation has two parts: \\[\\int \\left[{\\large\\strut}\\partial_x f(x) \\cdot G(x) + f(x)\\cdot g(x)\\right]dx = \\underbrace{\\int \\partial_x f(x) \\cdot G(x) dx}_\\text{Some NEW integral!}\\ \\ \\ \\  + \\underbrace{\\int f(x) g(x) dx}_\\text{The original integral we sought!}\\] Putting together the left and right sides of the equation, and re-arranging gives us a new expression for the original integral we sought to calculate: \\[\\text{Integration by parts re-arrangement}\\\\\\underbrace{\\int f(x) g(x) dx}_\\text{The original integral we sought.} = \\underbrace{f(x) g(x)}_\\text{We know this!}  - \\underbrace{\\int \\partial_x f(x) \\cdot G(x) dx}_\\text{Some NEW integral!}\\] It may seem that we haven’t accomplished much with this re-organization. But we have done something. We took a problem we didn’t otherwise know how to solve (that is \\(\\int f(x) g(x) dx\\)) and broke it down into two parts. One is very simple. The other is an integral. If we’re clever in picking \\(g()\\) and lucky, we’ll be able to figure out the new integral and, thereby, we’ll have computed the original integral. But everything depends on cleverness and luck!\n\nTask: Find \\(\\int x \\cos(x) dx\\).\nAn obvious choice for the two parts is \\(x\\) and \\(\\cos(x)\\). But which one to call \\(g(x)\\). We’ll just guess and say \\(g(x)\\equiv \\cos(x)\\) which implies \\(G(x) = \\sin(x)\\). The helper function is \\(h(x) \\equiv f(x) G(x) = x \\sin(x)\\).\nDifferentiating \\(h(x)\\) can be done by the product rule. \\[\\partial_x h(x) = \\sin(x) + x \\cos(x)\\ .\\] Now anti-differentiate both sides of the above, the left side by the fundamental theorem of algebra and the right side by other means: \\[\\int \\partial_x h(x) = h(x) = x \\sin(x)= \\underbrace{\\int\\sin(x)dx}_{-\\cos(x)} + \\underbrace{\\int x \\cos(x) dx}_\\text{The original integral}\\] Re-arranging gives the answer \\[\\underbrace{\\int x \\cos(x) dx}_\\text{The original integral} = x \\sin(x) + \\cos(x) + C\\] The constant of integration \\(C\\) needs to be included to make the equality true.\nTo confirm the result, you can differentiate the right-hand side; differentiation is always easy.\nAlternatively, we can check numerically if \\(\\int x \\cos(x) dx - (x\\sin(x)+cos(x))\\) is a constant. (See @fig-check-constant).)\n\nF1 <- antiD(x*cos(x) ~ x)\nF2 <- makeFun(x*sin(x) + cos(x) ~ x)\nslice_plot(F1(x) - F2(x) ~ x, domain(x=-5:5))\n\n\n\n\n\nFigure 38.3: ?(caption)\n\n\n\n\n\nTask: Find \\(\\int \\ln(x) dx\\).\nThe easy solution is to recognize that the anti-derivative of \\(\\ln(x)\\) is contained in the table at the top of the chapter. But let’s try doing it by parts as an example (and to show you how it got into the table in the first place).\nIt’s hard to see a separate \\(f(x)\\) and \\(g(x)\\) in the integrand \\(\\ln(x)\\). But sometimes you need to be clever. We’ll set \\(f(x) \\equiv \\ln(x)\\) and \\(g(x) \\equiv 1\\). This means that \\(G(x) = x\\). The helper function is therefore \\(h(x) = x\\ln(x)\\)\nDifferentiating the helper function gives (by the product rule): \\(\\partial_x h(x) = \\ln(x) + x \\frac{1}{x} = \\ln(x) + 1\\)\nIntegrating the differentiated helper function, we find \\[\\int \\partial_x h(x) dx = f(x)g(x) = x \\ln(x) = \\underbrace{\\int \\ln(x) dx}_\\text{The original integral} + \\underbrace{\\int 1 dx}_{x}\\] Re-arranging, we have \\[\\underbrace{\\int \\ln(x) dx}_\\text{The original integral} = x \\ln(x) - x\\ \\  =\\ \\  x\\left[\\strut \\ln(x) - 1\\right]\\]\n\n\nTask: Find \\(\\int \\sin(x) e^x dx\\).\nThis isn’t the integral of a pattern book or basic modeling function, and substitution didn’t work, so we try integration by parts.\nThe obvious choice for the two parts is \\(\\sin(x)\\) and \\(e^x\\). Both are really easy to anti-differentiate. Let’s choose \\(g(x) = \\sin(x)\\), giving \\(G(x) = -\\cos(x)\\). The re-arrangement of the original integral will be \\[\\sin(x) e^x + \\int \\cos(x) e^x dx\\] The new integral that we need to compute doesn’t look any friendlier than the original, but who knows? We’ll do \\(\\int cos(x) e^x dx\\) by parts as well and keep our fingers crossed. That integral turns out to be \\[\\int \\cos(x) e^x dx = \\cos(x) e^x - \\int \\sin(x) e^x dx\\] This may look like we’re going in circles, and maybe we are, but let’s put everything together. \\[\\underbrace{\\int \\sin(x) e^x dx}_\\text{The original problem} = \\underbrace{\\sin(x) e^x + \\cos(x) e^x}_\\text{Easy stuff!}\\ \\ \\  - \\underbrace{\\int \\sin(x) e^x dx}_\\text{Also the original problem}\\] Rearranging gives \\[\\int \\sin(x) e^x dx = \\frac{\\sin(x) e^x + \\cos(x) e^x}{2} = \\frac{e^x}{2}\\left[{\\large\\strut} \\sin(x) + \\cos(x)\\right]\\] And don’t forget the constant of integration.\n\n[The presentation of integration by parts in this section was formulated by Prof. Michael Brilleslyper.]"
  },
  {
    "objectID": "Accumulation/31-symbolic.html#didnt-work",
    "href": "Accumulation/31-symbolic.html#didnt-work",
    "title": "38  Symbolic anti-differentiation",
    "section": "38.6 Didn’t work?",
    "text": "38.6 Didn’t work?\nIf integration by parts doesn’t work … and it doesn’t always work! … there is a variety of possibilities such as asking a math professor (who has a much larger set of functions at hand than you), looking through a table of integrals (which is to say, the collective calculus diary of generations of math professors), using a computer algebra system, or using numerical integration. One of these will work.\nIf you have difficulty using u-substitution or integration by parts, you will be in the same league as the vast majority of calculus students. Think of your fellow students who master the topic in the way you think of ice dancers. It’s beautiful to watch, but you need a special talent and it hardly solves every problem. People who would fall on their face if strapped to a pair of skates have nonetheless made huge contributions in technical fields, even those that involve ice.\nProf. Kaplan once had a heart-to-heart with a 2009 Nobel-prize winner who confessed to always feeling bad and inadequate as a scientist because he had not done well in introductory calculus. It was only when he was nominated for the Nobel that he felt comfortable admitting to his “failure.” Even if you don’t master u-substitution or integration by parts, remember that you can integrate any function using easily accessible resources."
  },
  {
    "objectID": "Accumulation/31-symbolic.html#integrating-polynomials",
    "href": "Accumulation/31-symbolic.html#integrating-polynomials",
    "title": "38  Symbolic anti-differentiation",
    "section": "38.7 Integrating polynomials",
    "text": "38.7 Integrating polynomials\nOne of the most famous settings for integration comes from the physics of free fall under gravity.\nHere’s the setting. An object—a ball, let’s imagine—is being held at height \\(x_0\\). At \\(t=0\\) the ball is released. Perhaps the ball is released from a standstill in which case it’s velocity at release is \\(v_0 = v(t=0) =0\\). Or perhaps the ball has been tossed upward so that \\(v_0 > 0\\), or downward so that \\(v_0 < 0\\). Whichever it is, the initial velocity will be labelled \\(v_0\\).\nOn release, the force that held the ball steady is removed and the object moves under the influence of only one factor: gravity. The effect of gravity near the Earth’s surface is easy to describe: it accelerates the object at a constant rate of about 9.8 m/s\\(^2\\).\nAcceleration is the derivative with respect to time of velocity. Since we know acceleration, to find velocity we find an anti-derivative of acceleration: \\[v(t) = \\int -9.8\\ dt = -9.8\\ t + C\\] The constant of integration \\(C\\) is not just a formality. It has physical meaning. In this case, we see that \\(C=v(0)\\), that is, \\(C = v_0\\).\nVelocity is the derivative of position: height in this case. So height is an anti-derivative of velocity. \\[x(t) = \\int v(t) dt = \\int \\left[\\strut -9.8\\ t + v_0\\right]dt = - \\frac{9.8}{2} t^2 + v_0\\ t + C\\] Why is \\(C\\) back again? It’s a convention to use \\(C\\) to denote the constant of integration. Those experienced with this convention know, from context, that the value of \\(C\\) in the integration that produced \\(v(t)\\) has nothing to do with the value of \\(C\\) involved in the production of \\(x(t)\\). The situation is a bit like the presentation of prices in US stores: to the price of the item itself, you must always add “plus taxes.” Nobody with experience would assume that “taxes” is always the same number. It depends on the price and type of the item itself.4 You won’t have to deal with the taxes at the time you pick the item from the shelf, but eventually you’ll see them when you check out of the store. Think of \\(+\\ C\\) as meaning, “plus some number that we’ll have to deal with at some point, but not until checkout.”\nLet’s checkout the function \\(x(t)\\) now. For that, we need to figure out the value of \\(C\\). We can do that by noticing that \\(x(0) = C\\). So in the anti-differentiation producing \\(x()\\), \\(C = x_0\\) giving, altogether the formula for free-fall famous from physics classes \\[x(t) =  - \\frac{9.8}{2} t^2 + v_0\\ t + x_0\\] An important thing to notice about \\(x(t)\\): it’s a polynomial in \\(t\\). Polynomials can be birthed by successive anti-differentiations of a constant. At each anti-differentiation, each of the previous terms is promoted by one order. That is, the previous constant becomes the first order term. The previous first-order term becomes the second order term, with the division by 2 familiar from anti-differentiating \\(t\\). A previous second-order term will become the new third-order term, again with the division by 3 familiar from anti-differentiating \\(t^2\\).\nStated generally, the anti-derivative of a polynomial is\n\\[{\\Large\\int} \\left[\\strut \\underbrace{a + b t + ct^2 + \\ldots}_\\text{original polynomial}\\right] dt = \\underbrace{C + a\\,t + \\frac{b}{2} t^2 + \\frac{c}{3} t^3 + \\ldots}_\\text{new polynomial}\\] By use of the symbol \\(C\\), it’s easy to spot how the constant of integration fits in with the new polynomial. But if we were to anti-differentiate the new polynomial, we had better replace \\(C\\) with some more specific symbol to that we don’t confuse the old \\(C\\) with the one that’s going to be produced in the new anti-differentiation.\n\nIn exercise 26.16, we introduced a Taylor polynomial approximation to the gaussian function. That might have seemed like a mere exercise in high-order differentiation at the time, but there is something more important at work.\nThe gaussian is one of those functions for which the anti-derivative cannot be written exactly in terms of what the mathematicians call “elementary functions.” (See Section 38.1.) Yet integrals of the gaussian are very commonly used in science, especially in statistics where the gaussian is called the normal PDF.\nThe approach we’ve taken in this book is simply to give a name and a computer implementation of the anti-derivative of the gaussian. This is the function we’ve called \\(\\pnorm()\\) with the R computer implementation pnorm().\nWe never told you the algorithm contained in pnorm(). Nor do we really need to. We all depend on experts and specialists to design and build the computers we use. The same is true of software implementation of functions like pnorm(). And for that matter, for implementations of functions like exp(), log(), sin(), and so on. You don’t have to know about semi-conductors in order to use a computer productively, and you don’t need to know about numerical algorithms in order to use those functions.\nOne feasible algorithm for implementing \\(\\pnorm()\\) is to integrate the Taylor polynomial. It’s very easy integrate polynomials. To ensure accuracy, different Taylor polynomials can be computed for different centers, say \\(x=0\\), \\(x=1\\), \\(x=2\\), and so on.\nAnother feasible approach integrates \\(\\dnorm()\\) numerically using an advanced algorithm such as Gauss-Hermite quadrature."
  },
  {
    "objectID": "Accumulation/31-symbolic.html#exercises",
    "href": "Accumulation/31-symbolic.html#exercises",
    "title": "38  Symbolic anti-differentiation",
    "section": "38.8 Exercises",
    "text": "38.8 Exercises"
  },
  {
    "objectID": "dynamics-part.html",
    "href": "dynamics-part.html",
    "title": "Dynamics",
    "section": "",
    "text": "This is where I’ll explain what the block is about and the overall goals."
  },
  {
    "objectID": "Dynamics/B6-diff-eq.html",
    "href": "Dynamics/B6-diff-eq.html",
    "title": "39  Differential equations",
    "section": "",
    "text": "In this Block, we take on what an important application of derivatives: the representation of dynamical systems.\n“Dynamical systems” (but not under that name) were developed initially in the 1600s as a way of relating planetary motion to the force of gravity. Nowadays, they are used to describe all sorts of physical systems from oscillations in electrical circuits to the ecology of interacting species to the spread of contagious disease.\nAs examples of dynamical systems, consider a ball thrown thrown through the air or a rocket being launched to deploy a satellite. At each instant of time, a ball has a position—a point in \\(x,y,z\\) space—and a velocity \\(\\partial_t x\\), \\(\\partial_t y\\), and \\(\\partial_t z\\). These six quantities, and perhaps others like spin, constitute the instantaneous state of the ball. Rockets have additional components of state, for example the mass of the fuel remaining.\nThe “dynamical” in “dynamical systems” refers to the change in state. For the ball, the state changes under the influence of mechanisms such as gravity and air resistance. The mathematical representation of a dynamical system codifies how the state changes as a function of the instantaneous state. For example, if the instantaneous state is a single quantity called \\(x\\), the instantaneous change in state is the derivative of that quantity: \\(\\partial_t x\\).\nTo say that \\(x\\) changes in time is to say that \\(x\\) is a function of time: \\(x(t)\\). When we write \\(x\\), we mean \\(x()\\) evaluated at an instant. When we write \\(\\partial_t x\\), we mean “the derivative of \\(x(t)\\) with respect to time” evaluated at the same instant as for \\(x\\).\nThe dynamical system describing the motion of \\(x\\) is written in the form of a differential equation, like this:\n\\[\\partial_t x = f(x)\\ .\\] Notice that the function \\(f()\\) is directly a function of \\(x\\), not \\(t\\). This is very different from the situation we studied in Block 3, where we might have written \\(\\partial_t y = \\cos\\left(\\frac{2\\pi}{P} t\\right)\\) and assigned you the challenge of finding the function \\(y(t)\\) by anti-differentiation. (The answer to the anti-differentiation problem, of course, is \\(y(t) = \\frac{P}{2\\pi}\\sin\\left(\\frac{2\\pi}{P} t\\right) + C\\).)\n\nIt is essential that you train yourself to distinguish two very different statements\n\nanti-differentiation problems like \\(\\partial_{\\color{blue}{t}} y = g(\\color{blue}{t})\\), which has \\(t\\) as both the with-respect-to variable and as the argument to the function \\(g()\\).\n\nand\n\ndynamical systems like \\[\\partial_{\\color{blue}{t}} \\color{magenta}{y} = g(\\color{magenta}{y})\\ .\\]\n\nThis is one place where Leibniz’s notation for derivatives can be useful: \\[\\underbrace{\\frac{d\\color{magenta}{y}}{d\\color{blue}{t}} = g(\\color{blue}{t})}_{\\text{as in antidifferentiation}}\\ \\ \\ \\text{versus}\\ \\ \\ \\underbrace{\\frac{d\\color{magenta}{y}}{d\\color{blue}{t}} = g(\\color{magenta}{y})}_{\\text{dynamical system}}\\]\n\nDynamical systems with multiple state quantities are written mathematically as sets of differential equations, for instance: \\[\\partial_t y = g(y, z)\\\\\n\\partial_t z = h(y, z)\\] We typically use the word system rather than “set,” so a dynamical system is represented by a system of differential equations.\n\n\\(\\ \\)\nLet’s illustrate the idea of a dynamical system with a children’s game: “Chutes and Ladders”. Since hardly any children have studied calculus, the game isn’t presented as differential equations, but as a simple board and the rules for the movement along the board.\n\n\n\n\n\nFigure 39.1: ?(caption)\n\n\n\n\nA player’s state in this game is shown by the position of a token, but we’ll define the state to be the number of the square that the player’s token is on. In Chutes and Ladders the state is one of the integers from 1 to 100. In contrast, the dynamical systems that we’ll study with calculus have a state that is a point on the number line, or in the coordinate plane, or higher-dimensional space. Our calculus dynamical system describe the change of state using derivatives with respect to time, whereas in chutes and ladders the the state jumps from one value to the next value.\nThe game board displays not only the set of possible states but also the rule for changing state jumping from one state to another.\nIn the real game, players roll a die to determine how many steps to take to the next state. But we’ll play a simpler game: Just move one step forward on each turn, except … from place to place there are ladders that connect two squares. When the state reaches a square holding the foot of a ladder, the state is swept up to the higher-numbered square at the top of the ladder. Similarly, there are chutes. These work much like the ladders but carry the state from a higher-numbered square to a lower-numbered square.\nThe small drawings on the board are not part of the action of the game. Rather, they represent the idea that good deeds lead the player to progress, while wrong-doing produces regression. Thus, the productive gardener in square 1 is rewarded by being moved upward to the harvest in square 38. In square 64 a brat is pulling on his sister’s braids. This misdeed results in punishment: he is moved back to square 60.\nOur dice-free version of Chutes and Ladders is an example of a discrete-time, discrete-state dynamical system. Since there is no randomness involved, the movement of the state is deterministic. (With dice, the movement would be stochastic.)\nThe differential equations of a dynamical system correspond to a continuous-time, continuous-space system. This continuity is the reason we use derivatives to describe the motion of the state. The movement in the systems we’ll explore is also deterministic. (In ?sec-forcing we’ll encounter briefly some instances of stochastic systems.)"
  },
  {
    "objectID": "Dynamics/B6-diff-eq.html#state",
    "href": "Dynamics/B6-diff-eq.html#state",
    "title": "39  Differential equations",
    "section": "39.2 State",
    "text": "39.2 State\nThe mathematical language of differential equations and dynamical systems is able to describe a stunning range of systems, for example:\n\nphysics\n\nswing of a pendulum\nbobbing of a mass hanging from a spring.\na rocket shooting up from the launch pad\n\ncommerce\n\ninvestment growth\ngrowth in equity in a house as a mortgage is paid up. (“Equity” is the amount of the value of the house that belongs to you.)\n\nbiology\n\ngrowth of animal populations, including predator and prey.\nspread of an infectious disease\ngrowth of an organism or a crop.\n\n\nAll these systems involve a state that describes the configuration of the system at a given instant in time. For the growth of a crop, the state would be, say, the amount of biomass per unit area. For the spread of infectious disease, the state would be the fraction of people who are infectious and the fraction who are susceptible to infection. “State” in this sense is used in the sense of “the state of affairs,” or “his mental state,” or “the state of their finances.”\nSince we’re interested in how the state changes over time, sometimes we refer to it as the dynamical state.\nOne of the things you learn when you study a field such as physics or epidemiology or engineering is what constitutes a useful description of the dynamical state for different situations. In the crop and infectious disease examples above, the state mentioned is a strong simplification of reality: a model. Often, the modeling cycle leads the modeler to include more components to the state. For instance, some models of crop growth include the density of crop-eating insects. For infectious disease, a model might include the fraction of people who are incubating the disease but not yet contagious.\nConsider the relatively simple physical system of a pendulum, swinging back and forth under the influence of gravity. In physics, you learn the essential dynamical elements of the pendulum system: the current angle the pendulum makes to the vertical, and the rate at which that angle changes. There are also fixed elements of the system, for instance the length of the pendulum’s rod and the local gravitational acceleration. Although such fixed characteristics may be important in describing the system, they are not elements of the dynamical state. Instead, they might appear as parameters in the functions on the right-hand side of the differential equations.\nTo be complete, the dynamical state of a system has to include all those changing aspects of the system that allow you to calculate from the state at this instant what the state will be at the next instant. For example, the angle of the pendulum at an instant tells you a lot about what the angle will be at the next instant, but not everything. You also need to know which way the pendulum is swinging and how fast.\nFiguring out what constitutes the dynamical state requires knowledge of the mechanics of the system, e.g. the action of gravity, the constraint imposed by the pivot of the pendulum. You get that knowledge by studying the relevant field: electrical engineering, economics, epidemiology, etc. You also learn what aspects of the system are fixed or change slowly enough that they can be considered fixed. (Sometimes you find out that something your intuition tells you is important to the dynamics is, in fact, not. An example is the mass of the pendulum.)"
  },
  {
    "objectID": "Dynamics/B6-diff-eq.html#state-space",
    "href": "Dynamics/B6-diff-eq.html#state-space",
    "title": "39  Differential equations",
    "section": "39.3 State space",
    "text": "39.3 State space\nThe state of a dynamical system tells you the configuration of the system at any instant in time. It’s appropriate to think about the instantaneous state as a single point in a state space, a coordinate system with an axis for each component of state. As the system configuration changes with time—say, the pendulum loses velocity as it swings to the left—the instantaneous state moves along a path in the state space. Such a path is called a trajectory of the dynamical system.\nIn this book, we will work almost exclusively with systems that have a one- or two-dimensional state. Consequently, the state space will be either the number line or the coordinate plane. The methods you learn will be broadly applicable to systems with higher-dimensional state.\nFor the deterministic dynamical systems we will be working with, a basic principle is that a trajectory can never cross itself. This can be demonstrated by contradiction. Suppose a trajectory did cross itself. This would mean that the motion from the crossing point couple possibly go in either of two directions; the state might follow one branch of the cross or the other. Such a system would not be deterministic. Determinism implies that from each point in state space the flow goes only in one direction.\nThe dimension of the state space is the same as the number of components of the state; one axis of state space for every component of the state. has important implications for the type of motion that can exist.\n\nIf the state space is one-dimensional, the state as a function of time must be monotonic. Otherwise, the trajectory would cross itself, which is not permitted.\nA state space that is two- or higher-dimensional can support motion that oscillates back and forth. Such a trajectory does not cross itself, instead it goes round and round in a spiral or a closed loop.\n\nFor many decades, it was assumed that all dynamical systems produce either monotonic behavior or spiral or loop behavior. In the 1960s, scientists working on a highly simplified model of the atmosphere discovered numerically that there is a third type of behavior, the irregular and practically unpredictable behavior called chaos. To display chaos, the state space of the system must have at least three elements.\n\n\nThat calculus is the language of change can be seen in the words used in this section. For instance, instantaneous, continuous, and monotonic are all words introduced in Block 1 of this book.\n\nWhat does it take to describe the dynamical state of an epidemic?\nNews reports of the COVID pandemic usually focus on the number of new cases each day and the fraction of the population that has been vaccinated. But this is not adequate, even for a simple description of the dynamics.\nFrom a history of new-case counts over time (e.g. ?fig-NYT-covid-history) you can see that the number of new cases waxes and wanes. Knowing that the number of cases today is, say, 100 thousand doesn’t tell you what the number of cases will be in two weeks: 100 thousand is encountered both on the way up and on the way down.\n\n\n[COVID-19 new-case counts in the US over the first two years of the pandemic. Source: [New York Times]]](www/NYT-covid-report.png){#fig-NYT-covid-history fig-align=‘center’ width=90%}"
  },
  {
    "objectID": "Dynamics/B6-diff-eq.html#dynamics",
    "href": "Dynamics/B6-diff-eq.html#dynamics",
    "title": "39  Differential equations",
    "section": "39.4 Dynamics",
    "text": "39.4 Dynamics\nThe dynamics of a system is a description of how the individual components of the state change as a function of the entire set of components of the state.\nAt any instant in time, the state is a set of quantities. We’ll use \\(x\\), \\(y\\), and \\(z\\) for the purpose of illustration, although most of our work in this introduction will be with systems that have just one or two state variables.\nThe differential equations describing the \\(x, y, z\\) system have a particular form:\n\\[\\partial_t x(t) = f(x(t), y(t), z(t))\\ \\, \\\\\n\\partial_t y(t) = g(x(t), y(t), z(t))\\ \\, \\\\\n\\partial_t z(t) = h(x(t), y(t), z(t))\\ .\\]\nThe way these equations are written is practically impossible to read: the expression \\((t)\\) is repeated 12 times! It takes concentration to look beyond the \\((t)\\) to see the overall structure of the equations. In order to avoid this problem of not seeing the forest for the \\((t)\\)s, the convention is to omit the \\((t)\\): \\[\\partial_t x = f(x, y, z)\\\\\n\\partial_t y = g(x, y, z)\\\\\n\\partial_t z = h(x, y, z)\\] This leaves it to the reader to remember that \\(x\\) is really \\(x(t)\\) and so on.\nThis more concise way of writing the differential equations makes it easier to describe how to interpret the equations. Formally, \\(\\partial_t x\\) is a function, the derivative of the function \\(x(t)\\) with respect to time. But try to put this highly literal interpretation on a back burner. Think of the expression \\(\\partial_t x =\\) as meaning, “the way the \\(x\\)-component of state changes in time is described by ….” We need three differential equations because there are three components of state in the \\(x,y,z\\) system, and we need to describe for each component the way that component changes.\nOn the right side of each equation is a function that takes the state quantities as inputs. Each individual equation can be interpreted as completing the elliptical sentence (that is, ending in “…”) in the previous paragraph, so that the whole equation reads like, “The way the \\(x\\)-component of state changes at any instant in time is specified by the function \\(h()\\) evaluated at the instantaneous state.” These functions are called dynamical functions since they give the rules for the dynamics.\nRemember that \\(x\\), \\(y\\), and \\(z\\) are state variables, so they are all functions of time. At any instant in time, the values \\(x\\), \\(y\\), \\(z\\) have a specific value. Thus, at any instant in time, evaluating the functions \\(f(x, y, z)\\), \\(g(x, y, z)\\), and \\(h(x, y, z)\\) at the current state produces a specific, scalar value. If we wanted to make this perfectly explicit, we could write \\(g_x(x(t), y(t), z(t))\\), which makes it clear that the output of \\(g_x()\\) is a function of time.\n\nMathematically, a dynamical system consists of two things:\n\nThe state variables, which is a set of quantities that vary in time.\nThe dynamics, which is the set of dynamical functions, one function for each of the state variables.\n\n\nA simple example is the dynamics of retirement-account interest. In a retirement account, you put aside money—this is called “contributing”—each month. The value \\(V(t)\\) of the account accumulates over time, both due to new monthly deposits and to the interest \\(r\\) earned on the current account value. If you are setting aside \\(M\\) dollars per month, the dynamics are: \\[\\partial_t V = r V + M\\ .\\] The left-hand side of this equation is boilerplate for “the way the \\(V\\) component of state changes is described by the dynamical function \\(rV + M\\).” This is a function of \\(V\\) with parameters \\(r\\) and \\(M\\). In this example, there’s just the one state variable \\(V\\), so the dynamical function has only one argument: \\(V\\).\nRemember that the dynamical function is something that the modeler constructs from her knowledge of the system. To model the dynamics of a pendulum requires some knowledge of physics. Without getting involved with the physics, we note that the oscillatory nature of pendulum movement means that there must be at least two state variables. A physicist learns that a good way to describe the motion uses these two quantities: the angle \\(\\theta(t)\\) of the pendulum rod with respect to the vertical and the angular velocity \\(v(t)\\) telling how the velocity changes with time. Since there are two state variables, there must be two dynamical functions. For a pendulum, one of the functions, the one for \\(\\partial_t v\\) comes from applying Newton’s Second Law: \\(F = m a\\). (Remember that \\(\\partial_t v\\) is an acceleration.) So one of the differential equations is \\[\\partial_t v  =  f(\\theta, v) \\equiv - \\sin(\\theta)\\]\nThe other equation comes from the definition that the derivative of the position \\(\\theta\\) is the velocity. \\[\\partial_t \\theta  =  g(\\theta, v) \\equiv  v\\\\\n\\]\n\nWhy did you bother to define a state variable \\(v\\) when it is, by definition, the same as \\(\\partial_t \\theta(t)\\)?\nEven though the dynamical equation \\(\\partial_t \\theta(t) = v\\) is a calculus tautology, we need always to be explicit about what are the two quantities in the dynamical state. The \\(\\partial_t \\theta\\) differential equation comes for free from basic calculus concepts. The second equation is about the physics, that is, the relationship between forces and acceleration.\nThere is a style of writing dynamics equations that discards such tautologies. For example, the pendulum dynamics are often written \\[\\partial_{tt} \\theta(t) = - \\sin(\\theta)\\ .\\] This sort of equation, containing a second-order derivative, is called a second-order differential equation. In contrast, the two equations, one for \\(\\partial_t \\theta\\) and one for \\(\\partial_t v\\) are called first-order differential equations because each involves a first-order derivative. We’ll return to this second-order style in Section 46 since it is often encountered in physics and engineering. For now, we are avoiding the second-order style because it obscures the fact that there are two state variables: \\(\\theta(t)\\) and \\(v(t)\\).\n\n\n\\(\\ \\)\nConsider the population of two interacting species, say rabbits and foxes. As you know, the relationship between rabbits and foxes is rather unhappy from the rabbits’ point of view even if it is fulfilling for the foxes.\nMany people assume that such populations are more or less fixed: that the rabbits are in a steady balance with the foxes. In fact, as any gardener can tell you, some years there are lots of rabbits and others not: an oscillation. Just from this fact, we know that the dynamical state must have at least two components.\nIn a simple, but informative, model, the two components of the dynamical state are \\(r(t)\\) and \\(f(t)\\), the population of rabbits and foxes respectively. In the absence of foxes, the dynamics of rabbits are exponential growth; each successive generation is larger than the previous one. This can be described by a dynamical equation \\(\\partial_t r(t) = \\alpha r(t)\\), where \\(\\alpha\\) is a fixed quantity that describes rabbit fecundity.\nSimilarly, in the absence of food (rabbits are fox food), the foxes will starve or emigrate, so the dynamical equation for foxes is very similar \\(\\partial_t f(t) = - \\gamma f(t)\\), where \\(\\gamma\\) is a fixed quantity that indicates the rate at which foxes die or emigrate.\nOf course, in real ecosystems there are many other quantities that change and that are relevant. For instance, foxes eat not only rabbits, but birds and frogs and earthworms and berries. And the diet of rabbits eat weeds and grass (which is generally in plentiful supply), but also the gardener’s flowers and carrots (and other vegetables). Growth in the rabbit population leads to decrease in available flowers and vegetables, which in turn leads to slower growth (or even population decline) for rabbits.\nIn the spirit of illustrating dynamics, we’ll leave out these important complexities and imagine that the state consists of just two numbers: how many rabbits there are and how many foxes. The dynamics therefore involve two equations, one for \\(\\partial_t r\\) and one for \\(\\partial_t f\\). For the rabbit/fox model, we’ll allow the rabbit population change (\\(\\partial_t r\\)) to be affected by fox prediation and similarly let the fox population change (\\(\\partial_t f\\)) reflect the consumption of rabbits as food, writing: \\[\\partial_t r = \\ \\ \\ \\ \\ \\alpha\\, r - \\overbrace{\\beta\\, f r}^{\\text{fox predation}}\\\\\n\\partial_t f = \\underbrace{\\delta\\, r f}_{\\text{rabbits as food}} - \\gamma\\, f\\]\nThe quantities \\(\\alpha\\), \\(\\beta\\), \\(\\gamma\\), and \\(\\delta\\) are parameters quantify the biology of the system: the reproduction rate of rabbits, the need of foxes for food (rabbits) in order to reproduce, the hunting success of foxes, and the death or emigration of foxes in response to a shortage of food.\nHow are you supposed to know that \\(r\\) and \\(f\\) are state variables while quantities like \\(\\beta\\) and \\(\\gamma\\) are parameters? Because there is a differential equation involving \\(\\partial_t r\\) and \\(\\partial_t f\\), while no differential equation has been given describing \\(\\partial_t \\beta\\) or \\(\\partial_t \\alpha\\).\nComing up with this description of dynamics requires knowing something about rabbits and foxes. The particular forms used, for instance the interaction term \\(r f\\), come from modeling experience. The interaction term is well named because it is about the literal, biological interaction of foxes and rabbits."
  },
  {
    "objectID": "Dynamics/B6-diff-eq.html#state-space-and-flow-field",
    "href": "Dynamics/B6-diff-eq.html#state-space-and-flow-field",
    "title": "39  Differential equations",
    "section": "39.5 State space and flow field",
    "text": "39.5 State space and flow field\nFor the purpose of developing intuition it is helpful to represent the instantaneous state as a point in a graphical frame and the dynamics as a field of vectors showing how, for each possible state, the state changes. For instance, in the Rabbit-Fox dynamics, the state is the pair \\((r, f)\\) and the state space is the coordinate plane spanned by \\(r\\) and \\(f\\).\nThe present state of the system might be any point in the state space. But once we know the present state, the dynamical functions evaluated at the present state tell us how the state changes over a small increment in time. The step over a small increment of time can be represented by a vector.\nLet’s illustrate with the Rabbit-Fox system, whose dynamical equations are given above. The dynamical functions take a position in state space as input. Each of the functions returns a scalar.\nTo make a plot, we need numerical values for all the parameters in those equations.\nThe vector field corresponding to the dynamics is called a flow, as if it were a pool of swirling water. Figure 39.2 shows the flow of the rabbit/fox system.\n\n\n\n\n\nFigure 39.2: The dynamics of the rabbit/fox system shown as a vector field over the state space. The parameters have been set, for the purpose of illustration, to \\(\\alpha = 2/3\\), \\(\\beta = 4/3\\), \\(\\gamma = 1\\), and \\(\\delta = 1\\).\n\n\n\n\nStaying with the analogy to a pool of swirling water or the currents in a river, you can place a lightweight marker such as a leaf at some point in the flow and follow its path over time. This path—position in state space as a function of time—is called the trajectory of the flow. There are many possible trajectories, depending on where you place the leaf.\nIn Chapter 33 we considered the path followed by a robot arm. In that chapter, we separated out the \\(x\\)- and \\(y\\)-components of the arm’s position over time, calling them functions \\(x(t)\\) and \\(y(t)\\). Analogously, the the decomposition of a trajectory from an initial condition in the flow—this would be \\(r(t)\\) and \\(f(t)\\) for the rabbit/fox system—gives us the solution to the differential equation.\nEach component of the solution is called a time series and is often plotted as a function of time, for instance \\(r(t)\\) versus \\(t\\).\nFrom the flow field, you can approximate the trajectory that will be followed from any initial condition. Starting from the initial condition, just follow the flow. You already have some practice following a flow from your study of the gradient ascent method of optimization described in Chapter 23. At the argmax, the gradient is nil. Thus, the gradient ascent method stops at the argmax. We’ll see an analogous behavior in dynamical systems: any place where the flow is nil is a potential resting point for the state, called a fixed point.\n\n\\(\\ \\)\nLet’s return to the pendulum and examine its flow field. We’ll modify the equations just a little bit to include air resistance in the model. Air resistance is a force, so we know it will appear in the \\(\\partial_t v_\\theta(t)\\) equation. A common model for air resistance has it proportional in size to the square of the velocity and with a direction that is the opposite of the velocity. In a differential equation, the model of air resistance can be written as \\(- \\alpha\\, L\\, \\text{sign}(v(t))\\ v(t)^2\\), where \\(\\text{sign}()\\) is a piecewise function that has the value \\(+1\\) when the argument is positive and \\(-1\\) when the argument is negative. \\(L\\) is the length of the pendulum. \\[\\partial_t \\theta = v\\\\\n\\partial_t v = - \\sin(\\theta) - \\alpha\\,L^2\\, \\text{sign}(v)\\ v^2\\] (Keep in mind as always that for dynamical systems a state variable like \\(\\theta\\) is also a function of time \\(\\theta(t)\\).) Whenever you have a state variable, you know that it’s a function of time and so the explicit \\((t)\\) is often omitted for the sake of conciseness.\n?fig-pendulum-in-air shows the flow field of the pendulum. Also shown is a trajectory and the two time series corresponding to that trajectory.\n\n\n\n\n\nFigure 39.3: The flow field of a pendulum with air resistance. From the initial condition (marked by \\(\\color{red}{\\text{x}}\\)), a trajectory is sketched out for \\(0 \\leq t \\leq 20\\). The individual components of that trajectory are graphed as time series.\n\n\n\n\n\n\n\nFigure 39.4: The flow field of a pendulum with air resistance. From the initial condition (marked by \\(\\color{red}{\\text{x}}\\)), a trajectory is sketched out for \\(0 \\leq t \\leq 20\\). The individual components of that trajectory are graphed as time series.\n\n\n\n\nThe pendulum was started out by lifting it to an angle of \\(45^\\circ\\) and giving it an initial upward velocity. The bob swings up for a bit before being reversed by gravity and swinging toward \\(\\theta = 0\\) and beyond. Due to air resistance, the amplitude of swinging decreases over time.\n\nThe flow of a dynamical system tells how different points in state space are connected. Because movement of the state is continuous in time and the state space itself is continuous, the connections cannot be stated in the form “this point goes to that point.” Instead, as has been the case all along in calculus, we describe the movement in terms of a “velocity” vector. Each dynamical function specifies one component of the “velocity” vector, taken together they tell the direction and speed of movement of the state at each instant in time.\nPerhaps it would be better to use the term state velocity instead of “velocity.” In physics and most aspects of everyday life, “velocity” refers to the rate of change of physical position of an object. Similarly, the state velocity tells the rate of change of the position of the state. It’s a useful visualization technique to think of the state as an object skating around the state space in a manner directed by the dynamical functions. But the state space almost always includes components other than physical position. For instance, in the rabbit/fox model, the state says nothing about where individual rabbits and foxes are located in their environment; it’s all about the density of animals in a region.\nIn physics, often the state space consists of position in physical state as well as the physical velocity in physical space. For instance, the state might consist of the three \\(x, y, z\\) components of physical position as well as the three \\(v_x, v_y, v_z\\) components of physical velocity. Altogether, that’s a six-dimensional state space. The state velocity also has six components. Three of those components will be the “velocity of the velocity,” that is, the direction and speed with which the physical velocity is changing.\n\n\\(\\ \\)\nReturning to the Chutes and Ladders game used as an example near the start of this chapter …\nThe state in chutes and ladders is one of the hundred numbers 1, 2, \\(\\ldots\\), 100. This is a discrete state space. Therefore, we can describe the “flow” in a very concrete way: how each state is directly connected to another. Figure 39.5 shows these connections. There is no velocity involved because there is no infinitesimal movement of state. For instance, state 47 connects directly to state 26.\n\n\n\n\n\nFigure 39.5: The “flow” connecting the discrete states in the dice-free Chutes and Ladders game. Source: Maj. Austin Davis\n\n\n\n\nIn the no-dice game, the state follows the arrows. Looking carefully at Figure 39.5, you can see that each state has a forward connection to at most one state. This is the hallmark of determinism.\nIn the children’s game, the play is not deterministic because a die is used to indicate which state follows from each other state. A die has six faces with the six numbers 1 to 6. So, each state is connected to six other states in the forward direction. Which of the six is to be followed depends on the number that comes up on the die. Multiple forward connections means the dynamics are stochastic (random).\nStraightforward examination of the flow often tells you a lot about the big picture of the system. In dice-free Chutes and Ladders, The 100 states are divided into three isolated islands. State 1 is part of the island in the lower right corner of Figure 39.5. Follow the arrows starting from any place on that island and you will eventually reach state 84. And state 84 is part of a cycle \\(84 \\rightarrow 85 \\rightarrow \\cdots \\rightarrow 28 \\rightarrow 84 \\rightarrow \\cdots\\). Once you are on that cycle, you never get off. We’ll see such cycles in continuous-time dynamical systems as well.\n\n\nWeather forecasting by numerical process\nWeather forecasting by numerical process is a highly influential book, from 1922, by Lewis Fry Richardson. He envisioned a calculation for a weather forecast as a kind of function. The domain for the forecast is the latitude and longitude of a point on the globe, rather than the rectilinear organization of corridor.\nOne fantastic illustration of the idea shows a building constructed in the form of an inside-out globe. Source At each of many points on the globe, there is a business. (You can see this most clearly in the foreground, which shows several boxes of workers.)\n\n\n\n\n\nFigure 39.6: An artist’s depiction of the organization of calculations for weather forecasting by Richardson’s system.\n\n\n\n\nIn each business there is a person who will report the current air pressure at that point on the globe, another person who reports the temperature, another reporting humidity, and so on. To compute the predicted weather for the next day, the business has a staff assigned to visit the neighboring businesses to find out the pressure, temperature, humidity, etc. Still other staffers take the collected output from the neighbors and carry out the arithmetic to translate those outputs into the forecast for tomorrow. For instance, knowing the pressure at neighboring points enables the direction of wind to be calculated, thus the humidity and temperature of air coming in to and out of the region the business handles. In today’s numerical weather prediction models, the globe is divided very finely by latitude, longitude, and altitude, and software handles both the storage of present conditions and the calculation from that of the future a few minutes later. Repeating the process using the forecast enables a prediction to be made for a few minutes after that, and so on.\nSome of the most important concepts in calculus relate to the process of collecting outputs from neighboring points and combining them: for instance finding the difference or the sum. To illustrate, here is the first set of equations from Richardson’s Weather forecasting … written in the notation of calculus:\n\n\n\n\n\n\n\n\n\nYou can hardly be expected at this point to understand the calculations described by these equations, which involve the physics of air flow, the coriolis force, etc. but it’s worth pointing out some of the notation:\n\nThe equations are about the momentum of a column of air at a particular latitude (\\(\\phi\\)) and longitude.\n\\(M_E\\) and \\(M_N\\) are east-west and north-south components of that momentum.\n\\(\\partial M_E /\\partial t\\) is the rate at which the east-west momentum will change in the next small interval of time (\\(\\partial t\\)).\n\\(p_G\\) is the air pressure at ground level from that column of air.\n\\(\\partial p_G / \\partial n\\) is about the difference between air pressure in the column of air and the columns to the north and south.\n\nCalculus provides both the notation for describing the physics of climate and the means to translate this physics into arithmetic calculation."
  },
  {
    "objectID": "Dynamics/B6-diff-eq.html#exercises",
    "href": "Dynamics/B6-diff-eq.html#exercises",
    "title": "39  Differential equations",
    "section": "39.6 Exercises",
    "text": "39.6 Exercises\n\nD-93XWJ: Given a flow field in one or two dimensions, draw a plausible trajectory\nG-MC8XJ: Explain why determinism rules out two different trajectories passing through any single point in state space.\nX-KZLDP: Distinguish between the instantaneous state and the state space.\nM-P1ZSV: Distinguish between graphics of time series and trajectories by examination or construction of the graph’s axes.\nN-O88YI: From a trajectory drawn on a graph of a flow field, construct a plausible time-series plot\nX-MO2V8: Understand these terms and describe the relationships among them in the context of dynamics: instantaneous state, state space, state variable, dynamical function, flow field, trajectory, time-series, differential equation, initial condition, solution"
  },
  {
    "objectID": "Dynamics/B6-solution.html",
    "href": "Dynamics/B6-solution.html",
    "title": "40  Finding a “solution”",
    "section": "",
    "text": "As you saw in the previous chapter, each differential equation in a dynamical system relates the derivative of a function to the function itself. For instance, in \\[\\partial_t x = x\\,(1-x)\\] left-hand side of the equation involves the function \\(x(t)\\). The equation dictates that whatever \\(x(t)\\) might be, it has to be such that \\(\\partial_t x(t)\\) is exactly equal to the function \\(x(t)\\,\\left(\\strut 1- x(t)\\right)\\) Solving a differential equation is the phrase used for finding such self-consistent functions. This chapter is about techniques for finding solutions.\nGiven what you learned in studying Block 3 of this book, you likely will be tempted to approach the task of “finding a solution” by applying symbolic anti-differentiation techniques to the problem. After all, each differential equation in a dynamical system involves a function \\(\\partial_t x(t)\\). To find \\(x(t)\\) from \\(\\partial_t x(t)\\) seems like a matter of applying the “fundamental theorem of calculus,” namely\n\\[\\int \\partial_t x(t) dt = x(t)\\ .\\] Following this logic, we would translate the equation to \\[x(t) = \\int x(t)\\, (1-x(t))dt\\  .\\] But the problems in Block 3 were all of the form \\(\\frac{d\\color{magenta}{x}}{d\\color{blue}{t}} = g(\\color{blue}{t})\\), whereas the problems we work with in this Block are generally of the entirely different form \\(\\frac{d\\color{magenta}{x}}{d\\color{blue}{t}} = g(\\color{magenta}{x})\\). Thus, we will usually need special techniques suited to the format of dynamical systems.\nAdmittedly, in mathematics it is common to refer to integrating a differential equation, but this should be broadly understood as accumulating the increments \\(\\partial_t x(t)\\) starting at some initial condition \\(x(t_0)\\), even if that accumulation is not carried out by symbolic anti-differentiation.\nIn this chapter we’ll introduce three different techniques to accumulating a solution to a differential equation or a pair of such equations. First, we’ll look again at the graphical method of “following the flow” in a plot of the flow field. This technique is mainly of use for developing intuition about the dynamics.\nSecond, we’ll develop a simple Euler method for accumulating a solution. Third, we’ll explore how to take a guess about the solution and, when the guess is good enough, refine that into an actual solution. This is called the method of ansätze.\nThird, and briefly, we’ll look at some of the situations where symbolic anti-differentiation can be used. This includes a very brief introduction to substitution methods."
  },
  {
    "objectID": "Dynamics/B6-solution.html#the-flow-field",
    "href": "Dynamics/B6-solution.html#the-flow-field",
    "title": "40  Finding a “solution”",
    "section": "40.1 The flow field",
    "text": "40.1 The flow field\nWith a pair of differential equations, as with the pendulum or the rabbit-fox model, each equation gives one component of the change in state. To draw the flow at single point in state space, evaluate the dynamical functions at that point. Each dynamical function contributes, as its output, one of the components of the state velocity vector. If the parameters in the model have been assigned numerical values, the result of evaluating the right-hand sides will be two numbers.\nA case in point is the rabbit-fox. The axes in the rabbit-fox state space are denominated in units of rabbit density \\(r\\) and fox density \\(f\\). The differential equations are \\[\\partial_t r = 0.66 r - 1.33 r f\\\\\n\\partial_t f = -f + rf\\\\\n\\]\nTo to find the state velocity at, say, \\(r=2, f=1/4\\), plug those values into the right-hand side: \\[\\partial_t r = 1.33 - 0.66 = 0.66\\ \\ \\ \\text{rabbit density per month}\\\\\n\\partial_t f = -0.25 + 0.5 = 0.25\\ \\ \\ \\ \\ \\ \\text{fox density per month}.\\]\nOnce you know the numerical vector value of the state velocity, you need to convert it to a form suitable for plotting in the state space. The conversion is needed because the state space is denominated in rabbit density and fox density, not in rabbit density per month or fox density per month. The conversion is accomplished by multiplying the state velocity vector by a small \\(dt\\), say, 0.1 months.\nThe conversion produces a vector whose components are denominated in the same way as the state space and thus can be plotted meaningfully in the state space.\nTo illustrate, let’s draw a flow vector for the state space coordinate \\((r=2, f = 1/4)\\). Above, we already calculated the components of the state velocity vector;Given the value \\(\\partial_t f = 0.25\\) and \\(\\partial_t f = 0.66\\). For the sake of illustration, we’ll set \\(dt = 0.1\\) month. Consequently, the vector to be plotted will be \\((0.25, 0.66) dt = (0.025, 0.066)\\)$ with units of rabbit density and fox density respectively. the right. This flow arrow is drawn in Figure 40.1.\n\n\n\n\n\nFigure 40.1: The flow arrow for the state value \\((r=2, f=1/4)\\) using \\(dt=0.1\\) month.\n\n\n\n\nTo draw the entire flow field, repeat this process at many other points in the state space as in Figure 40.2.\n\n\n\n\n\nFigure 40.2: Left: The flow field depicted by drawing the state velocity vector (times \\(dt = 0.1\\)) for many points in the state space. Right: Instead of plotting the state velocity vector, small snippets of trajectories of duration 0.1 are shown. The curvature of the trajectories can help to envision the flow more precisely.\n\n\n\n\nSome people prefer a visualization of short segments of actual trajectories, as in the right panel in Figure 40.2, rather than the state velocity vector. This is a matter of personal preference.\nWith the flow field depicted in sufficient detail, you can now trace out trajectory.\nTo trace out a trajectory, select a initial condition for the system. Then follow the flow, taking only a small step in state space. The next step should be in the direction of the flow arrow at the end of the previous step.\nThe trajectory you draw will be only a sketch, but it can be effective for developing intuition. Figure 40.3 shows a semi-automated version of the go-with-the-flow method. The computer has been used to draw the arrows. When you click in the plot, the computer also undertakes calculation of the trajectory.\n\n\n\n\n\n\n\n\n\nFigure 40.3: The flow field for the rabbit/fox dynamics. Click at an initial state to generate the trajectory from that state. You may need to pinch in or out to see the flow arrows clearly.\n\n\n\n\n\nNEED A LINK TO THE FOX Dynamics app here\n\nRegrettably, from such a sketch of the trajectory, you can’t easily construct \\(r(t)\\) and \\(f(t)\\) for time-series plots. Also, you don’t get a sense of how slow or fast the flow is going. Click at different initial conditions in the flow and you will see different trajectories, each of which is a closed loop, the sort of cycles seen in the dice-free Chutes and Ladders game. But the shape of the trajectory doesn’t tell you whether it takes a long time or a short time to complete a loop.\nThe next section will show you how the computer constructed the trajectory and how we can get information on the speed of the flow."
  },
  {
    "objectID": "Dynamics/B6-solution.html#euler-method",
    "href": "Dynamics/B6-solution.html#euler-method",
    "title": "40  Finding a “solution”",
    "section": "40.2 Euler method",
    "text": "40.2 Euler method\nRecall from Block 2 the limit definition of the derivative: \\[\\partial_t x(t) = \\lim_{dt \\rightarrow 0} \\frac{x(t + dt) - x(t)}{dt}\\ .\\] We’re going to use this definition to develop a very general way to solve differential equations: the Euler method.\nThe differential equations specify the values of \\(\\partial_t x(t)\\) in terms of the dynamical function. In Block 2, we paid attention to whether the limit exists. But here, we know it must because the dynamical functions themselves don’t involve limits. In working with the differential equation it suffices to pick some small, finite \\(dt\\). How small? Pick \\(dt\\) to be small enough that the result wouldn’t change in any substantial way if we used an even smaller time increment, say \\(dt/10\\).\nOur starting point for solving each differential equation is to re-write it as a finite difference. To illustrate, we’ll solve the equation \\(\\partial_t x = x (1 - x)\\), which is often called the logistic equation.\nApplying the finite difference definition, we get \\[\\underbrace{\\frac{f(t + dt)- f(t)}{dt}}_{\\text{finite-difference approx.}} = \\underbrace{x (1-x)}_{\\text{dynamical function}}\\ .\\] Multiplying both sides of the above by \\(dt\\) and re-arranging terms produces \\[\\underbrace{f(t + dt)}_{\\text{future state}} = \\underbrace{f(t)}_{\\text{current state}} +\\ \\ \\  \\underbrace{x (1-x) dt}_{\\text{step}}\\] We call this last equation the Euler formula.\nTo use this, we start at the initial condition, say \\(x(t=0) = 0.2\\). This initial condition gives us the first row of a tabular representation of the function \\(x(t)\\):\n\n\n\n\n\ntime\nstate\n\n\n\n\n0\n0.2\n\n\n\nNext, pick a value for \\(dt\\) that we will use for all the following steps, each of which will add a new row to the table. For the example, we’ll set \\(dt = 0.1\\). When we have constructed the whole table we can go back and check whether that was small enough.\nTo fill in the next row, we apply the Euler formula. Sine \\(dt = 0.1\\), the next time step will be \\(0.1\\). Plug in the current state—which is 0.2 right now—to calculate the future state. The step will be \\(0.2 (1-0.2)\\, dt = \\color{brown}{0.016}\\). Add this step to the current state to get the future state. The table now looks like this:\n\n\n\n\n\ntime\nstate\n\n\n\n\n0.0\n\\(0.2\\)\n\n\n0.1\n\\(0.2 + \\color{brown}{0.016} = \\color{blue}{0.216}\\)\n\n\n\nThe next step will bring us to time \\(0.2\\). Use the Euler formula, pluggin in the value of the present state, \\(\\color{blue}{0.216}\\), to find the step. Here that will be \\(0.216 (1-0.216)\\, dt = \\color{magenta}{0.0169.}\\). Now the table looks like\n\n\n\n\n\ntime\nstate\n\n\n\n\n0.0\n\\(0.2\\)\n\n\n0.1\n\\(0.2 + \\color{brown}{0.016} = \\color{blue}{0.216}\\)\n\n\n0.2\n\\(\\color{blue}{0.216} + \\color{magenta}{0.0169} = 0.2329\\)\n\n\n\nAdd as many rows to the table as you like; the process will be the same.\nYou will recognize this as an iterative process, as discussed in Chapter 32.\n\n\\(\\ \\)\nAs is so often the case, it’s wise to think about carrying out processes in terms of fundamental tasks accomplished by calculus operations—evaluate, differentiate, anti-differentiate, solve, find argmax, iterate. The obvious choice for integrating differential equations is “anti-differentiate,” but as described previously, the techniques we covered in Block 3 are not sufficient for the task. Instead, we use iteration to solve differential equations.\nIn this example we’re going to use the software you have already seen, Iterate(), to carry out the task. In practice, however, you will use a special form of Iterate() called integrateODE() that makes use of interpolation techniques to give a more precise answer.\nTo implement the iteration to solve \\(\\partial_t x = x (1-x)\\), we need to create a function that takes the current state as input and produces the next state as output. Our one-step function can be this: ::: {.cell layout-align=“center” fig.showtext=‘false’}\nnext_step <- function(t, x, dt=0.1) {\n  t <- t + dt\n  x <- x + x*(1-x)*dt\n  \n  c(t=t, x=x) # return value\n}\n\nNotice that we wrote next_step() with an input slot for \\(dt\\). This will not be part of the state being iterated, just a parameter that allows us easily to explore different values for \\(dt\\).\nUse Iterate() to carry out the iteration of next_step(). Note that we use the fargs argument to Iterate() to pass our selected value for dt to the function next_step(). We’ll run the iteration for 100 steps. With \\(dt=0.1\\), those 100 steps will 10 units of time. ::: {.cell layout-align=“center” fig.showtext=‘false’}\nSoln <- Iterate(next_step, x0=c(t=0, x=0.2), n=100,\n                fargs=list(dt=0.1))\n:::\n\n\n\n \n  \n    n \n    t \n    x \n  \n \n\n  \n    0 \n    0.0 \n    0.2000000 \n  \n  \n    1 \n    0.1 \n    0.2160000 \n  \n  \n    2 \n    0.2 \n    0.2329344 \n  \n  ... and so on ...\n  \n  \n  \n    99 \n    9.9 \n    0.9998595 \n  \n  \n    100 \n    10.0 \n    0.9998736 \n  \n\n\n\n\n\nWe can now plot the time series \\(x\\) vs \\(t\\):\n\n\n\n\n\nFigure 40.4: The time series by the Euler method with \\(dt=0.01\\).\n\n\n\n\n:::\n\nIn the previous example using Iterate() to solve a differential equation, the output of the iteration was a data frame containing values for the solution at discrete times: 0, 0.1, 0.2, and so on. A data table is a perfectly good way to represent a function, but it’s handier to have a function in a form that operations like slice_plot() and D() can be applied to. Another way to look at things is that, mathematically, the solution to a differential equation should be a continuous-time function. Fortunately, we have at hand the interpolation techniques covered in Chapter 33 to carry out the construction of a continuous-time function from a tabular representation. The R/mosaic function integrateODE() connects together the iteration and interpolation to provide a solution that is in the form of continuous-time function(s).\nUse the R/mosaic function integrateODE() to solve differential equations numerically. It is a specialized function that handles sets of first-order differential equations, but any high-order differential equation can be separated into a set of first-order equations.\nTo illustrate, this command will solve the differential equation \\(\\partial_t x = x (1-x)\\) that we took on in the previous example with Iterate(). ::: {.cell layout-align=“center” fig.showtext=‘false’}\nSoln2 <- integrateODE(dx ~ x*(1-x), x = 0.2, tdur=list(from=0, to=10, dt=0.01))\n\nThe first argument is a tilde expression, but in a form that’s different from from that used in functions such as D() or contour_plot(), etc. To the left of the tilde is a single name composed of the state variable—x here—prefixed by a d. The d is just a reminder that we are describing not x itself, but \\(\\partial_t\\ \\mathtt{x}\\). On the right of the tilde is the function from the differential equation, in this case, \\(x(1-x)\\).\nThe next argument is the initial condition. We’re starting the integration at \\(x=0.2\\). Finally, the argument named tdur= consists of a description of the starting and ending times and the time-step size \\(dt\\).\nThe output of integrateODE() is an R structure of a type called a “list” that is new to us. The list contains the function(s) created by integrateODE() which you refer to by name (x) using a special form of R punctuation $ suited to lists.. In other words, Soln2$x will be a function, which you can plot like any other function, for instance:\n\nslice_plot(Soln2$x(t) ~ t, domain(t=0:10))\n\n\n\n\n\n\n\n\nAn important feature of integrateODE() is its ability to handle sets of first-order differential equations. For instance, the rabbit/fox system \\[\\partial_t r = 0.66\\, r - 1.33\\, r f\\\\\n\\partial_t f = -f + rf\\] will be integrated by this command: ::: {.cell layout-align=“center” fig.showtext=‘false’}\nEco_soln <- integrateODE(\n  dr ~ 0.66*r - 1.33*r*f, \n  df ~     -f +      r*f,\n  r = 2, f = 0.5, #initial conditions\n  tdur=list(from=0, to=5, dt=0.1))\n::: You can plot the time series using slice_plot()\n\npA <- slice_plot(Eco_soln$r(t) ~ t, domain(t=0:5)) %>% gf_labs(title=\"Rabbits\")\npB <- slice_plot(Eco_soln$f(t) ~ t, domain(t=0:5)) %>% gf_labs(title=\"Foxes\")\ngridExtra::grid.arrange(pA, pB, ncol=2)\n\n\n\n\nFigure 40.5: Times series of the rabbit and fox densities.\n\n\n\n\nTo plot the trajectory, use the traj_plot() function. Unlike slice_plot(), which creates a time series plot, traj_plot() shows the trajectory.\n\ntraj_plot(f(t) ~ r(t), Eco_soln, nt=10)\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "Dynamics/B6-solution.html#sec-symbolic-solutions-ODE",
    "href": "Dynamics/B6-solution.html#sec-symbolic-solutions-ODE",
    "title": "40  Finding a “solution”",
    "section": "40.3 Symbolic solutions",
    "text": "40.3 Symbolic solutions\nOccasionally it is possible to integrate a differential equation using symbolic techniques. This is particularly true for differential equations that are linear. The example we will handle here is the first-order linear differential equation \\[\\partial_t x = a\\, x\\ .\\] An advantage of symbolic solutions is that parameters can be handled symbolically.\nA method we will use repeatedly in this block is called the “method of ansätze.” An ansatz (singular of the German “ansätze”) is, in this context, a guess for the solution. Since differential equations have been a central part of science for more than 200 years, you can imagine that a large library of equations and their solutions has been assembled. For the equations that are most frequently used and that can be solved symbolically, the solutions are already known. Thus, the “guess” for the solution can be a very well informed guess.\nLet’s see how this works for \\(\\partial_t x = a\\, x\\). From experience, the ansatz will be an exponential function of time, which we can write \\(x(t) \\equiv A e^{\\omega t}\\). We don’t yet know what is the value of \\(\\omega\\) or \\(A\\), so we plug the ansatz into both the left and right sides of the differential equation to work it out.\nPlugging in the ansatz, translates the differential equation to a new form: \\[\\underbrace{A \\omega e^{\\omega t}}_{\\partial_t x(t)}\\  =\\  \\underbrace{a A e^{\\omega t}}_{a x(t)}\\ .\\] Cancelling out the terms that appear on both sides of the equation gives \\[\\omega = a\\ \\ \\ \\text{which implies}\\ \\ \\ x(t) = A e^{a t}\\ .\\] The ansatz substitution didn’t give any result at all for \\(A\\). That is to say, unlike \\(\\omega\\), the \\(A\\) is not determined by the differential equation itself. This means that \\(A\\) must be related to the initial condition. Setting \\(t=0\\) gives \\(x(0) = A\\), so in this simple differential equation, \\(A\\) is the initial condition.\nA slightly more complex differential equation is \\[\\partial_t x = a\\, (x - b)\\ .\\] This also has an exponential solution. It’s easiest to see this by defining a new variable \\(y \\equiv x - b\\). By the rules of differentiation, \\(\\partial_t y = \\partial_t x\\), so the differential equation can be re-written in the form \\(\\partial_t y = a y\\). We already know the solution to this is \\(y(t) = y_0 e^{a t}\\). Translating by to \\(x\\) we get \\[x(t) - b = (x_0 -b) e^{at}\\ \\ \\ \\implies x(t) = (x_0 -b)\\,e^{at} + b)\\ .\\]\nFor nonlinear dynamical function, there is no perfectly general way to find symbolic solutions. But for some dynamical functions, it can be done. We’ll demonstrate by integrating \\(\\partial_t x = x (1-x)\\). The method is made more plausible by using the Leibnizian notation for derivatives, with which the differential equation has this form: \\[\\frac{dx}{dt} = x(1-x)\\ .\\] The Leibnizian notation can be interpreted as the ratio of two differentials: \\(dx\\) and \\(dt\\) in this case.\nThe idea of separating the differential equation is to algebraically move all the \\(x\\) terms to the left side of the equation and all the \\(t\\) terms to the right and then to integrate each side of the equation. \\[dx = x(1-x) dt \\ \\ \\ \\implies \\ \\ \\ \\frac{1}{x(x-1)}dx = dt\\ \\ \\ \\implies\\ \\ \\ \\int\\frac{1}{x(x-1)}dx = \\int dt .\\]\nThe integral on the right side, \\(\\int dt\\), should be easily recognizable, giving \\(\\int dt = t + F\\), where \\(F\\) is the “constant of integration.”\nThe integral on the left side may not be as familiar, but the person solving this problem for the second time will remember that \\[\\frac{1}{x(1-x)} = \\frac{1}{x} + \\frac{1}{1-x}\\] as you can confirm by putting the right side over a common denominator. Each of \\(1/x\\) and \\(1/(1-x)\\) have integrals that are logs: \\(\\int dx/x = \\ln(x) + D\\) and \\(\\int dx/(1-x) = - \\ln(1-x) + E\\). Putting the equation back together again, produces \\[\\ln(x) + D - \\ln(1-x) + E = t + F\\ .\\] At this point, move all the constants of integration over to the right side and consolate them into a single constant of integration \\(C\\). At the same time, collect together the two logarithmic terms, giving: \\[\\ln\\left(\\frac{x}{1-x}\\right) = t + C\\ .\\] Exponentiate both sides to get: \\[\\frac{x}{1-x} = \\underbrace{e^C}_{A} e^t\\  .\\] Since \\(e^C\\) is just a constant, we’ll write it more simply as \\(A\\).\nNow we have \\[x = Ae^t - x A e^t \\ \\ \\implies\\ \\ \\ x (1 + Ae^t) = Ae^t\\] which gives our solution \\[x = \\frac{Ae^t}{1 + Ae^t}\\ .\\] To find the initial condition symbolically, plug in \\(t=0\\), giving \\(x_0 = A/(1+A)\\) or, equivalently \\(A = x_0/(1-x_0)\\). Our previous examples used \\(x_0 = 0.2\\), for which \\(A = 0.2/0.8 = 0.25\\). Graphing this solution gives us the familiar sigmoid: ::: {.cell layout-align=“center” fig.showtext=‘false’}\nSymb_soln = makeFun(A*exp(t)/(1 + A*exp(t)) ~ t)\nslice_plot(Symb_soln(t, A=0.2) ~ t, domain(t=-5:10))\n\n\n\n\n\n\n\n:::\nNot all differential equations can be separated in this way, and even for those that can, the integrals may not be tractable. So this route to a solution is not a general-purpose one, unlike the Euler method. Still, the Euler method gives only an approximate solution, so with Euler we need to take care that the approximation is close enough for the purpose at hand. In this case, we have both an Euler solution (with \\(dt=0.1\\)) and a symbolic solution. Figure 40.6 shows the difference between the two solutions, which ideally should be zero. To show more of the time domain of the solution, we’ll reset the initial condition to \\(x_0 = 0.01\\). This corresponds to \\(A = 1/99\\).\n\n\n\n\n\nFigure 40.6: The difference between the Euler and the symbolic solution to \\(\\partial_t x = x (1-x)\\) as a fraction of the symbolic solution. At the worst, the Euler solution is off by 1.5 parts in one-million."
  },
  {
    "objectID": "Dynamics/B6-solution.html#exercises",
    "href": "Dynamics/B6-solution.html#exercises",
    "title": "40  Finding a “solution”",
    "section": "40.4 Exercises",
    "text": "40.4 Exercises\n\nO-TEOG4: Recognize a first-order differential equation.\nU-EJM13: Given a set of state variables, write down the framework for a system of first-order differential equations.\nV-4KF8Q: Understand that there can be (infinitely) many solutions to a differential equation.\nK-LH9CX: Each solution has its individual initial condition.\nN-SUJO3: Given dynamical functions, use the computer to sketch the flow field.\nU-5PMG7: Given dynamical functions, find a trajectory numerically and plot it.\nN-9IU5J: Plot out the individual time series from a numerically computed trajectory."
  },
  {
    "objectID": "Dynamics/B6-flow-on-line.html",
    "href": "Dynamics/B6-flow-on-line.html",
    "title": "41  Flows on the line",
    "section": "",
    "text": "The previous two chapters presented ideas relating to dynamical systems: state, state-space, dynamical function, flow, trajectory, “solution.” Now we turn to the some of the phenomena seen in dynamical systems, starting in the simplest way possible: dynamical systems with a single state variable. We’ll focus on fixed points and their stability, which can be understood qualitatively (although you need to distinguish between a positive and a negative slope). Then we’ll look at a technique we have encountered since Block 2: approximation of a function by a straight-line function. Such linear dynamics have a straightforward exponential “solution.”\nFinally, we’ll look at an important example of how careful observation of fixed points and the way dynamics change when we modify a parameter in the dynamical functions provides an understanding of a ecological stability and instability and the consequences that result."
  },
  {
    "objectID": "Dynamics/B6-flow-on-line.html#dynamical-function-and-flow",
    "href": "Dynamics/B6-flow-on-line.html#dynamical-function-and-flow",
    "title": "41  Flows on the line",
    "section": "41.1 Dynamical function and flow",
    "text": "41.1 Dynamical function and flow\nIn the previous chapter, we saw how to draw a flow field in a two-dimensional state space, evaluating the dynamical functions and using the results to construct a vector. We can’t practically visualize both the flow and the shapes of the two dynamical functions in a single plot, which makes it harder to understand structures such as fixed points.\nHappily, with a one-dimensional state space, we can easily show both the flow vectors and the single dynamical function at once.\nFor ease of reference, we’ll name the dynamical function for the rest of this section \\(f(x)\\), so that the differential equation is \\[\\partial_t x = f(x)\\ .\\]\nThe flow itself appears as the example in Figure 41.1. The state space is the number line and the flow vectors are, as usual arrows that point from place to place in the state space.\n\n\n\n\n\nFigure 41.1: A one-dimensional state space shown with its flow vectors.\n\n\n\n\nBecause the state space can be drawn without using the vertical coordinate of the page, we can use that vertical coordinate to show something else: the dynamical function, as in Figure 41.2.\n\n\n\n\n\nFigure 41.2: A one-dimensional state space shown with its flow vectors.\n\n\n\n\nThe correspondence between the dynamical function and the flow field is easy to see in such a presentation. Where the output of the dynamical is large and positive (say, near \\(x=0\\)), the flow is in the positive direction and relatively fast, as shown by a long, right-pointing flow vector. When the output of the dynamical function is negative (around \\(x=3\\), for instance) the flow is in the negative direction: a left pointing arrow.\nNear a zero crossing of the dynamical function, the flow arrows are negligibly short: the state velocity is very slow. Indeed, at the zero crossings, the state velocity is exactly zero. Such zero crossings are called fixed points: since the state velocity is zero, the state never moves!\nWe can see the dynamics near fixed points more closely by zooming in, as in Figure 41.3 which shows two of the system’s fixed points.\n\n\n\n\n\nFigure 41.3: Zooming in on the flow for the system shown in @fig-phase-line-intro2.\n\n\n\n\nNotice in Figure 41.3 that the flow is slower the nearer the state is to the fixed point, but it is only exactly zero at the fixed point.\nA calculus technique you will be familiar with from previous Blocks is zooming in a region that we want to examine in detail.\n\n\n\n\n\nFigure 41.4: Zooming in closely on each of the fixed points seen in @fig-phase-line-intro3.\n\n\n\n\nThe short pieces of the dynamical function shown in Figure 41.4, are, like short pieces of any continuous function: almost exactly straight lines. For the left fixed point, the dynamical function is \\(f(x) \\approx -2.804 (x + 3.055)\\) while for the right it is \\(f(x) \\approx 5.065 (x + 1.586)\\). In Section @ref(symbolic-solutions-ODE) we found symbolically the solutions for dynamical functions in this form. For \\(x_0\\approx-3.055\\) the solution is \\[x(t) \\approx (x_0 + 3.055)e^{-2.804 t} - 3.055\\ ,\\] while for \\(x_0\\approx -1.586\\) the solution is \\[x(t) \\approx (x_0 +1.586)\\, e^{5.065 t} - 1.586\\ .\\] There is something fundamentally different about these two solutions. One of them is exponential decay toward the fixed point, while the other grows exponentially away from the fixed point. We call the dynamics near the fixed-point with exponential decay stable and the dynamics near fixed-point with exponential growth unstable.\n\nGraphics such as Figure 41.2 let you see both the flow and the dynamical functions together in one place.\nHow about also showing trajectories? Unfortunately, the two-dimensional extent of a computer screen or a piece of paper make it hard to include still more information in an intelligible way. It would be nice to have a third dimension for the display.\nMajor Austin Davis developed such a display, using time as the third dimension. In the movie below, the state space is shown as a horizontal line, as before. The vertical axis shows the dynamical function as in Figure 41.2. The dynamical function is shown in another way: as the hue and intensity of color, which lets you focus on the activity in the state space. This activity is shown by the moving gray triangles. Each triangle is placed on the phase line to mark an initial condition, then moves right or left according to the dynamics.\n::: {.cell layout-align=“center” fig.showtext=‘false’}  \nSorry, your browser doesn't support mp4 videos.\n\n\n\nNeed to provide a link to movie for PDF output.\n\n:::"
  },
  {
    "objectID": "Dynamics/B6-flow-on-line.html#generic-behavior",
    "href": "Dynamics/B6-flow-on-line.html#generic-behavior",
    "title": "41  Flows on the line",
    "section": "41.2 Generic behavior",
    "text": "41.2 Generic behavior\nSo long as two dynamical systems have similar fixed points with the same stability, their trajectories will be much the same. For example, our model dynamical function might be different in detail, as in Figure 41.5, and still produce the same behavior.\n\n## Warning: Removed 32 row(s) containing missing values (geom_path).\n\n\n\n\nFigure 41.5: The dynamical function shown in black is a distortion of \\(f(x)\\) from the previous plots. Yet the flow field is practically identical and leads to the same outcomes as \\(f(x)\\) for any initial condition.\n\n\n\n\nSo long as two flows have similar fixed points with the same stability, their trajectories will be much the same. Consequently, studying the fixed points without worrying about the details of the dynamics gives a huge amount of information about the system.\nFor example, Figure 41.6 shows a score of different time series following the solutions from a score of initial conditions. The long-term behaviors for all the time series is similar: they converge to one or another of the stable fixed points.\n\n\n\n\n\nFigure 41.6: Time series from the differential equation \\(\\partial_t x = f(x)\\) starting at many initial conditions. The locations of the three fixed points are marked with horizontal lines. All the solutions convert to one or the other of the two stable fixed points in the system, and depart from the unstable fixed point.\n\n\n\n\nIt’s worth pointing out a consequence of the mathematics of continuous functions: if a system with a continuous dynamical function has a region of state space with two different fixed points, there must be an unstable fixed point in between them."
  },
  {
    "objectID": "Dynamics/B6-flow-on-line.html#linearization",
    "href": "Dynamics/B6-flow-on-line.html#linearization",
    "title": "41  Flows on the line",
    "section": "41.3 Linearization",
    "text": "41.3 Linearization\nYou can see in Figure 41.6 that many of the solutions approach their final, equilibrium value in an exponential manner. This is particularly true for the solutions with initial conditions very near the stable fixed points. All these solutions are characterized quantitatively by the parameter \\(a\\) in the exponential solution \\(A e^{a t}\\). (Remember, \\(a < 0\\) when there is exponential decay.)\nQuantitative knowledge of \\(a\\) is helpful to understand the time scale of the exponential approach to stable fixed points. We can find a numerical value for \\(a\\) for each fixed point by constructing a linear approximation to the dynamical function near each of the fixed points.\nThe procedure involves the same principles as introduced in Block 2 for constructing low-order polynomial approximations to functions, but here “low-order” means “first order.”\nThe analysis is done separately for each of the fixed points, so the first step is to find the fixed points, the values \\(x^\\star\\) such that \\(f(x^\\star) = 0\\).\nRecall from Block 2 the Taylor polynomial approximation to a function \\(f(x)\\) centered on a point \\(x^\\star\\): \\[f(x) \\approx f(x^\\star) + \\partial_x f(x^\\star) \\left[x - x^\\star\\right]\\] When \\(x^\\star\\) is a fixed point, \\(f(x^\\star) = 0\\) so the approximation is simply \\(f(x) \\approx \\partial_x f(x^\\star) \\left[x - x^\\star\\right]\\). Keep in mind that \\(\\partial_x f(x^\\star)\\) is the derivative function \\(\\partial_x f\\) evaluated at the input \\(x^\\star\\), so \\(\\partial_x f(x^star)\\) is simply a quantity, not a function. Indeed, \\(\\partial_x f(x^star)\\) is exactly the quantity \\(a\\) in the exponential solution \\(e^{a t}\\).\nThis process of constructing the linear approximation \\(f(x) \\approx a \\left[x - x^\\star\\right]\\) is called linearization.\n\nConsider the first-order differential equation \\[\\partial_t x = f(x) \\equiv r x (x - x/K)\\] where \\(r\\) and \\(K\\) are parameters that are greater than zero. Linearizing the nonlinear function \\(f(x)\\) lets us figure out how fast or slow is the exponential growth or decay of the solutions for initial conditions near the fixed points.\n\nThere are two fixed points, one at \\(x_1^\\star = 0\\) and the other at \\(x_2^\\star = K\\). What is the exponential parameter \\(a\\) for each of the fixed points.\nThe derivative (with respect to \\(x\\)) \\(\\partial_x f(x)\\) can be found with the product rule from Block 2. It is \\[\\partial_x f(x) = r\\, (1 - x/K) - r\\, x\\, (1/K)\\]\nEvaluating \\(\\partial_x f(x)\\) at the two fixed points \\(x_1^\\star = 0\\) and \\(x_2^\\star = K\\) gives\n\n\\[\\partial_x f(x_1^\\star) = r\\ \\ \\ \\text{and}\\ \\ \\ \\partial_x f(x_2^\\star) = -r\\] Solutions near \\(x_1^\\star\\) will grow exponentially as \\(e^{r t}\\), unstable since \\(0 < r\\). Solutions near \\(x_2^\\star\\) will decay toward \\(x_2^\\star\\) in an exponential manner as \\(e^{-r t}\\).\n\n\nIt’s critical to distinguish carefully between \\(x^\\star\\), which is the location of the fixed point being examined, and \\(x_0\\), which is the initial condition of the state, that is, \\(x(t=0)\\).\n\n\n\\(\\ \\)\nLet’s return to the model of saving for retirement in ?sec-diff-eq-intro: \\[\\partial_t V = r\\, V + M\\ .\\] The state variable here is named \\(V\\). The dynamical function is \\[g(V) = r\\, V + M\\] where \\(r\\) is the interest rate (say, 3% per year which is \\(r=0.03\\) per year) and \\(M\\) is the monthly contribution. To keep the units consistent, we set the units of \\(t\\) to be years, of \\(r\\) to be 1/years, of \\(V\\) to be dollars and of \\(M\\) to be dollars-per-year. So a monthly contribution of $1000 would come to \\(M=12000\\) dollars-per-year.\nFind the amount \\(V\\) that will result from 30 years of savings with an initial condition \\(V_0 = 0\\).\nStep i) Find the fixed point. This is a value \\(V^\\star\\) such that \\[r\\, V^\\star + M = 0\\ \\ \\ \\implies \\ \\ \\ V^\\star = -M/r\\ .\\] Step ii) Find the derivative of the dynamical function evaluated at the fixed point: Since \\(g(V)\\) happens to be a straight-line function, we know the derivative is a constant. So \\(b = \\partial_x g(V^\\star) = r\\).\nStep iii) Translate the state variable into \\(y = V - V^\\star\\). The dynamics in terms of \\(y\\) are \\(\\partial_t y = b y\\), which has an exponential solution \\(y = A e^{bt}\\).\nStep iv) \\(A\\) is the initial condition in terms of \\(y\\). This will be \\(y_0 = V_0 - V^\\star\\). Since we stated that \\(V_0 = 0\\) (no savings at the start), \\(y_0 = -V^\\star\\) and the solution is \\[y(t) = -V^\\star e^{bt} = \\frac{M}{r} e^{rt}\\ .\\]\nStep v) Translate the solution in step (iv) back into terms of \\(V(t)\\). Since \\(y(t) = V(t) - V^\\star\\), this will be \\(V(t) = y(t) + V^\\star\\) or, \\[V(t) = \\frac{M}{r} e^{r t} + V^\\star = \\frac{M}{r} \\left[ e^{r t} - 1\\right]\\ .\\] To get an idea of this retirement plan, that is, \\(r=3\\%\\) and \\(M=12000\\) dollars-per-year, let’s see how much you’ll have after 30 years and 40 years. ::: {.cell layout-align=“center” fig.showtext=‘false’}\nV <- makeFun((M/r)*(exp(r*t)-1) ~ t, r=0.03, M=12000)\nV(30)\n## [1] 583841.2\nV(40)\n## [1] 928046.8\n\nAfter 40 years of contributions, your retirement account will have almost one-million dollars.\nYou could have accomplished the same calculation using integrateODE(), like this: ::: {.cell layout-align=“center” fig.showtext=‘false’}\nSoln <- integrateODE(dV ~ r*V + M, V=0, M=12000, r=0.03,  \n                     tdur=40)\nSoln$V(30)\n## [1] 583841.2\nSoln$V(40)\n## [1] 928046.8\n::: :::"
  },
  {
    "objectID": "Dynamics/B6-flow-on-line.html#bifurcation",
    "href": "Dynamics/B6-flow-on-line.html#bifurcation",
    "title": "41  Flows on the line",
    "section": "41.4 Bifurcation",
    "text": "41.4 Bifurcation\nA broad, pressing, social concern goes under the name sustainability. Is it sustainable to burn fossil fuels at steady historical levels, let alone at the increasing rate seen since over the last century? Climate scientists answer resoundingly with a no. Is it sustainable to increase food production to the levels needed for developing economies to approach the sort of consumption seen in rich economies?\nDynamical systems are highly relevant to the questions surrounding sustainability. If the economy is near a stable fixed point, then it is sustainable; the trajectory will bring the state of the economy toward the fixed point. On the other hand, if the economy is near an unstable fixed point, we can expect exponential change.\nIf such exponential changes are not seen, does that mean we’re not near an unstable fixed point? One of the terms used to mark the possibility that a stable system can quickly turn unstable is tipping point, defined as\n\nThe point at which a series of small changes or incidents becomes significant enough to cause a larger, more important change. Source: New Oxford American Dictionary\n\nThe mathematics of tipping points is not at all the same as exponential growth. Certainly, in exponential growth one sees a relatively slow rate of change increase to a large rate of change, a situation described by journalists as “sky-rocketing” or “explosive” or, literally, “exponential.” As you’ve seen, exponential growth is a phenomenon seen in linear dynamical systems; there is no special point at which the dynamics changes.\nThere is an area of mathematical theory called catastrophe theory. We’ll use a famous example to show how catastrophes or tipping points are modeled mathematically.\nThe example comes from a 1977 article in Nature, one of the world’s most prestigious scientific journals. The article, by Robert May, is entitled “Thresholds and breakpoints in ecosystems with a multiplicity of stable states.” The words “thresholds” and “breakpoints” have not been encountered yet in this book, but “multiplicity of stable states” should bring to mind the sort of dynamics seen in Figure 41.2.\nThe setting for the catastrophe is an otherwise bucolic scene, livestock grazing on a pasture. A pasture is a kind of factory for producing vegetable biomass; the grazing is the consumption of the biomass produced.\nAs a model for the production of biomass, denoted \\(v\\) for “vegetation,” we’ll use \\[\\partial_t v = r v \\left(1 - \\frac{v}{K}\\right)\\] which, as we’ve seen, has an unstable fixed point at \\(v_1^\\star=0\\) and a stable fixed point at \\(v_2^\\star=K\\). Physically, the fixed point \\(v_1^\\star\\) corresponds to a bare field, without any vegetation. It’s unstable because any small disturbance in the form of a stray seed landing in the dirt can lead to germination and the rapid growth of vegetation as seeds from the germinated plant spread across the field. Once the field is covered in vegetation, the growth can be exponentially rapid at first but then runs into limited resources: there is only so much sunlight that falls on the field, and the growing vegetation will eventually consume the soil nutrients and water.\nThis biomass production model corresponds to a sustainable system. Once the biomass level is at \\(v_2^\\star\\) it will stay there.\nBut biomass production is not the only thing going on in the pasture. The grazing animals—let’s imagine they are cows—are consuming the grass. To start very simply, suppose that each cow consumes amount \\(C\\) of biomass each day. If there are \\(H\\) cows, the total consumption is \\(H C\\) per day. This modifies the dynamics to a slightly new form \\[\\partial_t v = r \\,v(1-\\frac{v}{K}) - HC\\]. The original, ungrazed dynamics are compared with the grazed dynamics in Figure 41.7.\n\n\n\n\n\nFigure 41.7: Comparing the pasture dynamics for different herd sizes.\n\n\n\n\nWith grazing, the net growth of biomass is reduced due to the removal of the consumed biomass by the cows’ consumption. For a moderate herd size, there is still a stable fixed point, but it is at a lower level of biomass than would be seen in the ungrazed field. But if the herd size is too large, the ecosystem completely collapses.\nThis is an example of a tipping point or catastrophe. For moderate herd sizes, there remains a stable fixed point. A farmer might be tempted to add another cow to the pasture, and that’s sustainable: there is still a stable fixed point. Indeed, the movement of the stable fixed point might not even be noticed. But add even one cow too many and the fixed point entirely disappears. Still, herd management can fix the problem; take away the cow that tipped the pasture and the fixed point will return.\n\nWe’ve often referred to the modeling cycle, using the results of a model to suggest possible improvements in the model.\nMissing from the pasture model is a simple idea of how cows eat. If there is very little biomass, the cows can’t continue to eat their fill. Will the reduction in consumption per cow preserve the stable fixed point?\nIn his Nature article, May modeled the consumption rate by a single cow with the functional form \\[C(v) \\equiv \\frac{\\beta v^2}{v_0 - v^2}\\] which is graphed for \\(\\beta=0.1\\) and \\(v_0 = 3\\) in Figure 41.8\n\nconsumption <- makeFun((beta*v^2/(v0^2 + v^2))~ v, beta=0.1, v0=1)\nslice_plot(consumption(v) ~ v, domain(v=0:10)) %>%\n  gf_labs(y=\"Consumption (tons/day)\", x=\"v: available biomass (tons)\")\n\n\n\n\nFigure 41.8: Consumption of vegetation by a single cow as a function of the amount available in the pasture.\n\n\n\n\nYou can recognize this as a form of sigmoid. When the amount of vegetation is very large, a cow will eat her fill. That’s the saturation of the sigmoid. For small \\(v\\), the cow needs to hunt around for vegetation tall enough to eat, reducing the consumption steeply.\nFigure 41.9 modifies the pasture dynamics to incorporate this sigmoidal model of consumption.\n\n\n\n\n\nFigure 41.9: Pasture dynamics for a sigmoidal consumption function.\n\n\n\n\nWe can start the story with 3 cows in the pasture. Vegetation growth is more than sufficient to provide for these cows. You can see this from the stable fixed point at about 9 tons of biomass, which is more than enough to reach saturation of the sigmoidal consumption function.\nThe farmer decides to increase the herd to 5 cows. Nothing much happens. The stable fixed point is at about 8 tons of biomass, entirely adequate to keep the cows well fed in a sustainable manner.\nCan the pasture be sustainable with 7 cows? The stable fixed point remains, now at about 6.5 tons at biomass. The cows are still sustainably well fed.\nYou can see in the 7-cow dynamics a hint of what of what might go wrong. There is a new, unstable fixed point at about 3 tons of biomass. If the pasture ever happened transiently to fall below 3 tons—say due to a summer frost followed by a return to normal weather—the vegetation biomass will head toward the new stable fixed point at 0.5 tons of biomass. At this level, the cows are eating only about one-quarter their normal amount and we can fairly say that the ecosystem has collapsed. But until such a disaster happens, the farmer will see only a sustainable level of biomass with cows well fed.\nIt is only we, who have a mathematical model of the situation, who can anticipate the potential problems.\nSince things are fine with 7 cows in the field, the farmer lets an eighth cow join the herd. That’s the tipping point. The happy herd fixed point at 6.5 tons of biomass has disappeared, and the ecosystem collapses, even without a weather disaster.\nRemoving the eighth cow from the pasture will not fix the situation. With seven or even six cows in the pasture, the system won’t be able to grow out of the stable fixed point with 0.5 tons of biomass. Reducing the herd size to five will remove that 0.5 ton fixed point, but the grass will grow back very slowly; the dynamics give positive growth, but very close to zero.\nAvoiding such catastrophes is a major motivation for mathematical modeling."
  },
  {
    "objectID": "Dynamics/B6-flow-on-line.html#exercises",
    "href": "Dynamics/B6-flow-on-line.html#exercises",
    "title": "41  Flows on the line",
    "section": "41.5 Exercises",
    "text": "41.5 Exercises\n\nV-YGS71: Find the location of fixed points in a one-state-variable system by finding zeros of the dynamical function:\n\ngraphically or computationally when all parameters are known\nanalytically in simple cases (e.g. quadratic polynomial)\n\nJ-YOLEG: Deduce the stability of a fixed point by:\n\nexamination of the slope of the dynamical function in a first-order system\n\nF-QSK86: Identify the long-term behavior of trajectories starting near an unstable fixed point. For first-order systems, identify when the long-term behavior terminates at a stable fixed point, and which one.\nX-DE4WK: Construct the linear approximation to a dynamical function at a fixed point:\n\nevaluate the derivative of the dynamical functions at the fixed point\n\nC-QDOXL: Given a first-order differential equation of the form \\(\\partial_t x = a x + b\\), find the solution analytically in terms of \\(x\\).\n\nDetermine the location of the fixed point \\(x^\\star\\).\nTranslate the equation to be in terms of \\(y\\), where \\(y = x - x^\\star\\).\nWrite down the solution in terms of \\(y\\).\nTranslate the solution back to be in term of \\(x\\).\n\nL-ZPTTA: Verify (by differentiation) a proposed solution to a first-order differential equation.\nL-ZPDIJ: Construct graphs, with properly labeled axes, of\n\nNewton’s Law of Cooling\npopulation growth with and without a carrying capacity\n\n\nStill relevant …\n\nN-O88YI: From a trajectory drawn on a graph of a flow field, construct a plausible time-series plot"
  },
  {
    "objectID": "Dynamics/B6-flow-on-plane.html",
    "href": "Dynamics/B6-flow-on-plane.html",
    "title": "42  Flows on the plane",
    "section": "",
    "text": "Let’s return the rabbit/fox system as an example of flow. Since there are two state quantities, \\(r\\) and \\(f\\), the state space \\((r, f)\\) is a plane. At each point in the state space, the flow vector gives the direction and speed of motion. Like all vectors, a flow vector has only two properties: the direction and length. The speed of motion is the length of the flow vector.\nThe flow itself is a vector field. This is an assignment of a vector to each point of the state space. Graphically, we depict a flow field by selecting a grid of points in the state space, finding the flow vector for each grid point, and drawing those vectors positioned at their respective grid points.\nRecall from Block 5 that it’s conventional to specify a vector by giving a coordinate pair for the tip of the vector with the understanding that the tail is at the origin. For the rabbit/fox system, the tip’s coordinate is \\(\\left({\\Large\\strut} g_r(r, f),\\  g_f(r, f)\\right)\\). This notation is potentially confusing, because the letters \\(r\\) and \\(f\\) appear in so many places. Each each vector in ?fig-rf-flow2 is drawn at a particular point, say \\((r=0.96, f=0.48)\\). At that point, evaluate the dynamical functions: \\(g_r(r=0.96, f=0.48) = 0.0207\\) and \\(g_r(r=0.96, f=0.48)= 0.941\\).\nA fixed point of the dynamics is a point in the state space where the dynamical functions both evaluate to zero. It’s convenient to mark fixed points as the intersection of zero contours of the dynamical functions. Figure 42.2 shows these zero contours (red for rabbits, blue for foxes) laid on top of the flow field. Such zero contours of dynamical functions are called nullclines. (The word means “zero slope”. “Null” corresponds to zero and “cline” is the root of words like “incline” or “decline.”)\nDue to the nature of fixed points, if the initial condition is at the intersection of the nullclines the state will not change. But is the fixed point stable or unstable.\nAs you will see, in two and higher dimensional dynamical systems, there is more than one kind of stability and more than one kind of instability. These different kinds of stability and instability have a direct correspondence to different kinds of behavior in real-world systems.\nVery near the fixed point, dynamics are approximately linear. We’ll return to a quantitative analysis of this in Section 44. Our objective here is to show that there are several generic types of behavior and that the stability of dynamics near the fixed point has to be one of a handful of different types."
  },
  {
    "objectID": "Dynamics/B6-flow-on-plane.html#sec-qualitative-stability",
    "href": "Dynamics/B6-flow-on-plane.html#sec-qualitative-stability",
    "title": "42  Flows on the plane",
    "section": "42.1 Generic behaviors",
    "text": "42.1 Generic behaviors\nOn a nullcline of a dynamical variable \\(x\\), the \\(x\\)-component of the flow must be zero. The flow will point to positive \\(x\\) on one side of the nullcline and negative \\(x\\) on the other. This is really nothing more than saying that on one side of a zero contour the function value is positive and on the other side negative. We’ll indicate this on the following diagrams by shading the positive side of the nullcline with the same color as the nullcline itself. Figure 42.3 shows the nullclines of a linear system on separate plots. Notice that flow in the shaded side of the \\(x\\) (red) nullcline the flow always has a positive component to the right. Similarly, in the shaded side of the \\(y\\) (blue) nullcline, the flow always has a positive component to the right.\n\n\n\n\n\nFigure 42.3: The nullclines of a linear dynamical system near the fixed point. \\(x\\) nullcline is red, \\(y\\) nullcline is blue\n\n\n\n\nPlacing both nullclines on the same plot divides the region near the fixed point into four parts. This is generic behavior. Unless the two nullclines are the same as each other, the two nullclines split the region into four quadrants.\n\n\n\n\n\nFigure 42.4: Four quadrants of linear dynamics near the fixed point.\n\n\n\n\nWe can identify the quadrants by their color—white, red, blue, purple. In each quadrant, the “compass direction” of all flow vectors point to one quadrant of the compass: white to the south-west, red to the south-east, blue to the north-west, and purple to the north-east.\nThis particular linear flow is unstable. Notice that any initial condition in the purple quadrant will lead to a NE trajectory, away from the fixed point. Similarly, any initial condition in the white quadrant leads to a SW trajectory, again away from the fixed point. For an initial condition in the red or blue quadrants, the flow will take the trajectory into either the white or purple quandrants. The initial part of the trajectory may be towards the fixed point, but as soon as the trajectory crosses into white or purple territory, the trajectory leads away from the fixed point. So, the overall flow is unstable. This particular type of instability, where the initial path might be toward the fixed point but eventually leads away from it, is called a saddle. The flow is analogous to the movement of a marble placed on a horse saddle; it might start to roll toward the center of the saddle, but eventually it will roll off to the side.\nAll linear flows will lead to this quadrant structure. Another feature of the structure is that the white quadrant must always be opposite to the purple, and the red opposite to the blue. This allows us to enumerate the different possible types of stability.\nA very compact summary of the dynamics shows just the four compass directions and the relative positions of the quadrants. For instance, \\[\\begin{array}{c|c}\n\\color{red}{\\searrow} & \\color{purple}{\\nearrow}\\\\\\hline\n\\color{gray}{\\swarrow} & \\color{blue}{\\nwarrow}\n\\end{array}\\ ,\\] corresponds to the saddle flow seen in the previous flow field.\nThere are, altogether, eight possible configurations:\n\n\n\n\n\n\n\n\n\n[[See latex version below]]\n\nSaddles are unstable, although the trajectory might approach the fixed point at first. A source is unstable; any trajectory heads away from the fixed point. A sink is stable; any trajectory heads toward the fixed point.\nAs for the orbits, one in a clockwise direction and the other counter-clockwise, we can’t yet say from this simple theory whether they are stable or unstable. The orbit we have already met, the rabbit-fox dynamics, has counter-clockwise trajectories that form closed loops. This is called neutral stability.\n\n\n\n\n\nFigure 42.5: The rabbit/fox system has orbits that are neutrally stable."
  },
  {
    "objectID": "Dynamics/B6-flow-on-plane.html#linearization",
    "href": "Dynamics/B6-flow-on-plane.html#linearization",
    "title": "42  Flows on the plane",
    "section": "42.2 Linearization",
    "text": "42.2 Linearization\nFor dynamical systems with two state variables, constructing a linear approximation to dynamics near a fixed point follows a similar procedure to that with one-state-variable systems.\n\nLocate the fixed point.\nConstruct the first-order polynomial approximation to each of the dynamical functions at the fixed point.\n\nFor instance, the pendulum system has state variables \\(\\theta\\) and \\(v\\) with dynamics \\[\\partial_t \\theta  =  g_\\theta(\\theta, v) =  v\\\\\n\\partial_t v  =  g_{v}(\\theta, v) = - \\sin(\\theta)\n\\] There is a fixed point at \\(\\theta = 0\\), \\(v=0\\): this is just the situation of a pendulum hanging down that has no motion.\nThe dynamical function \\(g_\\theta(\\theta, v) = v\\) is already in first-order polynomial form.\nThe other dynamical function, \\(g_v(\\theta, v) = - \\sin(\\theta)\\) is nonlinear. The first order polynomial approximation centered on the fixed point will be \\[g_v(\\theta, v) \\approx \\underbrace{\\color{magenta}{g_{v}(0, 0)}}_0 + \\underbrace{\\color{magenta}{\\partial_\\theta g_v(0, 0)}}_{-\\cos(0)}\\ \\theta + \\underbrace{\\color{magenta}{\\partial_v g_v(0, 0)}}_0\\, v\\] The term \\(g_v(0, 0) = 0\\) because we are evaluating \\(g_v()\\) at a fixed point. The term \\(\\partial_v g_v(0, 0) = 0\\) because \\(g_v()\\) does not depend on \\(v\\).\nWe’ll use \\(u\\) and \\(w\\) as the dynamical variables in the linear approximation in order to avoid confusion with the original, nonlinear equations. The linearized dynamics are therefore: \\[\\partial_t u = \\ \\ w\\\\\n\\partial_t w = - u\\]\n\n\n\n\n\nFigure 42.6: Flow field, nullclines, and trajectories of the pendulum (black) and the linearized pendulum ($) from three different initial conditions."
  },
  {
    "objectID": "Dynamics/B6-flow-on-plane.html#exercises",
    "href": "Dynamics/B6-flow-on-plane.html#exercises",
    "title": "42  Flows on the plane",
    "section": "42.3 Exercises",
    "text": "42.3 Exercises\n\nD-OFZHG: Draw the nullclines of two dynamical functions on the phase plane using software.\nX-HGCV2: Find fixed points of a 2nd-order dynamical function by finding the intersection point(s) of the nullclines.\nN-CB2LE: Linearize a dynamical function of two state variables at a fixed point by constructing a first-order polynomial approximation in two variables.\nN-SCL6M: From a graph of a flow field near a fixed point, identify the qualitative stability of the fixed point as a source, center, saddle, or spiral."
  },
  {
    "objectID": "Dynamics/B6-modeling.html",
    "href": "Dynamics/B6-modeling.html",
    "title": "43  Modeling dynamics",
    "section": "",
    "text": "It’s a truism that starting a painting with a blank canvas can be daunting: so much choice and so many possibilities can be disabling. The same is true when it comes to constructing a model of a new phenomenon. You’ll need to decide what are the essential features of the phenomena, how they are connected to one another and how they connect to the question you seek to answer with the model you will eventually build.\nFor painters, there are numerous ways to confront the blank-canvas function. For instance, there are different types of paintings: landscapes, portraits, abstract, and so on. And there are different styles of painting: impressionist, rococo, cubist, art deco, and so on. I don’t think that painters would use this term, but I think of these aids to decision making as a framework, an organization of what you know to guide decision making.\nThree of the frameworks for modeling that we have worked with in this book might be called:"
  },
  {
    "objectID": "Dynamics/B6-modeling.html#a-single-state-quantity",
    "href": "Dynamics/B6-modeling.html#a-single-state-quantity",
    "title": "43  Modeling dynamics",
    "section": "43.1 A single state quantity",
    "text": "43.1 A single state quantity\nWe’ll start with situations that can be modeled with a single state variable. Throughout our examples, we’ll call that state variable \\(S\\), so the differential equation describing how \\(S\\) changes in time will always be \\[\\partial_t S = f(S)\\]. The modeler chooses the shape of \\(f()\\) depending on the situation being modeled.\nIn principle, there is an infinite number of shapes for \\(f(S)\\). But many modeling settings involve behavior that is simple. We’ll work with function shapes where the dynamical function \\(f(S)\\) is continuous and has one or two fixed points.\n\nIf \\(S\\) is observed to oscillate or to reverse the direction of change, then there must be at least one more state variable, that is, at least one more quantity that changes in time. A single first-order differential equation will not be able to model the situation.\nIf there are no fixed points, then the only possible dynamics are continuous increase in \\(S\\) or continuous decrease in \\(S\\). Often, the point of interest will be whether there is some other factor that changes increase to decrease or vice versa. Again, such situations should be modeled in the context of at least two state variables.\n\nFigure 43.1 shows four generic dynamical function shapes where these is one fixed point. The location of the fixed point is, of course, the \\(S_0\\) at which \\(f(S_0)=0\\), that is, the intersection of the function and the blue dashed line.\n\n\n\n\n\nFigure 43.1: Four generic functions shapes with one state variable having one fixed point.\n\n\n\n\nThe fundamental distinction is between models with stable and models with unstable fixed points. When the situation being modeled has a steady equilibrium, only the stable shapes of \\(f(S)\\) are relevant. A second distinction is between functions with a bounded shape and those with a linear shape. Use a linear shape when you are concerned only with the behavior near the fixed point. But when your model needs to account for behavior far from the fixed point, you need first to have a way to represent what is meant by “far from.” That is represented by the location of the shoulder of the curve relative to the fixed point.\nA setting for a linear stable model is the cooling or warming of an object to the ambient temperature. \\(S\\) stands for the temperature of the object and the fixed point is the ambient temperature. This model often goes under the name Newton’s Law of Cooling. The prestige of the model name distracts from the fact that this is a very simple model. But in the real world there are likely to be complications that make Newton’s Law imprecise, unlike, say, Newton’s Second Law of Motion which is exact (at non-quantum and non-relativistic scales). For instance, a cup of hot water will cool faster than a cup of cold water. In hot water, evaporation from the surface speeds up the warming. When ice is involved, the rate of temperature change slows when melting or freezing is encountered.\nAnother classic setting for a linear, stable model is radioactive decay. The rate at which the atoms in a mass of a radioactive isotope decay is a constant \\(\\alpha\\) that depends on the nuclear structure. A mass of \\(n\\) atoms will produce \\(\\alpha n\\) individual decay events in a given time interval. But, since each decay event reduces \\(n\\) by 1, the differential equation describing the number of radioactive atoms is \\[\\partial_t n = - \\alpha nt\\] which leads to exponential decay towards zero. Notice that only the \\(0 \\leq n\\) half of the state space is relevant, because the number of atoms can’t be negative.\nAn example of a setting where the bounded stable model applies is one where \\(S\\) stands for the amount of prey or food stock, and there is a constant population of predators who have a limited capacity for eating. Consider, for example, \\(S\\) being the availability of acorns. There might be a fixed population of, say, oaks that produce acorns at a given rate. When predation is low, the acorns accumulate. But when there are a lot of acorns, predators might focus on that bountiful food source. Still, they can only eat so many acorns per day before they are full.\n\nRemember that in a differential equation \\(\\partial_t S = f(S)\\), the input to \\(f()\\) is has dimension \\([S]\\), while the output of \\(f()\\) has a different dimension: \\([S]/[t]\\). Thus, in the oak/acorn example above, the output of \\(f()\\) has a dimension corresponding to acorns per day, a rate of consumption. \\(S\\) is acorns, the output of \\(f(S)\\) is acorns per day.\n\nThe linear unstable model is often used to model population growth. The underlying idea, which might or might not correspond to reality, is that there is a set reproduction rate per member of the population. The differential equation is \\[\\partial_t{S} = a S + c\\] with \\(S\\) being the size of the population. The parameter \\(c\\) captures immigration (\\(0 < c\\)) or emigration (\\(c < 0\\)). To be more detailed, the model can be written as summing a birth process and a death process: \\[\\partial_t S = b S - d S + c\\] where \\(b\\) is the birth rate and \\(d\\) is the death rate. Of course, the detailed model collapses arithmetically to the \\(a S + c\\) model, with \\(a = b - d\\). Still, elaborations on the birth or death processes may include the influence of changing factors. We’ll return to this idea in a bit.\nTake care to use the parameters \\(a\\) and \\(c\\) correctly. The output of \\(f(S) = a S + c\\) must have dimension \\([S]/[t]\\), for instance organisms per hour might be appropriate for bacteria. Thus the individual terms \\(aS\\) and \\(c\\) must have dimenion \\([S]/[t]\\). Consequently, the parameter \\(a\\) has dimension \\(1/[t]\\) as in per hour. That might seem odd until you remember that \\(a\\) is about the creation of new organisms, \\([S]/t\\), per existing organism. Thus the dimension of \\(a\\) is \\([S] / [S][t]\\) which works out to be simply \\(1/[t]\\).\n\n\\(\\ \\)\nUnder ideal reproductive conditions, some bacteria can split in two every 20 minutes. What does this tell us about \\(a\\)?\nIt’s easy to get confused. For instance, a single bacterium that splits every 20 minutes will go from an initial population of \\(S=1\\) at time \\(t=0\\) to a population of \\(S=2\\) at \\(t=\\frac{1}{3}\\) hour to \\(S=4\\) at \\(t=\\frac{2}{3}\\) hour to \\(S=8\\) at \\(t=1\\) hour. This might make it seem that the reproduction rate is 8 per hour. But this calculation of the population size at hour 1 is redundant with the accumulation that will be accomplished in solving the differential equation.\nThe correct way to calculate \\(a\\) from the stated information that there is a split every 20 minutes works like this:\n\nThe dynamics are \\(\\partial_t S = a S\\). Therefore the solution is \\(S(t) = S_0 e^{a t}\\).\nAccording to the given information about splitting, when the initial condition is that \\(S(0) = 1\\), \\[S(1/3) = S_0 e^{a/3} = e^{a/3} = 2\\ .\\]\nWorking from \\(e^{a/3} = 2\\) gives the parameter value we see: \\(a = 3 \\ln(2)\\).\n\n\nFor bacteria, the linear unstable model may be realistic for short periods of time, or, more precisely, for as long as the population is small compared to the carrying capacity. (See Section @ref(nonlinear-on-line)/). In contrast, human and other animal populations often have an important age structure, which is just to say that neither a 6 nor a 60 year old person has the same reproduction rate as a 26 year old. Such an age structure calls for a dynamical state with multiple components.\nBut if the environment is steady—no food shortages, no disease, economy unchanging, etc.—it can be reasonable to describe even age-structured populations as a percentage growth per unit time, e.g. percent per year. Realize that such a description is not only about the biology of reproduction, but summarizes the whole system of aging, death, and reproduction. This summary description may no longer be relevant when the system as a whole changes. An example of this in the human population is seen in countries where the number of births per woman has fallen substantially—by half or more—over the time of a generation. Such falls typically accompany a growth in economic wealth and the realization that more resources (e.g. education) needs to be provided to each offspring.\n\nA situation where the linear unstable model is realistic involves nuclear decay. Previously, we’ve pointed out that radioactive decay of an isotope is well modeled by the linear stable model. This leads the number of atoms of the radioactive isotope to decay exponentially.\nBut there is an important exception. Some radioactive isotopes are fissile, for instance uranium-233, uranium-235, plutonium-239, and plutonium-241. Fissile materials decay via two different mechanisms. One is each-atom-on-its-own decay that applies generally to radioactive isotopes. The other mechanism involves the decay of one atom triggering the decay of others.\nThe means of triggering involves a sub-atomic particle called a neutron. The decay of a fissile atom releases one or more neutrons, depending on the nuclear structure. If one of these neutrons has the correct energy, and if they collide in the appropriate way with a second fissile atom, that second atom will itself undergo decay, leading to the release of more neutrons. Such a process is called a chain reaction.\nTypically, a fissile chain reaction takes place inside an engineered device called a reactor. A simple differential equation of a chain reaction can be constructed using the number of neutrons in the reactor, and is \\[\\partial_t N = \\alpha N\\ .\\] As you’ve already seen, the solution to this is \\(N(t) = A e^{\\alpha t}\\): exponential growth. The value of \\(\\alpha\\) is determined by the design of the device. If the device is small, then neutrons can escape from the device before triggering a reaction, so alpha is small. If there are non-fissile neutron absorbers in the device, neutrons are taken out of play so, again, alpha is small and can even be negative.\nIn everyday terms, rapid exponential growth is called an explosion. Exponential growth can’t continue forever, and indeed a fissile bomb blows itself up, resulting in negative \\(\\alpha\\) as the fissile material is scattered.\nControl of a fission bomb requires a mechanism that changes \\(\\alpha\\) from negative (stable \\(N\\), so no explosion) to positive. This can be accomplished, for instance, by bringing together pieces of fissile material that by themselves has negative \\(\\alpha\\) into a critical mass where \\(\\alpha\\) positive.\nNon-explosive nuclear reactions, as in power plants, call for a kind of juggling act. The device can’t have negative \\(\\alpha\\) or the reaction would die out exponentially. It can’t have positive \\(\\alpha\\) or the reaction would become explosive.\nA power reactors is designed to keep \\(\\alpha\\) near zero. Near zero not at zero. The reactor design needs to allow \\(0 < \\alpha\\) to start up the reaction, but trim this down to zero when the reactor is at the desired power. Typically, there is some combination of active and passive mechanisms to provide this capability. An active mechanism is the insertion of “control rods,” which absorb neutrons by reactor operators to make \\(\\alpha < 0\\) when the power generation is higher than desired. Passive mechanisms can involve the transformation of reactor water into steam, which reduces the ability of neutrons to induce new fissile decays.\nReactors can be very complicated, however. The explosion of the Soviet Union’s Chernobyl reactor in 1986 was caused by a chain of events that led to control rods being withdrawn beyond the design intentions. Due to the construction of the rods, reinserting the rods to dampen the run-away reaction caused the reaction to accelerate. Avoiding such disasters requires a combination of safety oriented design and proper training of the operators. Neither of these were a feature of the 1980s Soviet environment, where secretiveness interfered with proper training and economic motivations to produce were so strong as to encourage widespread cheating.\n\nThe bounded unstable model is a way to incorporate factors that interfere with sustained exponential growth. Exponential growth requires that the growth rate \\(\\partial_t S\\) increase as \\(S\\) increases: a kind of positive feedback. In the bounded model, the growth rate becomes constant for large \\(S\\). A constant growth rate means that \\(S\\) will grow steadily, that is \\(\\partial_t S = c\\) which has a solution that grows linear in time, as distinct from the exponential solution that results from \\(\\partial_t S = a S\\).\nAn application of the bounded unstable model is seen in the description of micro-organism growth given by Jacques Monod (1910-1976), a Nobel Prize winning biochemist. His idea was that the organisms are reproducing in a kind of sea that has a limited concentration of an essential nutrient, but very large amounts of the nutrient spread out over space. Even though the nutrient is begin consumed by the organisms, more nutrient diffuses in from far away to keep the concentration steady. At large population sizes, the growth rate is nutrient concentration limited, hence constant.\nIn Chapter 14 we introduced the idea of a modeling cycle: taking an initial model, examining the consequence/predictions of that model, and then modifying the model to better correspond to observed reality or new mechanism.\nA case in point is the linear unstable model for population growth. The linear model is always appropriate near a fixed point. This is just a consequence of the calculus idea that any function can be approximated by a linear function over a small enough domain. In defining derivatives, the question was what constitutes “small enough.” So a linear dynamical function is a good starting point for dynamics near a fixed point. But, as we’ve seen, extending the linear model far from the fixed point leads to population explosion: exponential growth. This can be a valid idea for modeling a pathogen growing in a bowl of room-temperature chicken salad: the pathogen need not consume all the salad to become a threat, so in the domain of interest—human health—the linear model can do the job.\nBut we observe generally that exponential growth does not continue indefinitely. The demographer Thomas Malthus (1766-1834) famously propounded a “principle of population” which held that it is in the nature of populations to growth exponentially until linally limited by famine or disease. He wrote, “[G]igantic inevitable famine stalks in the rear, and with one mighty blow levels the population with the [lack of] food of the world.”\nMalthus’s model is exponential growth that runs into a wall of limited food. Malthus saw human reproduction as the engine of the immense poverty and suffering of the lower classes in early industrial Britain. This became the basis of an important political dispute, two poles of which are “there’s no point helping the poor, because they create their own poverty,” and “the poverty is due to exploitation, not reproduction.”\nFor us in calculus, there’s a middle road: Malthus’s mathematical model, the unstable linear model, is much too abrupt and narrow minded and can easily be made more realistic. Adding that realism removes the “one mighty blow” from the situation. Let’s add that realism now.\nRecall the earlier suggestion that the linear unstable model \\(\\partial_t S = a S + c\\) be broken into components: \\[\\partial_t S = \\underbrace{b S}_{\\text{births}}\n- \\underbrace{d S}_{\\text{deaths}} + \\underbrace{c}_{\\text{immigration}}\\ .\\]\nEven in Malthus’s time, there were calls to alleviate poverty by encouraging people to leave for less crowded lands: emigration. In the dynamics, emigration corresponds to a negative value for \\(c\\).\nMaking \\(c\\) negative does not do the job on its own. Note that whatever the value of \\(c\\), the dynamics are unstable. Emigration at a constant rate changes the location of the fixed point, but since the dynamics are unstable, growth will still be unbounded. Suppose, however, that government policy sets an emigration goal not as a constant number of people per year but as a constant fraction, \\(eS\\) of the population. Now the dynamics become \\[\\partial_t S = b S - d S - e S\\ .\\] These dynamics are stable or unstable depending on the value of \\(b - (d+e)\\). If that value is negative, the dynamics are stable, if positive, the dynamics are unstable. The situation resembles (mathematically) that of a nuclear power reactor: the control parameter \\(e\\) has to be carefully manipulated to set the population at a fixed level.\nBut there are other things that come into play. One of them is that the parameter setting the death rate, \\(d\\), need not be constant. From Malthus’s perspective, \\(d\\) would change in episodes set by disease and starvation. In Malthus’s era, pandemics were common and wiped out a major fraction of the population in “one mighty blow.” Similarly, starvation plays out on a smaller time scale than reproduction and seems to cut through the population.\nBut the death rate can also be a function of population \\(S\\). For instance, \\(d = d_0 + d_1 S\\) corresponds to a death rate that increases gradually with population size. (The parameters \\(d_0\\) and \\(d_1\\) are positive.)\nSimilarly, birth rate can depend on population, that is \\(b = b_0 - b_1 S\\). As the population gets larger, there’s less food and less space, and these changes can reduce the reproduction rate. (The parameters \\(b_0\\) and \\(b_1\\) are positive.)\nThese models for \\(d\\) and \\(b\\) are simplistic. Why should they have a linear form? The answer is … calculus. Whatever are the functions \\(b(S)\\) and \\(d(S)\\), they must be approximately linear over a small domain.\nLet’s plug in the refined models for birth and death rates into the population models. We get: \\[\\partial_t S = (b_0 - b_1 S) S - (d_0 + d_1 S) S - e\\ .\\] A little algebraic simplification reduces this to:\n\\[\\partial_t S = (b_0 - d_0) S - (b_1 + d_1) S^2 - e\\] Whatever are the size of the quantities \\(b_0, b_1, d_0, d_1\\), so long as they are positive, the dynamical function \\(f(S)\\) will have two fixed points, one at small \\(S\\) and the other at large \\(S\\). For small \\(S\\), the fixed point is unstable. The population will grow away from this fixed point. The fixed point at large \\(S\\) will be stable, hence no population explosion.\nOne of the major flaws with the Malthusian viewpoint is that it treated all the dynamical functions as linear, whereas in reality the functions can have a quadratic shape. The classical differential equation for limited population growth, \\[\\partial_t S = a S (1-S/K)\\ ,\\] was introduced by Pierre-François Verhulst in 1838, just four years after Malthus’s death.\nAnother important flaw with Malthus’s model is that it failed to account for the transition from purely agricultural economies to economies that produced large amounts of other goods and services. It turns out as populations grow wealthier, their reproduction rates decrease. With wealth available in non-food terms—clothing, public health, education—reproduction rates can go down even without the “one mighty blow” of starvation and disease.\nThe next section examines both of these factors—the introduction of multiple state variables and the ability to “soften” the explosive unstable linear dynamics with nonlinear corrections—in making subtle models of the behavior of systems."
  },
  {
    "objectID": "Dynamics/B6-modeling.html#multiple-state-quantities",
    "href": "Dynamics/B6-modeling.html#multiple-state-quantities",
    "title": "43  Modeling dynamics",
    "section": "43.2 Multiple state quantities",
    "text": "43.2 Multiple state quantities\nThe previous section examined dynamics of a single state variable. Now we will consider the possibilities when there is a second state variables. It turns out that adding more state variables above two does not introduce many fundamentally new behaviors, so we’ll focus on dynamical systems with two variables. We’ll continue to use capital letters, like \\(S\\), to stand for the state variables. But with two (or more) state variables, we’ll need to give them different names so we can keep tract of what’s doing what to what. The parameters in the dynamical functions will, as has been our practice, be written as lower-case letters, such a, b, r, c, and so on.\nA starting observation is that for dynamics to be genuinely two-dimensional, the differential equations for the state variables need to be coupled to one another. For example, a dynamical system that nominally has two state variables \\(X\\) and \\(Y\\) is:\n\\[\\partial_t X = f(X)\\\\\n\\partial_t Y = g(Y)\\ .\\]\nThe state variables here are not coupled, since the change in each variable depends only on the value of that variable and not on the other.\nCoupled state variables have dynamics that look like this:\n\\[\\partial_t X = f(X, Y)\\\\\n\\partial_t Y = g(X, Y)\\ .\\] The time evolution of each state variable depends on the other state variable.\nThe most mathematically simple form of coupled dynamics is this:\n\\[\\partial_t R = a B\\\\\n\\partial_t B = c R\\ .\\]\nWhat type of real-world setting might such a simple model correspond to? Surprisingly, even this simple model has important things to say about complex phenomena such as love and warfare.\nWe’ll start with warfare, where the signs of the parameters are easy to determine. The model, called Lanchester’s Law, is \\[\\partial_t R = - b B\\\\\n\\partial_t B = -r R\\] with both parameters \\(r\\) and \\(b\\) taken to be positive.\nThe state variables \\(R\\) and \\(B\\) stand for the size of the two armies in conflict: the Red army versus the Blue army. As the two armies meet in battle, the Blue army causes casualties in the Red army. These casualties reduce the size of the Red army. Similarly, the Red army causes casualties in the Blue army.\nThe model describes the rate of reduction in the armies as being proportional to the size of the opposing army. But the two armies can be different in their efficiency of causing casualties, reflected by possibly different values of the \\(r\\) and \\(b\\) parameters.\nThe dynamics are not exponential. Exponential decay of the army size would correspond to a model like \\(\\partial_t R = - r R\\), an army fighting itself. But the Lanchester model has \\(\\partial_t R = - b B\\).\nWe’ll defer for a moment finding the trajectories of the state variables in the course of battle. (Hint: in the model, one army wipes out the other.) Instead, we’ll focus on a surprisingly rich implication of of such simple dynamics.\nLanchester’s Law has a surprising consequence for measuring the overall strength of a force in a way that combines size (\\(R\\) and \\(B\\)) and effectiveness (\\(r\\) and \\(b\\)) and the implications that has for tactics.\nLanchester proposed that the quantity \\[Q(R, B) \\equiv rR^2 - b B^2\\] is a good way to characterize the dynamics. His reasoning was based on a fundamental idea from physics and chemistry: that quantities are conserved. In physics, examples of conserved quantities are energy, momentum, and angular momentum. In chemical reactions, the number of atoms of each species is conserved.\nIt’s hard to say how Lanchester came up with the formula \\(rR^2 - b B^2\\): insight is hard to explain. But we can easily demonstrate that it is conserved, that is, the quantity doesn’t change in time regardless of how the battle proceeds. We’ll do this by showing \\(\\partial_t Q(R, B) = 0\\).\n\\[\\partial_t Q(R, B) = \\partial_t \\left[\\strut rR^2 - b B^2\\right]\\] Applying the chain rule we find that \\[\\partial_t r R^2 = 2 r R\\, \\partial_t R\\ \\ \\ \\ \\text{and}\\ \\ \\ \\partial_t b B^2 = 2 b B\\, \\partial_t B\\ .\\] Substituting in \\(\\partial_t R = - b B\\) and \\(\\partial_t B = - r R\\) gives \\[\\partial_t Q(R, B) =  - 2 r b R B + 2 b r  B R = 0\\ .\\] The conserved quantity \\(Q(R, B)\\) describes an aspect of the battle that goes unchanged over the course of the battle. At any moment, it describes the match between the overall capability of the two armies. That the difference between the capabilities is conserved does not mean the individual capabilities are unchanged in battle. Those capabilities decrease as the army sizes, \\(R\\) and \\(B\\) are reduced. But at any instant in time, the capability of each army is proportional to the square of the army size. change The consequence, is that the capability of each army is, at all times,\nTo illustrate, consider a battle between two armies of archers. The B-army archers are more skilled: they can fire 12 arrows per minute. The R-army archers can fire at only half the rate—6 arrows per minute. But the R army is twice the size of the B army.\nAre the armies equally matched? It may at first glance seem so, since both armies can fire at the same rate. For instance, if there are 1000 archers in the R army and 500 in the B army, both armies start out capable of firing 6000 arrows per minute. But Lanchester’s Law tells us that the R army is twice as capable as the B army: \\(6 \\times 1000^2\\) is twice as big as \\(12 \\times 500^2\\).\nTo see why the R army is superior, remember that each arrow can take out only one of the opposing archers. For each B arrow that’s on target, the firing rate of R is reduced by 6 arrows per minute. But for each R arrow that hits, the firing rate of B is reduced by 12 arrows per minute. The initial casualty rate for the two armies is the same, but B sees a twice as large reduction in its firing rate.\n\nFrederick William Lanchester (1868-1946) was a British engineer, considered one of the greats of British automotive engineering. But that hardly does justice to him.\nWhile voyaging across the Atlantic to America, he became captivated by the gliding flight of herring gulls. This led to his development of his circulation theory of flight, a foundation of aerofoil theory. In 1906 he published Aerial Flight containing the first full theory of lift and drag. In Aerodonetics (1908) he developed his phugoid theory of aircraft stability, describing oscillations and stalls.\nIn 1914, Lanchester wrote a book-length series of journal articles that were published in 1916 as Aircraft in Warfare: the Dawn of the Fourth Arm. Imagine trying to theorize about a form of conflict that had never been seen!\n\nThe difficulty … is that in order to get the future into true perspective, it is necessary to be able to look forward along two parallel lines of development—i.e. to visualize the improvement of aircraft possible in the near future as a matter of engineering development, and simultaneously to form a live conception of what this improvement and evolution will open up in the potentialities of the machine as an instrument of war. (p.3)\n\n\nMathematician Steven Strogatz proposed in the 1990s that similar equations might be used to describe how love between two people varies over time. Strogatz’s equations are usually written with state variables R and J, standing for Romeo and Juliet. Positive values represent love, negative values are hate. And best to think of the model as a cartoon, but a cartoon that captures some of the behavior seen in reality.\nTo start, let’s consider a form of love that is really more like warfare:\n\\[\\partial_t R = -j J\\\\\n\\partial_t J = - r R \\ .\\] In this pathological relationship, the more Romeo loves Juliet, the faster Juliet’s love decreases toward hate. And vice versa.\nImagine that, somehow, these two perverse people started out in love: \\(R(t=0) > 0\\) and \\(J(t=0) > 0\\). As with Lanchester’s Law, both lovers fall increasingly out of love. Depending on the initial intensity of their love and whether or not \\(jJ^2\\) is bigger than \\(rR^2\\) (Lanchester’s conserved quantity), one of the parties will become indifferent, that is, a love level of 0 while the other’s love level is still positive. For the purpose of example, let’s suppose that Juliet is the first to reach indifference. But unlike the warring armies, the love quantity can become negative. As Juliet’s love becomes negative—remember, Romeo still has a positive level of love—then the true perversity of Romeo’s personality becomes apparent. Juliet’s increasing hostility causes Romeo’s love to grow. Without bound, because this is a linear dynamical function. The result is that Juliet’s hate increases even while Romeo’s love increases. But don’t blame Juliet. If Romeo had been the first to reach indifference, Juliet would suffer the unrequited love and Romeo would be villainously hateful.\nStrangely, if Romeo and Juliet started out mutually hating each other, their personalities would still lead to one having unbounded love for the other, who hates their partner without limit.\nA mathematically small change in the Romeo-Juliet dynamical system can lead to a profound change in the outcome. For instance, changing one sign, as in \\[\\partial_t R = r J\\\\\n\\partial_t J = - j J\\ ,\\] produces, as we’ll see, a never-ending cycle of alternating love/hate.\nThe two dynamical functions in the previous examples, \\(-r R\\) and \\(-j J\\) are low-order polynomials. A sensible human being might suggest that the constant term in the polynomials should be added, but the cold, analytic mind of the mathematician would see that this would only change the location of the fixed point and not its stability. That suggests that the next more complicated model to consider involves includes both variables in the dynamical function. Like this:\n\\[\\partial_t R = a R + b J\\\\\n\\partial_t J = c R + d J\\ ,\\] where the coefficients \\(a, b, c, d\\) might be either positive or negative depending on the personality of the lovers. Analysis of this model will have to await the introduction of new mathematical tools in Section 45.\nWhether Strogatz’s love model is realistic or not, it does illustrate a basic idea of model building: start with simple dynamical functions, check out their consequences, then modify the dynamical functions. We’re going to do this now, with the modifications being purely mathematical along the lines of including different terms in low-order polynomial approximations and considering positive and negative coefficients. As you’ll see, the simple models correspond to a surprisingly wide range of behaviors."
  },
  {
    "objectID": "Dynamics/B6-modeling.html#classical-phase-plane-models",
    "href": "Dynamics/B6-modeling.html#classical-phase-plane-models",
    "title": "43  Modeling dynamics",
    "section": "43.3 Classical phase-plane models",
    "text": "43.3 Classical phase-plane models\nWe have been using the term state space to refer to the set of possible values for the state variables. When there is only one state variable, the state space corresponds to the number line, or perhaps just the positive half of the number line. When there are two state variables, the state space corresponds to the coordinate plane; any point in the plane is a legitimate state for the system.\nHistorically, another term is used for the two-variable state space: the phase plane. This is just a matter of terminology, but it is so prevalent that you will occasionally see it mentioned. We don’t use it since dynamical systems can have a state space that is 1, 2, 3, or higher dimensional, but the phrase “phase plane” only works for 2-dimensional state spaces.\nIn this section, we’ll look at some famous models that involve two state variables. Out of respect for history, we’ll call these “classical phase plane” models, but this is entirely equivalent to saying “classical dynamical models with two state variables.”\nOur purpose in studying these classical models is two-fold: to show how simple models can make it easier to draw out the consequences of the mechanisms that we think are at work in real-world systems; and to show you how modifications to purely linear models can produce dynamics that are realistic even away from fixed points.\nTo start, let’s return to the Rabbit-Fox dynamics models. Classically this is called the predator-prey model. It’s also called the “Lotka-Volterra” model in honor of it’s inventors: American biophysicist Alfred Lotka (1880-1949) and Italian mathematical physicist Vito Volterra (1860-1940).\nThe two first-order differential equations in the Lotka-Volterra model are \\[\\partial_t R = \\alpha R - \\beta F R\\\\\n\\partial_t F = \\delta F R - \\gamma F\\] each of which contains a linear term (\\(\\alpha R\\) in the \\(R\\) equation, \\(\\gamma F\\) in the F equation). Each equation also contains an interaction term. Here, the mathematical/statistical name for the product of two quantities corresponds nicely with the physical reality that the terms describe what happens to rabbits when they interact with a fox, and similarly what happens to foxes. The parameters \\(\\alpha, \\beta, \\gamma\\), and \\(\\delta\\) can, mathematically, be either positive or negative, but they make sense in terms of rabbits and foxes only if all of them are positive. So the “interaction” is always negative for the rabbits and positive for the foxes.\nRewriting the model provides a bit of insight: \\[\\partial_t R \\ = \\underbrace{(\\alpha - \\beta F)}_{k_R} R\\\\\n\\ \\\\\n\\partial_t F = \\ \\underbrace{(-\\gamma + \\delta R)}_{k_F} F\\ . \\] Think about the \\(k_R\\) and \\(k_F\\) terms as the reproduction rates. If the fox population were constant, then the rabbit dynamics would be exponential growth or decay, depending on the sign of \\(k_R = \\alpha - \\beta F\\). Similarly, if the rabbit population were constant, the fox dynamics would be exponential decay or growth, depending on the sign of \\(k_F = -\\gamma + \\delta R\\).\nThe two equations are coupled so that the rabbit population alternating between growth and decay leads the fox population to so alternate, and vice versa."
  },
  {
    "objectID": "Dynamics/B6-modeling.html#epidemic",
    "href": "Dynamics/B6-modeling.html#epidemic",
    "title": "43  Modeling dynamics",
    "section": "43.4 Epidemic",
    "text": "43.4 Epidemic\nIn a communicable disease, such as COVID-19, the infectious agent is transmitted from an infective person to another person who is susceptible. The time course of an epidemic can be modeled simply with two state variables. We’ll let \\(S(t)\\) be the number of susceptible people and \\(I(t)\\) the number of infective people at any time \\(t\\).\nThe dynamics of the \\(S\\) variable can be simple: \\(S\\) changes when an infective person meets (interacts with!) a susceptible person. That susceptible person, with some probability, becomes infective. So \\[\\partial_t S = -\\beta S I\\ .\\] The dynamics of the \\(I\\) variable are a just a little more complicated. First, every person who is converted from susceptible to infective becomes a new infective. This is the \\(\\beta S I\\) term in the following differential equation. Second, infectives gradually recover. This is often modeled as a simple \\(-\\alpha I\\) term.\n\\[\\partial_t I = \\beta S I - \\alpha I\\] This is famously called the SIR model, standing for the susceptible, infective, recovered chain of events.\nIn the model, recovery means “no longer able to infect.” Thus, a person who has been isolated is considered “recovered,” whether or not they display symptoms of the disease.\nWe usually think of recovery in terms of a time span, for instance taking a week to recover. But \\(\\alpha I\\) doesn’t work this way. To see why, consider the situation starting on the day that there are no more infective people, that is, \\(S=0\\). The dynamics from this day forward are simplified: \\(\\partial_t I = =\\alpha I\\).\nOf course, the solution to this simplified differential equation is \\(I(t) = I_0 e^{-\\alpha t}\\); the size of the infective group gets smaller exponentially. Figure 43.2 compares what \\(I(t)\\) would look like if it takes, say, one week to recover and what \\(I(t)\\) looks like under the model’s \\(\\partial_t I = =\\alpha I\\) dynamics.\n\n\n\n\n\nFigure 43.2: Comparing \\(I(t)\\) for the “takes a week to recover” model and the \\(\\partial_t I = -\\alpha I\\) model.\n\n\n\n\nTo show the dynamics of the SIR model, we need to propose numerical values for \\(\\alpha\\) and \\(\\beta\\). This is not a trivial matter if the goal is to match the dynamics to a particular disease and size of population. For our purposes here, we’ll imagine that \\(S(0) = 0.999\\) and \\(I(0) = 0.001\\), which is to say we are looking at the proportion of the population that is susceptible or infective.\nFigure 43.3 shows the flow field for \\(\\beta = 1/2\\) and \\(\\alpha = 1/7\\).\n\n\n\n\n\nFigure 43.3: SIR flow field for \\(\\beta=1/2, \\alpha = 1/7\\), and the trajectory for initial conditions \\(S_0 = 0.999, I_0 = 0.001\\)."
  },
  {
    "objectID": "Dynamics/B6-modeling.html#exercises",
    "href": "Dynamics/B6-modeling.html#exercises",
    "title": "43  Modeling dynamics",
    "section": "43.5 Exercises",
    "text": "43.5 Exercises\n\nS-BOXLN: Identify and interpret mechanistically interaction terms in a two-state variable system.\nWP-205-61: Model and solve population growth problems using the natural and logistic growth models.\nL-CGDLK: Understand “coupling” and why oscillation requires that the dynamical functions in a two-state variable system must each take the other state variable as an input.\nX-LG744: Apply dynamics skills and concepts to develop a solution to a complex problem of an interdisciplinary nature.\nD-OFZHG: Draw the nullcline of a dynamical function using software.\nX-HGCV2: Find fixed points of a 2nd-order dynamical function by finding the intersection point(s) of the nullclines."
  },
  {
    "objectID": "Dynamics/B6-equilibria.html",
    "href": "Dynamics/B6-equilibria.html",
    "title": "44  Equilibrium and transient",
    "section": "",
    "text": "Many of the natural and constructed objects and systems that we encounter—buildings, bridges, airplanes, the orbits of satellites, heating systems, birds in flight, and so on—are more fully understood if seen as dynamical systems. That may seem strange; a building doesn’t move (we hope!), an airplane stays in steady flight, the seasons have been steady in their progression for as long as records have been kept. And yet … a building might be shaken and even destroyed by an earthquake, airplanes require pilots and control systems for steady flight. Even satellites in far Earth orbit can drift from their desired positions and attitudes and require control corrections.\nA system is said to be in steady state when it stays put, unchanging. Another term often used to express such constancy is equilibrium which occurs when the various forces or processes acting on the system balance out. In the language of dynamical systems, the equilibrium state of a system is called a fixed point. Mathematically, this is a coordinate in the state space where all the right-hand sides of the differential equations equal zero. For a two-dimensional system with dynamics \\[\\partial_t x = f(x, y)\\\\\\partial_t y = g(x,y)\\ ,\\] a fixed point will be a particular value for the state which we’ll write as \\((x^\\star, y^\\star)\\) where both \\(f(x^\\star, y^\\star) = 0\\) and \\(g(x^\\star, y^\\star) = 0\\).\nAn important vocabulary word in dynamics is transient. In everyday speech, this means something like “just passing through.” It’s the same in dynamics: that part of the trajectory which precedes stable, fixed behavior such as at a fixed point. Transients occur whenever a dynamical system has an initial state not on a stable, fixed state. They are also common in systems that are disrupted by some external force, for example in the recovery of an electrical power distribution grid after a disturbance such as an ice storm. After a sharp bang, the ringing in your ears is a transient. When you stand up too suddenly, the “stars” you see are a transient due to diminished blood flow. Turn on an oven? The transient is the warming up until the oven reaches the temperature setting.\nAlthough transients are … well, transient, they can be very important. Key to the Wright Brothers success was their recognition that air turbulence elicits transients in attitude and that aircraft need control systems that can work fast enough for the craft to survive the transient. If you have driven a car with a broken suspension, you’ll know that it can be hard to control after the transient caused by hitting a bump in the road.\nSmall disturbances often elicit transients that decay away exponentially. Such transients, like all exponentially decaying processes, can be characterized by a half life: the time it takes the transient to shrink to half its original value. (Not all transients decay exponentially, but that’s a story for another course.)\nIn this chapter, we’ll study the quantitative response to dynamical systems with a fixed point when the state is perturbed by some outside force. Our focus will be on linear or linearized dynamical functions, which are generally an excellent description of dynamics near a fixed point."
  },
  {
    "objectID": "Dynamics/B6-equilibria.html#one-state-variable",
    "href": "Dynamics/B6-equilibria.html#one-state-variable",
    "title": "44  Equilibrium and transient",
    "section": "44.1 One state variable",
    "text": "44.1 One state variable\nLinear systems with one state variable have simple dynamics: \\[\\partial_t y = k y\\] which has a fixed point at \\(y^\\star = 0\\). Even dynamics like \\(\\partial_t x = k x + b\\) can be easily transformed into this simple form; the fixed point is \\(x^\\star = - b/a\\) and defining \\(y \\equiv x - x^\\star\\) gives the \\(\\partial_t y = k y\\) form.\nThe solution is also simple: \\(y(t) = y_0\\  e^{kt}\\), where \\(y_0\\) is the initial condition on \\(y\\). If the parameter \\(k < 0\\), the dynamics are exponential decay to the fixed point. If \\(0 < k\\), the dynamics are exponential growth away from the fixed point."
  },
  {
    "objectID": "Dynamics/B6-equilibria.html#two-state-variables",
    "href": "Dynamics/B6-equilibria.html#two-state-variables",
    "title": "44  Equilibrium and transient",
    "section": "44.2 Two state variables",
    "text": "44.2 Two state variables\nIf the state variables \\(x\\) and \\(y\\) are measured with respect to a fixed point, the differential equation of the linear or linearized system is: \\[\\partial_t x = a x + b y\\\\\n\\partial_t y = c x + d y\\]\nExponentials are an important form of ansatz for linear differential equations. To show why, let’s review the solution to \\(\\partial_t x = k x\\), but assume that all we know is that the solution is an exponential function of time: \\(x(t) = A e^{\\lambda t}\\) and that we don’t yet know the parameters \\(A\\) or \\(\\lambda\\). As usual for an ansatz, we plug it into both sides of the differential equation, giving \\[\\partial_t A e^{\\lambda t} = k A e^{\\lambda t}\\ \\ \\implies \\lambda A e^{\\lambda t} = k A e^{\\lambda t}\\ \\ \\implies \\lambda = k\\ .\\] Now we know the value of \\(\\lambda\\).\nWhat about \\(A\\)? Evaluate the solution at \\(t=0\\). This gives \\(x(0) = A e^{\\lambda 0} = A\\). So we know \\(A\\) is the initial condition \\(x(0)\\) (which we usually abbreviate \\(x_0\\)).\nWe’ll try the same approach with the two-state variable system, but we’ll start with a special case where some of the parameters \\(a, b, c\\), and \\(d\\) are zero.\n\\[\\text{Simplification:}\\ \\ \\  \\ \\ \\begin{array}{l}\\partial_t x  = \\cancel{ax}  +  b y\\\\\\partial_t y =\\ c x + \\cancel{dy}\\end{array}\\ .\\]\nIn the spirit of exponential ansatze, we might try \\[x(t) \\equiv C e^{\\lambda_1 t} \\ \\ \\text{and}\\ \\ \\ y(t) \\equiv D e^{\\lambda_2 t}\\ .\\]\nBut this is unnecessary complexity. To see why plug the ansatze in to the first differential equation to get \\[\\lambda_1 C e^{\\lambda_1 t} = b D e^{\\lambda_2 t}\\ .\\] This can be true only if \\(\\lambda_1 \\= \\lambda_2\\) because exponentials with different half-lives can’t be proportional to one another.\nIf \\(x(t)\\) and \\(y(t)\\) are proportional to one another, then we hardly need to keep track of both. In fact, we need just one differential equation in \\(x(t)\\). To turn the system of differential equations into a single differential equation we’ll take the derivative with respect to time of both sides of the top equation, giving: \\[\\partial_{tt} x = b\\,  \\partial_{t\\ }y\\\\\n\\partial_{t\\ } y  =  c\\, x \\] Substitute in the value for \\(\\partial_t y\\) from the bottom equation to get a single, second-order differential equation: \\[ \\partial_{tt} x = b\\, c\\, x\\ .\\]\nPlug in the usual ansatz, \\(x(t) = A e^{\\lambda t}\\) to get \\[\\lambda^2 A e^{\\lambda t} = b\\,c\\, A e^{\\lambda t}\\ \\ \\ \\implies\\ \\ \\ \\ \\lambda = \\pm \\sqrt{\\strut b\\,c}\\] The \\(\\pm\\) is the interesting part here. If, say, \\(b=1\\) and \\(c=1\\), there are two values for \\(\\lambda\\) that will be consistent with the differential equation: \\(\\lambda_1 = 1\\) and \\(\\lambda_2 = -1\\). Either of these will produce a solution that satisfies the differential equation: \\(x_1(t) = A e^{\\lambda_1 t}\\) or \\(x_2(t) = B e^{\\lambda_2 t}\\). So which of the two possibilities is it?\nSince everything about the differential equation is linear, any linear combination of the two possibilities will also satisfy the equation. So we can conclude that \\[x(t) = A e^{\\lambda_1 t} + B e^{\\lambda_2 t}\\ .\\]\nSince \\(\\lambda_2 = -1\\), we know that the \\(B e^{\\lambda_2 t}\\) component of the linear combination will decay to zero. That is, \\(B e^{\\lambda_2 t}\\) is the transient part of the solution.\nWhat are \\(A\\) and \\(B\\)? That depends on the initial condition. Evaluate both sides of the solution equation at \\(t=0\\) to get \\[x(0) = A e^{\\lambda_1 0}+ B e^{\\lambda_2 t} = A + B\\ .\\] At this point, you need to look back at the original system of equations. There are two state variables \\(x\\) and \\(y\\) and therefore we need to specify two components of the initial condition. If \\(x(0)\\) is interpreted as the initial position, then following the example of the pendulum we can look to the velocity \\(\\partial_t x\\) as the second component of the initial condition. From \\(x(t)\\) we can easily calculate the velocity: \\[\\partial_t x(t) = \\lambda_1 A e^{\\lambda_1 t} + \\lambda_2 B e^{\\lambda_2 t}\\ .\\] Again, evaluate this at \\(t=0\\) to get a second equation for the initial condition the pair \\[\\begin{array}{c}\\partial_t x(0)  =   \\lambda_1 A  +  \\lambda_2 B\\\\x(0)  = \\ \\ A \\ \\  + \\ B\\\\\\end{array}\\ \\ \\ \\ \\implies\\ \\ \\ \\\n\\left[\\begin{array}{c}\\lambda_1 \\ \\ \\ \\ \\ \\lambda_2\\\\1 \\ \\ \\ \\ \\ \\  1\\end{array}\\right] \\left[\\begin{array}{c}A\\\\ B\\end{array}\\right] = \\left[\\begin{array}{c}\\partial_t x(0)\\\\ x(0)\\end{array}\\right] .\\] From Block 5, we know how to solve such matrix equations. So, given the initial values \\(x(0)\\) and \\(\\partial_t x(0)\\)—position and velocity—we can find an exact, quantitative solution to the differential equation.\n\n\\(\\ \\)\nFigure 44.1 shows the flow field, some trajectories and their time series for the system \\[\\partial_t x = b y\\\\ \\partial_t y = c x\\] for \\(b=1\\) and \\(c=2\\).\n\n\n\n\n\nFigure 44.1: Three trajectories from the system \\(\\partial_t x = y\\) & \\(\\partial_t y = 2 x\\)\n\n\n\n\nEach of these trajectories starts out by heading toward the fixed point at (0,0). Then, each turns and heads away toward \\(\\pm \\infty\\) from the fixed point,\n\n\n\n\n\nFigure 44.2: The time series \\(x(t)\\) for the three different trajectories in Figure @ref(fig:bc-system).\n\n\n\n\nEach of the time series is similar, first showing exponential decay toward 0 then exponential growth toward \\(\\pm \\infty\\).\nThe initial conditions for the black and \\(\\color{magenta}{\\text{magenta}}\\) trajectories are very similar. You can imagine a trajectory starting between those initial conditions that would go down the middle of the “trumpet.” This trajectory would be exponential decay toward 0, but would be hard to see since \\(x=0, y=0\\) is an unstable fixed point (a saddle).\nThe initial condition for the black trajectory is \\(x(0)=0.72\\) and \\(y(0)=\\partial_t x(0) = -1\\), while for the \\(\\color{magenta}{\\text{magenta}}\\) trajectory it is \\(x(0)=0.70\\) and \\(y(0)=\\partial x(0) = -1\\). Let’s find each trajectory as a separate linear combination \\(A e^{\\lambda_1 t} + B e^{\\lambda_2 t}\\). The equations to solve are \\[\\left[\\begin{array}{c}1 \\ \\ \\ \\ 1\\\\\\lambda_1 \\ \\  \\lambda_2\\end{array}\\right] \\left[\\begin{array}{c}A\\\\ B\\end{array}\\right] = \\left[\\begin{array}{c}x(0)\\\\ \\partial_t x(0)\\end{array}\\right] .\\]\nBy plugging in the parameters \\(a=0\\), \\(b=1\\), \\(c=2\\), \\(d=0\\) in the dynamical functions, we find that \\[\\lambda = \\pm \\sqrt{\\strut 2} \\approx \\pm 1.4142 \\ .\\] Therefore, we solve \\[\\left[\\begin{array}{c}1.4142 \\ \\ \\  -1.4142\\\\1 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   1\\end{array}\\right] \\left[\\begin{array}{c}A\\\\ B\\end{array}\\right] = \\left[\\begin{array}{c}\\partial_t\\,x(0)\\\\x(0)\\end{array}\\right] .\\]\n\nM <- cbind(rbind(1.4142, 1), rbind(-1.4142,1))\nb_black = rbind(-1, 0.72)\nb_magenta = rbind(-1, 0.70)\nqr.solve(M, b_black)\n##             [,1]\n## [1,] 0.006443219\n## [2,] 0.713556781\nqr.solve(M, b_magenta)\n##              [,1]\n## [1,] -0.003556781\n## [2,]  0.703556781\n\nThe two trajectories are therefore \\[x_\\text{black}(t) = 0.0064 e^{1.4142 t} + 0.7136 e^{-1.4142}\\\\\n\\color{magenta}{x_\\text{magenta}(t)} = -0.00356 e^{1.4142 t} + 0.70356 e^{-1.4142 t}\\] For both trajectories, the initial amplitude of the decaying exponential is much larger than for the growing exponential. That’s why the time series decay toward zero initially. As \\(t\\) grows, the exponential growth become much more important. For the black trajectory, the exponential growth has a positive coefficient, so the growth is toward \\(\\infty\\). But for the \\(\\color{magenta}{\\text{magenta}}\\) trajectory, the exponential growth has a negative coefficient, thus that trajectory grows toward \\(-\\infty\\).\n\nThe method we used to solve the simplified problem also works for the original problem \\[\\begin{array}{c}\\partial_t x  = ax  +  b y \\\\ \\partial_t y = c x +  dy\\end{array}\\ .\\]\nStep 1: Differentiate with respect to \\(t\\) both sides of the top equation, giving\n\\[\\begin{array}{c}\\partial_{tt} x  =   a\\, \\partial_t x  +  b\\, \\partial_t y\\\\ \\  \\ \\ \\partial_t y =  c x \\ \\ \\ \\ \\ \\ \\ +  dy\\ \\ \\ \\ \\ \\ \\ \\ \\end{array}\\ .\\] Step 2: Use the second equation to substitute for \\(\\partial_t\\, y\\) in the top equation, giving \\[\\partial_{tt} x = a \\partial_t x + b\\left(\\strut c x + dy\\right) = a\\, \\partial_t x + b\\, c\\, x + b\\, d\\, y\\] Step 3: One more substitution. From the original top equation, we know \\[y = \\frac{\\partial_t x - a x}{b}\\ .\\] Plug this in for \\(y\\) in the result from Step 2, giving \\[\\partial_{tt} x = a\\, \\partial_t x + b\\, c\\, x + b\\, d\\, \\frac{\\partial_t x - a x}{b} = \\left(\\strut a + d\\right)\\ \\partial_t x + \\left(\\strut b c - a d\\right)\\] Step 4: Use the ansatz \\(x(t) = e^{\\lambda t}\\). This produces \\[\\lambda^2 e^{\\lambda t}= (a + d) \\lambda e^{\\lambda t}+ \\left(\\strut bc - ad\\right)e^{\\lambda t} \\ \\ \\ \\implies\\ \\ \\ \\lambda^2 = (a + d) \\lambda + \\left(\\strut bc - ad\\right)\\] which can be solved for \\(\\lambda\\): \\[\\lambda = \\frac{1}{2}\\left(a + d\\right) \\pm \\frac{1}{2}\\sqrt{\\left(a - d\\right)^2 - 4 b c}\\] Again, the \\(\\pm\\) is the interesting bit here. There are two simple solutions that satisfy the differential equation: \\(x_1(t) = e^{\\lambda_1 t}\\) and \\(x_2(t) = e^{\\lambda_2 t}\\). In addition, any linear combination \\(A e^{\\lambda_ t} + B e^{\\lambda_2 t}\\) of these simple solutions will satisfy the differential equations. Once we know \\(\\lambda_1\\) and \\(\\lambda_2\\), the situation is identical to the simplified version. Again, knowing the initial condition \\(x(0)\\) and \\(\\partial_t x(0)\\) allows us to find the coefficients in the linear combination by solving the matrix equation \\[\\left[\\begin{array}{c}\\lambda_1 \\ \\ \\  \\lambda_2\\\\1 \\ \\ \\ \\ \\ 1\\end{array}\\right] \\left[\\begin{array}{c}A\\\\ B\\end{array}\\right] = \\left[\\begin{array}{c}\\partial_tx(0)\\\\  x(0)\\end{array}\\right] .\\]"
  },
  {
    "objectID": "Dynamics/B6-equilibria.html#exercises",
    "href": "Dynamics/B6-equilibria.html#exercises",
    "title": "44  Equilibrium and transient",
    "section": "44.3 Exercises",
    "text": "44.3 Exercises"
  },
  {
    "objectID": "Dynamics/B6-eigen.html",
    "href": "Dynamics/B6-eigen.html",
    "title": "45  Eigenvalues, eigenvectors",
    "section": "",
    "text": "In the previous chapters, you’ve seen how linear dynamics, when unstable, lead trajectories off to infinity. Section 43 looked at some ways that nonlinearity can tame instability, as in the simple models of linear growth.\nIn this chapter, we return to linear dynamics to develop a quantitative theory of stability. Such theory is important in many engineering and design applications. For instance, a building exposed to earthquake risk can be economically designed to be strong specifically against the type of shaking produced by earthquakes. An electronic circuit can be designed to be sensitive to certain kinds of communication signals while still resisting noise or jamming."
  },
  {
    "objectID": "Dynamics/B6-eigen.html#vector-solutions-to-linear-differential-equations",
    "href": "Dynamics/B6-eigen.html#vector-solutions-to-linear-differential-equations",
    "title": "45  Eigenvalues, eigenvectors",
    "section": "45.1 Vector solutions to linear differential equations",
    "text": "45.1 Vector solutions to linear differential equations\nThe form in which we have been writing linear differential equations in two state variables is \\[\\partial_t x = a x + b y\\\\\n\\partial_t y = c x + d y\\]\nA key part of constructing a theory of stability is finding a set of mathematical ideas that enable us to view dynamics in a simpler way. The idea we will introduce here is thinking about the state and trajectory of a differential equation in terms of vectors. We’ll work here with systems with a two-variable dynamical state, but the results apply just as well to higher dimensional states. That’s important in applied work, where the systems being modeled are complicated with many state components.\nWe can re-write the linear differential equation using vector and matrix notation. Suppose that we collect the \\(x\\) and \\(y\\) components of the state into a vector, \\[\\vec{w(t)} =\\left[\\begin{array}{c}x(t)\\\\y(t)\\end{array}\\right]\\ .\\] The differential equation, in terms of \\(\\vec{w(t)}\\) is \\[\\partial_t \\vec{w(t)} = \\left[\\begin{array}{cc}a&b\\\\c&d\\end{array}\\right] \\vec{w(t)}\\ .\\] Now imagine that we pick two non-colinear vectors, \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\) that span the state space. Since the vectors are assumed to span the state, any initial condition can be written as a linear combination of those two vectors: \\[\\vec{w(0)} =\\left[\\begin{array}{c}x(0)\\\\y(0)\\end{array}\\right] = m_1 \\vec{u_1} + m_2 \\vec{u_2}\\ .\\]\nFor the moment, we won’t worry about how best to choose \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\); any two vectors that are not colinear will do.\n\n\\(\\ \\)\nAs a running example, we’ll work with the pair of first-order differential equations \\[\\partial_t x = x + y\\\\\n\\partial_t y = 2 x \\ \\ \\ \\ \\] which, in vector/matrix form are \\[\\partial_t \\vec{w(t)} = \\left[\\begin{array}{cc}1&1\\\\2&0\\end{array}\\right] \\vec{w(t)}\\ .\\] Imagine that we choose, arbitrarily, \\[\\vec{u_1} = \\color{magenta}{\\left[\\begin{array}{r}1\\\\-3\\end{array}\\right]}\\ \\ \\ \\text{and}\\ \\ \\ \\vec{u_2} = \\color{blue}{\\left[\\begin{array}{r}1.0\\\\0\\end{array}\\right]}\\ .\\]\nFor the example, we’ll calculate a trajectory starting at the initial condition \\(\\vec{w(0)} = \\left[\\begin{array}{r}-1.1\\\\ 2.1\\end{array}\\right]\\):\n\ntraj <- integrateODE(dx ~ x + y, dy ~ 2*x, x=-1.1, y=2.1, tdur=2)\ntraj_plot(y(t) ~ x(t), traj)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe trajectory calculated starting at (-1.1, 2.1). The graph is annotated with the vectors \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\) and the flow field.\n\n\n\n\nThe initial condition (marked “0” in ?fig-vec-example-1) is, like any other point in the state space, a linear combination of \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\). We can find the scalar coefficients of the linear combination using any of the methods presented in Block 5, for instance the telescope method. We’ll illustrate with qr.solve(): ::: {.cell layout-align=“center” fig.showtext=‘false’}\nM <- cbind(rbind(1,-3), rbind(1,0))\nw0 <- rbind(-1.1, 2.1)\nqr.solve(M, w0)\n##      [,1]\n## [1,] -0.7\n## [2,] -0.4\n\nSo, \\(\\vec{w(0)} = -0.7 \\vec{u_1} - 0.4 \\vec{u_2}\\). Keep these scalar coefficients, \\(-0.7\\) and \\(-0.4\\) in mind for the next example. :::\nWe can use integrateODE() to find the solution starting at any initial condition. In particular, we can find the solution \\(\\vec{u_1}\\) as the initial condition and, similarly, using \\(\\vec{u_2}\\) as the initial condition.\n\ntraj_u1 <- integrateODE(dx ~ x + y, dy ~ 2*x, x=1, y=-3, tdur=2)\ntraj_u2 <- integrateODE(dx ~ x + y, dy ~ 2*x, x=1, y= 0, tdur=2)\n\n?fig-vec-example-2 shows these trajectories.\n\n\n\n\n\nTrajectories from the initial conditions \\(\\color{magenta}{\\vec{u_1}}\\) and \\(\\color{blue}{\\vec{u_2}}\\).\n\n\n\n\nAt first glance, the two trajectories \\(\\vec{u_1(t)}\\) and \\(\\vec{u_2(t)}\\) in ?fig-vec-example2 that start from \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\) might not look much like the trajectory in ?fig-vec-example-1 that starts from \\(\\vec{w(0)} = -0.7 \\vec{u_1} - 0.4 \\vec{u_2}\\). But in fact there is a very simple relationship between the trajectories: \\[\\vec{w(t)} = -0.7 \\vec{u_1(t)} - 0.4 \\vec{u_2(t)}\\ .\\] To state the situation more generally, any solution to the differential equations can be written as a linear combination of the solutions starting at \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\), regardless of how \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\) were chosen.\nWe can see this algebraically. Since \\(\\vec{u_1(t)}\\) and \\(\\vec{u_2(t)}\\) are solutions to the linear differential equation, it must be that \\[\\partial_t \\vec{u_1(t)} = \\left[\\begin{array}{cc}1&1\\\\2&0\\end{array}\\right] \\vec{u_1(t)}\\ \\ \\text{and}\\ \\ \\partial_t \\vec{u_2(t)} = \\left[\\begin{array}{cc}1&1\\\\2&0\\end{array}\\right] \\vec{u_2(t)}\\ .\\] Taking a linear combination of these equations gives\n\\[\\partial_t \\left[m_1\\, \\vec{u_1(t)} + m_2 \\vec{u_2(t)}\\right] = \\left[\\begin{array}{cc}1&1\\\\2&0\\end{array}\\right] \\left[m_1\\, \\vec{u_1(t)} + m_2 \\vec{u_2(t)}\\right]\\] The same will be true in general, that is, for the matrix \\(\\left[\\begin{array}{cc}a&b\\\\c&d\\end{array}\\right]\\)."
  },
  {
    "objectID": "Dynamics/B6-eigen.html#eigenvectors-and-eigenvalues",
    "href": "Dynamics/B6-eigen.html#eigenvectors-and-eigenvalues",
    "title": "45  Eigenvalues, eigenvectors",
    "section": "45.2 Eigenvectors and eigenvalues",
    "text": "45.2 Eigenvectors and eigenvalues\nIn the previous section, we saw that the solution to any linear differential equation starting at any initial condition can be written as a linear combination \\(m_1 \\vec{u_1(t)} + m_2 \\vec{u_2(t)}\\), where \\(\\vec{u_1(t)}\\) is the solution starting at an initial condition \\(\\vec{u_1}\\) and \\(\\vec{u_2(t)}\\) is the solution starting at \\(\\vec{u_2}\\). It does not matter how \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\) are chosen, so long as they are not colinear, that is, so long as they span the state space.\nIn this section, we’ll demonstrate that there is a particular way of selecting \\(\\vec{u_1}\\) and \\(\\vec{u_2}\\) that makes the solutions \\(\\vec{u_1(t)}\\) and \\(\\vec{u_2(t)}\\) have a very simple, purely exponential format. The vectors to be chosen are the eigenvectors of the matrix \\(\\left[\\begin{array}{cc}a&b\\\\c&d\\end{array}\\right]\\). We’ll call these eigenvectors \\(\\vec{\\Lambda_1}\\) and \\(\\vec{\\Lambda_2}\\). (This use of the Greek letter \\(\\Lambda\\) (capital “lambda”) and it’s lower-case version \\(\\lambda\\), is conventional in mathematics, physics, and engineering. So it’s worth learning to identify the letters.)\nOur task in this section is to show how to compute the eigenvectors \\(\\vec{\\Lambda_1}\\) and \\(\\vec{\\Lambda_2}\\) and that the solutions \\(\\vec{\\Lambda_1(t)}\\) and \\(\\vec{\\Lambda_2(t)}\\) are in fact simple exponentials. In Section 46 we’ll derive the formula for the eigenvectors. Here, we’ll use the R function eigen() to do the calculations for us.\n\n\\(\\ \\) Eigenvectors can be calculated using the R function eigen() applied to the abcd matrix that defines the linear differential equation.\nFor the system of first-order differential equations \\[\\partial_t x = x + y\\\\\\partial_t y = 2x\\ \\ \\ \\ \\ \\] the matrix is, as we’ve seen, \\[\\left[\\begin{array}{cc}1&1\\\\2&0\\end{array}\\right]\\ .\\]\nCarrying out the eigenvector calculation is straightforward:\n\nM <- cbind(rbind(1,2), rbind(1,0))\neigen(M)\n## eigen() decomposition\n## $values\n## [1]  2 -1\n## \n## $vectors\n##           [,1]       [,2]\n## [1,] 0.7071068 -0.4472136\n## [2,] 0.7071068  0.8944272\n\nThe eigenvectors are the two columns of the matrix labeled vectors returned by the calculation. Here, that’s \\[\\vec{\\Lambda_1} = \\left[\\begin{array}{r}0.7071\\\\0.7071\\end{array}\\right]\n\\ \\ \\ \\text{and}\\ \\ \\ \\\n\\vec{\\Lambda_2} = \\left[\\begin{array}{r}-0.4472\\\\0.8944\\end{array}\\right]\\ .\\]\nThe calculation also produces eigenvalues. Here that’s \\(\\lambda_1 = 2\\) and \\(\\lambda_2 = -1\\).\n\nWe can see what’s special about \\(\\vec{\\Lambda_1}\\) and \\(\\vec{\\Lambda_2}\\) by plotting them along with the flow field, as in Figure 45.1.\n\n\n\n\n\nFigure 45.1: The eigenvectors for the \\(\\left[\\begin{array}{cc}1&1\\\\2&0\\end{array}\\right]\\) plotted along with the flow.\n\n\n\n\nThe eigenvectors mark the directions where the flow is either directly toward the fixed point or directly away from it. Here, the flow on the subspace of \\(\\color{magenta}{\\vec{\\Lambda_1}}\\) is away from the fixed point, while the flow along the subspace of \\(\\color{blue}{\\vec{\\Lambda_2}}\\) is inward to the fixed point.\nThe consequence of this alignment of the flow with the eigenvectors is that the trajectory from any initial condition \\(m_1 \\vec{\\Lambda_1}\\) will have the form \\(m_1(t) \\vec{\\Lambda_1}\\) and similarly for an initial condition \\(m_2(t) \\vec{\\Lambda_2}\\).\nAs we did in the previous section, let’s calculate the trajectories \\(\\color{magenta}{\\vec{\\Lambda_1(t)}}\\) and \\(\\color{blue}{\\vec{\\Lambda_2(t)}}\\) starting at the two eigenvectors and plot out the \\(y(t)\\) component of the solution. Since we’re anticipating an exponential form for the function, we’ll use semi-log axes, where an exponential will look like a straight line.\n\ntraj_eigen1 <- integrateODE(dx ~ x + y, dy ~ 2*x, x=0.7071, y=0.7071)\ntraj_eigen2 <- integrateODE(dx ~ x + y, dy ~ 2*x, x=-0.4472, y=0.8944)\ntraj_plot(y(t) ~ t, traj_eigen1, color=\"magenta\") %>%\n traj_plot(y(t) ~ t, traj_eigen2, color=\"blue\") %>% \n  gf_refine(scale_y_log10(breaks=c(0.3290, 0.7071, 0.8944, 5.2248)))\n\n\n\n\n\n\n\n\nWe’ve marked the \\(y\\) axis with the starting and ending values of each function, so that you can find the exponential parameter \\(k\\) for each function.\n\\[\\color{magenta}{y_1(t) = 0.7071 e^{k_1 t}}\\\\\n\\color{blue}{y_2(t)} = 0.8944 e^{k_2 t}\\] To find \\(k_1\\) and \\(k_2\\), plug in \\(t=1\\) to the solution:\n\\[\\color{magenta}{y_1(1) = 5.2248 = 0.7071 e^{k_1}} \\implies k_1=2\\\\\n\\color{blue}{y_2(1) = 0.3290 = 0.8944 e^{k_2}} \\implies k_2 = -1\\]\nLook back at the results from the eigen(M) calculation. These values for \\(k_1\\) and \\(k_2\\) are exactly the eigenvalues that were computed from the matrix M. In standard notation, rather than \\(k_1\\) and \\(k_2\\), the notation \\(\\lambda_1 = k_1\\) and \\(\\lambda_2 = k_2\\) is preferred. (Remember, \\(\\lambda\\) is the Greek letter “lambda” in it’s lower-case form.) Every solution to the differential equation has the form \\[m_1\\, e^{\\lambda_1 t} \\vec{\\Lambda_1} + m_2\\, e^{\\lambda_2 t} \\vec{\\Lambda_2}\\ .\\] The scalar coefficients \\(m_1\\) and \\(m_2\\) can be found from the initial condition. The stability of the system depends only on \\(\\lambda_1\\) and \\(\\lambda_2\\). If either one of these is positive, then the system is unstable."
  },
  {
    "objectID": "Dynamics/B6-eigen.html#exercises",
    "href": "Dynamics/B6-eigen.html#exercises",
    "title": "45  Eigenvalues, eigenvectors",
    "section": "45.3 Exercises",
    "text": "45.3 Exercises\n\nWP-103-16: Using eigenvalues, eigenvectors, and vector decomposition, develop closed form solutions to initial value problems involving systems of linear equations.\nD-BRUPM: Calculate the eigenvalues of a 2x2 numerical matrix by hand, and larger matrices by computer.\nWP-103-14: Explain the graphical/geometrical interpretation of an eigenvector and eigenvalue and how to compute each for a two-by-two matrix."
  },
  {
    "objectID": "Dynamics/B6-second-order.html",
    "href": "Dynamics/B6-second-order.html",
    "title": "46  Force-balance equations",
    "section": "",
    "text": "Up to now, we have been studying dynamics in the format of one or more first-order differential equations. For instance, \\[\\partial_t x = f(x, y)\\\\\n\\partial_t y = g(x, y)\\] where \\(f(x,y)\\) and \\(g(x,y)\\) are the dynamical functions. This is not the style in which differential equations were introduced in the late 1600s. Instead, Isaac Newton (1642-1727) wrote his differential equations in the format of his Second Law of Motion, which reads (in a 1792 translation):\nIn contemporary language, we would say things differently. Instead of “alteration of motion” we would write \\(\\partial_t v\\), where \\(v\\) is the velocity of the moving object. We call \\(\\partial_t v\\) the acceleration. Instead of “motive force” we would say simply “force,” and instead of “made in the direction of the right line in which that force is impressed”, we would say that velocity, acceleration, and force are vector quantities. Newton’s “ever proportional to” amounts to saying that \\[\\partial_t \\vec{v} = b \\vec{F}\\,\\] that is, change in motion is proportional to force. Newton stipulated that the constant of proportionality, \\(b\\), is the reciprocal of mass, that is \\(1/m\\). Writing acceleration \\(\\vec{a} = \\partial_t \\vec{v}\\), the previous equation amounts to \\[m \\vec{a} = \\vec{F}\\ ,\\]\nthe form in which beginning physics students first hear it.\nNewton, of course, was very interested in gravity. From previous experiments dropping weights and rolling balls down ramps, as was done by Galileo Galilee (1564-1642), Newton knew that the force of gravity on an object (near the surface of Earth) is proportional to the object’s mass, that is \\[\\vec{F} = -g m\\ ,\\] where the direction of \\(\\vec{F}\\) is straight downwards toward the center of the Earth. The negative sign in front of \\(g\\) reflects this downward direction. We’re assuming that position and velocity are both defined in a positive, upward direction.1 developed his Theory of General Relativity.]\nThe simple model of an object moving under the force of gravity is \\(\\partial_t v = g\\). Notice that this is not a linear differential equation—\\(g\\) is not a linear function of \\(v\\) but a constant, and there’s no fixed point—so the solution is not an exponential. But we can find the solution easily enough by integrating both sides of the equation with respect to \\(t\\).\n\\[\\int \\partial_t v\\, dt = \\int -g\\, dt \\ \\ \\implies v(t) = -g\\, t + C\\] where \\(C\\) captures the constants of integration from both integrals into one number.\nIt’s worth noticing how much mathematics needs to be understood before this method of solution makes sense. The fundamental theorem of calculus is what tells us that \\(\\int \\partial_t v\\, dt = v(t) + B\\), and you have to know about how to anti-differentiate a constant function to make sense of \\(\\int g\\, dt = -g\\,t + D\\). You also need to know why constants of integration, such as \\(B\\) and \\(D\\), get included when writing the function that results from an anti-differentiation. (You might need to revisit Block 3 to refresh your memory about such things.)\nThere’s also some physical context to be considered. By setting \\(t=0\\) in \\(v(t) = -g\\,t + C\\), for instance, we can identify \\(C\\) as the velocity at time zero, which we might write \\(v(0)\\) or \\(v_0\\) for short. And what about the position of the object? The solution \\(v(t) = -g\\,t + v_0\\) has nothing to say directly about the position \\(x(t)\\) of the object as a function of time. We can work position \\(x(t)\\) into things by recognizing that \\(v(t) = \\partial_t x(t)\\), which is the definition of velocity.\nAnti-differentiating both sides of \\(v(t) = -g\\, t + v_0\\) gives us a more complete story that include both initial velocity \\(v_0\\) and initial position \\(x_0\\): \\[\\int v(t)\\, dt = \\int \\left(\\strut -g\\, t + v_0\\right)\\ dt \\implies x(t) = -\\frac{1}{2} g\\,t^2 + v_0\\,t + x_0\\ ,\n\\] where \\(x_0\\) is the constant of integration from this second stage of anti-differentiation. (Plug in \\(t=0\\) to see why we’re justified in taking \\(x_0\\) as the initial position.)2\nStill one more way to write the dynamics of falling under the influence of gravity …. Recognizing that \\(v(t) = \\partial_t x(t)\\), we can see that \\(\\partial_t v(t) = \\partial_{tt} x(t)\\). So the original differential equation could be written:\n\\[\\partial_{tt} x = -g\\] This is an example of a second-order differential equation, so called because of the appearance of a second derivative, \\(\\partial_{tt}x\\).\nIn this chapter, we’ll study second-order differential equations in a variety of contexts. But, as for Newton, movement under the influence of gravity will be a focus. Since the second-order differentiation can be interpreted as representing the balance between force and acceleration, we’ll call these force-balance equations.\nIn general, a force-balance equation has the form \\[\\partial_{tt} x = f(\\partial_t x, x)\\], the acceleration is a function both of position and velocity. In the above example, the dynamical function has a particularly simple form: \\(f(\\partial_t x, x) \\equiv -g\\).\nSecond-order differential equations can always be written as a pair of first-order differential equations. To see this, let one of the first-order equations be \\[\\partial_t x = v\\ .\\] The other equation, \\(\\partial_{tt} x = f(\\partial_t x, x)\\) can be re-written in terms of \\(v\\): \\[\\partial_t v = f(v, x)\\ .\\]\nSince we know how to solve sets of first-order differential equations by Euler’s method, we can always find the solution \\(x(t)\\) to any second-order differential equation."
  },
  {
    "objectID": "Dynamics/B6-second-order.html#sec-ballistics",
    "href": "Dynamics/B6-second-order.html#sec-ballistics",
    "title": "46  Force-balance equations",
    "section": "46.1 Ballistics",
    "text": "46.1 Ballistics\nA lot of the theory of second-order differential equations was developed in the setting of a ball being set off with an initial velocity from an initial position. Such a focus on the flight of balls might seem trivial. Fortunately, language allows us to construct a scientific-sounding word by adding the suffix “istic” to the root “ball.” This suffixing produces the word ballistics.\nThe importance of ballistics to Newton can be seen by a famous diagram he drew, shown in Figure 46.1. In the diagram, Newton traces the path of a ball shot horizontally from a cannon placed at the top of a mountain.\n\n\n\n\n\nFigure 46.1: Newton’s diagram showing ballistic motion under the force of gravity.\n\n\n\n\nSince the motion in Newton’s diagram has both vertical and horizontal components, we’re going to need two second-order differential equations:\n\\[\\text{Horizontal}: \\ \\ \\partial_{tt} x = 0\\\\\n\\ \\ \\ \\text{Vertical}: \\ \\ \\ \\ \\ \\ \\partial_{tt} y = -g\\] The zero on the right-hand side of the equation of horizontal movement reflects that gravity does not act horizontally.\nWe found a solution for the vertical equation in the previous section, \\[y(t) = -\\frac{1}{2} g\\,t^2 + 0\\,t + y_0\\ .\\] The \\(0\\, t\\) component to the solution reflects that the vertical component of the ball, coming out of the cannon, is zero.\nThe solution for the horizontal component of motion can be found by anti-differentiating both sides of the equation of hortizontal motion: \\[\\int \\partial_{tt} x(t)\\, dt = \\partial_t x(t) = \\int 0\\, dt = v_0\\] where \\(v_0\\) is the initial horizontal velocity. A second stage of anti-differentiation gives \\(x(t)\\) itself: \\[\\int \\partial_t x(t) = \\int v_0 dt = v_0\\, t + x_0\\]\nRegrettably, symbolic anti-differentiation works only in simple cases. To support more realistic models of ballistics, let’s see how to translate the two second-order differential equations into sets of first-order equations. The state variables will be \\(x(t)\\) and \\(y(t)\\), but we also have to add another pair, \\(u(t)\\) and \\(v(t)\\) standing for the horizontal and vertical velocities respectively. The first-order equations will be: \\[\\partial_t x = u\\\\\n\\partial_t y = v\\\\\n\\partial_t u = 0\\\\\n\\partial_t v = -g\n\\] To illustrate, we’ll solve this set of four first-order equations numerically. We need to specify the initial values for \\(x_0\\), \\(y_0\\), \\(u_0\\) and \\(v_0\\). We’ll let the cannon be located at horizontal position \\(x_0 = 0\\) and vertical position \\(y_0 = 100\\) meters. The vertical velocity is, initially, zero, so \\(v_0 = 0\\). And suppose the cannon produces an initial horizontal velocity of \\(u_0 = 250\\) meters/sec. The constant \\(g\\) is known to be 9.8 meters/sec2.\nHere’s the trajectory:\n\ntraj <- integrateODE(\n  dx ~ u, dy ~ v, du ~ 0, dv ~ -9.8, #dynamics\n  x=0, y=100, u = 250, v=0, #initial conditions\n  tdur=5\n) \ntraj_plot(y(t) ~ x(t), traj)\n\n\n\n\n\n\n\ntraj_plot(v(t) ~ u(t), traj)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 46.2: Trajectory of the cannon ball shot with an initial horizontal velocity and no initial vertical velocity. The trajectory is plotted in slices of state space: position \\((x, y)\\) and velocity \\((u, v)\\). The time at which the ball reaches the points marked on the trajectory give the time.\n\n\n\n\nThe left panel in Figure 46.2 shows that the trajectory is a parabola. At about \\(t=4.4\\) secs the \\(y\\) position is zero. If zero is the location of the ground, the part of the trajectory for \\(4.4 < t\\) is invalid, since the ball has already hit the ground. The ball travels a little more than 1100 meters horizontally before hitting the ground.\nThe right panel might seem somewhat strange. You can see that the vertical component of velocity, \\(v(t)\\) starts out at zero and increases linearly with time, becoming more and more negative as gravity continuous to accelerate the ball downward. The vertical velocity, \\(u(t)\\), stays constant at \\(u(t) = 250\\) meters per second. This is because there is no horizontal force on the ball.\n\nThe world’s first programmable, electronic, general-purpose digital computer was started up in 1945 at the University of Pennsylvania, where it is still on display. The date and location have something to say about why the computer was built. 1945 is, of course, at the end of World War II. The computer was built to carry out some important war-time calculations. The place, Philadelpha, Pennsylvania, has to do with the location of the US Army’s center for developing and testing ordnance: the Aberdeen Proving Ground which is only 75 miles from the University of Pennsylvania.\nThe name given to the computer, ENIAC, has a science-fiction flavor but is in fact rooted in its purpose: the Electronic Numerical Integrator and Computer. ENIAC was constructed to calculate the trajectories of artillery shells. Knowing the trajectory is essential to being able to fire artillery accurately.\nThe ballistics of real world artillery shells is more complex than the simple model we constructed earlier. What’s missing from that model is air resistance, which is a function of the shell’s velocity and altitude. To illustrate, let’s add in a simple model of air resistance to the earlier ballistic model. In this model, the force of air resistence is a vector pointing in the opposite direction to overall velocity and proportional to velocity squared.\nThe velocity vector is simply \\(\\left[\\begin{array}{c}u\\\\v\\end{array}\\right]\\). The air resistence force will be \\[-\\alpha\\sqrt{\\strut u^2 + v^2} \\left[\\begin{array}{c}u\\\\v\\end{array}\\right]\\ .\\] Consequently, the horizontal component of the air-resistence vector is \\(-\\alpha\\, u \\sqrt{\\strut u^2 + v^2}\\) and the vertical component is \\(-\\alpha\\, v \\sqrt{\\strut u^2 + v^2}\\).\nIncorporating air resistence into the model can be done like this: \\[r(u, v) \\equiv \\alpha \\sqrt{\\strut u^2 + v^2}\\\\\n\\partial_t x = u\\\\\n\\partial_t y = v\\\\\n\\partial_t u = -u\\, r(u,v)\\\\\n\\partial_t v = -g - v\\, r(u,v)\\] ENIAC would have been programmed to carry out the calculation we now do with integrateODE():\n\nr <- makeFun(alpha*sqrt(u^2 + v^2) ~ u & v, alpha=0.003)\ntraj2 <- integrateODE(\n  dx ~ u, dy ~ v, du ~ -u*r(u,v), dv ~ -9.8 - v*r(u,v), #dynamics\n  x=0, y=100, u = 250, v=0, #initial conditions\n  tdur=6\n)\ntraj_plot(y(t) ~ x(t), traj)\n\n\n\n\n\n\n\ntraj_plot(v(t) ~ u(t), traj)\n\n\n\n\n\n\n\n\n\nP1 <- \n  gf_hline(yintercept=~0, color=\"brown\") %>%\n  traj_plot(y(t) ~ x(t), traj, nt=2, color=\"orange\") %>%\n  traj_plot(y(t) ~ x(t), traj2) %>%\n  gf_labs(subtitle=\"(x, y) position as a function of time\")\nP2 <- traj_plot(v(t) ~ u(t), traj2) %>%\n  gf_labs(subtitle=\"(u, v) velocity as a function of time\")\ngridExtra::grid.arrange(P1, P2, nrow=1)\n\n[](B6-second-order_files/figure-html/cannon-shot-2, fig-cap- “Adding air resistence to the model changes the trajectory. For reference, the trajectory without air resistence is plotted in \\(\\color{orange}{\\text{orange}}\\).”-1.png){fig-align=‘center’ width=90%}\n\n\nAir resistance causes the cannon ball to travel a shorter horizontal distance and to arrive with a much reduced velocity."
  },
  {
    "objectID": "Dynamics/B6-second-order.html#the-harmonic-oscillator",
    "href": "Dynamics/B6-second-order.html#the-harmonic-oscillator",
    "title": "46  Force-balance equations",
    "section": "46.2 The harmonic oscillator",
    "text": "46.2 The harmonic oscillator\nConsider the motion of a weight attached to a spring, as in ?fig-spring-mass. We’ll denote the vertical position of the mass by \\(y(t)\\). Such a spring-mass system has a fixed point where the spring is stretched just enough to cancel out gravity and the velocity is zero. We’ll measure \\(y\\) relative to this fixed point.\n::: {.cell .column-margin layout-align=“center” fig.cap = “A spring-mass system in motion. Source=’Svjo CC BY-SA via Wikimedia Commons”’ fig.showtext=‘false’} ::: {.cell-output-display}  ::: ::: According to Hooke’s Law, a stretched or compressed spring exerts a force that is proportional to the amount of extension or compression. With our measuring \\(y\\) relative to the fixed point, the Hooke’s Law force will be \\[m\\, \\partial_{tt} y = - s\\, y\\ ,\\] where \\(m\\) is the amount of mass and \\(s\\) is the stiffness of the spring. This force-balance equation corresponds to the second-order differential equation \\[\\partial_{tt} y = - \\frac{s}{m} y\\ .\\]\nYou can see that the motion is oscillatory, which suggests that the solution to the differential equation will be of the form \\(y(t) = A \\sin(\\omega t)\\). Taking this as an ansatz leads to finding a value of \\(\\omega\\), which is called the angular frequency of the oscillation. (In terms of the period of oscillation \\(P\\), the angular frequency is \\(\\omega = 2 \\pi/P\\).)\nTo find \\(\\omega\\), plug in the ansatz to the differential equation:\n\\[\\partial_{tt} A \\sin(\\omega t) = - \\frac{s}{m}\\, A \\sin(\\omega t)\\] Differentiating \\(\\sin(\\omega t)\\) once let’s us re-write the left-hand side of the equation in terms of a first derivative\n\\[\\partial_{t} A \\omega\\, \\cos(\\omega t) = - \\frac{s}{m}\\, A \\sin(\\omega t)\\] Differentiating again gives \\[- \\omega^2 A\\sin(\\omega\\, t) = - \\frac{s}{m}\\, A\\sin(\\omega t)\\ .\\] Simplifying this by cancelling out the \\(A \\sin(\\omega t)\\) term gives \\(\\omega^2 = \\frac{s}{m}\\), where \\(\\omega\\) is the angular frequency of the oscillation.\n\nInstead of using \\(A \\sin(\\omega t)\\) as the ansatz we could have used \\(A \\sin(\\omega t) + B \\cos(\\omega t)\\). Working through this ansatz would produce the same result, that \\(\\omega^2 = \\frac{s}{m}\\). So the solution to the spring-mass system will be, in general, a linear combination of the sine and the cosine functions with angular frequency \\(\\omega\\)."
  },
  {
    "objectID": "Dynamics/B6-second-order.html#exponential-or-sinusoid",
    "href": "Dynamics/B6-second-order.html#exponential-or-sinusoid",
    "title": "46  Force-balance equations",
    "section": "46.3 Exponential or sinusoid?",
    "text": "46.3 Exponential or sinusoid?\nIn Section 45, we established that solutions to second-order linear differential equations have the form \\(m_1 e^{\\lambda_1 t} + m_2 e^{\\lambda_2 t}\\). Yet in the previous section, we saw one linear second-order differential equation, \\(\\partial_{tt} y = - \\omega^2 y\\) where the solution is a linear combination of a sine and a cosine function: \\(y(t) = A \\sin(\\omega t) + B \\cos(\\omega t)\\) with \\(\\omega = \\sqrt{\\frac{s}{m}}\\).\nHow is it possible for the solution to be both in the form of a linear combination of exponentials and a linear combination of sine and cosine? Sinusoids oscillate up and down and up and down, whereas exponentials are monotonic.\nTo find out what might be the relationship between an exponential and a sinusoid, let’s plug an exponential ansatz \\(y(t) = A e^{\\lambda t}\\) into the spring-mass system \\(\\partial_{tt} y = -\\omega^2 y\\).\n\\[\\partial_{tt} A e^{\\lambda t} = \\lambda^2 A e^{\\lambda t} = -\\omega^2 A e^{\\lambda t}\\ .\\] As before, we’ll cancel out the common term \\(A e^{\\lambda t}\\) to get a simple relationship: \\[\\lambda^2 = -\\omega^2\\ \\ \\ \\implies\\ \\ \\ \\lambda = \\pm \\sqrt{\\strut-1}\\  \\omega \\ .\\] Generally, the symbol \\(i\\) is used to stand for \\(\\sqrt{\\strut -1}\\), so our eigenvalues can be written \\(\\lambda = \\pm i \\omega\\). The solution to the spring-mass system, according to this analysis, is: \\[y(t) = m_1 e^{i\\omega t} + m_2 e^{-i \\omega t}\\]\nIn other words, \\(e^{i \\omega t}\\)—notice the \\(i\\) in the argument to the exponential—is a sinusoid with angular frequency \\(\\omega\\)."
  },
  {
    "objectID": "Dynamics/B6-second-order.html#exponentials-with-imaginary-inputs",
    "href": "Dynamics/B6-second-order.html#exponentials-with-imaginary-inputs",
    "title": "46  Force-balance equations",
    "section": "46.4 Exponentials with “imaginary” inputs",
    "text": "46.4 Exponentials with “imaginary” inputs\nThe “imaginary” in the section title is used in it’s mathematical sense. In interpreting the word “imaginary,” you should keep in mind a long history in mathematics of assigning insulting names to mathematical objects that, at the time they were first introduced. That’s why some numbers are vilified as “negative,” and some as “irrational.” The insult is even more dire for numbers like \\(i\\), which are called the “imaginary” numbers. Regrettably, the word “imaginary” leads many people to shy away from them, just as many people avoid genres such as fantasy fiction. That imaginary numbers are introduced as kind of freakish—is there a numerical value for \\(\\sqrt{\\strut -1}\\)?—and rarely touched until advanced calculus, means that students are unused to them.\nYou’ll only get comfortable with “imaginary” numbers when you start to work with them extensively, as happens in physics and engineering courses. Our goal here is merely to increase your awareness of imaginary numbers and some of the ways they are used in the sciences. To that end, we offer three different approaches to understanding the function \\(e^{i\\omega t}\\).\n\nBasic, pragmatic understanding. This is the level of understanding that you must have in order to make sense of the rest of this chapter and ?sec-forcing. Here it is: \\[e^{i\\omega t}\\ \\text{is simply a shorthand for}\\ \\cos(\\omega t).\\] So whenever you see \\(e^{i \\omega t}\\), think of \\(\\cos(\\omega t)\\).\nAlgebraic understanding via Taylor Polynomials. (optional) This level of understanding can give you confidence that the basic, pragmatic understanding in (1) has honest roots. It also shows the way that (1) is not 100% on target (although good enough for a large fraction of mathematical work). But for many people, algebra is a rocky road to understanding.\n\nThe starting point for the algebraic understanding is the Taylor polynomial approximation for \\(e^{\\omega t}\\). Recall from Chapter 26 that \\[e^{\\omega t} = 1 + \\omega t + \\frac{1}{2!}\\omega^2 t^2 + \\frac{1}{3!}\\omega^3 t^3 + \\frac{1}{4!} \\omega^4 t^4 + \\frac{1}{5!} \\omega^5 t^5 + \\frac{1}{6!} \\omega^6 t^6 + \\cdots\\] You may also recall the Taylor polynomial expansion of sine and cosine: \\[ \\cos(\\omega t) = 1 - \\frac{1}{2!} \\omega^2 t^2 + \\frac{1}{4!}\\omega^4 t^4 - \\frac{1}{6!} \\omega^6 t^6 + \\cdots\\] \\[\\color{magenta}{\\sin(\\omega t) = \\omega t - \\frac{1}{3!}\\omega^3 t^3 + \\frac{1}{5!} \\omega^5 t^5 +  \\cdots}\\] You can see some association between \\(e^{wt}\\), \\(\\cos(\\omega t)\\), and \\(\\sin{\\omega t}\\) by looking at \\[\\cos(\\omega t) + \\color{magenta}{i \\sin(\\omega t)} = 1 + \\color{magenta}{i \\omega t} -\\frac{1}{2!} \\omega^2 t^2 - \\color{magenta}{i \\frac{1}{3!} \\omega^3 t^3} + \\frac{1}{4!}\\omega^4 t^4 + \\color{magenta}{i \\frac{1}{5!} \\omega^5 t^5} - \\frac{1}{6!}\\omega^6 t^6 + \\cdots\\] Now consider the Taylor polynomial for \\(e^{i\\omega t}\\). This will be the same as the Taylor polynomial for \\(e^{\\omega t}\\) but everywhere substituting \\(i \\omega\\) in place of the plain \\(\\omega\\). That is:\n\\[e^{i \\omega t} = 1 + \\color{magenta}{i\\omega t} + \\frac{1}{2!}i^2\\omega^2 t^2 + \\color{magenta}{\\frac{1}{3!}i^3\\omega^3 t^3} + \\frac{1}{4!} i^4\\omega^4 t^4 + \\color{magenta}{\\frac{1}{5!} i^5\\omega^5 t^5} + \\frac{1}{6!} i^6\\omega^6 t^6 + \\cdots\\] Since \\(i\\equiv \\sqrt{\\strut -1}\\), we have the following facts for the powers \\(i^n\\):\n\\[i^2 = -1\\ \\ \\ \\ \\ \\color{magenta}{i^3 = -i}\\ \\ \\ \\ \\ i^4 = 1\\ \\ \\ \\ \\ \\color{magenta}{i^5 = i}\\ \\ \\ \\ \\ i^6 = -1\\ \\ \\text{and so on}.\\] Substitute these facts about \\(i^n\\) into the Taylor polynomial for \\(e^{i\\omega t}\\):\n\\[e^{i \\omega t} = 1 + \\color{magenta}{i\\omega t} - \\frac{1}{2!}\\omega^2 t^2 - \\color{magenta}{i \\frac{1}{3!}\\omega^3 t^3} + \\frac{1}{4!} \\omega^4 t^4 + \\color{magenta}{i \\frac{1}{5!} \\omega^5 t^5} - \\frac{1}{6!} \\omega^6 t^6 + \\cdots\\] which exactly matches the Taylor polynomial for \\(\\cos{\\omega t} + \\color{magenta}{i \\sin(\\omega t)}\\).\n\nThe arithmetic of complex numbers. (optional) A complex number is a number like \\(2 - 3i\\) which consists of two parts: the real-part \\(2\\) and the imaginary part \\(-3\\). When you multiply one complex number by another you get a complex number (although either the real or imaginary parts might happen to be zero.) For example: \\[(2 + 3i)^2 = (2+3i)(2+3i) = \\underbrace{4}_{2\\times 2} + \\underbrace{ \\ 6 i\\ }_{2 (3i)} +   \\underbrace{\\ 6 i\\ }_{(3i)2}\\ \\  \\underbrace{- 9}_{(3i)(3i)}\\  = -5 +12 i.\\] R knows the rules for arithmetic on complex numbers. Here’s a demonstration of the oscillations that result from raising a complex number to successive powers.\n\n\nlambda <- 0.65 + 0.76i\nlambda^2\n## [1] -0.1551+0.988i\nlambda^3\n## [1] -0.851695+0.524324i\nlambda^4\n## [1] -0.952088-0.3064776i\nlambda^5\n## [1] -0.3859342-0.9227973i\nlambda^6\n## [1] 0.4504687-0.8931283i\nlambda^7\n## [1] 0.9715821-0.2381771i\nlambda^8\n## [1] 0.812543+0.5835873i\nlambda^9\n## [1] 0.0846266+0.9968644i\nlambda^10\n## [1] -0.7026097+0.7122781i\n\nNotice that the real part of the result oscillates between negative and positive. The imaginary part also oscillates, but delayed a bit from the real part. Just like sine and cosine.\nWe can get a clearer picture by plotting \\(e^{i\\omega t}\\) over the domain \\(0 < t < 10\\). As an example, in ?fig-complex-exponential-plot we’ll set \\(\\omega = 2\\). We need to be a little careful, since our plotting functions are not arranged to display complex numbers. But there is an easy workaround: plot the “real” and “imaginary” parts separately. The R operators Re() and Im() do this work.\n\nf <- makeFun(exp(1i * omega * t) ~ t, omega = 2)\nslice_plot(Re(f(t)) ~ t, \n           domain(t=0:10), color = \"magenta\") %>%\n  slice_plot(Im(f(t)) ~ t, color=\"brown\")\n\n\n\n\nThe real and imaginary parts of \\(e^{i \\omega t}\\) plotted as a function of \\(t\\)."
  },
  {
    "objectID": "Dynamics/B6-second-order.html#damping",
    "href": "Dynamics/B6-second-order.html#damping",
    "title": "46  Force-balance equations",
    "section": "46.5 Damping",
    "text": "46.5 Damping\nIt’s common for there to be friction, called damping, in a spring mass system. To keep things very simple, we’ll consider that the friction is proportional to the velocity and, as in the cannonball example, in the direction opposite to velocity. That is: \\[\\partial_{tt} y = -r\\, \\partial_t y -b y\\ ,\\] where \\(b\\) would be the positive number \\(\\frac{s}{m}\\) and \\(r\\) is another positive number reflecting the magnitude of friction. (Think of \\(r\\) as standing for “resistance.”)\nAs always, this second-order differential equation can be written as a pair of first-order differential equations. One of the first-order differential equations will be \\[\\partial_t y = v\\ ,\\], which is just the definition of velocity \\(v\\). The other first-order equation will be \\[\\partial_t v = -r v  - b y\\ .\\] Both equations are linear.\nIn the previous chapter, we wrote such a pair of linear first-order differential equations in terms of a vector \\[\\vec{w(t)} = \\left[\\begin{array}{c}v(t)\\\\y(t)\\end{array}\\right]\\ .\\] In terms of the vector \\(\\vec{w(t)}\\) the dynamics can be written in vector/matrix form: \\[\\partial_t \\vec{w} = \\left[\\begin{array}{c}-r \\ \\ \\  -b\\ \\ \\\\1 \\ \\ \\ \\ \\ \\ \\ 0\\end{array}\\right]\\, \\vec{w}\\ .\\] This form suggests, at least to the avid reader of the previous chapter, that we look for a solution \\(y(t) = m_1\\, e^{\\lambda_1\\, t} + m_2\\, e^{\\lambda_2\\, t}\\) in terms of the eigenvectors and eigenvalues of the matrix \\(\\left[\\begin{array}{cc}r & b\\\\1 & 0\\end{array}\\right]\\).\nWe used the R function eigen() to compute the eigenvalues and eigenvectors of the matrix, given numerical values for \\(r\\) and \\(b\\). Let’s now try to find an algebraic formula for the eigenvalues. After all, it’s the eigenvalues that determine the stability of the fixed point.\nAs an ansatz for the for the original second-order differential equation \\[\\partial_{tt} y = r\\, \\partial_t y + b y\\ ,\\] let’s use \\(y(t) = A e^{\\lambda t}\\), a simple exponential function. Plugging in the ansatz to the differential equation gives: \\[A \\lambda^2 e^{\\lambda t} = - r A \\lambda e^{\\lambda t} - b A e^{\\lambda t}\\ .\\] We can cancel out the common term \\(A e^{\\lambda t}\\) from all the terms in the equation, and bring all the terms to the left-hand side of the equation, leaving us with \\[\\lambda^2 + r \\lambda + b = 0\\ .\\] This is a quadratic polynomial in \\(\\lambda\\), so we can use the “quadratic formula” to find values for \\(\\lambda\\) that are consistent with the parameters \\(a\\) and \\(b\\). In applying the quadratic formula you have to remember that the standard statement is for the roots of \\(a x^2 + b x + c = 0\\) and make adjustment for the fact that our polynomial uses the parameter names differently: \\(\\lambda^2 + r \\lambda + b = 0\\).\n\\[\\lambda = \\frac{- r \\pm \\sqrt{\\strut r^2 - 4 b}}{2}\\ .\\] Recall that the parameter \\(r\\) describes the amount of friction or resistence in the system; it’s a positive number. Similarly, the nature of springs is that \\(b\\) is a positive number. The relative values of \\(r\\) and \\(b\\) determine the motion of the system.\nSuppose the stiffness of the spring is much larger than the friction. Then \\(r^2 < 4b\\). This being the case, the \\(\\sqrt{\\strut r^2 - 4 b}/2\\) will be an imaginary number. Altogether, the eigenvalues will be \\(\\lambda = -\\frac{r}{2} \\pm {i \\omega}\\). The solution will be \\[y = m_1 e^{\\lambda_1 t} + m_2 e^{\\lambda_2 t} \\\\\n= m_1 e^{-\\frac{r}{2}t + i \\omega t} + m_2 e^{\\frac{r}{2} - i\\omega t} \\\\\n= m_1 e^{-r t/2} e^{i\\omega t} + m_2 e^{-r t/2} e^{-i \\omega t} \\\\\n= e^{-r t/2}\\underbrace{\\left[m_1 e^{i \\omega t} + m2 e^{i\\omega t}\\right]}_{\\text{sinusoid}(\\omega t)}\\] Result: an exponentially decaying sinusoid.\nTo graph this function, we need to choose appropriate numerical values for \\(r\\) and \\(b\\). Let’s set \\(r=1\\). Since \\(r^2 < 4b\\), we must have \\(\\frac{1}{4} < b\\): we’ll choose \\(b = 6\\) which meets this criterion. Figure 46.3 shows the solution to the differential equation:\n\ntraj <- integrateODE(dv~ -r*v - b*y, dy ~ v, v=10, y=0, r=1, b=6, tdur=20)\ntraj_plot(y(t) ~ t, traj)\n\n\n\n\nFigure 46.3: An exponentially decaying sinusoid arising from \\(r = 1\\) and \\(b = 6\\).\n\n\n\n\nThis is the situation with a swinging door. You shove it to swing open, after which it oscillates with a decreasing amplitude.\nIn contrast, suppose the spring is weak compared to the damping such that \\(4b < r^2\\). Now \\(\\sqrt{\\strut r^2 - 4b}\\) is a positive number, not imaginary. What’s more, since \\(b\\) is positive, \\(\\sqrt{\\strut r^2 - 4 b} < r\\). This means that both eigenvalues are negative. We’ll illustrate the situation with \\(r=1, b=0.2\\):\n\ntraj2 <- integrateODE(dv~ -r*v - b*y, dy ~ v, v=10, y=0, r=1, b=0.1, tdur=20)\ntraj_plot(y(t) ~ t, traj2) %>%\n  gf_lims(y = c(0, NA))\n\n\n\n\nFigure 46.4: A heavily damped spring-mass system with \\(r = 1\\) and \\(b = 0.1\\).\n\n\n\n\nThe situation in Figure 46.4 is the sort of behavior one expects when giving a shove to an exit door in theater or stadium. The shove causes the door to swing open, after which it slowly returns to the closed position. That gives plenty of time for the people following you to get to the door before it closes.\nFinally, consider the case where \\(r^2 - 4 b = 0\\), a balance between resistance and springiness. In this case, both eigenvalues are \\(\\lambda = -r/2\\).\n\ntraj3 <- integrateODE(dv~ -r*v - b*y, dy ~ v, v=10, y=0, r=1, b=0.25, tdur=20)\ntraj_plot(y(t) ~ t, traj3) %>%\n  gf_lims(y = c(0, NA))\n\n\n\n\nFigure 46.5: A critically damped oscillation with \\(r=1\\), \\(b=0.25\\).\n\n\n\n\nThis is a situation called critically damped. The door swings open, then closes as fast as it can without any oscillation.\n\n\\(\\ \\) Consider the second-order linear differential equation \\[\\partial_{tt} y + 2\\, \\partial_t y - 3\\, y = 0\\ .\\] Is this system stable?\nFor this system, \\(a=2\\) and \\(b = - 3\\), so the eigenvalues are \\[\\lambda = \\left(-2 \\pm \\sqrt{\\strut 4 + 12}\\right)/2 = 1 \\pm \\sqrt{\\strut 16}/2 = -1 \\pm 2\\] In other words, \\(\\lambda_1 = -3\\) and \\(\\lambda_2 = +1\\). This indicates that the system is a saddle: unstable in one direction and stable in the other.\nTo confirm our work, let’s use eigen() to find the eigenvalues of the matrix \\(\\left[\\begin{array}{cc}2 & 3\\\\1 & 0\\end{array}\\right]\\):\n\nM <- cbind(rbind(-2,1), rbind(3,0))\neigen(M)\n## eigen() decomposition\n## $values\n## [1] -3  1\n## \n## $vectors\n##            [,1]       [,2]\n## [1,] -0.9486833 -0.7071068\n## [2,]  0.3162278 -0.7071068\n\nAlthough R is doing all the calculations for us, it’s possible to write the directions of the eigenvectors only in terms of the eigenvectors: \\[\\vec{\\Lambda_1} = \\left[\\begin{array}{c}\\lambda_1\\\\1\\end{array}\\right]\\ \\ \\text{and}\\ \\ \\vec{\\Lambda_2} = \\left[\\begin{array}{c}\\lambda_2\\\\1\\end{array}\\right]\\]\nFor the system with \\(\\lambda_1 = 3\\) and \\(\\lambda_2 = -1\\), you can confirm that the eigenvectors calculated with this formula point in the same directions as the eigenvectors reported by eigen().\n\nLet’s return to the car-following control system introduced in Section 45. Recall that \\(x\\) was defined to be the distance between two cars and \\(x_0\\) the distance to be maintained. In terms of \\(y = x - x_0\\) the system was \\[\\partial_{tt} y = - b y\\ .\\] You can see that this system has no damping; \\(y(t)\\) will be a sinusoidal oscillation. The ride will be more pleasant, however, if the oscillations can be damped out. To accomplish this, we should add a new term to the second-order differential equation, a damping term to give \\[\\partial_{tt} y = -a\\, \\partial_t y- b\\, y\\ .\\] We should set the parameters \\(a\\) and \\(b\\) to make the real part of the eigenvalues negative. Only then will we have designed a workable control system.\n\nFor a human driver, following a car at a steady distance requires careful attention but in practice is not too difficult a task. Could it be the case that drivers have an intuitive understanding of the need for damping? Perhaps complex eigenvalues ought to be a standard topic in driving schools? That might be, but there is a more down-to-earth explanation of how humans handle the car-following task.\nThe quantity \\(\\partial_{tt} y\\) is the acceleration, and the control pedal that leads to positive acceleration is called the “accelerator.” But the pedal does not set acceleration. In reality, the pedal sets velocity as well as acceleration. A simple model is \\(\\text{pedal} = r \\partial_t y + s \\partial_{tt} y\\), where \\(y\\) is the velocity of the car and \\(r\\) and \\(s\\) are positive parameters.\nTo understand this model of the pedal, think what happens when you press the accelerator and hold it. The car accelerates, but only up to the point where a steady state velocity is reached. Or, consider what happens if you partially release the pedal. The car slows down until it reaches a new, slower, steady-state velocity.\nWith a human driver, the control system is not \\(\\partial_{tt} y = - b y\\). Instead, the control system is \\[\\text{pedal} - p_0 =  - b y\\ .\\] For steady-state driving at the desired velocity \\(\\partial_t y\\) we press the pedal by an amount \\(p_0\\). To perform the car-following task, we push down or lighten up on the pedal, depending on whether we are farther or closer to the car ahead than our desired distance.\nCombining the models for how \\(\\text{pedal}\\) is controlled and how \\(\\text{pedal}\\) relates to velocity and acceleration, we have \\[r \\partial_t y + s \\partial_{tt} y  - p_0 = -b y\\] or, re-arranging terms \\[ \\partial_{tt} y = \\underbrace{- \\frac{r}{s} \\partial_t y}_{\\text{damping}} - \\frac{b}{s} y + p_0\\ .\\] The nature of the gas pedal itself leads to a damping term in the dynamics, without our having to think about it consciously."
  },
  {
    "objectID": "Dynamics/B6-second-order.html#exercises",
    "href": "Dynamics/B6-second-order.html#exercises",
    "title": "46  Force-balance equations",
    "section": "46.6 Exercises",
    "text": "46.6 Exercises\n\nT-ZO94U: Identify the components of a force-balance differential equation: mass, acceleration, friction (damping, air resistance), restorative force.\nS-BOXLN: Identify and interpret mechanistically interaction terms in a second-order differential equation\nF-189B3: Interpret the complex exponential \\(e^{i\\omega t}\\) as a sinusoid of frequency \\(\\omega\\).\nP-7PXE3: Identify a differential equation in force-balance form and, for linear equations, determine if the solution is stable or unstable and, if oscillatory, what the frequency of oscillation is.\nZ-DPT7M: For a linear differential equation in force-mass form, use the ansatz \\(e^{kt}\\) to find the quadratic polynomial in \\(k\\) (“characteristic equation”) that describes the eigenvalues of the differential equation.\nW-5ZT92: Construct and solve numerically a system of two first-order differential equations that represent a vertically rising or falling object in the presence of gravity and air resistance."
  },
  {
    "objectID": "manifestations-part.html",
    "href": "manifestations-part.html",
    "title": "Manifestations",
    "section": "",
    "text": "This is where I’ll explain what the block is about and the overall goals."
  },
  {
    "objectID": "Manifestations/B4-operations.html",
    "href": "Manifestations/B4-operations.html",
    "title": "47  Operations on functions",
    "section": "",
    "text": "Block 1 introduced the idea of mathematical modeling: creating a representation of some aspect of the world out of mathematical “stuff.” The relevant “stuff” includes the concept of a function with its inputs and output, units and dimensions of quantities, frameworks such as the basic modeling functions and ways of combining functions via linear combination, composition, and multiplication.\nOur emphasis in calculus has been and will continue to be functions. This contrasts with high-school algebra where the emphasis was on equations and manipulations such as the movement of quantities from one side of the equal sign to another.\nIt pays to think a little about what equations mean and what information they are intended to convey. Consider an equation like \\[{\\mathbf{\\text{equation:}}}\\ \\ \\ x^2 - 4 x + 3 = 0\\] which you might see in a beginning algebra text. What does this equation mean?\nA simple equation like \\(3 + 4 = 7\\) is a statement of fact: three plus four is indeed the same as seven. But \\(x^2 - 4 x + 3 = 0\\) is not a fact. The equality might be true or false, depending on what \\(x\\) happens to be. In an algebra course, the equation is intended to be an instruction to a person: \\[\\text{Given}\\ x^2 - 4 x + 3  = 0, \\ \\ \\text{find x.}\\] or, equivalently, \\[\\text{Solve}\\ x^2 - 4 x + 3  = 0\\ \\ \\text{for}\\ x.\\] “Find \\(x\\)” or “Solve for \\(x\\)” direct you to determine which numerical values (if any) when substituted for \\(x\\) in the equation will produce a true statement.\n“Solve for \\(x\\)” is an example of a mathematical task. We undertake such tasks in order to extract useful information from a mathematical object. For instance, textbook “word problems” involve two phases: i) a modeling phase where you translate a verbal description of a situation—often involving paddling canoes across a flowing river—into a matching mathematical form and ii) having constructed a suitable mathematical form, you apply some mathematical task to the form in order to reveal the answer you seek.\nIn this chapter, we’re going to look at a small list of mathematical tasks, calling them operations on functions. These operations, combined in various ways, enable you to extract relevant information from the functions you build in your models. A simple important part of this introduction is to give a name to each task. That way, confronted with a mathematical problem, you will be able to look down the short mental menu of opertions to decide which ones are applicable to your circumstance. Even better, once each operation has a name, you can tell a computer to do it for you.\nHere are four common mathematical tasks that you’ve already encountered in Blocks 1 through 3 of this book:\nIn this chapter, we focus on the following operations on functions that you may not yet have mastered.\nThese seven tasks allow you to perform the mathematical work of extracting useful information from a model. Human judgement and creativity is needed to construct the model. And judgement and experience is needed to figure out which tasks to perform and in what order. But carrying out the tasks does not require judgement, experience, or creativity. Performing the tasks requires only an algorithm and the tools to step through the algorithm. Computers are excellent for this; you just have to give them the function and whatever additional input is required (e.g. the name of a with-respect-to input), and then tell the computer which task it is to perform."
  },
  {
    "objectID": "Manifestations/B4-operations.html#task-solve",
    "href": "Manifestations/B4-operations.html#task-solve",
    "title": "47  Operations on functions",
    "section": "47.1 Task: Solve",
    "text": "47.1 Task: Solve\nStarting materials:\n\na function \\(f(x)\\),\n\na known output value \\(v\\), and\n\na candidate for a suitable input value \\(\\color{brown}{x_0}\\)\n\nIdeal result from the algorithm: A new candidate \\(\\color{magenta}{x^\\star}\\) such that \\(f(\\color{magenta}{x^\\star}) = v\\) or, equivalently, that \\[\\left\\|\\strut f(\\color{magenta}{x^\\star}) - v \\right\\| = 0\\ .\\]\nRealistic result from the algorithm: The new candidate \\(\\color{magenta}{x^\\star}\\) will be better than \\(x_0\\), that is, \\[ \\left\\|\\strut f(\\color{magenta}{x^\\star}) - v\\right\\|\\ \\  {\\mathbf <}\\ \\  \\left\\|\\strut f(\\color{brown}{x_0}) - v\\right\\|\\] One algorithm for the operation involves approximating the function \\(f(x)\\) with a straight-line function \\(\\widehat{f}(x) = a x + b\\). For straight-line functions, the solution \\(x^\\star\\) can be found by simple arithmetic:\n\\[a x^\\star + b - v = 0 \\ \\ \\implies \\ \\ \\ x^\\star = \\frac{b-v}{a}\\] You saw in Block 2 how to construct the straight-line approximation to a function \\(f()\\) in a region of interest near \\(x_0\\) by evaluating the function and its derivative at \\(x_0\\). In other words, \\[\\widehat{f}(x) \\equiv f(x_0) + \\partial_x f(x_0) \\left[\\strut x - x_0 \\right]\\ .\\]\nBecause \\(\\widehat{f}(x)\\) is a straight-line function, it’s easy to find an input \\(x_1\\) that will generate exactly the desired output value \\(v\\). In other words, to solve \\(\\widehat{f}(x_1) = v\\) for \\(x_1\\).\n\\[\\begin{equation}\nx_1 = x_0 + \\frac{v-f(x_0)}{\\partial_x f(x_0)}\n\\end{equation}\\]\nAlthough \\(x_1\\) is an exact solution to the approximate problem, all we can hope is that for nonlinear \\(f(x)\\), \\(x_1\\) will be an approximate solution to the actual problem. In particular, we want \\(x_1\\) to be a better guess than \\(x_0\\): \\[\\|f(x_1) - v\\| \\underbrace{\\ \\ <\\ \\ }_\\text{We hope!} \\|f(x_0) - v\\|\\]\nThis (hopefully) improved solution \\(x_1\\) can become the starting guess for a new round of improvement based on the straight-line approximation to \\(f(x)\\) around \\(x_1\\). The refinement of \\(x_1\\) will be calculated as \\[\\begin{equation}\nx_2 = x_1 + \\frac{v-f(x_1)}{\\partial_x f(x_1)}\n\\end{equation}\\]\nEach round of improvement—that is, “iteration”—calculates a new value \\(x_{i+1}\\) from the previous \\(x_i\\). The improvement can be encapsulated as a function, which we will call solve_step(): \\[\\text{solve-step}(z) \\equiv z + \\frac{v-f(z)}{\\partial_x f(z)}\\ .\\]\nThis particular form of solve_step() is called a Newton step. The idea is to take successive steps, each refining the previous approximation, to get closer and closer (hopefully!) to the actual answer \\(x^\\star\\):\n\\[x_1 = \\text{solve-step}(x_0)\\\\\nx_2 = \\text{solve-step}(x_1)\\\\\nx_3 = \\text{solve-step}(x_2)\\\\\n\\vdots\\\\\nx_{i+1} = \\text{solve-step}(x_{i})\\\\\\ \\\\\n\\text{until eventually}\\ \\|f(x_{i+1}) - v\\|\\ \\text{is practically zero.}\\]\n\n\n\n\n\nFigure 47.1: A Newton-step calculation seen graphically. The brown function is approximated as a straight-line function at the initial point \\(x_0\\). The resulting \\(x_1\\) is where that straight line crosses the value \\(v\\) on the output scale. Here, \\(x_1\\) is a little to the left of the actual place where \\(f()\\) crosses \\(v\\). The Newton step produced an improved guess, since \\(\\|x_1 - x^\\star\\|\\) is smaller than \\(\\| x_0 - x^\\star\\|\\).\n\n\n\n\n\nConstruct the Newton-step function for finding zeros of the function \\[f(x) \\equiv x^2 - x\\ \\]\nSince \\(\\partial_x f(x) = 2 x - 1\\), the custom-built Newton-step function will be: \\[\\text{solve-step}(z) = z - \\frac{z^2 - z - 4}{2 z - 1}\\] ::: {.cell layout-align=“center” fig.showtext=‘false’}\n\nThe algorithm requires a starting guess. We’ll use \\(x_0 = 2\\). After each application of solve_step(), we’ll print out the refined value as well as the function output at that refined value.\n  x0 <- 2  \n  x1 <- solve_step(x0)  ()2.66666667\n\n  f(x1)  ()4.44444444\n\n  x2 <- solve_step(x1)  ()2.56410256\n\n  f(x2)  ()4.0105194\n\n  x3 <- solve_step(x2)  ()2.56155439\n\n  f(x3)  ()4.00000649\n\nThe output \\(f(x_3)\\) is practically the desired \\(v=4\\) so we have our result: \\(x^\\star = 2.56155\\)!\nAfter the first Newton step, producing \\(x_1 = 2.666666\\), the function output and \\(f(x_1) = 4.44444\\) was not sufficiently close to the desired output for us to take \\(x_1\\) as the solution. You can think of the problem like the task of digging a well. You need to start with the first shovelful. Then take another and another and … until you have your well. :::\nNewton’s method involves creating a custom solve_step() function for each new problem. The process is simple enough that we can create such functions automatically:\n\nmake_solve_step_fun <- function(tilde, v) {\n  f <- makeFun(tilde)\n  df <- D(tilde)\n  custom_fun <- function(z) {z + (v-f(z))/df(z)}\n\n  return(custom_fun)\n}\n\nLet’s test it out with this function:\n  f <- makeFun(x^2 - x ~ x)  \nConstruct the take-a-step function:\n  take_step <- make_solve_step_fun(f(x) ~ x, v = 4)  \nTake three steps starting at \\(x_0 = 3\\):\n  x0 <- 3  \n  x1 <- take_step(x0)  ()2.6\n\n  x2 <- take_step(x1)  ()2.5619\n\n  x3 <- take_step(x2)  ()2.5616\n\n  f(x3)  ()4\n\nThe Newton-step process is not guaranteed to work. By exploring cases where it fails, computational mathematicians1 have developed strategies for increasing the range of situations for which it works. Some of these strategies are incorporated in the R/mosaic function Zeros().\n\nZeros() takes two arguments: a function and a domain. The function is specified, as with other R/mosaic operators such as D(), slice_plot(), etc., as a tilde expression. Zeros() searches the domain for an input which makes the value of the function zero. If, instead, you want to find an input that makes the function value some other value, say \\(f(x^\\star) = v\\), you construct an intermediate expression f(x) - v ~ x. Finding the zero of the intermediate function corresponds to finding \\(f(x^star) = v\\).\nSometimes there will be multiple zeros on the specified domain. To handle such situations, Zeros() returns a data frame with two columns. The first gives input values that correspond to an output near zero. The second column, named .output. calculates the output (and will be near zero). We’ll illustrate by solving \\(x^3 = 6\\) for \\(x\\).\n  Zeros(x^3 - 6 ~ x, domain(x = c(1, 6)))  ()\n\n\n\n\nx\n\n\n.output.\n\n\n\n\n\n\n1.8171\n\n\n0"
  },
  {
    "objectID": "Manifestations/B4-operations.html#task-argmax",
    "href": "Manifestations/B4-operations.html#task-argmax",
    "title": "47  Operations on functions",
    "section": "47.2 Task: Argmax",
    "text": "47.2 Task: Argmax\nThe task of finding the input value that corresponds to a local maximum is called argmax finding. We don’t need to know the value of the local maximum to solve this problem. Instead, we designate a locale by specifying an initial guess \\(x_0\\) for the argmax. For argmax finding of an objective function \\(f(x)\\), we seek a \\(x^\\star\\) such that \\(f(x^\\star) > f(x_0)\\).\nTo accomplish this, we’ll approximate \\(f(x)\\) with a low-order polynomial, as we so often do. We’ll call the approximation \\(\\widehat{f(x)}\\). In the solving task, the approximation was with a first-order polynomial. But first-order polynomials—that is, straight-line functions—don’t have a local argmax. We need to use a second-order polynomial. Easy enough: construct the second-order Taylor polynomial around \\(x_0\\):\n\\[\\widehat{f}(x) \\equiv f(x_0) + f'(x_0) \\left[x - x_0\\right] + \\frac{1}{2} f''(x_0) \\left[x-x_0\\right]^2\\] Remember that \\(f(x_0)\\), \\(f'(x_0)\\) and \\(f''(x_0)\\) are all fixed quantities; the output of the functions for the specific input \\(x_0\\).\nTo find the argmax of \\(\\widehat{f}(x)\\), differentiate it with respect to \\(x\\) and find the zero of the derivative: \\[\\partial_x \\widehat{f(x)} = f'(x_0) \\underbrace{\\partial_x\\left[x - x_0\\right]}_{{\\large\\strut}1} +\n\\frac{1}{2} f''(x_0) \\underbrace{\\partial_x\\left[x-x_0\\right]^2}_{2 \\left[x - x_0\\right]} = 0\n\\]\nThis gives \\[f'(x_0) + f''(x_0) \\left[x - x_0\\right] = 0\\ .\\] We’ll solve this equation for \\(x\\) and, having in mind the iterative process of the previous section, call the result \\(x_1\\) \\[x_1 = x_0 - \\frac{f'(x_0)}{f''(x_0)}\\ .\\] In other words, our new guess \\(x_1\\) will be a step away from the old guess \\(x_0\\), with the step being \\(-f'(x_0) / f''(x_0)\\). This also is called a Newton step. What’s different from the Newton step of the previous section is that the function whose zeros are being sought is not \\(f(x)\\) but \\(f'(x)\\).\n\nUse the R/mosaic argM() function to find argmaxes and argmins. Like other R/mosaic calculus functions, the first argument is a tilde expression defining the objective function. The second argument is the domain to search.\nTo illustrate, the following code creates a randomly shaped function (displayed in ?fig-argm-ex1) and calls argM() to generate the argmaxes and argmins.\n  f <- rfun(~x, 3215) \n\n\n\n\n\n\n\n\n\n  argM(f(x) ~ x, domain(x = -5:5))  ()\n\n\n\n\nx\n\n\n.output.\n\n\nconcavity\n\n\n\n\n\n\n1.0280\n\n\n-26.5265\n\n\n1\n\n\n\n\n-2.9508\n\n\n3.7998\n\n\n-1\n\n\n\n\nNotice that argM() identified both a local maximum and a local minimum, that is, one argmax and one argmin. Visually, it’s easy to tell which one is which. In terms of the data frame returned by argM(), the sign of the concavity does the identification for you: positive concavity points to an argmin, negative concavity to an argmax. The name argM() refers to this versatility of finding both argmins and argmaxes."
  },
  {
    "objectID": "Manifestations/B4-operations.html#task-iterate",
    "href": "Manifestations/B4-operations.html#task-iterate",
    "title": "47  Operations on functions",
    "section": "47.3 Task: Iterate",
    "text": "47.3 Task: Iterate\nIn everyday language, to iterate means simply to repeat: to do something over and over again. In mathematics and in computing, “iterate” has a more specific meaning: to repeatedly perform an operation, each time taking the output from the previous round as the input to the current round.\nFor our purposes, it suffices to define iteration in terms of the use of a function \\(g(x)\\). The function must be such that the output of the function can be used as an input to the function; the output must be the same kind of thing as the input. The iteration starts with a specific value for the input. We’ll call this value \\(x_0\\). Iteration then means simply to compose the function with itself starting with \\(x_0\\) as the initial input. Here, for instance, is a four-step iteration: \\[g(g(g(g(x_0))))\\] Or, you might choose to iterate for ten steps: \\[g(g(g(g(g(g(g(g(g(g(x_0))))))))))\\] However many iteration steps you take, the output from the final step is what you work with.\nIteration is the mathematical engine behind many function operations. You’ve already seen it at work for the “solve” task and the “argmax” task.\n\nThe R/mosaic function Iterate() provides a very simple way to see the results of iteration. Typically when iteration is used as part of a function operation, the software has been written specifically for that task and includes logic about when to stop or start over or handle a variety of troublesome cases. The function Iterate() is provided in R/mosaic just for demonstration purposes.\nIterate() takes arguments specifying the function to be iterated (as a tilde expression), the starting \\(x_0\\), and the number \\(n\\) of steps to take. To illustrate, we’ll iterate a famous function called the logistic map: \\(f(x) \\equiv \\mu x (1-x)\\). Depending on the value of the parameter \\(\\mu\\), the iterates can show different patterns.\nEventually reaching a fixed point: ::: {.cell layout-align=“center” fig.showtext=‘false’}\nIterate(2*x*(1-x) ~ x, x0=0.3, n=10)\n##     n         x\n## 1   0 0.3000000\n## 2   1 0.4200000\n## 3   2 0.4872000\n## 4   3 0.4996723\n## 5   4 0.4999998\n## 6   5 0.5000000\n## 7   6 0.5000000\n## 8   7 0.5000000\n## 9   8 0.5000000\n## 10  9 0.5000000\n## 11 10 0.5000000\n\nEventually reaching a periodic oscillation: ::: {.cell layout-align=“center” fig.showtext=‘false’}\nIterate(3.2*x*(1-x) ~ x, x0=0.3, n=50) |> tail()\n##     n         x\n## 46 45 0.5130445\n## 47 46 0.7994555\n## 48 47 0.5130445\n## 49 48 0.7994555\n## 50 49 0.5130445\n## 51 50 0.7994555\n:::\nA never-ending, random-seeming fluctuation, called mathematical chaos:\n\nIterate(4.0*x*(1-x) ~ x, x0=0.3, n=5000) |> tail()\n##         n          x\n## 4996 4995 0.56824790\n## 4997 4996 0.98136889\n## 4998 4997 0.07313595\n## 4999 4998 0.27114833\n## 5000 4999 0.79050766\n## 5001 5000 0.66242119\n\n:::"
  },
  {
    "objectID": "Manifestations/B4-operations.html#software-for-the-tasks",
    "href": "Manifestations/B4-operations.html#software-for-the-tasks",
    "title": "47  Operations on functions",
    "section": "47.4 Software for the tasks",
    "text": "47.4 Software for the tasks\nEvaluation of a function—number one in the list at the head of this chapter—is so central to the use of computer languages generally that every language provides a direct means for doing so. In R, as you know, the evaluation syntax involves following the name of the functions by a pair of parentheses, placing in those parenthesis the values for the various arguments to the function. Example: log(5)\nThe other six operations on functions listed above, there is one (or sometimes more) specific R/mosaic functions. Every one of them takes, as a first argument, a tilde expression describing the function on which the operation is to be formed; on the left side is a formula for the function (which can be in terms of other, previously defined functions), on the right side is the with-respect-to input.\n\nDifferentiate: D(). Returns a function.\nAnti-differentiate: antiD(). Returns a function.\nIntegrate: Integrate(). Returns a number.\nSolve: Zeros(). Returns a data frame with one row for each solution found.\nArgmax: argM() Finds one argmax and one argmin in the domain. local_argM() looks for all the local argmaxes and argmins. Returns a data frame with one row for each argmax or argmin found.\nIterate: Iterate() Returns a data frame with the value of the initial input and the output after each iteration.\n\nEach of operations 4-6 involves the specification of a domain. For Integrate(), this is, naturally, the domain of integration: the upper and lower bounds of the integral\nFor Zeros() and argM() the domain specifies where to search for the answer. Iterate() is slightly different. After the tilde expression comes an initial value \\(x_0\\) and then n= which you use to set the number of times to iterate."
  },
  {
    "objectID": "Manifestations/B4-operations.html#exercises",
    "href": "Manifestations/B4-operations.html#exercises",
    "title": "47  Operations on functions",
    "section": "47.5 Exercises",
    "text": "47.5 Exercises\n\nExercise 32.03: THpUtP unassigned\n\nCreate a function, which iterated sufficiently from a starting guess, will implement Newton’s method to calculate \\(\\sqrt{10}\\).\n\n\nPart A Which of these functions is appropriate to use in Newton’s method for calculating \\(\\sqrt{10}\\)?\n\n\\(f(x) \\equiv x^2 - 10\\)\n\\(f(x) \\equiv x - \\sqrt{10}\\)\n\\(f(x) \\equiv (x - 10)^2\\)\n\n\n\nNow you are going to translate \\(f(x)\\) into a function, when iterated from some starting guess \\(x_0\\), will tend toward a zero of \\(f(x)\\). The function will have the form \\[N(x) \\equiv x - \\frac{f(x)}{f'(x)}\\ .\\]\n\n\nPart B What is the function \\(f'(x)\\) for the \\(\\sqrt{10}\\) problem?\n\n\\(2x - 10\\)\n\\(2x\\)\n\\(\\frac{1}{3} x^3 + 10 x + C\\)\n\\(x\\)\n\n\n\n\n\nPart C Which of these is the correct form for the Newtons-method iterator \\(N(x) \\equiv x - \\frac{f(x)}{f'(x)}\\)?\n\n\\(N(x) \\equiv x - \\frac{x^2 - 10}{2 x}\\)\n\\(N(x) \\equiv x + \\frac{x^2 - 10}{2 x}\\)\n\\(N(x) \\equiv x + \\frac{2x}{x^2 - 10}\\)\n\\(N(x) \\equiv x - \\frac{2x}{x^2 - 10}\\)\n\n\n\nIn a SANDBOX, implement \\(N(x)\\).\n\n\nPart D Using \\(N()\\) as the dynamics and starting with \\(x_0 = 1\\), what is \\(x_5\\)?\n5.53.6590913.1415933.1960053.1624563.1623543.162278\n\n\n\n\nPart E Modify N() to find \\(\\sqrt{20}\\). Starting at \\(x_0=1\\), how many times do you have to apply your new N() to get an answer right to within 1% of the true number?\n\nAfter 2 steps we get 4.202\nAfter 3 steps we get 4.713.\nAfter 3 steps we get 4.472.\nAfter 4 steps we get 4.472.\nAfter 4 steps we get 4.478.\n\n\n\n\n\nPart F Modify your N() once again to find \\(\\sqrt[3]{10}\\). (That is, the cube-root of 10.) Starting at \\(x_0 = 1\\), take 3 Newton steps. What is \\(x_3\\)?\n2.1542.3202.8752.912\n\n\n\nExercise 32.05: ZRYTU3 unassigned\n\nAs an example of situation where Newton’s method fails, consider \\(x_0\\) accidentally picked close to an argmax, that is \\(f'(x_0) \\approx 0\\). (The situation is illustrated in Figure @ref(fig:newton-too-big).) The length of the Newton step is proportional to \\(1/f'(x_0)\\), which is large when \\(f'(x_0) \\approx 0\\). Such a Newton step can produce \\(x^\\star\\) further from the actual solution rather than closer to it.\n\n\n\n\n\nFigure 47.2: An unlucky choice (magenta) of \\(x_0\\) near a local maximum has resulted in a Newton step that is too long. The Newton step creates \\(x_1 \\approx -3\\), far to the left of the actual zero crossing which is near \\(x\\approx 0\\).\n\n\n\n\n\nTake a second Newton step, that is, a step starting at \\(x_1\\) and ending at \\(x_2\\). You can eyeball the linear function that approximates \\(f(x)\\) near \\(x_1\\). What is the approximate value of \\(x_2\\).\nTry a simple modification to Newton’s method that can help deal with such situations. In the figure above, the full Newton step puts \\(x_1\\) where the dotted line crosses the brown line. This full step has length \\(\\| x_1 - x_0 \\|\\), in this case roughly 4.5.\n\nIn your modification, instead of taking the full Newton step, take a step from \\(x_0\\) that is only half as long. That half step will bring you to a new \\(x_1\\). From there, take another half Newton step to find \\(x_2\\). Will this process converge toward the actual zero crossing of \\(f(x)\\)?\n\nExercise 32.07: 36xJU8 unassigned\n\n\nWrite a Newton-step better() function to solve for \\(x\\) in the equation \\(\\sin(x) = \\cos(x)\\). Start with the guess \\(x_0 = 0\\) and iterate better() enough times to get \\(\\| x_i - x^\\star\\| < 0.001\\).\n\nTo help, we’ll give the hint that \\(x^\\star \\approx 0.785\\).\n\nSuppose we hadn’t told you the answer \\(x^\\star\\). How could you know, just from your iterations of better(), that you are very close to the true answer.\n\n\nExercise 32.09: 6bX0Zx unassigned\n\nWe introduced Newton’s method as a technique for finding zeros of functions. For instance, for finding zeros of \\(g(x)\\), you would apply the function better() iteratively to an initial guess \\(x_0\\).\n\\(\\text{better}(x) \\equiv x - \\frac{g(x)}{\\partial_x g(x)}\\)\nA. Suppose your goal is not to find a zero of \\(g(x)\\) but instead to find an argmax. One way to do this is to find the zeros of \\(\\partial_x g(x)\\). Write down the Newton-step suitable for the argmax problem.\nB. Imagine that \\(g(x)\\) has an output of miles-per-gallons and an input speed in miles-per-hour. What will be the dimension of the Newton step for the optimization problem?\nC. Taking into account the dimension of the input \\(x\\) and of the output \\(f(x)\\), what is the dimension of the step \\(-f'(x_0) / f''(x_0)\\). Explain why this makes sense in terms of what a step needs to be.\n\nExercise 32.11: gCKs9N unassigned\n\n\n\nPart A Which of the following R/mosaic functions takes an initial condition as one of the inputs?\nantiD()D()Iterate()\n\n\n\n\nPart B Which of the following R/mosaic functions requires that you specify a domain as one of the inputs to the function?\nantiD()D()Iterate()Solve()\n\n\n\n\nPart C The R/mosaic functions Solve() and argM() return what kind of computer object?\na numbera functiona grapha data frame\n\n\n\nExercise 32.13: JBw8oV unassigned\n\nA simple robot arm to move things in the \\((x,y)\\) plane consists of two links, the first connected to the base of the robot and the second to the free end of the first link, as in the diagram. At the end of the second link is a tool, such as a drill. Such a robot would be used to drill a series of precisely positioned whole in a metal plate.\nEach link is moved by a digitally-controlled motor. To position the robot, commands are sent to the two motors to set their respective angles. For instance, in the diagram the motor-1 angle, \\(\\theta_1\\) is set to 45 degrees, while the motor-2 angle \\(\\theta_2\\) is set to -60 degrees.\nThe problem faced by the robot designer is to allow the user to input a series of \\((x,y)\\) coordinates (where the holes are to be drilled) and have the robot controller calculate the resulting angles.\nFor simplicity, assume that the link lengths are both \\(L = 1\\), but generalizing this to two different link lengths would not be difficult.\nAt this point, play with the problem a bit. Mark a point on your desk or paper. This will be the location of the base of the robot. Take two pencils, let’s call them “yellow” and “green,” putting the eraser of yellow at the base location and the eraser of green at the tip of yellow. Now, pick another point on your desk or paper to be the target for the robot arm. (This must be closer to the base than the sum of lengths of the two pencils.) Change the orientation of the pencils, keeping yellow attached to the base and green attached to the tip of yellow. Your job is to find an orientation that will place the tip of green on the target. Try different target points until you feel comfortable that you understand how to solve the problem.\nNow to create a mathematical model of the situation so that we can automate the solution. The purpose of this model is to find \\(\\theta_1\\) and \\(\\theta_2\\) given the \\((x, y)\\) position of the target.\nFrom your experience using pencils as the model of the robot, you may have noticed that the location of the “elbow” of the robot arm is key to the solution. Find the right position for the elbow and the angles can be calculated from trigonometry.\nNote that the position of the elbow, which we will denote with coordinates \\((u, v)\\) is determined solely by \\(L\\) and \\(\\theta_1\\).\n\nWrite down a formula for the \\(u\\) and for the \\(v\\) position of the elbow as a function of \\(\\theta_1\\) (taking the base as the origin). Hint: sine and cosine functions are relevant.\nImplement the formulas from (1) into two functions, one called elbow_u(theta1) and the other elbow_v(theta1).\nWrite another function, elbow_to_target_dist(theta1, x, y) that will use elbow_u() and elbow_v() to calculate the distance from the elbow to the target point \\((x, y)\\). (The distance will be \\(\\sqrt{\\strut (x - u)^2 + (y-v)^2}\\).)\nWrite yet another function, dist_at_theta(theta1, x, y) that, given an angle theta, will return the distance from the elbow to the target. The logic is to use elbow_u() and elbow_v() to find the location of the elbow \\(u\\) and \\(v\\) and then give these as the argments to elbow_to_target_dist().\nThe next phase of the solution is to use elbow_to_target_dist(theta1, x, y) to find a value of theta1 that will make the distance equal to the length \\(L\\) of link2. When you have found this theta1, you’ll know the position of the elbow that is consistent with reaching the target from the base with the two links.\n\nPick a target location. This can be anything within distance \\(2L\\) from the base. We’ll call the coordinates of your target target_x and target_y.\nPlot out elbow_to_target_dist(theta1, x=target_x, y=target_y) as a function of theta1 over the domain \\(-\\pi \\leq \\theta_1 \\leq \\pi\\).\nLocate a value of \\(\\theta_1\\) where the output of the function is \\(L\\).\n\nWrite another function, elbow_theta1(x, y) that takes the \\((x, y)\\) position as input and produces as output suitable value(s) of \\(\\theta_1\\). To do this within the elbow_theta1(x, y) function, use Zeros(dist_at_theta(theta1) - L, domain(theta1=-pi:pi))."
  },
  {
    "objectID": "Manifestations/B4-splines.html",
    "href": "Manifestations/B4-splines.html",
    "title": "48  Data-driven functions",
    "section": "",
    "text": "As early as Chapter 3 of this book, we noted that a function can be described as a table where each row stands for one set of input values together with a corresponding output value. We did not, however, make much use of the table-as-function concept. Instead, we used data tables to motivate the choice of parameters, as in linear combinations of the basic modeling functions. We called this function fitting: constructing a function that stays near the data values. (We will say more about function fitting in Block 5 where we introduce new tools for treating functions as geometrical objects.)\nThis chapter introduces yet another important method for constructing functions that match with data. What’s different here is that each data point will be a mandate; the function is required to go through each and every data point exactly."
  },
  {
    "objectID": "Manifestations/B4-splines.html#generating-smooth-motion",
    "href": "Manifestations/B4-splines.html#generating-smooth-motion",
    "title": "48  Data-driven functions",
    "section": "48.1 Generating smooth motion",
    "text": "48.1 Generating smooth motion\nAs a motivating example, consider the programming of robotic arms as in the video:\n\n\nSince this isn’t a robots course, we’ll simplify. The arm has a resting position. When a car frame comes into place, the arm moves so that its welding electrodes are at a specific, known place in space near the car body. Then it moves in sequence to other places where a weld is required, perhaps passing through waypoints to avoid obstacles.\nThe problem of converting the discrete list of weld and waypoints into a continuous signal for the actuator is an instance of a mathematical process called interpolation. In real robot arms, there are multiple joints that need to be controlled simultaneously. For our illustration, we’ll use a simple setup where the robot hand rolls along a set of rails in the y-direction and another x-rail running crosswise to the y direction.\n\n\n\n\n\n\n\n\n\nThe task for our example robot will be to visit the points shown in Figure 48.1 in order, taking 15 seconds to traverse the whole path.\n\n\n\n\n\nFigure 48.1: The waypoints on a path the robot hand is supposed to follow. All the action is taking place in roughly 1x1 meter area.\n\n\n\n\nFigure 48.1 shows a continuous path in \\((x,y)\\) coordinates together with discrete labels indicating when each waypoint is to be reached. Note that the path is not a function \\(y(x)\\). Mathematical functions are required to be single valued, meaning that for each value of the input (in the function domain) there can be only one, unique output value. The path in Figure 48.1 often involves two or more different \\(y\\) values for a single \\(x\\) value. There is even a small domain of \\(x\\) near \\(x=900\\) where the path at any given \\(x\\) crosses six different \\(y\\)-values.\nEven so, functions can be a useful way of describing the \\((x,y)\\) path. The key is the plural: functions. For the path in Figure 48.1 we need two quantities varying with time in a coordinated way. One approach, familiar to navigators, is to specify direction of movement and velocity at each instant of time. Perhaps not as familiar, but more fundamental mathematically, is to specify \\(x\\) as a function of time and, separately, \\(y\\) as a function of time. Using this formalism, the trajectory of the robot arm will consist of two functions, \\(x(t)\\) and \\(y(t)\\). To build those functions, well start with the waypoints stored in the data frame Zcalc::Robot.stations.\n\n\n\n \n  \n    t \n    x \n    y \n  \n \n\n  \n    1 \n    496 \n    191 \n  \n  \n    2 \n    1037 \n    138 \n  \n  \n    3 \n    1251 \n    191 \n  \n  ... and so on ...\n  \n  \n  \n    15 \n    928 \n    432 \n  \n  \n    16 \n    737 \n    240 \n  \n\n\n\n\n\n\nGET THE TABLE HERE IN PDF mode\n\nThe \\(x(t)\\) and \\(y(t)\\) functions in this table aren’t complete enough to operate the robot. We need to provide the \\(x,y\\)-location data in the form of two continuous functions of \\(t\\) so that the robot, at any time \\(t\\), can look up where it is supposed to be, what its velocity should be, and how that velocity should be changing in time (acceleration).\nOne strategy is to construct the functions as piecewise linear functions of \\(t\\), like this:\n\n\n\n\n\nFigure 48.2: Two functions \\(x(t)\\) and \\(y(t)\\) which describe the path shown in Figure 48.1.\n\n\n\n\nIt can be difficult at first glance to see the relationship between the \\(x(t)\\) and \\(y(t)\\) functions and the path shown in @ref(fig:robot-points). As an exercise, look specifically at the segment \\(9 \\leq t \\leq 10\\). In Figure 48.2, this is the segment connecting points 9 and 10. In the path view, you can see that on this segment \\(x\\) changes a lot while \\(y\\) changes only a little. Correspondingly, in the function view (Figure 48.2) \\(\\partial_t x(t)\\) is large in magnitude compared to \\(\\partial_t y(t)\\).\nEach functions shown in @ref(fig:piecewise-linear-path) is an interpolating function. You’re entitled to think of the \\(x(t)\\) function as connecting with lines the sequence of \\(x\\) versus \\(t\\) coordinates from the table and similarly for \\(y(t)\\). Each of the two functions is clearly continuous. But, based on your work in Blocks 1 through 3, you have a richer set of concepts for interpreting those two functions.\nFor instance, let’s look at \\(\\partial_t y(t)\\). Since \\(y\\) is a position along the cross rail, \\(\\partial_t y(t)\\) is the velocity in that direction. Figure 48.3 shows the velocity versus time for both the \\(x\\) and \\(y\\) components of the movement.\n\nlabels <- latex2exp::TeX(c('\\\\partial_t x(t)  (mm/s)', \"\\\\partial_t y(t)  (mm/s)\"))\ndt_xl <- D(xl(t) ~ t)\ndt_yl <- D(yl(t) ~ t)\nP1 <- slice_plot(dt_xl(t) ~ t, domain(t=1:16), npts=901, singularities = 1:16) %>% \n  gf_labs(y=labels[[1]], x=\"\")\nP2 <- slice_plot(dt_yl(t) ~ t, domain(t=1:16), npts=901,, singularities = 1:16) %>%\n  gf_labs(y=labels[[2]], x=\"t (sec)\")\ngridExtra::grid.arrange(P1, P2, nrow=2)\n\n\n\n\nFigure 48.3: Velocity versus time time along the path defined by \\(x(t)\\) and \\(y(t)\\) as shown in Figure @ref(fig:piecewise-linear-path),\n\n\n\n\nThe speed of the robot arm maxes out at about 600 mm-per-second. You can get a sense for this by moving your finger two feet in 1 second: a normal human speed of movement.\nSince the original \\(x(t)\\) and \\(y(t)\\) functions are piecewise linear, it makes sense that the derivatives with respect to time are piecewise constant. But the robot hand is a physical thing; it has to have a velocity at every instant in time. It can’t instantaneously have an undefined velocity.\nThink about what it is that causes the change from one velocity step to another. There’s a motor that’s spinning and changing its rate of spin, perhaps using a pulley and a belt to move the robot hand to the right position at any instant of time. Changing the velocity requires a force to create an acceleration. We can differentiate the velocity to see what the acceleration must be to create the simple piecewise linear function shown in Figure 48.2.\n\n\n\n\n\nFigure 48.4: ?(caption)\n\n\n\n\nMathematically, the second derivatives \\(\\partial_{tt} x(t)\\) and \\(\\partial_{tt} y(t)\\) do not exist, because \\(\\partial_{t} x(t)\\) and \\(\\partial_{t} y(t)\\) are discontinuous. There is no physical amount of force that will change the velocity in an instant.\nAs an accommodation to the physical existence of the robot hand, we’ve softened the transition between consecutive velocity segments to allow it to take 0.2 seconds, ramping up from zero force 0.1 second before the hand reaches the station, to maximum force at the station, then back down to zero 0.1 second after the hand reaches the station. Consequently the actual motion is smoother and the maximum acceleration is about half that of gravity. Figure 48.5 shows the resulting trajectory which can be likened to that of a baseball player rounding a base.\n\n\n\n\n\nFigure 48.5: A smoothed x-trajectory near station 2. The position of the station is marked with a dot.\n\n\n\n\nA consequence of smoothing the trajectory is that the robot hand comes near, but doesn’t touch the station. It misses by about 2 mm. For many human tasks that might be good enough, but for precision manufacturing a miss by 2 mm is about 1000 times more than allowed.\nIf you like working with practical problems, you might find a simple solution to the problem. For instance, we could have aimed the robot hand 2 mm further to the right than the actual station. In falling short by 2mm, the hand would miss the new target but cross right over the originally intended station.\nSolutions like this ae sometimes called ad hoc, meaning that they are so specifically tailored to one situation that they do not generalize well to slightly different problems. The next section introduces an approach that is much more general."
  },
  {
    "objectID": "Manifestations/B4-splines.html#piecewise-but-smooth",
    "href": "Manifestations/B4-splines.html#piecewise-but-smooth",
    "title": "48  Data-driven functions",
    "section": "48.2 Piecewise but smooth",
    "text": "48.2 Piecewise but smooth\nThe approach we will take to smoothly connect the points on the path is based on ideas of derivatives and on the construction of low-order polynomials. In Block 2, we emphasized low-order polynomials up to the square term, and we’ll pick that up again here for demonstration purposes. For this example, we’ll construct only the \\(y(t)\\) function. Constructing \\(x(t)\\) would be done using the same procedure.\nOur task is to find a function \\(y(t)\\) to interpolate discrete points such as those shown in Figure 48.6. The discrete points are called knots1 in the language of interpolating functions. Each knot is a coordinate pair \\((t_i, y(t_i))\\) shown as an orange dot in Figure 48.6.\nThe piecewise linear interpolating function is easily constructed and is shown as a dotted curve. As we saw in the previous section, such a function has a discontinuous first derivative. We would like something smoother, with a continuous first derivative. A curve such as the one we seek is shown as the multi-colored function.\n\n\n\n\n\nFigure 48.6: Two interpolating functions of the four discrete points (orange). One is piecewise linear (dotted curve), the other is piecewise quadratic (multi-color curve).\n\n\n\n\nThe framework we will adopt for the smooth interpolating function is piecewise quadratic segments between adjacent knots. There are four knots, requiring three segments. We’ll call the segment \\(p_1(y)\\) connecting the first knot to the second, with \\(p_2(y)\\) connecting the second to the third knot and \\(p_3(y)\\) connecting the third to the fourth knot. Each of those segments will be a second-order polynomial. To keep things organized, we’ll use coefficient names systematically:\n\\[p_1(t) \\equiv a_1 + b_1 \\left[t - t_1\\right] + c_1 \\left[t - t_1\\right]^2\\\\\np_2(t) \\equiv a_2 + b_2 \\left[t - t_2\\right] + c_2 \\left[t - t_2\\right]^2\\\\\np_3(t) \\equiv a_3 + b_3 \\left[t - t_3\\right] + c_3 \\left[t - t_3\\right]^2\\\\\\] The four knots are \\[\\left[\\begin{array}{c}\\left(t_1, x_1\\right)\\\\\n\\left(t_2, y_2\\right)\\\\\n\\left(t_3, y_3\\right)\\\\\n\\left(t_4, y_4\\right)\\\\\n\\end{array}\\right]\\] which you can think of as two columns of a data frame, one with the \\(t\\)-coordinates of the knots and the other with the \\(y\\)-coordinates. For the knots in Figure 48.6 the data table is\n\n\n\n \n  \n    t \n    y \n  \n \n\n  \n    1 \n    0.0 \n  \n  \n    2 \n    2.0 \n  \n  \n    3 \n    0.5 \n  \n  \n    4 \n    1.7 \n  \n\n\n\n\n\nConstructing the interpolating function is a matter of making good choices for \\(a_1,\\) \\(a_2,\\) \\(a_3,\\) \\(b_1,\\) \\(b_2,\\) \\(b_3,\\) \\(c_1,\\) \\(c_2,\\) and \\(c_3\\).\nWe require these things of each of the interpolating polynomials:\n\nIt passes exactly through the two knots marking the segment’s endpoints. That is \\(p_1(t_1) = y_1\\) and \\(p_1(t_2) = y_2 = p_2(t_2)\\) and \\(p_2(t_3) = y_3 = p_3(t_3)\\) and, finally, \\(p_3(t_4) = y_4\\). Note that at the interior knots where two polynomials join, the left-hand polynomial and the right-hand polynomial should exactly match the function value and each other.\nThe derivative (with respect to \\(t\\)) should match where the segments join. That is, \\(\\partial_t p_1(t_1) = \\partial_t p_2(t_2)\\) and \\(\\partial_t p_2(t_3) = \\partial_t p_3(t_3)\\). Thus, the function we want to build will be \\(C^1\\), that is, have a continuous first derivative.\n\nHow to accomplish (1) and (2)?\nNotice first that because we wrote each of the polynomials in the style of Taylor polynomials, we can read the values of \\(a_1\\), \\(a_2\\), and \\(a_3\\) directly from the data table: \\[p_1(t_1) = a_1 = y_1\\\\p_2(t_2) = a_2 = y_2\\\\p_3(t_3) = a_3 = y_3\\\\\\]\nWe can find other coefficients from the requirement that the right side of each segment pass through the knot on that side. This gives:\n\\[p_1(t_2) = y_2 = a_1 + b_1 \\left[t_2-t_1\\right] + c_1\\left[t_2-t_1\\right]^2\\\\\np_2(t_c) = y_3 = a_2 + b_2 \\left[t_3-t_2\\right] + c_2\\left[t_3-t_2\\right]^2\\\\\np_3(t_c) = y_4 = a_3 + b_3 \\left[t_4-t_3\\right] + c_3\\left[t_4-t_3\\right]^2\\] (Notice that \\(t_2 - t_1\\) and the like are simply numbers that can be computed from the known knot points.)\nAnother two conditions are that the derivatives of the polynomials from either side of each interior knot point must match at the knot point. Finding the derivatives of the segments is a simple exercise:\n\\[\\partial_t p_1(t) = b_1 + 2 c_1 \\left[t - t_1\\right]\\\\\n\\partial_t p_1(t) = b_2 + 2 c_2 \\left[t - t_2\\right]\\\\\n\\partial_t p_1(t) = b_3 + 2 c_3 \\left[t - t_3\\right]\\] Matching these derivatives at the \\(t_2\\) and \\(t_3\\) knot points—the interior knots where two segments come together—gives two more equations: \\[\n\\partial_t p_1(t_2) = b_1 + 2 c_1 \\left[t_2 - t_1\\right] = b_2 = \\partial_t p_2(t_2)\\\\\n\\partial_t p_2(t_3) = b_2 + 2 c_2 \\left[t_3 - t_2\\right] = b_3 = \\partial_t p_3(t_3) \\] All together, we have five equations in six unknowns: \\(b_1, b_2, b_3\\) and \\(c_1, c_2, c_3\\).\nPlugging in the specific values \\(t_1\\) through \\(t_4\\), and \\(x_1\\) through \\(x_4\\) from the data table translates the equations for the polynomial values and derivatives gives this system of equations: \\[\nb_1 + c_1 = x_2 - x_1 = \\ \\ \\ \\ \\ \\ 2\\\\\nb_2 + c_2 = x_3 - x_2 = -1.5\\\\\nb_3 + c_3 = x_4 - x_3= \\ \\ 1.2\\\\\nb_1 + 2 c_1 - b_2 = 0\\\\\nb_2 + 2 c_2 - b_3 = 0\\]\nThis is not the place to go into the details of solving the five equations to find the six unknowns. (Block 5 introduces the mathematics of such things, which turns out to the same math used to find model parameters to “fit” data.) But there are some simple things to say about the task.\nFirst, you may recall being told in high-school mathematics that to find six unknowns you need six equations. We have only five equations to work with. But it is far from true that there is no solution for six unknowns with five equations. There are in fact an infinite number of solutions. (Again, Block 5 will show the mathematics behind this statement.) Essentially, all we need to do is make up a sixth equation to identify a particular one of the infinite number of solutions. It’s nice if this made-up equation reflects something interpretable about the curve.\nWe’ll choose to have the sixth equation specify what the derivative of the interpolating function should be at the far right end of the graph. That right-most derivative value will be \\[\\partial_t p_3(t_4) = b_3 + 2 c_3 \\left[t_4 - t_3\\right]\\ .\\] We can set this value to anything we like. For instance, in Figure 48.6 the right-most derivative is set to zero; you can see this from the curve being flat at the right-most knot point.\n\n\n\n\n\nFigure 48.7: Four different \\(C^1\\) piecewise quadratic functions that interpolate the knot points. The functions have different values of the derivative at the right end of the domain.\n\n\n\n\nKeeping in mind the piecewise nature of the interpolating polynomial, it may seem surprising that changing the slope at \\(t_4\\) leads to a change in value of the function almost everywhere. Yet the stiffness of the parabolic segments means that conditions in one segment have an impact on adjacent segments. In turn, the segments adjacent to these also change, a change that percolates down to every segment in turn.\n\nQuadratic spline functions can be created with the R/mosaic qspliner() function. The second argument is a data frame giving the knot locations. The first argument is a tilde expression specifying the variables to use from the data frame.\n\nxfun <- qspliner(x ~ t, data = Zcalc::Robot.stations)\nyfun <- qspliner(y ~ t, data = Zcalc::Robot.stations)\n\n\n\n\n\n\n\n\n\nFigure 48.8: A quadratic spline interpolation of the \\(x\\)-coordinates of the robot-path knots. The data hardly speak for themselves, since the interpolationg function tends to alternate between concave up and concave down in adjacent segments between the knots.\n\n\n\n\n\nPutting together the \\(x(t)\\) and \\(y(t)\\) interpolating functions, each of which has that extremum between knot points, leads to an absurdly complicated path, as seen in Figure 48.9.\n\n\n\n\n\nFigure 48.9: Connecting the robot-path knots with a piecewise quadratic polynomial, constructed to be \\(C^1\\). The path is pretty perhaps, but absurd.\n\n\n\n\nQuadratic splines are rarely used in practice. (A cubic spline provides helpful flexibility. See Section 48.3.) In Figure 48.8 you can see one of the reasons: the quadratic form is so stiff that the interpolating function tends to shift from concave up to concave down (or vice versa) at each knot point. This results in the interpolating function tending to have a local minimum or maximum between adjacent knots, even if the data themselves to not indicate such a structure."
  },
  {
    "objectID": "Manifestations/B4-splines.html#sec-cubic-splines",
    "href": "Manifestations/B4-splines.html#sec-cubic-splines",
    "title": "48  Data-driven functions",
    "section": "48.3 C2 smooth functions",
    "text": "48.3 C2 smooth functions\nIn the previous section, we arranged the functions \\(x(t)\\) and \\(y(t)\\) composed from the piecewise quadratic segments to be \\(C^1\\) smooth. (Recall that \\(C^1\\) smooth means that the derivatives \\(\\partial_t x(t)\\) and \\(\\partial_t y(t)\\) are continuous.) We established this continuity by make sure that each segment has a value of the derivative at its end-point know that matches the derivative of the adjacent segment.\nTo arrange \\(C^2\\) continuity requires that the segment include a new parameter. Most commonly, this is done by moving from quadratic segments to cubic segments. This can be done by an approach similar to that of the previous section but somewhat more elaborate. Such a \\(C^2\\) interpolating function is called a cubic spline. Cubic splines are very commonly encountered in applications requiring interpolation.\nWith the ability to match piecewise cubic polynomials to a set of knots, we can easily construct the smooth path to connect the knots in @ref(fig:robot-points). Figure 48.10 shows a \\(C^2\\) path connecting the knots. The path is constructed by plotting simultaneously the output of two functions, \\(x(t)\\) and \\(y(t)\\), with the input \\(t\\) on the domain \\(1 \\leq t \\leq 16\\).\n\nCubic spline functions can be created with the R/mosaic spliner() function. The second argument is a data frame giving the knot locations. The first argument is a tilde expression specifying the variables to use from the data frame.\n\nxfun <- spliner(x ~ t, data = Zcalc::Robot.stations)\nyfun <- spliner(y ~ t, data = Zcalc::Robot.stations)\n\n\n\n\n\n\n\n\n\n\nFigure 48.10: Connecting the robot-path knots with a piecewise cubic polynomial, constructed to be \\(C^2\\). This is a much smoother path than produced by interpolation with quadratic polynomials.\n\n\n\n\n\n\n\n\n\nFigure 48.11: A cubic spline interpolation of the \\(x\\)-coordinates of the robot-path knots. The cubic spline respects the monotonicity of consecutive knot points.\n\n\n\n\n\nWe saw that using a line-segment interpolation produces discontinuity in the derivative of the function. Mathematically, discontinuity in the velocity can be thought of as an infinite acceleration, requiring an infinite force. In the physical world, accelerations must be finite. Even if a force is large, there is often slack in connections between components and the components are not perfectly rigid.\nThe videos show motion of a robotic dog. In the left video, the motors in the robot are being asked to make a straight-line transition between waypoints. The result is vibration and a tremor-like movement. The right video shows the same robot, but with smoothly interpolated waypoints. This produces a gentle and vibration-free movement.\n\n\n\n\nWithout interpolation\n\n\nWith interpolation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWHAT SHOULD GO HERE IN PDF?\n\nLink to entire video by James Bruton."
  },
  {
    "objectID": "Manifestations/B4-splines.html#bézier-splines",
    "href": "Manifestations/B4-splines.html#bézier-splines",
    "title": "48  Data-driven functions",
    "section": "48.4 Bézier splines",
    "text": "48.4 Bézier splines\nThe sort of interpolating functions described in the previous two sections were designed to be smooth at the \\(C^1\\) level (quadratic spline) or the \\(C^2\\) level (cubic spline). Such smoothness makes sense for, say, robotic motion where we want at all times to keep the force on each robot joint small.\nNot all path-related design problems require such smoothness. Indeed, in some settings, non-smoothness is called for. For instance, ?fig-letter-e shows the outline of a familiar shape ::: {.cell .column-margin layout-align=“center” fig.showtext=‘false’} ::: {.cell-output-display}  ::: :::\nFor both quadratic and the more commonly used cubic splines, matching the derivatives on either side of a knot is essential to constructing the function. For Bézier splines, each segment is mathematically independent from every other segment. It is up to the human designer of the curve to determine whether the curves derivative should be continuous or discontinuous at the knot point between two segments.\nThe shape of a Bézier spline segment is established by four independent points. The first and last points determine the endpoints of the segment. Each endpoint is associated with a control point that sets the angle and “speed” with which the path leaves or enters the endpoint. You can interact with the graph in Figure 48.12 to develop an intuition.\n\n\n\n\n\n\n\nLink to the Bezier app for PDF version\n\n\n\n\n\n\nFigure 48.12: A single Bézier segment is defined by two endpoints and two control points. Drag the control points to see how the shape of the curve is defined by them.\n\n\n\n\nThe curve for a given segment is gratifyingly smooth. The real power of Bézier splines stems from how segments can be connected in various ways. Figure 48.13 shows two Bézier segments that have been initialized to have a smooth junction at endpoints 4 and 5. The smoothness is set by the corresponding control points (marked 3 and 6). So long as those four points (3, 4, 5, 6) are colinear and in order, the junction will be smooth. You can alter control points 2 and 7 in any way you like; the junction will remain smooth.\n\n\n\n\n\n\n\nWHAT TO PUT HERE FOR PDF version?\n\n\n\n\n\n\nFigure 48.13: Two Bézier segments can be arranged in to create a smooth or non-smooth junction between them.\n\n\n\n\nConsider the path followed by a Bézier curve as it leaves one of the endpoints. Figure 48.13 has been initialized so that the tangent to the curve is horizontal at the right endpoint and almost vertical at the left endpoint. The further the control point is from the endpoint, the longer the Bézier curve will stay close to the tangent line. Another way to think of this is that the position of a control point has little impact on the shape of the curve near the opposite endpoint. You can observe this on the canvas by, say, moving control point 2 and observing the relatively little change near endpoint 4.\n\n\n\n\n\n\n\nProvide link to bezier app\n\n\n\n\n\n\nFigure 48.14: A Bézier curve leaves each endpoint in a direction that is tangent to the line drawn between the endpoint and its control point.\n\n\n\n\nAlgebraically, each Bézier segement is a pair of cubic functions, \\(x(t)\\) for the x-coordinate and \\(y(t)\\) for the y-coordinate. The input \\(t\\) varies between 0 and 1 for each segment. The coordinate pair \\(\\left({\\large\\strut} x(0), y(0)\\right)\\) is one endpoint of the curve, while \\(\\left({\\large\\strut} x(1), y(1)\\right)\\). Each intermediate value of \\(t\\) corresponds to a point on the interior of the curve.\nThe \\(x(t)\\) and \\(y(t)\\) functions have the same form, the difference between the functions being only the values of the end values (\\(x_1\\) and \\(x_4\\) for the \\(x(t)\\) function, and similarly \\(y_1\\) and \\(y_4\\) for the \\(y(t)\\) function), as well as the control-point values (\\(x_2\\) and \\(x_3\\) for one function, \\(y_2\\) and \\(y_3\\) for the other.)\n\\[x(t) = (1-t)^3\\, x_1 + 3(1-t)^2 t\\, x_2 + 3(1-t) t^2\\, x_3 + t^3\\, x_4\\\\\\text{and}\\\\\ny(t) = (1-t)^3\\, y_1 + 3(1-t)^2 t\\, y_2 + 3(1-t) t^2\\, y_3 + t^3\\, y_4\\]\n\n\n\n\nBefore the advent of digital design and manufacturing, smooth curves were described by clay or wooden models hand-crafted by skilled workers. Material was removed to conform to the models by machine tools directed by cams running over the models, by hand sanding and polishing, as shown in this video of propeller manufacture during World War II.\n\n\n\n\n\nPROVIDE PDF VERSION OF VIDEO\n\nSpline functions and digital actuators have largely replaced such analog models."
  },
  {
    "objectID": "Manifestations/B4-splines.html#exercises",
    "href": "Manifestations/B4-splines.html#exercises",
    "title": "48  Data-driven functions",
    "section": "48.5 Exercises",
    "text": "48.5 Exercises"
  },
  {
    "objectID": "Manifestations/B4-optimization.html",
    "href": "Manifestations/B4-optimization.html",
    "title": "49  Optimization and constraint",
    "section": "",
    "text": "In Chapter Section 24 we introduced optimization and some of the terms used to describe optimization problems:\nA simple optimization problem has three main phases:\nTo illustrate, consider this simple but unrealistic problems found in hundreds of calculus texts: Finding the configuration to construct the rectangular box with the largest possible volume out of a piece of cardboard. The modeling phase starts with a representation of the box-construction and volume-finding process. Suppose, for the sake of simplicity, that we are working with a piece of cardboard fixed at 20 inches by 30 inches. For box construction, we’ll propose cutting out squares from each corner of the box of some side length \\(x\\). Those squares will be discarded and the box formed by folding up the flaps generated by the squares’ removal, as in Figure 49.1.\nFor the volume of the box, we’ll multiply the area of the bottom of the box by the height \\(x\\). Examination of Figure 49.1 should be enough to convince you that the volume \\(V\\) is a function of \\(x\\):\n\\[V(x) = \\underbrace{\\strut x}_\\text{height} \\cdot \\underbrace{(20-2x)}_\\text{width}\\cdot \\underbrace{(30-2x)}_\\text{length} =  x(600 - 100 x + 4 x^2)\\ .\\] Since the goal is to find the maximum possible volume, \\(V(x)\\) is our objective function.\nThe solution phase can be completed by drawing a graph of \\(V(x)\\) and finding the \\(x\\) corresponding to the peak value of \\(V(x)\\). We’ll leave this for you to do in a sandbox; you can figure out the relevant domain by noting that the corner squares cannot overlap. Calculus texts typically emphasize another approach, using symbolic differentiation to examine \\(\\partial_x V(x)\\) and solve for \\(x^\\star\\) such that \\(\\partial_x V(x^\\star) = 0\\). The derivative is \\[\\partial_x V(x) = 600 - 200 x + 12 x^2\\ .\\] The symbolic solution task is to find the zeros of \\(\\partial_x V(x)\\). They work out to be \\(x_1^\\star = 3.92\\) or \\(x_2^\\star = 12.74\\).\nThe third phase of an optimization problem, evaluation phase, can start with plugging in the objective function the values of \\(x^\\star\\).\n\\[V(x_1^\\star) = 1056.3\\ \\text{in}^3 \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ V(x_2^\\star) = -315.6\\ \\text{in}^3\\] It’s common sense that \\(x_2^\\star\\) is not a viable solution. The negative volume at \\(x_2^\\star\\) is a consequence of looking at \\(V(x)\\) beyond the sensible domain for cardboard boxes. More generally, as part of the evaluation phase we can look at the value of the convexity \\(\\partial_{xx} V(x^\\star)\\) to find out whether an \\(x^\\star\\) value is an argmax or an argmin. Since \\(\\partial_{xx} V(x) = 24 x - 200\\) we see that \\(\\partial_{xx} V(x_1^\\star) < 0\\), corresponding to an argmax. Alternatively, instead of computing the convexity, we could check whether we have an argmin or an argmax by evaluating the objective function at a nearby input.\nAdditional examination of the phase-two solution can give useful information, such as an indication of how sensitive the output is to small changes of the input near the argmax (or argmin). For example, setting \\(x=4\\) in will produce a volume output \\(V(4) = 1056\\) in2, hardly different than the “exact” maximum of 1056.3 in3 and perhaps preferred for the person who wants to make standard-size boxes.\nThe evaluation phase in a genuine application (as opposed to a textbook toy example) should also include a reflection on how well the model reflects the real-world situation. For example we’ve neglected the creases that arise from folding cardboard, so a more complete examination would estimate this effect. And the person skeptical about calculus-book chestnuts might wonder whether the object is really to create a box without a top!\nCommonly, optimization problems involve much more complicated objective functions with many inputs. The next section considers the basis for a more general and practical approach to the solving phase of optimization. Later sections examine how this more general approach leads to methods for approaching the sort of real-world optimization problem where there are multiple objectives."
  },
  {
    "objectID": "Manifestations/B4-optimization.html#gradient-descent",
    "href": "Manifestations/B4-optimization.html#gradient-descent",
    "title": "49  Optimization and constraint",
    "section": "49.1 Gradient descent",
    "text": "49.1 Gradient descent\nThe general approach we will take to the solving phase of optimization problems will be iterative as in Section 47. Start with an initial guess for an argmin and then construct a new function that can improve the guess. Applying this improvement function iteratively leads to better and better estimates of the true argmin.\nFor illustration purposes, we’ll use optimization problems where the objective function has two inputs. Such objective functions can be graphed on paper or a display screen and it’s possible to see the action of the iterative improvement process directly. For optimization in problem with many inputs, the improvement can be monitored from the objective function output at each step.\n\nSpring-mass systems: an example context\nAs our example context for discussing the optimization process, we’ll consider how to use optimization to calculate the configuration of simple mechanical systems consisting of interconnected springs and masses. Such configuration problems are especially important today in understanding the structure and function of proteins, but we will stick to the simpler context of springs and masses.\n\nFigure 49.2 shows a mechanical system consisting of a mass suspended from a fixed mounting by three nonlinear springs.\n\n\n\n\n\nFigure 49.2: A mass suspended from three springs.\n\n\n\n\nThe mass is shown by a black circles. Springs are the zig-zag shapes. The bold bar is the fixed mounting, as if from a beam on the ceiling of a room. The system has an equilibrium configuration where the springs are stressed sufficiently to balance each other left to right and to balance the gravitational force downward on the mass.\nWe want to calculate the equilibrium position. The basic strategy is to model the potential energy of the system, which consists of:\n\nthe gravitational potential energy of the mass.\nthe energy stored in stretched or compressed springs.\n\nSince the configuration of the system is set by the coordinate \\((x_1, y_1)\\), the potential energy is a function \\(E(x_1, y_1)\\). For brevity, we’ll leave out the physics of the formulation of the potential-energy function; shown in Figure 49.3.\n\n\n\n\n\nFigure 49.3: The potential energy of the spring-mass system in Figure 49.2.\n\n\n\n\nThe potential energy function \\(E(x,y)\\) has a bowl-like shape. The bottom of the bowl—the argmin—is near \\((x=1.7, y=-1.3)\\). In terms of Figure 49.2, the equilibrium position is a bit upward and to the right of the position shown in the figure.\nWith a graph of the objective function like Figure 49.3, the solution phase is simple; a graph will do the job. But for more complicated objective functions, with more than 2 inputs, drawing a complete graph is not feasible. For example, in the spring-mass system shown in Figure 49.4, the potential energy function has six inputs: \\(x_1, y_1, x_2, y_2, x_3, y_3\\). In genuine applications of optimization, there are often many more inputs.\n\n\n\n\n\nFigure 49.4: A more complicated spring-mass system.\n\n\n\n\nIn a multi-input optimization problem, we don’t have a picture of the whole objective function. Instead, we are able merely to evaluate the objective function for a single given input at a time. Typically, we have a computer function that implements the objective function and we’re free to evaluate it at whatever inputs we care to choose. It’s as if, instead of having the whole graph available, the graph is covered with an opaque sheet with a loophole, as in Figure 49.5.\n\n\n\n\n\nFigure 49.5: A more realistic view of what we can know about a function.\n\n\n\n\nWe can see the function only in a small region of the domain and need to use the information provided there to determine which way to move to find the argmin.\nThe situation is analogous to standing on the side of a smooth hill in a dense fog and finding your way to the bottom. The way forward is to figure out which direction is uphill, which you can do directly from your sense of balance by orienting your stance in different ways. Then, if your goal is the top of the hill (argmax) start walking uphill. If you seek a low point (argmin), walk downhill.\nThe mathematical equivalent to sensing which direction is uphill is to calculate the gradient of the objective function. In Chapter (sec?)–partial-change we used partial differentiation with respect to each of the input quantities to assemble the gradient vector, denoted \\(\\nabla f() = \\left({\\large \\strut} \\partial_x f(), \\ \\partial_y f()\\right)\\). In terms of Figure 49.5, where we are standing at about \\((x_i=0.8, y_i=-2.3)\\), we would evaluate the each of the partial derivatives in the gradient vector at \\((0.8, -2.3)\\).\nThe gradient points in the steepest direction uphill so, once you know the direction, take a step in that direction to head toward the argmax, or a step in the opposite direction if you seek the argmin. The process of following the gradient toward the top of the hill is called gradient ascent. Correspondingly, following the gradient downhill is gradient descent.\n\n\n\n\n\nFigure 49.6: The gradient provides information about the shape of the local function in a convenient form to guide the step to the next locale in your journey toward the argmin or argmax.\n\n\n\n\nFor humans, the length of a step is fixed by the length of our legs and the size of our feet. The mathematical step has no fixed size. Often, the modeler gains some appreciation for what constitutes a small step from the modeling process. Referring to Figure 49.4 for example you can see that a small increment in \\(x\\) is, say, \\(0.1\\), and similarly for \\(y\\). There is little point in taking an infinitesimal step—that gets you almost nowhere! Instead, be bold and take a finite step. Then, at your new location, calculate the gradient vector again. If it’s practically the same as at your earlier position, you can wager on taking a larger step next time. If the new gradient direction is substantially different, you would be well advised to take smaller steps.\nFortunately, a variety of effective ideas for determining step size have been implemented in software and packaged up as algorithms. The modeler need only provide the objective function in a suitable forma starting guess for the inputs.\n\nThe R/mosaic function argM() is set up to find argmins and argmaxes using the familiar tilde-formula/domain style of arguments used throughout this book. For instance, the potential energy of the spring-mass system shown in Figure 49.2 is available as Zcalc::SM_2_potential()\n\nargM(SM_2_potential(x, y) ~ x & y, domain(x=0:3, y=-3:0))\n## # A tibble: 1 × 3\n##       x     y .output.\n##   <dbl> <dbl>    <dbl>\n## 1  1.65 -1.21    -3.55\n\n\n\nTextbook formulas in physics, chemistry, engineering, and economics often have a root in an optimization problem. Since a formula is the desired result, symbolic differentiation is used in the solution phase. This allows parameters to be represented with symbols rather than as specific numbers. Usually the objective functions involved are simple. And in order to make the objective functions simple enough for symbolic work, it’s common to make approximations, for example by replacing functions like \\(\\sin(x)\\) with \\(x\\) and \\((1+p)^n\\) with \\(1+np\\). But simplifying the objective function should really be considered part of the solution phase rather than the modeling phase.\nNumerical techniques are the most widely used in practice. Optimization is an important operation in both science and management and much human ingenuity has gone into the development of effective algorithms. The modeler rarely if ever needs to reach beyond the software provided in technical computing environments such as R, MATLAB, Mathematica, or the many packages available for Python.\nIn data science and machine learning, often advanced solution-phase software is provided as web services and APIs (application programming interfaces). An example is the Google technology product TensorFlow used to find optimal parameters for functions in the machine technique called “deep learning.”\n\n\n\nThe potential energy function of the spring-mass system in Figure 49.4 is available as the R/mosaic function Zcalc::SM_3_potential(). This potential energy function has six inputs: the \\(x\\) and \\(y\\) coordinates of each of the three masses. The code below shows how to use the R/mosaic argM() function to locate an argmin of the potential energy.\n\nargM(SM_3_potential(\n  x1, y1, x2, y2, x3, y3) ~ x1 & y1 & x2 & y2 & x3 & y3, \n  domain(x1 = 0:3, y1=-3:0, x2=0:3, y2=-3:0, x3=0:3, y3=-3:0))\n## # A tibble: 1 × 7\n##      x1    y1    x2    y2    x3    y3 .output.\n##   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>\n## 1 0.800 -2.15  1.60 -3.05  2.40 -2.70    -8.86\n\nThe argM() function reports the final result, the end of the path followed in descending the gradient field. Figure 49.7 gives a movie of the path as it is being followed.\n\n\n\n\n\nFigure 49.7: The path to equilibrium for the 3-body spring-mass system shown in Figure 49.4. The top two frames show a 2-dimensional slice through the 6-dimensional gradient field. The bottom frame translates the current point on the path into a picture of the spring-mass locations.\n\n\n\n\nAt the start of the movie, the masses are (absurdly) misplaced and far from their equilibrium position. As system configuration moves downhill toward the argmin of the potential energy function, the masses sort themselves out.\nThe two gradient-field frames show a different two-dimensional slices of the potential energy function which has six inputs. Watch the gradient-fields carefully to see that the field itself is changing as time goes by. All six inputs are changing. At each point in time, we’re plotting the gradient field as a function of the two inputs shown on the axes. These stay the same through the whole movie, but the other four inputs are changing as the system moves along the gradient descent path. The last frame shows the gradient field at the final position in six-dimensional space. You can see that the early parts of the path are not aligned with the end-of-path gradient fields, but they were aligned at the earlier time when each point in the path was passed.\nThe familiar tilde-expression format used by argM() and the other R/mosaic functions is suitably compact for function of one or two arguments, but for functions with many inputs it becomes ungainly. For objective functions with many inputs, a different programming style is more appropriate that packages up the multiple inputs into a single, vector input. Since this is not a programming book, we won’t go into the vector-input programming style, but be aware that in professional-level work, learning new tools for programming becomes essential."
  },
  {
    "objectID": "Manifestations/B4-optimization.html#objectives-and-constraints",
    "href": "Manifestations/B4-optimization.html#objectives-and-constraints",
    "title": "49  Optimization and constraint",
    "section": "49.2 Objectives and Constraints",
    "text": "49.2 Objectives and Constraints\nMany real-world decision-making settings do not fit neatly into the framework of constructing an objective function and then finding the argmin (or argmax). A common situation is having multiple objectives. These objectives often compete and the output of the respective objective functions may not necessarily be directly comparable. For instance, in health care one objective is to save lives, while another is to minimize costs. But lives and money are not directly comparable.\nOften, the original problem statement does not include all of the objectives and the modeler needs to be perceptive to discern important objectives left out of the initial description of the problem. When such missing objectives become apparent, it’s necessary to visit the modeling phase of the problem to insert the new objectives. By adopting the right approach to modeling, such situations can be readily handled and, even better, the modeling phase can bring new insight into the real-world problem.\nTo illustrate, let’s returning to the mathematically simplified problem of constructing an optimal cardboard box. Before, we stipulated that the raw cardboard stock has dimension 20 inches by 30 inches. Now we’ll generalize and work with a piece of cardboard that has edges of length \\(y\\) from which, as before, we’ll cut out square corners of length \\(x\\) on a side. (See ?fig-box-shape). Our objective is to make a box with the largest possible volume. (This will be an argmax problem.)\n\n\n\n\n\nFigure 49.8: The cardboard cut lines and the eventual shape of the folded box.\n\n\n\n\n\n\n\nFigure 49.9: The cardboard cut lines and the eventual shape of the folded box.\n\n\n\n\nThe area of the bottom of the box is \\((y - 2x)^2\\) and the box height is \\(x\\). The objective function is the volume of the box, area times height: \\[V(x, y) \\equiv x (y - 2x)^2\\ .\\] There are two inputs, \\(x\\) and \\(y\\), so a simple plot should suffice to find the argmax.\n\n\n\n\n\nFigure 49.10: The volume of the box (in cubic inches) constructed by cutting corners of size \\(x\\)-by\\(x\\) out of a \\(y\\)-by-\\(y\\) piece of cardboard.\n\n\n\n\nScanning Figure 49.10 reveals a couple of things that you might not have anticipated. First, the argmax is in the extreme lower-right corner of the graphics frame, not in the center as in previous examples. Second, the argmax in this corner, \\((y=0, x=10)\\) is logically inconsistent with the idea of a cardboard box.\nThe inconsistency stems from an inadmissible value for \\(x\\). For \\(2x > y\\), the bottom of the box would have negative edge length. But because the objective function \\(V(x,y)\\) squares this negative quantity—in the \\((y - 2x)^2\\) term—the output of the objective function doesn’t signal that anything is wrong. The source of the problem is not the objective function formula itself, but neglecting to consider carefully what is the proper practical domain for the function.\nTo make the calculation realistic, we should search for the argmax only in that region of the graphics frame where \\(y > 2x\\). That restriction on the search domain is called a constraint. In this case, the constraint takes the form of an inequality \\(y > 2x\\) so we call it an inequality constraint. (Later, we’ll work with equality constraints.)\n\n\n\n\n\nFigure 49.11: The inequality constraint that \\(y > 2x\\) renders much of the graphics frame inadmissible as a possible solution. The inadmissible region is shaded in blue. The argmax must be sought in the unshaded region of the frame.\n\n\n\n\nWith the \\((x,y)\\)-domain restricted to the values that are physically realistic, we can see that the argmax is still on the edge of the frame, at \\(y=30\\) and \\(x\\approx 5\\), where the volume of the box will be about 1800 in3. This result should cause you pause, since there was nothing in the problem statement that limited \\(y\\) to be 30” or less. If we replotted with a larger domain for \\(y\\), we should see still larger boxes, without any limit.\nThe interpretation of the problem as originally posed is: With enough cardboard we can make a box of any size! Since the goal was to recommend the “best” size, this conclusion is not so useful. The weak conclusion stems from a fault in the problem statement. The statement omitted an important second objective function: use as little cardboard as possible.\nIf using as little cardboard as possible were our sole objective, the optimization problem has an easy-to-find solution: we would make a zero-volume box out of zero-area of cardboard. What we want, somehow, is to make as big a box as possible out of as little cardboard as possible: we have two objectives! In this case, the objectives are in conflict: making a bigger box (good) uses more cardboard (bad).\nCommon sense tells us to balance the two objectives, but how to represent this mathematically? Ideally—note that “ideally” is sometimes far from “realistically” or “productively”—we would know how much box-volume is worth to us and how much cardboard costs, and we could construct an objective function that incorporates both value and cost. For instance, if each cubic inch of volume is worth 1 cent, and each square inch of cardboard costs 3 cents, then the objective function will be the following (with output in cents):\n\\[\\text{Profit}(x,y) \\equiv 1\\, x (y-2x)^2 - 3 y^2\\] ::: {.cell layout-align=“center” fig.showtext=‘false’} ::: {.cell-output-display}  ::: :::\nEven with including the cardboard cost in the objective function, we’ll still want to make \\(y\\) as large as possible. Not much guidance there!\nBut let’s imagine a new factor coming into play. At the meeting where the box-design decisions are being made and where you are presenting your analysis in ?fig-total-cost, the graphic designer speaks up. “The trending shape for this year is cubic. We want the box, whatever it’s size, to be a cube.”\nLuckily, you the modeler can quickly incorporate this into your analysis. To be a cube, the height \\(x\\) of the box has to be the same as the width and depth \\(y - 2x\\). So you can incorporate the designer’s wish into the model of the decision factors by adding a new constraint:\n\\[x = y - 2x \\ \\ \\ \\implies y-3x=0\\ \\ \\ \\ \\text{constraint: box must be cubic}\\] This is called an equality constraint. Figure 49.12 shows the equality constraint in green: to be a cube, \\(x\\) and \\(y\\) must be somewhere along the green line.\n\n\n\n\n\nFigure 49.12: The profit function shown in more detail along with the equality constraint (green) for the box to be cube-shaped.\n\n\n\n\nFollow the green path uphill. As \\(x\\) gets larger along the constraint, the output of the objective function grows, reaching a level of 1350 cents when \\((x=15, y=45)\\) at the right border of the graphics frame.\nIt’s worth pointing out, for later use, that the be-a-cube constraint is almost parallel to the objective function contours.\n\nMany organizations use a budget mechanism to manage their affairs. The organization defines divisions or projects, and each of these is given a dollar budget to stay within. The individual division or project manager can arrange things more or less as she thinks best, so long as she stays within the budget. This is a kind of constraint: a budget constraint.\nSuppose you have been tasked to set up a new factory and given a budget of $5,500,000 to do so. You were given this task because you have a particular expertise in how best to set up the factory, but your design will of course depend on the relative prices of the different inputs to the production process.\nFor simplicity, let’s imagine that there are two main inputs: labor \\(L\\) and capital/equipment \\(K\\). It would be silly to spend all the budget on labor and none on capital; the workers would have no tools to work with. Similarly, capital without labor has no productive value. The best design for the factory will be a mix of labor and capital.\nSince the purpose of the factory is to make things for sale, a good objective function will be the sales value of the output produced by the factory. Economists have a favored form for production functions of this sort, a power-law called the Cobb-Douglas function. The essential insight behind the Cobb-Douglas function is that doubling both capital and labor (as if you built a second factory alongside the first) should double production. The Cobb-Douglas form for production as a function of capital and labor is \\[Q(L, K) = p b L^a K^{1-a}\\ .\\] You will use your expertise to set the values of the \\(a\\) and \\(b\\) parameters. The price \\(p\\) of each unit of output will be set by the market: Let’s assume for planning purposes that it’s \\(p - \\$450\\) per unit. Suppose you have determined that \\(a=0.3\\) and \\(b=40\\) are appropriate. This production function is shown in Figure 49.13.\n\n\n\n\n\nFigure 49.13: A Cobb-Douglas production function with \\(p=100\\), \\(b=40\\) and \\(a=0.3\\). (Output units in millions of dollars).\n\n\n\n\nAs you can see from Figure 49.13, the more labor and the more capital you use, the higher the production. Notice that the production function itself does not have an argmax interior to the domain being plotted. It’s one of those “more is better” situations.\nSuppose that labor costs $6000 per person-month. Capital, in units of production stations, costs $13,000 per unit. Your budget constraint reflects the total cost of capital and labor: \\(6000 \\cdot L + 15000 \\cdot K \\leq 5500000\\). This constraint is graphed in Figure 49.14.\n\n\n\n\n\nFigure 49.14: The production function with the budget constraint shown in green.\n\n\n\n\nAny mixture of labor and capital that falls outside the green zone stays within your budget. What’s the best mixture? The one that gives the largest production. You can read this off the graph, \\(L\\approx 650\\) person-months and \\(K\\approx 125\\) workstations which gives slightly more than $7 million dollars in production.\nThe argmax is right on the frontier of the constraint region. Put into more operational terms: You will want to spend your entire budget to maximize production. This is hardly a surprise to anyone who has to work within a budget. Knowing that you’re going to use the whole budget, you might as well have found the argmax by walking along the constraint frontier from left to right. As you start near \\(K=250\\) and \\(L=380\\), the path you walk goes uphill in terms of the production function. The path continues uphill until you reach the argmax. Near the argmax, the path is level. After the path crosses the argmax, it is leading downhill. At the argmax, the production function contours are parallel to the constraint boundary.\nYou might like to think of this in terms of bicycling along a path in hilly terrain. When you reach the local high point on the path, you may not be at the top of the hill. But you will be on a flat spot on the path, meaning that the path is parallel to the contour of the hill at that point."
  },
  {
    "objectID": "Manifestations/B4-optimization.html#constraint-cost",
    "href": "Manifestations/B4-optimization.html#constraint-cost",
    "title": "49  Optimization and constraint",
    "section": "49.3 Constraint cost",
    "text": "49.3 Constraint cost\nOptimization techniques have an important role to play as aids to human decision making. Let’s see how the mathematical representation of a constraint as a function can facilitate the human decision-making process.\nIn the previous section, the box designer’s request that the box be cubic was translated into an equality constraint, \\(y-3x=0\\), shown as the green line in Figure 49.12. The skilled modeler can bring additional power to the analysis by translating that constraint, \\(y-3x=0\\) into a function, for example \\[\\text{Equation:}\\ \\  \\ y - 3x = 0\\ \\ \\longrightarrow\\ \\ \\ \\text{Function:}\\ \\ \\text{cube-box}(x, y) = y / 3x\\ .\\] Any \\((x^+, y^+)\\) that produces \\(\\text{cube-box}(x^+, y^+) = 1\\) is a pair that satisfies the constraint. In other words, the equality constraint amounts the 1-contour of the cube_box() function.\nTranslating the constraint into a function provides the opportunity to reframe the situation from the mandate, “the box must be a cube,” into a question, “How cubic-like is the box?” If the value of \\(\\text{cube-box}(x,y) > 1\\), the box is flatter than a cube; something in the direction of a pizza box. If \\(\\text{cube-box}(x,y) < 1\\) the box is taller than a cube, as if flowers were being shipped in it.}\nThe constraint-to-function translated situation is shown in Figure 49.15:\n\n\n\n\n\nFigure 49.15: Zooming in on the objective function Profit() and showing the function version of the constraint, cube_box() with green contours, with the heavy green line being the contour at cube_box(x,y)=1.\n\n\n\n\nEarlier, we saw that if restricted to inputs on the contour \\(\\text{cube-box}(x,y) = 1\\), the optimal output value of Profit() is about $13.50. Now we have a broader picture. For instance, suppose we allow a “little” deviation in box shape from a cube, say, cube_box(x,y) = 1.05. If we allowed this, the value of the Profit() function could be increased from $13.50 to about $22.50 .\nWhether the $9 increase in value justifies the deviation from a cube by 5% is a matter of judgement. We don’t have an immediate way to translate the output of cube_box() into the same units as the output of profit(). The two different units are said to be incommensurate, meaning that they can’t be directly compared. Nonetheless, we now have a basis for a conversation. It might go like this:\nModeler to Designer: I realize that from your perspective, a cube is the optimal shape for the box.\nDesigner: Right. Cubes are in fashion this year. Last year it was the Golden Ratio.\nModeler: It might sound surprising, but we find that so long as you are close to the optimal, it doesn’t much matter if you are exactly on it. How close to a perfect cube would be good enough?\nDesigner: What’s really important is that the box be perceived as a cube in our sales material. I think that most customers would think “cube” so long as the edge lengths are within about 15% of one another.\nModeler: That’s very helpful. Let’s see if I can translate that into the cube_box() function.\n[Modeler does some scribbling while mumbling to himself. “\\(y-2x\\) is the base width and depth of the box, and \\(x\\) is the height of the box. So if \\(y-2x = 1.15 x\\) then \\(y = 3.15 x\\). \\(\\text{cube-box}(x, 3.15 x) = 1.05\\).]\nModeler: [to Designer] *The 15% deviation corresponds to an output of 1.05 from \\(\\text{cube-box}()\\).\nModeler: [To product manager] *Making that change in shape increases profit per box from $13.50 to $22.50 .\nProduct manager: Good job! How about a 30% deviation? That let’s us get up to about $33 in profit.\nDesigner: But it would make the box shaped like a brick! Bricks are so 1990s!\nModeler: It sounds like a 15% deviation would be about right.\nMaking the constraint negotiable by representing it with a function, broadens the scope of the discussion and points to new ways of improving the result.\n\nLet’s return to a previous example about determining optimal levels of labor and capital in a factory. In that example, the objective function was the money value of the product produced. There was also a budget constraint. Translating the budget constraint into a function, which we’ll call expenditure(K, L), we have \\(\\text{expenditure}(K, L) = 4000 L + 15000 K\\). Our budget amounts to enforcing \\(\\text{expenditure}(K, L) = \\$5,500,000\\).\nA manager presented with a budget knows that she should work within the constraints of that budget. Mathematically, however, it’s easy to imagine the budget being changed, either relaxed or tightened. This mathematical possibility provides the means to extract new information that can be helpful in making decisions at a higher level, that is, above the rank of the manager. This can be helpful to higher management—the people who are responsible for seeing the bigger picture.\nFigure 49.16 show the production function plotted along with the expenditure function. The budget constraint corresponds to a single output level of the expenditure function, that is, a single contour of the expenditure function. Other contours correspond to different values for the budget constraints. Such a graph makes it easy to calculate the consequences for relaxing (or tightening) the constraint.\n\n\n\n\n\nFigure 49.16: The production function (black, curved lines) and the expenditure function (magenta, straight lines). Contour labels are in millions of dollars. We’ve drawn contours at levels that happen to be tangent to the expenditure contours.\n\n\n\n\nWith the budget fixed at $5.5 million—that is, on the $5.5-million contour of the expenditure function—the maximum production was $7.1 million.\nWhat happens if we pretend that the budget level was different? Doing so is a matter of looking at a different contour of the expenditure function. For example, if the budget had been smaller, say only $5 million, then production also goes down, to $6.5 million. On the other hand, if we had the means to increase the budget to $6 million, production would go up to $7.7 million.\nIn this example we see that an increase in budget of $500K produces an increase in production worth $600K. It might seem logical that it’s worth raising the budget to harvest the extra production, but that is not necessarily the case. To see why, recall that we use constraints such as the budget constraint in this problem to represent a real-world situation where there are multiple objectives, not just the particular objective represented by the objective function. There is a budget in the first place because there are other, competing uses for the money. For instance, the money might be better spent in some other product line that is even more profitable. Or perhaps higher management, taking a long-term strategic view, would prefer to spend the funds on research and development.\nThe point of exploring theoretical changes in the budget is to provide information to the higher-level decision makers, the people who set the budget as opposed to the managers who have to work within the budget. The format that most non-technical people would find accessible is simple: a $500K increase in the budget will result in $600K greater production.\nIn mathematical presentations, this same information is often formatted differently, as a ratio called the Lagrange multiplier. The Lagrange multiplier in this example would be 600/500, that is, 1.2. There is no intrinsic advantage of the Lagrange multiplier format over the common sense format, but the Lagrange multiplier is the format used in many textbooks, so it’s worthwhile to know the nomenclature. Some economists have a more evocative name for the ratio: the shadow price of the constraint. Thus, the theoretical exploration of relaxing the constraint provides a straightforward way to put a cost on the constraint. This gives a reasonable way to determine the value of something when there is no direct market for it.\nAn important example of a shadow price comes in the setting of life-saving interventions. For example, increasing spending on highway safety can save lives. If $7.5 billion in increased expenditures saves 1000 lives, the shadow price is $7.5 M per life. People who misinterpret the constraint-to-function methodology often think that it’s about cravenly putting a money value on life. In reality, the method merely reveals the money value on life implicit in decisions such as budget allocations. Knowing that the shadow price is $7.5 M does not say what the value of life should be. But it provides a mechanism for comparing different uses for the money. For instance, if the shadow price for increased regulation of toxic industrial chemicals is $11.3 M per life, the relative shadow prices provide an indication that budget money might reasonably be shifted from chemical regulation to highway safety. Economists and epidemiologists who undertake such calculations reveal that the mixture of spending on different life-preserving interventions is far from optimal.\n\n\nGenerations of calculus students have been taught a method of mathematical optimization in the presence of constraints that involves positing a Lagrange multiplier, typically written as \\(\\lambda\\), and carrying out a series of differentiations followed by equation solving to find an argmax, which simultaneously provides a numerical value for \\(\\lambda\\). It’s easier to understand the motivation behind this by considering the gradient of the objective function and the gradient of the constraint function. If the goal is, say, to maximize production and simultaneously minimize expenditures, we would want to walk up the production gradient and down the expenditure gradient.\nFigure 49.17 shows two gradient fields, one for the production function in the factory-design example and one for expenditure. (The negative of the expenditure gradient is shown, since the goal is to keep expenditures small.)\n\n## Warning in makeFun.formula(P(L, K, a, p, b) ~ L, a = 0.3, p = 450, b = 40, :\n## Implicit variables without default values (dangerous!): K\n## Warning in makeFun.formula(P(L, K, a, p, b) ~ K, a = 0.3, p = 450, b = 40, :\n## Implicit variables without default values (dangerous!): L\n## Warning in makeFun.formula(-(6000 * L + 13000 * K) ~ L, suppress.warnings =\n## FALSE): Implicit variables without default values (dangerous!): K\n## Warning in makeFun.formula(-(6000 * L + 13000 * K) ~ K, suppress.warnings =\n## FALSE): Implicit variables without default values (dangerous!): L\n\n\n\n\nFigure 49.17: The production and expenditure functions displayed as gradient fields. Expenditure is brown, production is magenta.\n\n\n\n\nAt each point in the graphics frame, the two gradient vectors form an angle. For example, near the point labeled (a) the angle is roughly 140 degrees, while near (b) the angle is 180 degrees.\nAny value of \\(K\\) and \\(L\\) where the angle is less than 180 degrees is sub-optimal or dominated by some other choice of \\(K\\) and \\(L\\). For instance, near label (a), you could improve both production and expenditures by moving to the southeast. When the angle is 180 degrees, the objective and constraint functions are in complete opposition to one another; any movement in favor of one comes at the cost in the other."
  },
  {
    "objectID": "Manifestations/B4-optimization.html#note-other-optimization-algorithms",
    "href": "Manifestations/B4-optimization.html#note-other-optimization-algorithms",
    "title": "49  Optimization and constraint",
    "section": "49.4 Note: Other optimization algorithms",
    "text": "49.4 Note: Other optimization algorithms\nContemporary work often involves problems with tens, hundreds, thousands, or even millions of inputs. Even in such large problems, the mechanics of finding the corresponding gradient vector are straightforward. Searching through a high-dimensional space, however, is not generally a task that can be accomplished using calculus tools. Instead, starting in the 1940s, great creativity has been applied to develop algorithms with names like linear programming, quadratic programming, dynamic programming, etc. many of which are based on ideas from linear algebra such as the qr.solve() algorithm that you’ll meet in Block 5, or ideas from statistics and statistical physics that incorporate randomness as an essential component. An entire field, operations research, focuses on setting up and solving such problems. Building appropriate algorithms requires deep understanding of several areas of mathematics. But using the methods is mainly a matter of knowing how to set up the problem and communicate the objective function, constraints, etc. to a computer.\nPurely as an example, let’s examine the operation of an early algorithmic optimization method: Nelder-Mead, dating from the mid-1960s. (There are better, faster methods now, but they are harder to understand.)\nNelder-Mead is designed to search for maxima of objective functions with \\(n\\) inputs. The video shows an example with \\(n=2\\) in the domain of a contour plot of the objective function. Of course, you can simply scan the contour plot by eye to find the maxima and minima. The point here is to demonstrate the Nelder-Mead algorithm.\nStart by selecting \\(n+1\\) points on the domain that are not colinear. When \\(n=2\\), the \\(2+1\\) points are the vertices of a triangle. The set of points defines a simplex, which you can think of as a region of the domain that can be fenced off by connecting the vertices.\nEvaluate the objective function at the vertices of the simplex. One of the vertices will have the lowest score for the output of the objective. From that vertex, project a line through the midpoint of the fence segment defined by the other \\(n\\) vertices. In the video, this is drawn using dashes. Then try a handful of points along that line, indicated by the colored dots in the video. One of these will have a higher score for the objective function than the vertex used to define the line. Replace that vertex with the new, higher-scoring point. Now you have another simplex and can repeat the process. The actual algorithm has additional rules to handle special cases, but the gist of the algorithm is simple."
  },
  {
    "objectID": "Manifestations/B4-optimization.html#exercises",
    "href": "Manifestations/B4-optimization.html#exercises",
    "title": "49  Optimization and constraint",
    "section": "49.5 Exercises",
    "text": "49.5 Exercises"
  },
  {
    "objectID": "Manifestations/B4-probability.html",
    "href": "Manifestations/B4-probability.html",
    "title": "50  Probability and evidence",
    "section": "",
    "text": "We often deal with situations of uncertainty, situations where only partial predictions are possible. For instance, we can say whether a person may be at high risk for a disease, say, diabetes or lung cancer. But this doesn’t let us predict with certainty whether the person will get the disease. Instead, the term “high risk” indicates that we know something but not everything about the situation: not whether or not the person will get the disease but whether they are “likely” to have or to get it. Another example: a car might be said to be “unreliable.” We do not mean by this that the car cannot be used. Rather we’re thinking that from time to time the car might fail to start or run. A car where this happens once over a few year span is reliable, a car where this happens on a month-to-month basis is not reliable.\nYou may well have had some textbook exposure to probability as an intellectual field. Typical examples used to illustrate concepts and methods are coins being flipped, dice being tossed, and spinners spun. Colored balls are drawn from urns, slips of paper from hats, and so on. Each of these is a physical representation of an idealized mechanism where we feel sure we understand how likely each possible outcome is to happen.\nIn this chapter, we’ll use two basic imagined settings where uncertainty comes into play: the risk of disease before the disease is diagnosed and the safety of a self-driving car as it comes out of the factory. The word “imagined” signals that you should not draw conclusions about the facts of any particular disease or any particular self-driving car; we are merely using the imagined settings to lay out concepts and methods for the mathematical presentation and analysis of uncertainty and risk. Of particular importance will be the mathematical means by which we represent our knowledge or belief in these settings and the way we can properly update our knowledge/belief as new information becomes available."
  },
  {
    "objectID": "Manifestations/B4-probability.html#probability-density",
    "href": "Manifestations/B4-probability.html#probability-density",
    "title": "50  Probability and evidence",
    "section": "50.1 Probability density",
    "text": "50.1 Probability density\nA probability, as you may know, is a dimensionless number between zero and one (inclusive). In this chapter, you’ll be dealing with functions relating to probabilities. The input to these functions will usually be a quantity that can have dimension, for instance, miles driven by a car. For some of the functions we will see in this chapter, the output will be a probability. For other functions in this chapter, the output will be a probability density.\nProbability relates to the abstract notion of an event. An event is a process that produces an outcome. For instance:\n\nFlipping a coin is an event where the possible outcomes of H and T.\nTaking a medical screening test is an event where the outcomes are “positive” or “negative.”\nThrowing a dart at a bullseye is an event where the outcome is the distance of the impact point from the center of the bullseye.\n\nAn event with a discrete outcome—coin flip, medical screening test—can be modeled by assigning a probability number to each of the possible outcomes. To be a valid probability model, each of those assigned numbers should be greater than or equal to zero. In addition, the sum of the assigned numbers across all the possible outcomes should be 1.\nFor events with a continuous outcome, such as the dart toss where the outcome is distance from the center, the probability model takes the form of a function whose domain is the possible outcomes. For the model to be a valid probability model, we require that the function output should never be less than zero. There’s another requirement as well: the integral of the function over the entire domain should be 1. For the dart-toss event, if we denote the distance from the bullseye as \\(r\\) and the assigned number for the probability model as \\(g(r)\\), the integral requirement amounts to \\[\\int_0^\\infty g(r) dr = 1\\ .\\]\nNote that the output \\(g(r)\\) is not a probability, it is a probability density. To see why, let’s use the fundamental theorem of calculus to break up the integral into three segments:\n\nclose to the bullseye: \\(0 \\leq r \\leq a\\)\nfar from the bullseye: \\(b < r\\)\nnot close but not far: \\(a < r \\leq b\\)\n\nThe total integral is \\[\\int_0^\\infty g(r) dr = 1\\ = \\int_0^a g(r) dr + \\int_a^b g(r) dr + \\int_b^\\infty g(r) dr.\\] The probability that the dart lands at a distance somewhere between \\(a\\) and \\(b\\) is \\[\\int_a^b g(r) dr\\ .\\] Since \\(r\\) is a distance, the dimension \\([r] =\\ \\)L. Suppose the units of \\(r\\) are centimeters. We need \\(\\int g(r) dr\\) to be a dimensionless number. Since the dimension of the integral is \\([r] \\cdot [g(r)] = [1]\\), it must be that \\([g(r)] = [1/r] = \\text{L}^{-1}\\). Thus, \\(g(r)\\) is not a probability simply because it is not dimensionless. Instead, in the dart example, it is a “probability-per-centimeter.” This kind of quantity—probability per something—is called a probability density and \\(g(r)\\) itself is a probability density function.\nTo show the aptness of the word “density,” let’s switch to a graphic of a function that uses literal density of ink as the indicator of the function value. ?fig-dart-g) shows what the dart toss’s \\(g(r)\\) probability density function might look like: ::: {.cell layout-align=“center” fig.showtext=‘false’} ::: {.cell-output-display}  ::: :::\n\nConsider a simple competition of the sort you might encounter at a fund-raising fair. There is a jar on display, filled with coins that have been donated by one of the fair’s sponsors. You pay $1 (which goes to a good cause) to enter the contest. Your play is to describe how much money is in the jar, writing your description down along with your name on an entry form. At the end of the day, an official will open the jar, count the money, and announce who made the best estimate. The winner gets the money in the jar.\n\n\n\n\n\n\n\n\n\nIn the usual way these contests are run, the contestants each write down a guess for the amount they think is in the jar, say $18.63. The winner is determined by seeing whose guess was closest to the actual value of the coins in the jar.\nIn reality, hardly anyone believes they can estimate the amount in the jar to the nearest penny. The person guessing $18.63 might prefer to be able to say, “between 18 and 19 dollars.” Or, maybe “$18 \\(\\pm\\) 3.” To communicate what you know about the situation, it’s best to express a range of possibilities that you think likely.\nIn our more mathematical contest, we ask the participants to specify a function that describes their beliefs about the money in the jar. The instructions state, “On the graph-paper axes below, sketch a continuous function expressing your best belief about how much money is in the jar. The only requirement is that the function value must be zero or greater for all inputs.”\n\n\n\n\n\n\nFigure 50.1: The entry form for the money-in-the-jar contest.\n\n\n\nTake a minute to look at the picture of the jar and draw your function on the axes shown above. Think about why the contest form appropriately doesn’t ask you to scale the vertical axis.\nHere are contest entries from three competitors.\n\n## Scale for 'y' is already present. Adding another scale for 'y', which will\n## replace the existing scale.\n\n\n\n\nFigure 50.2: Three contestants’ contest entries.\n\n\n\n\n\nThe functions called for by the contest instructions are relative density functions. The “relative” means that the function clearly indicates where the probability is more or less dense, but the function has not yet been scaled to be a probability density function. Suppose \\(h(x)\\) is a relative density function such that \\[\\int_{-\\infty}^\\infty h(x)\\, dx = A \\neq 1\\ .\\] Although \\(h(x)\\) is not a probability density function, the very closely related function \\(\\frac{1}{A} h(x)\\) will be a probability density function. We’ll use the term normalizing to refer to the simple process of turning a relative density function into a probability density function.\nA relative density function is entirely adequate for describing the distribution of probability. However, when comparing two or more probability distributions, it’s important that they all be on the same scale. Normalizing the relative density functions to probability density functions accomplishes this. Figure 50.3 compares the three relative probability functions in Figure 50.2. Johnny makes the density large over a narrow domain and zero elsewhere, while Louisa specifies a small density over a large domain. All three competitors’ functions have an area-under-the-curve of dimensionless 1.\n\n\n\n\n\nFigure 50.3: Comparing the contest entries by normalizing each of them to a probability density function."
  },
  {
    "objectID": "Manifestations/B4-probability.html#three-density-functions",
    "href": "Manifestations/B4-probability.html#three-density-functions",
    "title": "50  Probability and evidence",
    "section": "50.2 Three density functions",
    "text": "50.2 Three density functions\nThree commonly used families of probability density functions are:\n\nthe gaussian density function\nthe exponential density function\nthe uniform density function.\n\n?fig-three-density-funs shows their shapes.\n\n\n\n\n\nFigure 50.4: Three probability density functions that are often used in applied work.\n\n\n\n\n\n\n\nFigure 50.5: Three probability density functions that are often used in applied work.\n\n\n\n\n\n\n\nFigure 50.6: Three probability density functions that are often used in applied work.\n\n\n\n\nThe uniform density function, \\(u(x, a, b)\\) is more or less the equivalent of the constant function. The family has two parameters \\(a\\) and \\(b\\) with the function defined as: \\[\\text{unif}(x, a, b) \\equiv \\left\\{\\begin{array}{cl}\\frac{1}{b-a} & \\text{for}\\ a \\leq x \\leq b\\\\0& \\text{otherwise} \\end{array}\\right.\\] This function is used to express the idea of “equally likely to be any value in the range \\([a, b]\\).” For instance, to describe a probability that a January event is equally likely to occur at any point in the month, you can use \\(u(x, 0, 31)\\) where \\(x\\) and the parameters \\(a\\) and \\(b\\) have dimension T and are in units of days. Notice that the density itself has dimension T-1 and units “per day.”\nThe gaussian density function, \\(\\dnorm(x, \\text{mean}, \\text{sd})\\) is familiar to you from previous blocks in this book: the bell-shaped function. It’s known also as the normal distribution because it is so frequently encountered in practice. It is a way of expressing, “The outcome of the event will likely be close to this particular value.” The parameter named mean specifies “this particular value.” The parameter sd specifies what’s mean by “close.” The gaussian density function is smooth. It is never zero, but \\(\\lim_{x \\rightarrow \\pm \\infty} \\dnorm(x, \\text{mean}, \\text{sd}) = 0\\).\nTo use an analogy between physical density (e.g., kg per cubic-meter), where density times size gives mass, we can say that the total mass of a probability density function is always 1. For the gaussian density, 68% of of the total mass is within \\(\\pm 1\\)sd of the mean, 95% is within \\(\\pm 2\\)sd of the mean, 99.7% within \\(\\pm 3\\)sd, and 99.99% within \\(\\pm 4\\)sd.\nThe exponential probability density is shaped just like an exponential function \\(e^{-kx}\\). It’s used to describe events that are equally likely to happen in any interval of the input quantity, and describes the relative probability that the first event to occur will be at \\(x\\)."
  },
  {
    "objectID": "Manifestations/B4-probability.html#sec-expected_value",
    "href": "Manifestations/B4-probability.html#sec-expected_value",
    "title": "50  Probability and evidence",
    "section": "50.3 Expectation value, mean and variance",
    "text": "50.3 Expectation value, mean and variance\nProbability theory was originally motivated by problems in gambling, specifically, figuring out what casino games are worth betting on. A feature of casino games—roulette, slot machines, blackjack, Texas hold’em, etc.—is that they are played over and over again. In any one round of play, you might win or you might lose, that is, your “earnings” might be positive or they might be negative. Over many plays, however, the wins and loses tend to cancel out. One way to summarize the game itself, as opposed to the outcome of any single play, is by the average earnings per play. This is called the expected value of the game.\nThis logic is often applied to summarizing a probability density function. If \\(x\\) is the outcome of the random event described by a probability density \\(f(x)\\), the expected value of the probability density is defined as \\[\\mathbb{E}\\!\\left[{\\strut} x\\right] \\equiv \\int_{-\\infty}^\\infty x\\, f(x) \\, dx\\ .\\] In Section 52.4, we’ll see this same form of integral for computing the center of mass of an object.\n\nWhy are you using square braces \\(\\left[\\strut\\ \\ \\right]\\) rather than parentheses \\(\\left(\\strut \\ \\  \\right)\\).\nWe always used parentheses to indicate that the enclosed quantity is the input to a function. But \\(\\mathbb{E}\\!\\left[{\\strut} x\\right]\\) is not a function, let alone a function of \\(x\\). Instead, \\(\\mathbb{E}\\!\\left[{\\strut} x\\right]\\) is a numerical summary of a probability density function \\(f(x)\\).\n\n\nFind the expected value of the gaussian probability density \\(\\dnorm(x, \\text{mean}=6.3, \\text{sd}= 17.5)\\). Using the R/mosaic Integrate() function, we have ::: {.cell layout-align=“center” fig.showtext=‘false’}\nIntegrate(x * dnorm(x, 6.3, 17.5) ~ x, domain(x=-Inf:Inf))\n## [1] 6.3\n\nThe expected value of a gaussian is the same as the parameter called mean which describes the argmax of the gaussian. :::\nAnother important quantity to describe data or probability distributions is the variance, which is the average of the square distance from the mean. In math notation, this looks like \\[\\mathbb{E}\\!\\left[{\\large\\strut} (x - \\mathbb{E}[x])^2\\right] = \\int_{-\\infty}^{\\infty} \\left(\\strut x - \\text{mean}\\right)^2\\, \\dnorm(x, \\text{mean}, \\text{sd})\\, dx\\ .\\]\n\nCompute the variance of a gaussian probability density \\(\\dnorm(x, \\text{mean}=6.3, \\text{sd}= 17.5)\\).\nTo do this, we must first know the mean, then we can carry out the integration. ::: {.cell layout-align=“center” fig.showtext=‘false’}\nIntegrate((x-6.3)^2 * dnorm(x, mean=6.3, sd=17.5) ~ x, domain(x=-Inf:Inf))\n## [1] 306.25\n\nAgain, you might have anticipated this result, since the variance is the square of the standard deviation (sd) and we were using a particular gaussian distribution with sd equaling 17.5. Of course, \\(17.5^2 = 306.25\\). :::\nTo illustrate the calculations in another setting, we will use an exponential probability function. Just as the R function dnorm() gives the density of the “normal”/gaussian distribution, the R function dexp() outputs the density of the exponential distribution. We used \\(k\\) as the parameter in the exponential distribution. In R, the parameter is framed in terms of the rate at which events happen, that is, the expected number of events per unit time. For instance, the following integrals compute the mean and standard deviation of an exponential process where events happen on average twice per time unit.\n\nIntegrate(x * dexp(x, rate=2) ~ x, domain(x=0:Inf))\n## [1] 0.5\n\nThe result shouldn’t surprise you. If events are occurring on average twice per unit time, the average time between events should be 0.5 time units.\nHere’s the variance of the same distribution ::: {.cell layout-align=“center” fig.showtext=‘false’}\nIntegrate((x-0.5)^2 * dexp(x, rate=2) ~ x, domain(x=0:Inf))\n## [1] 0.25\n::: It works out that for an exponential distribution with parameter \\(k\\), the mean is \\(1/k\\) and the standard deviation (square root of the variance) is also \\(1/k\\).\nFinally, let’s look at the mean and variance of a uniform distribution with, say, \\(a=0\\) and \\(b=10\\). We can do this symbolically or numerically. For the mean: \\[\\int_{-\\infty}^\\infty x\\  \\text{unif}(x, 0, 10)\\, dx = \\int_0^{10} \\frac{x}{10-0}\\, dx = \\left.{\\Large\\strut} \\frac{x^2}{20}\\right|_{x=0}^{10} \\\\= \\frac{100}{20} - \\frac{0}{20} = 5\\] For the variance, \\[\\int_{-\\infty}^\\infty (x-5)^2\\  \\text{unif}(x, 0, 10)\\, dx  \n= \\int_0^{10} \\frac{(x-5)^2}{10-0}\\, dx =\n\\left.{\\Large\\strut}\\frac{(x-5)^3}{30}\\right|_{x=0}^{10}\\\\\n=\\frac{5^3}{30} - \\frac{(-5)^3}{30} = \\frac{125}{30} - \\frac{-125}{30} = 8 \\tiny{\\frac{1}{3}}\\]\nOr, numerically1\n\nIntegrate(x * dunif(x, 0, 10) ~ x, domain(x=0:Inf))\n## [1] 5.000001\nIntegrate((x-5)^2 * dunif(x, 0, 10) ~ x, domain(x=0:Inf))\n## [1] 8.333336"
  },
  {
    "objectID": "Manifestations/B4-probability.html#likelihood-and-data",
    "href": "Manifestations/B4-probability.html#likelihood-and-data",
    "title": "50  Probability and evidence",
    "section": "50.4 Likelihood and data",
    "text": "50.4 Likelihood and data\nIn this section, we’ll examine the accepted technique for combining data with probability density functions in order to combine previous knowledge with new observations. The technique, called Bayesian inference, is used throughout science and engineering.\nRecall that a relative density function is a format to describe the relatively likeliness of possible outcomes from a random event. The domain for a relative density function is the complete set of possible outcomes from the event. An example: The distance of a dart’s impact from the bullseye.\nThe output of a relative density function is a non-negative number. For an expert dart thrower, the relative density will be high for small distances and low for large distances. This is just a way of quantifying that the expert’s is likely to hit close to the bullseye.\nIn comparing two relative density functions, for instance the function for an expert dart thrower versus that for an amateur, it’s helpful to normalize them so that the integral of the relative density over the entire domain is dimensionless 1. The normalized version of a relative density function is called a probability density functions. Note that the probability density function contains the same information as the relative density function.\nIn this section, we introduce a new type of function that’s important in probability calculations involving data. This new type of function is, perhaps confusingly, called a likelihood function.\nLikelihood functions always involve hypothetical reasoning. The idea is to construct a model world whose characteristics are exactly known. In that world, we can imagine constructing a function that gives the probability or probability density of any possible value of a measurement.\nFor instance, Johnny, Louisa, and Geoff each created hypothetical worlds that describe the amount of money in the jar. For each contestant, their personal hypothesis states a probability density over all the theoretically possible amounts of money in the jar.\nThe domain of a likelihood function is all the competing hypotheses. Take a moment to digest that. The domain of money-in-jar likelihood function is not the amount of money in the jar, it is instead the three hypotheses: Johnny’s, Louisa’s, and Geoff’s.\nIt’s conventional to denote name a likelihood function \\({\\cal L}()\\). For the competition, a likelihood function will be \\({\\cal L}(\\text{contestant})\\), where \\(\\text{contestant}\\) will be one of “Johnny” or “Louisa” or “Geoff” in our example.\nThere are many likelihood functions that might be relevant to the money-in-jar situation. There is one likelihood function for each possible amount of money in the jar. For instance, \\({\\cal L}_{\\$10}(\\text{contestant})\\) is relevant if there were ten dollars in the jar. Another likelihood function \\({\\cal L}_{\\$11.50}(\\text{contestant})\\) would be relevant if there were eleven dollars and fifty cents in the jar.\nThis notation of naming functions using a subscript can get awkward when there are a huge number of functions. For instance, for the money-in-jar contest there will be a likelihood function for $0.01, $0.02, $0.03, and all other possibilities such as $21.83 or \\(47.06\\). If we want to be able to refer to the whole set of likelihood functions, better to replace the dollar amount in the subscript with a symbol, say \\(m\\) for money. Then the whole set of likelihood functions potentially relevant to the contest would be written \\({\\cal L}_m(\\text{contestant})\\).\n\nThere is another style for notation that you may encounter in your future work. In the alternative style, for example, instead of \\({\\cal L}_m(\\text{contestant})\\) the likelihood function would be written \\({\\cal L}(\\text{contestant}\\, {\\mathbf |} m )\\). The vertical bar is pronounced “given” and is part of a notational system often used in probability calculations.\n\nSince the output of any likelihood function is a probability or a probability density depending on context, we know that the output will be a non-negative quantity.\nLikelihood functions provide the link between data and hypotheses. The idea is that when data become available, it’s possible to choose the relevant likelihood function.\nTo illustrate, let’s return to the jar-of-money contest and the three competitors’ entries as shown in Figure 50.3. For convenience, that Figure is reproduced here:\n\n\n\n\n\nFigure 50.7: The contest entries shown in Figure 50.3.\n\n\n\n\nThe functions shown in the Figure are not likelihood functions. But we can use them to construct whatever likelihood function turns out to be relevant in the money-in-jar contest.\n\nIt’s time to calculate who won the jar-of-coins contest! That is, we’ll calculate whose entry is best. The word “best” should remind you of optimization and indeed the winner of the contest will be the argmax of the relevant likelihood function. At this point, remember that the likelihood functions are \\({\\cal L}_m(\\text{contestant})\\), so the argmax will be one of the contestants!\nFirst, we need to pick the relevant likelihood function. Common sense tells us that you can only pick a winner when the jar has been opened and the money counted. That is, we need some data.\nHere’s the data: The officials have opened the jar and carefully counted the money. There was $32.14 in the jar. This tells us that the relevant likelihood function is \\({\\cal L}_{\\$32.14}(\\text{contestant})\\).\nThe output of \\({\\cal L}_{\\$32.14}(\\text{contestant})\\) is the probability density assigned by the contestant to the observed value $32.14. You can read this from ?fig-jar-functions2). For your convenience, the observation \\(32.14\\) has been annotated with a faint brown vertical line.\nHere’s a tabular version of \\({\\cal L}_{\\$32.14}(\\text{contestant})\\).\n\n\n\n\\(\\text{contestant}\\)\n\\({\\cal L}_{\\$32.14}(\\text{contestant})\\)\n\n\n\n\nJohnny\n0.000 per dollar\n\n\nLouisa\n0.010 per dollar\n\n\nGeoff\n0.066 per dollar\n\n\n\nIn statistics, likelihood functions are used to describe how to estimate a quantity given some data about the quantity. The techique is called maximum likelihood estimation: the estimate is the argmax of the likelihood function. For the coins-in-jar contest, the argmax is Geoff. Therefore, Geoff wins!\nIn the spirit of “Monday morning quarterbacking,” let’s look carefully at Johnny’s entry. If his bar-shaped probability density function were shifted just a little to the right, he would have won. This illustrates a weakness in Johnny’s logic in constructing his probability density function. The function indicates that he thought the probability of the amount being $23 was the same as being 30 dollars. In other words, he was uncertain to a considerable extent. But given this uncertainty, why would he insist that $30.01 is impossible (that is, has probability density 0 per dollar). Wouldn’t it make more sense to admit nonzero density for $30.01, and similarly for $30.02 and upward, with the density gradually decreasing with the amount of money. This is why, absent very specific knowledge about the circumstances, probability densities are so often framed as Gaussian distributions, as in Geoff’s entry.\n\nThe previous example is intended to give you an idea about what a likelihood function is. In that example, we use the calculus operator argmax to find the contest winner.\nLet’s turn now to another important use of likelihood functions: their role in the Bayesian inference process. The example concerns figuring out the risk of disease transmission.\n\nConsider the situation in November 2019 at the start of the COVID-19 pandemic. At that time, there was almost no information about the illness or how it spreads. In the US and many other countries, most people assumed that the spread of illness outside its origin in Wuhan, China, would be prevented by standard public health measures such as testing, contact tracing, quarantine, and restrictions on international travel. Intuitively, most people translated this assumption into a sense that the personal risk of illness was small.\nIn communicating with the public about risk, it’s common to present risk as a number: a probability. This is an adequate presentation only when we have a solid idea of the risk. To form a solid idea, we need evidence.\nBefore there’s enough evidence responsibly to form a solid idea, it’s best to present risk not as a probability but as a probability density function. To illustrate, Figure 50.8) shows three different examples of what such probability density functions might look like for vague, preliminary ideas of risk.\n\n\n\n\n\nFigure 50.8: Three different opinions about the risk of a disease.\n\n\n\n\nPanel (A) in Figure 50.8 is a strong statement that the risk is believed to be small. Even so, the density function is non-zero even for values of the risk near 100%. This is an honest admission that, as with COVID-19, something that we don’t know might be going on. In the case of COVID-19, what most people didn’t realize is 1) that the reported numbers were completely unrepresentative of the extent of spread, since most cases are asymptomatic and 2) that the illness can spread even by those who are asymptomatic. Epidemiologists and other public health workers knew enough from previous experience to be aware of their lack of knowledge about (1) and (2), but the rest of us, including many policy makers, didn’t even know what they didn’t know. The word “unk-unk” is sometimes used by engineers to refer to such an “unknown unknown”.\nPanel (B) says, “I have no idea!” This can often be an honest, useful appraisal of the situation. But experts who are honest in this way are often regarded by the public and policy makers as lacking credibility.\nPanel (C) expresses the belief that the risk might well be small but also might be large.\nAny of the three probability density functions would be reasonable statements about what we knew and didn’t know about COVID-19 at the very beginning of the pandemic, before there was much data. Such statements are called priors; summaries of what we know up to the present.\nIn Bayesian inference, as data become available we can revise or update the priors, giving a better informed description of the risk.\nFor COVID-19, data eventually came in many different forms: estimates of incubation periods, testing to determine what fraction of cases are asymptomatic, and so on.\nFor our presentation of Bayesian reasoning, we’ll consider a simplified situation where data come in only one form: screening tests for the illness. Imagine that you are conducting a contact-tracing study. Whenever a patient presents with COVID-19 symptoms and has a positive PCR test, that patient’s close contacts are given a screening test for COVID. The objective is to estimate how transmissible the virus is by figuring out what proportion of close contacts become infected.\nWe can’t know which of the three priors in Figure 50.8 is most appropriate. After all, until rich enough data become available, each prior is just an opinion. So we’ll repeat the update-with-data analysis for each of the three priors. If, in the end, the results from the three priors substantially agree, then we can conclude that the data is shaping the results, rather than the prior.\nThe unknown here is the risk \\(R\\) of transmission. We’ll denote the three priors as \\(\\text{prior}_A (R)\\), \\(\\text{prior}_B (R)\\), and \\(\\text{prior}_C (R)\\). But, in general, we’ll write \\(\\text{prior}(R)\\) to stand for any of those three specific priors.\n\nIn Bayesian inference, the prior represents the starting point for what we know (or, more precisely, “believe”) about the risk of transmission. It has the form of a relative density function. As data come in, we update our prior beliefs on the basis of the data.\nAfter we have updated our prior, our state of knowledge is called a posterior belief. Think of the prior as “pre-data” belief and the posterior as “post-data” belief. The posterior also has the form of a relative density function.\nThe formula for updating is called Bayes’ Rule: posterior is likelihood times prior. \\[\\text{posterior}(R) = {\\cal L}_\\text{data}(R) \\times \\text{prior}(R)\\ .\\] Recall that the output of a likelihood function is a non-negative quantity. Since the prior is a relative density function, it too is non-negative for all \\(R\\). Therefore the posterior will have a non-negative output and be a valid relative density function.\n\nMost texts prefer to define priors and posteriors as probability density functions rather than relative density functions. The only difference, of course, is the normalization. But that can be performed at any time, so to streamline the updating process, we’ll let posteriors and priors be relative density functions.\n\nNotice that the posterior has just one input, the parameter \\(R\\). That’s because the \\(\\text{data}\\) is fixed by our observations: the posterior only makes sense once we have the data available in order to choose the relevant likelihood function.\nOur task now is to construct the appropriate likelihood function that reflects how the screening test works. To outline the process, let’s consider a group of 1000 people who are taking the screening test. If we knew the parameter \\(R\\), we could split those 1000 people into two groups: one group with the illness and one group without.\n\nWhole group of 1000, made up of\n\n1000 \\(R\\) with the illness\n1000 \\((1-R)\\) without the illness\n\n\nFor instance, if \\(R=0.2\\), then out of the whole group of 1000 people, 200 would have the illness and 800 would not.\nAfter taking the screening test, each person will have either a positive test result (we’ll write this “+”) or a negative test result (we’ll write “-”).\nIn order to make sense of a screening test, you need to know two probabilities. These are:\n\nThe probability of a + test in a group of people with the disease. We’ll call this \\(p_d(+)\\).\nThe probability of a - test in a group of people without the disease. We’ll call this \\(p_h(-)\\).\n\nNote that the subscript indicates whether we are referring to the probability in the has-the-illness group (\\(p_d\\)) or in the no-illness (“healthy”) group (\\(p_h\\)).\nYou may know that the result of a screening test is not definitive. That is, a person with a \\(+\\) result may not have the illness. Likewise, a \\(-\\) result is no guarantee that the person does not have the illness. The word “screening” is meant to emphasize the imperfections of such tests. But often the imperfect test is the best we have available.\nAfter the screening test has been taken by the 1000 people in our example group, we can divide them further\n\nWhole group of 1000, made up of\n\n1000 \\(R\\) with the illness, made up of\n\n1000 \\(R\\ p_d(+)\\) who had a correct positive test result\n1000 \\(R\\ (1-p_d(+))\\) who had a negative result despite having the illness\n\n1000 \\((1-R)\\) without the illness, made up of\n\n1000 \\((1-R)\\ (1-p_h(-))\\) who had a positive test result despite being healthy\n1000 \\((1-R)\\ p_h(-)\\) who had a correct negative result.\n\n\n\n\nSuppose that \\(R=0.2\\), \\(p_d(+) = 80\\%\\), and \\(p_h(-) = 70\\%\\). Then the division would be:\n\nWhole group of 1000, made up of\n\n200 with the illness, of whom\n\n160 who got a correct \\(+\\) result\n40 who got a \\(-\\) result, despite having the illness\n\n800 without the illness, of whom\n\n240 who got a \\(+\\) result, despite not having the illness\n560 who got a correct \\(-\\) result.\n\n\n\nThere are two likelihood functions reflecting the two different possible test results: \\({\\cal L}_+ (R)\\) and \\({\\cal L}_- (R)\\). We will need to construct both of these functions since the test result is going to be \\(+\\) for some people and \\(-\\) for others.\nRecall now that each likelihood function is based on a hypothesis about the world. In this case, the hypothesis is a particular value for \\(R\\). Let’s look at the situation for the hypothesis that \\(R=0.2\\). We can figure out the values of both \\({\\cal L}_+ (R=0.2)\\) and \\({\\cal L}_- (R=0.2)\\) from the breakdown given in the above example.\n\\({\\cal L}_+ (R=0.2)\\) is the probability of observing the given data (\\(+\\)) in the hypothetical world where \\(R=0.2\\). Out of the 1000 people, 160 will get a correct test result \\(+\\) and 240 people will get a \\(+\\) despite not having the illness. Therefore, \\[{\\cal L}_+ (R=0.2) = \\frac{160+240}{1000} = 40\\%\\ .\\]\nSimilarly, \\({\\cal L}_- (R=0.2)\\) is the probability of observing the given data (\\(-\\)) in the hypothetical world where \\(R=0.2\\). In the above breakdown, altogether 600 people received a \\(-\\) result: 560 of these were indeed healthy and 40 had the illness but nonetheless got a \\(-\\) result. So, \\[{\\cal L}_- (R=0.2) = \\frac{40+560}{1000} = 60\\%\\ .\\]\n\nThe above example calculated the output of the likelihood function for both \\(+\\) and \\(-\\) results when \\(R=0.2\\). We can repeat the calculation for any other value of \\(R\\). The results, as you can confirm yourself, are\n\\[{\\cal L}_+(R) = p_d(+)\\ R + (1-p_h(-))\\ (1-R) \\] and\n\\[{\\cal L}_-(R) = (1-p_d(+))\\ R + p_h(-)\\, (1-R)\\ .\\] In a real-world situation, we would have to do some experiments to measure \\(p_h(-)\\) and \\(p_d(+)\\). For our example we’ll set \\(p_d(+) = 0.8\\) and \\(p_h(-) = 0.7\\).\nNow that we have constructed the likelihood functions for the two possible observations \\(+\\) and \\(-\\), we can use them to update the priors.\nSuppose our first observations are the results of screening tests on ten randomly selected individuals.\n\n\n\nSubject ID\nTest outcome\n\n\n\n\n4349A\n\\(+\\)\n\n\n7386A\n\\(-\\)\n\n\n6263E\n\\(+\\)\n\n\n5912C\n\\(-\\)\n\n\n7361C\n\\(-\\)\n\n\n9384C\n\\(-\\)\n\n\n6312A\n\\(-\\)\n\n\n3017C\n\\(+\\)\n\n\n1347B\n\\(-\\)\n\n\n9611D\n\\(-\\)\n\n\n\nTo summarize: Three \\(+\\) tests out of ten.\nAfter the first test outcome is available we can calculate the posterior: \\[\\text{posterior}_1 (R) = {\\cal L}_+(R) \\times \\text{prior(R)}\\ .\\] After the second test outcome, the new posterior is \\[\\text{posterior}_2 (R) = {\\cal L}_-(R) \\times {\\cal L}_+(R) \\times \\text{prior(R)}\\ .\\] And after the third (a \\(+\\) result!) it will be \\[\\text{posterior}_3 (R) = {\\cal L}_+(R) \\times {\\cal L}_-(R) \\times {\\cal L}_+(R) \\times \\text{prior(R)}\\ .\\] We continue on in this way through all ten rows of the data to get the posterior distribution after all 10 test results have been incorporated.\nFigure 50.10 shows the posterior after the 10 rows of data have been considered for each of the three priors from Figure 50.8).\n\n\n\n\n\n\n\n\nFigure 50.9: Posteriors (blue) after the first screening test, which was \\(+\\), for each of the priors in Figure 50.8. The prior itself is drawn in gray.\n\n\n\n\nWith just one row of data considered, the posteriors depend very much on the particular prior selected. This shouldn’t be a surprise; one test result from an imperfect screening test is not going to tell us much. Let’s process all of the\n\n\n\n\n\nFigure 50.10: Posteriors (blue) after the first ten rows of data, for each of the priors in Figure 50.8. The prior itself is drawn in gray.\n\n\n\n\nAfter the first 10 rows of data have been considered, the posteriors are similar despite the different priors.\n\n\n\n\n\nFigure 50.11: Posteriors (blue) after 100 subjects have been screen, with 30 \\(+\\) results.\n\n\n\n\nAs data accumulates, the priors become irrelevant; the knowledge about the risk of disease is being driven almost entirely by the data.\nRemarkably, even though 30% of the tests were positive, all the posteriors place almost all the probability density on transmission risks less than 20%. This is because the likelihood functions correctly take into account the imperfections of the screening test."
  },
  {
    "objectID": "Manifestations/B4-probability.html#exercises",
    "href": "Manifestations/B4-probability.html#exercises",
    "title": "50  Probability and evidence",
    "section": "50.5 Exercises",
    "text": "50.5 Exercises"
  },
  {
    "objectID": "Manifestations/B4-future-value.html",
    "href": "Manifestations/B4-future-value.html",
    "title": "51  Present and future value",
    "section": "",
    "text": "Comparison is an important element of human decision making. Often, comparison amounts to translating each of the options at hand into a scalar score. (Recall that a scalar is just an ordinary quantity, e.g. 73 inches. As we get more deeply involved with vectors it will become more important to be perfectly clear when we are talking about a vector and when about a scalar. So we’ll be using “scalar” a lot.) Scalars are easy to compare; the skill is taught in elementary school. Scalar comparison is completely objective. Putting aside the possibility of error, everyone will agree on which of two numbers is bigger. Importantly, comparison of scalars is transitive, that is if \\(a > b\\) and \\(b > c\\) then it is impossible that \\(a \\leq c\\).\nThe comparison of scalars can be extended to situations where the options available form a continuum and the score for each option \\(x\\) is represented by a function, \\(f(x)\\). As we saw in Chapters 23 and Section 49 selecting the highest scoring option is a matter of finding the argmax.\nMany decisions involve options that have two or more attributes that are not directly comparable. Expenditure decisions have this flavor: Is it worth the money to buy a more reliable or prettier or more capable version of a product? The techniques of constrained optimization (Section 49) provide one useful approach for informing decisions when there are multiple objectives.\nElections are a form of collective decision making. The options—called, of course, “candidates”—have many attributes. Three such attitudes are attitudes toward social policy, toward fiscal policy, and toward foreign policy. Perceived honesty and trustworthiness as well as the ability to influence other decision makers and perceived ability to win the election are other attributes that are considered and balanced against one another. Ultimately the decision is made by condensing the diverse attributes into a single choice for each voter. The election is decided by how many votes the candidate garners. With this number attached to each of the candidates, it’s easy to make the decision, \\[\\text{winner} \\equiv\\mathop{\\text{argmax}}_{i} \\text{votes}(\\text{candidate}_i)\\ .\\] There are many voting systems. For instance, sometimes the winner is required to have a majority of votes and, if this is not accomplished, the two highest vote-getting candidates have a run-off. Some jurisdictions have introduced “rank-choice” voting, where each voter can specify a first choice, a second choice, and so on. US federal elections involve a primary system where candidates compete in sub-groups before the groups complete against one another. It’s tempting to think that there is a best voting system if only we were clever enough to find one and convince authorities to adopt it. But two mathematical theorems, Arrow’s impossibility theorem and the Gibbard-Satterthwaite theorem demonstrate that this is not the case for any system that involves three or more candidates. All such voting systems potentially create situations where a voter’s sincere interests are best served by an insincere, tactical vote choice. A corollary is that voters can be tricked into making a sincere choice that violates their interests.\nThis chapter is about a very common situation where there are multiple attributes that need to be condensed into a single score. The setting is simple: money. The question is how to condense a future income/expense stream—a function of time—into an equivalent value of money in hand at the present. This is called the present value problem. There is a solution to the problem that is widely accepted as valid, just as voting is a hallowed process of social optimization. But like voting, with its multiplicity of possible forms, there is a subtlety that renders the result somewhat arbitrary. This is not a situation where there is a single, mathematically correct answer but rather a mathematical framework for coming to sensible conclusions."
  },
  {
    "objectID": "Manifestations/B4-future-value.html#present-value",
    "href": "Manifestations/B4-future-value.html#present-value",
    "title": "51  Present and future value",
    "section": "51.1 Present value",
    "text": "51.1 Present value\nPeople and institutions often have to make decisions about undertakings where the costs and benefits are spread out over time. For instance, a person acquiring an automobile or home is confronted with a large initial outlay. The outlay can be financed by agreeing to pay amounts in the future, often over a span of many years.\nAnother example: Students today are acutely aware of climate change and the importance of taking preventive or mitigating actions such as discouraging fossil fuel production, investing in renewable sources of energy and the infrastructure for using them effectively, and exploring active measures such as carbon sequestration. The costs and benefits of such actions are spread out over decades, with the costs coming sooner than the benefits. Policy makers are often and perhaps correctly criticized for overvaluing present-day costs and undervaluing benefits that accrue mainly to successive generations. There are many analogous situations on a smaller scale, such as setting Social Security taxes and benefits or the problem of underfunded pension systems and the liability for pension payments deferred to future taxpayers.\nThe conventional mechanism for condensing an extended time stream of benefits and costs is called discounting. Discounting is based on the logic of financing expenditures via borrowing at interest. For example, credit cards are a familiar mechanism for financing purchases by delaying the payment of money until the future. An expense that is too large to bear is “carried” on a credit card so that it can be paid off as funds become available in the future. This incurs costs due to interest on the credit-card balance. Typical credit-card interest rates are 18-30% per year.\nAs notation, consider a time stream of income \\({\\cal M}(t)\\), as with the apartment building example. We’ll call \\({\\cal M}(t)\\) the nominal income stream with the idea that the money in \\({\\cal M}(t)\\) is to be counted at face value. “Face value” is the literal amount of the money. In the case of cash, a $20 bill has a face value of $20 regardless of whether it becomes available today or in 50 years. The word “nominal” refers to the “name” on the bill, for instance $20.\nThe big conceptual leap is to understand that the present value of income in a future time is less than the same amount of income at the present time. In other words, we discount future money compared to present money. For example, if we decide that an amount of money that becomes available 10 years into the future is worth only half as much as that same amount of money if it were available today, we would be implying a discounting to 50%. In comparison, if that money were available 20 years in the future, it would make sense to discount it by more strongly to, say, 25%.\nTo represent the discounting to present value as it might vary with the future time horizon, we multiply the nominal income stream \\({\\cal M}(t)\\) by a discounting function \\({\\cal D} (t)\\). The function \\({\\cal D}(t)\\, {\\cal M}(t)\\) gives the income stream as a present value rather than a nominal value. It’s sensible to insist that \\({\\cal D} (t=0) \\equiv 1\\) which is merely to say that the present value of money available today is the same as the nominal value.\nThe net present value (NPV) of a nominal income stream \\({\\cal M}(t)\\) is simply the sum of the stream discounted to the present value. Since we’re imagining that the income stream is a function of continuous time, the sum amounts to an integral: \\[\\text{NPV} \\int_\\text{now}^\\text{forever} {\\cal M}(t)\\ {\\cal D}(t)\\, dt\\ .\\]"
  },
  {
    "objectID": "Manifestations/B4-future-value.html#sec-discount-functions",
    "href": "Manifestations/B4-future-value.html#sec-discount-functions",
    "title": "51  Present and future value",
    "section": "51.2 Discounting functions",
    "text": "51.2 Discounting functions\nWhat should be the shape of the discounting function?\nRecall that the purpose of the discounting function is to help us make comparisons between different income streams, that is, between the various options available to an entrepreneur. Each individual can in principle have his or her own, personal discounting function, much as each voter is entirely free to weight the different attributes of the candidates when deciding whom to vote for. As a silly example, a person might decide that money that comes in on a Tuesday is lucky and therefore worth more than Thursday money. We won’t consider such personalized forms further and instead emphasize discounting functions that reflect more standard principles of finance and economics.\nAs a thought experiment, consider the net present value of an income stream, that is \\[\\text{NPV}_\\text{original} = \\int_0^\\infty {\\cal M}(t)\\ {\\cal D}(t)\\, dt\\ .\\] Imagine now that it has been proposed to delay the income stream by \\(T=10\\) years. This new, delayed income stream is \\({\\cal M}(t-T)\\) and also has a net present value: \\[\\text{NPV}_\\text{delayed} = \\int_0^\\infty {\\cal M}(t - T)\\ {\\cal D}(t)\\, dt\\ .\\] There are at least two other ways to compute \\(\\text{NPV}_\\text{delayed}\\) that many people would find intuitively reasonable:\n\nSimply discount the original NPV to account for it becoming available \\(T\\) years in the future, that is, \\[\\text{NPV}_\\text{delayed} = {\\cal D}(T)\\ \\text{NPV}_\\text{original} = \\int_0^\\infty {\\cal M}(t)\\ {\\cal D}(T)\\ {\\cal D}(t)\\, dt\\ \\]\nApply to \\({\\cal M}(t)\\) a discount that takes into account the \\(T\\)-year delay. That is:\n\\[\\text{NPV}_\\text{delayed} = \\int_0^\\infty {\\cal M}(t)\\ {\\cal D}(t + T)\\, dt\\ .\\] For (1) and (2) to be the same, we need to restrict the form of \\({\\cal D}_r(t)\\) so that \\[{\\cal D}(T)\\ {\\cal D}(t) = {\\cal D} (t+T)\\ .\\] The form of function that satisfies this restriction is the exponential, that is \\({\\cal D}(t) \\equiv e^{kt}\\)."
  },
  {
    "objectID": "Manifestations/B4-future-value.html#compound-interest",
    "href": "Manifestations/B4-future-value.html#compound-interest",
    "title": "51  Present and future value",
    "section": "51.3 Compound interest",
    "text": "51.3 Compound interest\nA more down-to-earth derivation of the form of \\({\\cal D}(t)\\) is to look at how financial transactions take place in the everyday world: borrowing at interest. Suppose that a bank proposes to lend you money at an interest rate of \\(r\\) per year. To receive from the bank one dollar now entails that you pay the bank \\(1+r\\) dollars at the end of the year.\nFor this proposition to be attractive to you, the present value of \\(1+r\\) dollars to be paid in one year must be less than or equal to the present value of one dollar today. In other words, \\[{\\cal D}_\\text{you}(1)\\ (1+r) \\leq 1\\ .\\] From the bank’s perspective, the present value of your payment of \\((1+r)\\) dollars in a year’s time must be greater than one dollar today. That is\n\\[1 \\leq {\\cal D}_\\text{bank}(1)\\ (1+r) \\ .\\] It’s perfectly reasonable for you and the bank to have different discounting functions, just as it’s perfectly legitimate for you and another voter to have different opinions about the candidates. It’s convenient, though to imagine that the two discounting functions are the same, which will be the case if \\[{\\cal D}(1) = \\frac{1}{1+r}\\ .\\]\nIf you were to borrow money for two years, the bank would presumably want to charge more for the loan. A typical practice is to charge compound interest. Compound interest corresponds to treating the loan as having two phases: first, borrow one dollar for a year and owe \\(1+r\\) dollars at the end of that year. At that point, you will borrow \\((1+r)\\) dollars at the interest rate \\(r\\). At the end of year two you will owe \\((1+r) (1+r) = (1+r)^2\\) dollars. In general, if you were to borrow one dollar for \\(t\\) years you would owe \\((1+r)^t\\) dollars. In order for the loan to be attractive to both you and the bank, the discounted value of \\((1+r)^t\\) should be one dollar: \\[{\\cal D}(t) = \\frac{1}{(1+r)^t} = (1 + r)^{-t}\\ .\\]\n\nLet’s return to the entrepreneur considering the apartment-building project.\nThe entrepreneur goes to the bank with her business plan and financial forecasts. The bank proposes to lend money for the project at an interest rate of 7% per year.\n\n\n\n\n\nFigure 51.2: Blue curve: The apartment project income stream discounted at 7% per year. Black curve: The undiscounted income stream.\n\n\n\n\nFigure 51.2 shows the income stream discounted at 7% per year. The net present value of the income stream for the apartment project is the accumulation of the discounted income stream: \\[\\text{NPV}(7\\%) = \\int_0^{30} (1 + 0.07)^{-t} {\\cal M}(t) \\ dt \\ .\\] This works out to be negative $1,095,000. As things stand, the apartment building will be a money pit.\nThe entrepreneur responds to the bank’s offer with some business jargon. “I’ll have to go back to the drawing board, put the team’s heads together, and see how to get the numbers to work. I’ll circle back with you tomorrow.” This might involve reconsidering her model of the income stream. Perhaps she should have taken into account yearly rent increases. Maybe she can re-negotiate with the city about zoning height restrictions and build a 12-unit building, which will cost $4 million, lowering the cost per apartment?"
  },
  {
    "objectID": "Manifestations/B4-future-value.html#mortgages",
    "href": "Manifestations/B4-future-value.html#mortgages",
    "title": "51  Present and future value",
    "section": "51.4 Mortgages",
    "text": "51.4 Mortgages\nA mortgage is a form of loan where you pay back the borrowed amount at a steady rate, month by month. At the end of a specified period, called the term of the mortgage, your have completely discharged the debt.\nSuppose you decide to buy a product that costs \\(\\$\\cal P\\), say \\(\\cal P=\\) $10,000 for a used car. Let’s say you need the car for your new job, but you don’t have the money. So you borrow it.\nYour plan is to pay an amount \\(A\\) each month for 30 months—the next \\(2\\,\\small\\frac{1}{2}\\) years. What should that rate be?\nYou can put the purchase on your credit card at an interest rate of \\(r=2\\%\\) per month. This corresponds to \\(k = \\ln(1+r) = 0.0198\\) per month. The net present value of your payments over 30 months at a rate of \\(A\\) per month will be\n\\[\\int_0^{30} A {\\cal D}_r(t)\\, dt = \\int_0^{30} e^{-kt} A = -\\frac{A}{k} e^{-kt}\\left.{\\Large\\strut}\\right|_{t=0}^{30}\\\\ =- A \\left(\\strut \\frac{e^{-30k}}{k} - \\frac{e^{-0k}}{k} \\right)\\\\ = - A\\left(\\strut27.88 - 50.50\\right) = 22.62 A\\]\nThe loan will be in balance if the net present value of the payments is the same as the amount \\({\\cal P}\\) you borrowed. For this 30-month loan, this amounts to \\[22.62 A = {\\cal P}\\ ,\\] from which you can calculate your monthly payment \\({\\cal A}\\). For the $10,000 car loan, your monthly payment will be $10,000/22.62 or $442.09."
  },
  {
    "objectID": "Manifestations/B4-future-value.html#exercises",
    "href": "Manifestations/B4-future-value.html#exercises",
    "title": "51  Present and future value",
    "section": "51.5 Exercises",
    "text": "51.5 Exercises"
  },
  {
    "objectID": "Manifestations/B4-mechanics.html",
    "href": "Manifestations/B4-mechanics.html",
    "title": "52  Mechanics",
    "section": "",
    "text": "In Block 2, we introduced the ideas of instantaneous rate of change and infinitesimal intervals of time. These are mathematical concepts introduced in the 17th century for describing motion. (In the 16th century, Galileo’s measurements of motion involved averages over finite time intervals.) With this new mathematical tool, Newton understood that the velocity of an object is its instantaneous rate of change of position with respect to time, and to define acceleration as the instantaneous rate of change of velocity with respect to time. With these definition, Newton was able to connect motion to the palpable forces acting on objects. Thus was born the field of dynamics, the study of forces and their effects on motion.\nIn contrast, statics is about physical systems that do not change. A non-changing system is said to be in equilibrium or balance. Static systems are incredibly important in everyday life; a bridge that is not static is one that you do not want to cross! The equilibrium in a bridge is the balance between the downward force of gravity and the compressive and tensile forces in the materials that make up the bridge.\n“Mechanics” is a catch-all term for the combination of statics and dynamics studied in physics and used in engineering and design. The sense of the word is the study of machines, with the “-ic” signifying “practice of” in the sense of scientific, physics, mathematics, optics, chiropractic, and such. This starts with simple machines—simple devices that change the direction or strength of a force— such as the lever, wheel and axle, pulley, inclined plane, wedge, and screw. Mechanics goes on to deal with more complicated machine components such as a gas-filled cylinder and piston, flywheel, valve, turbine, etc. Many concepts originally developed for the theory of machines are familiar, and intuitive to the modern mind: force, pressure, momentum.\nThis chapter illustrates the central role of calculus concepts and methods in mechanics."
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#work",
    "href": "Manifestations/B4-mechanics.html#work",
    "title": "52  Mechanics",
    "section": "52.1 Work",
    "text": "52.1 Work\n“Work” is a familiar, everyday concept, but a nuanced one; one person’s work can be another person’s play. In mechanics, work has a much more specific meaning stemming from the study of simple machines. A lever, for instance, can be used to move an object that is otherwise too heavy to handle. It still takes toil and effort to move the object, but the effort is eased by the mechanics of the lever.\nOur intuitive sense of work is perhaps rooted in physiology: effort, fatigue, muscle pain. For instance, it takes work to pick up a heavy object, but it is also work to hold the object steady even without moving it. Generations of thinking about machines has brought us to a different notion of work that doesn’t involve human subjectivity. In mechanics, holding an object steady, no matter how heavy, does not involve work. Although a human tasked to hold a heavy load will become exhausted, the same duty can be accomplished by placing the load on a table, completely eliminating the effort. In mechanics, work and motion go hand in hand; without motion there is no mechanical work.\nThe table holding the heavy load does no work. Work is done only when the load is moved, and the amount of work depends on how the load is moved. For instance, moving a block along level ground involves a lot of work, but pulling a cart filled with blocks can be almost effortless. In mechanics, work combines both the amount of motion and the force needed to accomplish the motion.\n\nWork is force times displacement.\n\nConsider, for instance, the work involved in lifting a mass \\(m\\) to table height \\(h\\).\n\nknitr::include_graphics(\"www/mass-on-table.png\")\n\n\n\n\n\n\n\n\nThe lifting is accomplished by applying an upward force to counter the force of gravity. The gravitational force on the mass is \\(m g\\), where \\(g\\) is the instantaneous acceleration of an object released to fall freely (about 9.8 m/s2 near the Earth’s surface). The distance traveled is \\(h\\). So the work performed on the mass is \\(m g h\\).\nNotice that the mechanical work has nothing to do with the speed with which the mass is moved up to the table. Lift it fast or lift it slow, it amounts to the same mechanical work. (Of course, to human perception, lifting an object very slowly up to table height involves more effort than snapping it up quickly. But human effort is only peripherally related to mechanical work.)\nLet’s introduce a machine to the situation in the form of a ramp or a pulley. The purpose of the machine is to ease human labor by changing the strength or direction of forces. You can perhaps intuit that rolling the mass up the ramp will be an easier task than lifting it. How so?\n\nknitr::include_graphics(\"www/mass-up-ramp.png\")\n\n\n\n\n\n\n\n\nThe ramp can be seen as a sort of partial table. The ramp does most of what’s needed to hold the mass up. To keep the mass in place on the ramp the human worker need only supply a modest additional force parallel to the ramp surface. Calculating that modest additional force can be accomplished by a basic mathematical technique in mechanics: decomposing a vector.\nYou encountered vectors (in Section 24.003) in the context of the gradient vector of a function, say, \\(f(x,y)\\). At any given input \\((x,y)\\) the gradient vector, written \\(\\nabla f(x,y)\\), points in the steepest uphill direction of the function \\(f(x,y)\\). Recall that the gradient vector was written as a set of values; the partial derivative of \\(f()\\) with respect to each of its inputs in turn. That is, \\[\\nabla f(x,y) = \\left({\\large\\strut} \\partial_x f(x,y),\\ \\  \\partial_y f(x,y)\\right)\\ .\\] In this representation, the vector \\(\\nabla f(x, y)\\) is decomposed into two components: \\(\\partial_x f(x,y)\\) and \\(\\partial_y f(x,y)\\).\nTo decompose the vector of gravitational forces, we can place a coordinate grid over the gravity vector. In ?fig-ramp-decomposition this grid has been arranged so that one cardinal direction is aligned with the ramp itself and the other is perpendicular—that is, “normal”—to the ramp. Merely by noting the coordinates of the gravitational vector in the coordinate grid, we decompose that vector into two components, one along the surface of the ramp and the other perpendicular to the ramp.\n\n\n\n\n\nFigure 52.1: Decomposing the vector of gravitational force into two perpendicular components, one tangent to the ramp and the other perpendicular to it. For clarity, the right triangle of decomposition is shown twice, once without the grid.\n\n\n\n\n\n\n\nFigure 52.2: Decomposing the vector of gravitational force into two perpendicular components, one tangent to the ramp and the other perpendicular to it. For clarity, the right triangle of decomposition is shown twice, once without the grid.\n\n\n\n\nWe return to the idea of vector decomposition in much more detail in Block 5 of this course; it has a major (though perhaps unexpected) role to play in fitting models to data. But for now, we’ll simply examine the right triangle in ?fig-ramp-decomposition. In that right triangle, the gravitational force vector \\(F_{gravity} = m g\\) is the hypotenuse. The component tangential to the ramp is \\(m \\sin(\\theta) g\\). The worker pushing the mass up the ramp need provide only tangential component of force which is smaller than the force imposed on the worker picking up the mass without a ramp. Thus human effort is reduced by the machine.\nWhat about the mechanical work? Is that also reduced? Remember that mechanical work is the product of force times distance. The force has been reduced to \\(m \\sin(\\theta) g\\), but the distance \\(D_{ramp}\\) along the ramp is much longer than the distance \\(h\\) from floor to table top.\n\n\n\n\n\n\n\n\n\nAgain, referring to the ramp itself as a right triangle, you can see that \\(D_{ramp}\\sin(\\theta) = h\\) or, \\(D_{ramp} = h / \\sin(\\theta)\\). The total mechanical work, the product of applied force times distance moved is \\[m \\sin(\\theta) g \\times D_{ramp} = m \\sin(\\theta) g \\times \\frac{h}{\\sin(\\theta)} = m g h\\ .\\] The ramp does nothing to reduce the mechanical work needed to lift the mass!\nWe usually think of ramps as an inclined plane. But, from Blocks 1 to 3 we have the tools to figure out the work for a (smooth) ramp with any shape at all. We’re going to do this not because odd-shaped ramps are encountered frequently, but to provide an example in a relatively familiar setting of some techniques we will use elsewhere in this chapter.\nThe ramp we have in mind has a surface whose height \\(f(x)\\) is zero at the foot (\\(x=a\\)) and reaches \\(f(x=b) = h\\) where it joins the table.\n\n\n\n\n\n\n\n\n\nThe slope of the ramp at any location \\(x\\) is, as you know, \\(\\partial_x f(x)\\). It’s helpful to convert this rise/run formulation of slope into the slope-angle form we used to study the simple ramp. As you can see from the diagram, which zooms in on one place on the ramp, rise over run amounts to \\(L\\sin(\\theta) / L\\cos(\\theta) = \\partial_x f(x) = \\tan(\\theta)\\), with the result: \\[\\theta = \\arctan({\\large\\strut}\\partial_x f(x))\\ .\\] Consequently, the force that needs to be applied parallel to the ramp’s surface is \\(m \\sin(\\arctan(\\partial_x f(x))) g = m \\sin(\\theta) g\\). To find the work done in pushing the mass an infinitesimal distance along the ramp we need to know the instantaneous length of the ramp. This is potentially confusing to the reader since we’ve already said that the distance is infinitesimal. As you know, infinitesimal is different from zero. We’ll write \\(dx\\) as an infinitesimal increment along the floor, but the zoomed-in length \\(dL\\) of the corresponding part of the ramp is the hypotenuse of a right triangle where one leg has length \\(dx\\) and the other leg has length \\(\\partial_x f(x) dx\\): slope times distance.\n\n\n\n\n\n\n\n\n\nThe hypotenuse of the infinitesimal segment of the ramp has length \\(dL = \\sqrt{\\strut dx + \\partial_x f(x) dx}\\), or \\(dL = \\sqrt{\\strut 1 + \\partial_x f(x)}\\ dx\\). Things are a bit simpler if we write \\(dL\\) in terms of the slope angle \\(\\theta(x)\\). Since \\(dx = \\cos(\\theta(x)) dL\\), we know \\(dL = dx/\\cos(\\theta(x))\\). Consequently the infinitesimal of work is \\[dW \\ = \\ m g \\frac{\\sin(\\theta(x))}{\\cos(\\theta(x))}\\ dx\\  = \\ m g \\tan(\\theta(x)) dx \\ .\\]\nThe total work is the accumulation of \\(dW\\) over the extent of the ramp. In other words, \\[\\int_a^b m g \\tan(\\theta(x))\\ dx\\ = \\ \\int_a^b m g \\tan(\\arctan(\\partial_x f(x)))\\ dx = \\int_a^b m g \\partial_x f(x) dx\\ ,\\] where we’ve used the formula \\(\\theta(x) = \\arctan(\\partial_x f(x))\\). From the “fundamental theorem of calculus” we know that\n\\[\\int_a^b m g\\ \\partial_x f(x)\\ dx \\ = \\ \\left.m g \\ f(x){\\Large\\strut}\\right|_a^b = mg \\left[\\strut f(b) - f(a)\\right] = mg h\\ .\\]\nWhat’s remarkable is that pushing the mass up the \\(f(x)\\)-shaped ramp involves an amount of work, \\(m g h\\), that does not depend on \\(f(x)\\), only on \\(f(b) - f(a)\\), the net height comprised by the ramp.\nWe haven’t yet said what this notion of work is good for and we’ve given no detailed justification for the definition of mechanical work as force times distance. You could imagine a dictatorial authority deciding to measure work as the square-root of force times distance squared. But … that particular measure is not going to make sense if we think about the dimension of the quantity. Force has dimension [force] = M L T-2. Square root of force times length squared would have dimension [sqrt(force) \\(\\times\\) length-squared] = M1/2 L5/2 T-2. The non-integer exponents mean that this is not a legitimate physical quantity.\nThe dimension of force-times-length are straightforward: [force \\(\\times\\) length] = M L2 T-2, that is, energy. The particular definition of work as force times length will make sense in the context of a more comprehensive mechanical theory of energy. The significance of energy itself is that, as a fundamental proposition of physics, the various forms of energy are interchangeable but conserved; energy is neither created nor destroyed, just moved around from one form to another and one place to another.\n\nNear the surface of the Earth, gravitational acceleration is approximately constant regardless of latitude or longitude. But gravity varies with distance \\(r\\) from the Earth’s center. Newton’s law of universal gravitation gives the force on an object of mass \\(m\\) due to the Earth’s gravity as \\[F = \\frac{m M_e G}{r^2}\\] where \\(M_e = 5.972 \\times 10^{24}\\) kg is the mass of the Earth and \\(G = 6.674 \\times 10^{-11}\\) N m2 / kg2 is the universal gravitational constant. The Earth’s radius is roughly \\(6,370,000\\) m, so the force on a 1 kg object near the surface of the Earth is \\(F = 1 \\text{kg} (5.972 \\times 10^{24} \\text{kg}) (6.674 \\times 10^{-11})/ (6.37 \\times 10^6 \\text{m})^2\\) N m2 kg-2. Carrying out the arithmetic and consolidating the units gives \\[F = 9.823 N\\] for the 1 kg object.\nSuppose we want to lift the 1 kg object from the Earth’s surface to 10000 km away, that is, to a distance of 1,6370,000 m from the center of the Earth. For the purpose of the example, we’ll ignore the gravitational force exerted by the Sun, Moon, planets, and other galaxies, etc. The work performed in the lifting is\n\\[\\int_{6.47\\times 10^6}^{16.47\\times 10^6} \\frac{1 \\text{kg}\\ M_e\\ G}{r^2}\\ dr = -\\left.  {\\Large\\strut}\\frac{1 \\text{kg}\\ M_e\\ G}{r}\\right|_{6.47\\times 10^6}^{16.47\\times 10^6} \\\\\\ \\\\\\ \\\\=\n-\\ 3.986 \\times 10^{14}\\left[\\strut \\frac{1}{16.47 \\times 10^6} - \\frac{1}{6.47 \\times 10^6}\\right] \\text{N m} \\\\\\ \\\\\\ \\\\= 37,405,840\\ \\text{J}.\\]\nA Newton-meter (N m) is also known as a Joule (J), a unit of energy. With 37,000,000 J, you could toast about 2000 pieces of bread. (A toaster uses about 300 W of power and takes about 60 seconds to process a slice of bread. \\(\\text{300 W} \\times \\text{60 s} = 18,000 \\text{J}\\)."
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#energy",
    "href": "Manifestations/B4-mechanics.html#energy",
    "title": "52  Mechanics",
    "section": "52.2 Energy",
    "text": "52.2 Energy\nMechanical work, as discussed in the previous section, is a form of energy. When we lift a object, we put energy into the object. But we cannot say from examining the object how much work was done to place it on the table. The amount of work depends on how the object came to be on the table: lifted from the floor (positive work; force is positive upward, displacement is also positive upward) or perhaps lowered from a helicopter (negative work: force exerted by the cable is positive upward but the displacement is downward, therefore negative). We might call the work energy latent, the word meaning “unobservable,” “hidden,” “concealed,” “dormant.” To have an operational meaning, the work-energy that we assign to an object at rest must be with respect to some “ground state.” A convenient ground state here is to imagine the object resting on the ground. The assigned energy will then be the work that would have to be performed to raise the object to table height. Once at table height, the energy is again latent.\nHow then to measure the work energy that’s latent in the object resting on the table? The idea is to return the object to its ground state, which we could do by lowering it—a negative displacement—to the ground, measuring the force needed to support the object (upward, so positive) and multiplying this by the displacement.\nAnother idea for measuring the latent energy is to let the object fall freely back toward its ground state and see what changes about the object. Perhaps you have already caught on to what will happen: the object’s speed increases steadily until the instant before it hits the ground.\n“Latent” is an apt but unusual word to express the energy imbued in the object resting on the table. We might equally say that the energy is “associated with position (at the height the table),” or we could call it “gravitational energy.” The term that’s generally used is a near synonym of “latent.” We call the energy of the stationary object on the table potential energy. More precisely it can be called gravitational potential energy to distinguish it from the potential energy created by other forms of work, for instance pulling apart magnets or electric charges or compressing a gas into a cylinder.\nThere’s also a form of energy associated with motion. We could call this “energy of motion,” but the conventional term is kinetic energy. (A dictionary definition of “kinetic” is “relating to or resulting from motion.” so we might as well say simply that kinetic energy is “energy relating to motion.)\nVelocity is a good way to observe motion. We can use dimensional analysis to anticipate how velocity and kinetic energy are related. Recall that energy has dimension M L2 T-2 and velocity has dimension L/T. Consequently, if an object’s kinetic energy at any instant stems from its mass and its velocity, then the energy must be mass times velocity squared, perhaps multiplied by a scalar, that is: \\[E_{kinetic} = \\alpha\\, m v^2\\ .\\]\nTo find the scalar \\(\\alpha\\), we can use calculus and accumulation. We know that the acceleration of a free-falling object due to gravity is \\(-g\\) (where the negative sign reflects the downward direction). Starting from rest (that is zero velocity so zero kinetic energy) the newly released mass will have a velocity that is the accumulated acceleration over time. In other words: \\[v(t) = \\int_0^t - g\\ dt = -\\left.g \\ t{\\large\\strut}\\right|_0^t = -g\\ t\\ .\\] Correspondingly, the position at time \\(t\\) will be the accumulated velocity: \\[x(t) = x(t=0) + \\int_0^t v(t) dt \\\\ =\nh  + \\int_0^t -g\\ t\\ dt \\\\\n= h - \\frac{1}{2} \\left.g\\ t^2{\\Large\\strut}\\right|_0^t \\ \\ =\\ \\  h - \\frac{1}{2} g\\ t^2 \\ .\\] The mass reaches the ground at time \\(t_g\\) such that \\(h - \\frac{1}{2} g\\ t_g^2 = 0\\). Solving this for \\(t_g\\) gives \\(t_g = \\sqrt{\\strut 2 h/g}\\).\nNow that we know the time when the object reaches its ground state, we can calculate the velocity at that instant: \\[v(t_g) = -g\\ t_g = - g\\ \\sqrt{\\strut 2 h / g} = - \\sqrt{\\strut 2 g h}\\] As the object reaches its ground state, its gravitation potential energy is zero (because it’s at the ground state) and, since total energy is conserved, the kinetic energy will be the same size as the potential energy at \\(t=0\\) when the object was released from the table, that is \\[E_{kinetic}(t_g) = \\alpha\\ m\\ v(t_g)^2 =\n= \\alpha\\ m \\left(\\sqrt{\\strut 2 g h\\ }\\ \\right)^2 = \\\\\\ \\\\2\\, \\alpha\\, m\\, g\\, h\\  = m\\, g\\, h = E_{potential}(t=0)\\]\nSolving \\(2 \\alpha\\ m\\,g\\,h = m\\,g\\,h\\) gives \\(\\alpha = \\frac{1}{2}\\). Thus, the kinetic energy as a function of mass \\(m\\) and velocity \\(v\\) is \\(\\frac{1}{2} m\\, v^2\\).\n\nIn the previous section, we calculated the potential energy of a 1 kg object at an altitude of 10,000 km above the Earth’s surface: 37,405,840 J. How fast would the 1 kg object need to be moving to have this much kinetic energy?\n\\[\\frac{1}{2} (1 \\text{kg}) v^2 = 37,\\!405,\\!840 \\text{J} = 37,\\!405,\\!840 \\ \\text{kg}\\ \\text{m}^2\\ \\text{t}^{-2}\\]\nSolving for \\(v\\) we get \\(v^2 = 2 \\times 37,\\!405,\\!840 \\text{kg}\\ \\text{m}^2\\ \\text{t}^{-2}\\ \\text{kg}^{-1}\\) or \\[v = 8649.4\\ \\text{m}/\\text{s}\\ ,\\] about eight-and-a-half kilometers per second.\n\n\nThe photograph (source) shows a simple exercise: holding a dumbbell out horizontally.\n\n\n\n\n\n\n\n\n\nAs anyone who does this exercise can tell you, even when there is no movement of the dumbbell, there is a strong sense of work being done. Your muscle fatigues and, for most people, the dumbbells can be held in place for only a short time.\nWe’ve said that mechanical work always involves motion; no motion, no work. So how come the exercise feels like work even though the hands do not move?\nTo perform the exercise, you contract the muscles of the shoulder and upper arm. There is no skeletal joint that can be locked in place (unlike, say, the knee). It is only the muscle force that holds the arms in place.\nOn the size scale that we normally perceive, it can appear that nothing is moving during the exercise. But zoom in to the molecular scale to see the action by which force is generated by muscle. The functional unit of muscle force involves two proteins, actin and myosin, that interact in a complicated way. The animation (from the online textbook by Michael D. Mann, The Nervous System in Action, chapter 14) shows the situation. The “head” of a myosin unit (red) acts like an oar. It attaches to a site on the actin molecule (orange) causing the head to contract and pull on the actin. Once contracted, a molecule of ATP (green sphere) binds to the myosin, releasing the head and preparing it for another stroke. ATP is an organic molecule that serves as a primary energy carrier and is found in all known forms of life. Transformation of ATP to ADP releases the energy. The ADP is then cycled, though other metabolic processes, back into ATP. This happens rapidly. Humans recycle approximately their own body weight in ATP each day.\n\n\n\n\n\nFigure 52.3: Animation of the generation of force by the interaction of actin and myosin, from The Nervous System in Action.\n\n\n\n\nWhen muscle is under tension, the actin can slip back in between strokes of the myosin head. Thus, a constant-length muscle in tension on a macroscopic scale is steadily consuming energy, in much the same way as an oarsman on an anchored boat can do work via the movement of oars against the water even when the boat itself is not moving."
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#momentum",
    "href": "Manifestations/B4-mechanics.html#momentum",
    "title": "52  Mechanics",
    "section": "52.3 Momentum",
    "text": "52.3 Momentum\nIn the previous sections we looked at force \\(\\times\\) distance. Dimensional analysis showed that [force \\(\\times\\) distance] = energy and, in the setting of lifting an object and letting it fall back toward its ground state, we traced out the conversion of the energy of position (“potential energy”) into the energy of velocity (“kinetic energy”).\nNow consider a somewhat different quantity: force \\(\\times\\) time. Dimensional analysis gives \\[\\underbrace{M^1 L^1 \\ T^{-2}}_\\text{[force]}\\  \\times\\ \\underbrace{T}_\\text{[time]} = \\underbrace{M^1}_\\text{[mass]} \\underbrace{L^1 T^{-1}}_\\text{[velocity]} \\] The product of force times time is dimensionally equivalent to the product of mass times velocity. The quantity is called momentum. Newton’s second law of motion, often written in terms of acceleration, \\(F = m a\\), is more fundamentally written in terms of momentum: \\(F = \\partial_t\\, m\\, v\\). The conservation of momentum refers to the situation when outside forces on a system are nil. In such case, momentum of the system doesn’t change with time; momentum is constant or “conserved.”\nAn example of such a system is a deep-space probe, sufficiently far from other matter that gravitational force is negligible. In order to speed up or slow down (or turn), the probe is made to throw out fast moving molecules of burnt fuel. These particles have “new” momentum, but since momentum of the whole system is conserved, the body of the probe gains “new” momentum in the opposite direction. This is the operating principle of the rocket engine.\n\n\n\n\n\nFigure 52.4: Left: A turbojet engine uses air for combustion and emits a relatively low amount of mass at high velocity. Right: A turbofan engine uses a fan blade (1) to convert some of the combustion energy into a large mass of relatively slow velocity, unburnt air.\n\n\n\n\n\n\n\nFigure 52.5: Left: A turbojet engine uses air for combustion and emits a relatively low amount of mass at high velocity. Right: A turbofan engine uses a fan blade (1) to convert some of the combustion energy into a large mass of relatively slow velocity, unburnt air.\n\n\n\n\nAircraft jet engines work in a similar matter, burning fuel to create energy. Whereas the force generated by a rocket engine is entirely produced by the newly created momentum of the burnt fuel, aircraft engines have an additional material to work with: air. The earliest jet engines, turbojet engines, were small in diameter, bringing in air mainly as a fuel for combustion. (?fig-jet-engines (left)1 Today’s more efficient engines are large diameter: turbofan engines. (?fig-jet-engines (right)2) In addition to using air for combustion, they use large fan blades to convert the energy of combustion into a large mass of relatively slowly moving, uncombusted air. This moving air carries momentum; more than that contained in the fast moving particles generated directly through combustion."
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#sec-center-of-mass",
    "href": "Manifestations/B4-mechanics.html#sec-center-of-mass",
    "title": "52  Mechanics",
    "section": "52.4 Center of mass",
    "text": "52.4 Center of mass\nIn considering a physical object of extended shape, it can be a great simplification to be able to treat the whole extended object as if it were a simple point object at a single location. For instance, Figure 52.6 imagines a space probe (orange dot) coasting through the edge of a galaxy.\n\n\n\n\n\n\n\n\nFigure 52.6: An imagined space probe (orange dot) on the outer edges of a galaxy.\n\n\n\n\nWhat is the gravitational attraction of the galaxy on the probe? One way to find this is by adding up the individual gravitational attractions of the individual stars. Another is to find the center of mass of the galaxy and calculate the force as if all the mass were at that point. The two calculations give the same answer.\nFor the galaxy, the center of mass is located at a point \\((\\bar{x},\\bar{y})\\) where \\[\\bar{x} \\equiv \\sum_\\text{galaxy} m_i x_i\\ \\ \\ \\text{and}\\ \\ \\ \\ \\bar{y} \\equiv \\sum_\\text{galaxy} m_i y_i\\]\n\n\n\n\n\n\n\n\nFigure 52.7: An irregular shape used in the example. The \\((x,y)\\) coordinates of closely spaced points on the boundary are available as Zcalc::Blob1 in the sandbox software.\n\n\n\n\nFor a continuous shape, such as in Figure 52.7 (left) we can describe the center-of-mass calculation as an accumulation of the mass-density function \\(\\rho(x, y)\\) over the entire shape \\(S\\). The mass of the object is the accumulation of mass-density itself \\[M = \\int_\\text{S} \\rho(x,y)\\ d\\text{S}\\] while the components of the center of mass are the accumulation of \\(x\\ \\rho(x,y)\\) and \\(y\\ \\rho(x,y)\\), that is: \\[\n\\bar{x} = \\int_\\text{S} x\\ \\rho(x,y)\\ d\\text{S} / M\\\\\n\\bar{y} = \\int_\\text{S} y\\ \\rho(x,y)\\ d\\text{S} / M\n\\] where \\(S\\) refers to the whole object and \\(d\\)S is a differential of the object, that is, a tiny piece of the object.\nThere are many ways to split an object up into differentials so that they can be accumulated to give the whole integral. One simple way, shown in Figure 52.7 (right), is to divide the object into a set of discrete, non-overlapping, adjacent rectangles (or cubes for a three-dimensional object). Then, as with adding up the stars, just add up \\(x \\rho(x, y) d\\)S or \\(y \\rho(x,y) d\\)S contained in each of the rectangular \\(d\\)A regions. For the rectangle located at $(x_i, y_i), the mass \\(m_i\\) will be \\(m_i = \\rho(x_i, y_i) d\\)S: density times area of each rectangle. This turns the integrals in Eq. @ref(eq:cm-integral) into a sum:\n\\[\\bar{x} \\approx \\sum_\\text{rectangles} m_i x_i/ M\\ \\ \\ \\text{and}\\ \\ \\ \\ \\bar{y} \\approx \\sum_\\text{rectangles} m_i y_i / M\\] where \\[M = \\sum_\\text{rectangles} m_i\\ .\\]\n\n\n\n\n\nFigure 52.8: A continuous shape can be approximated by a set of rectangles within the borders of the shape. Integrating over the shape is a matter of adding up across all of the rectangles the relevant quantity for each rectangle.\n\n\n\n\nFor the center of mass calculation, the relevant quantity for \\(\\bar{x}\\) for each rectangle is the mass times the \\(x\\)-position. Similarly, for \\(\\bar{y}\\) the relevant quanty is the mass times the \\(y\\)-position.\n\n\n\n\n\nFigure 52.9: For the \\(y\\)-component of the center of mass (left panel), the \\(x\\)-coordinate of each rectangle is irrelevant. It is as if all the rectangles were moved to \\(x=0\\). Similarly for the \\(x\\)-component of the center of mass (right panel).\n\n\n\n\n\nCompute the center of mass of the object Zcalc::Blob1 shown in Figure 52.7, assuming the mass-density \\(\\rho(x,y) = 10\\).\nThe mass of the object is \\[M = \\int_\\text{Blob1} \\rho(x, y)\\, dA\\] The \\(x\\)-component of the center of mass is\n\\[\\bar{x} = \\int_\\text{Blob1} x \\rho(x, y)\\, dA / M\\] and similarly for \\(\\bar{y}\\).\nTo find the center of mass, we first need to know the total mass of the object. We’ll carry out the calculation by dividing the object into a series of rectangles, computing the mass of each rectangle, then adding together the masses. The R/mosaic function box_set() takes as input the density function, a data frame with points on the boundary of the object, and a size for the boxes, which we’ll set to \\(dx=0.1\\).\n\nBoxes <- box_set(10 ~ x + y, Zcalc::Blob1, dx=0.1)\n\nGive this command in a sandbox and look at the resulting data frame Boxes. Each row is one box. The x and y columns give the location of the center of that box, dx and dy are the lengths of the box sides in the \\(x\\) and \\(y\\) directions. The value ofthe function being accumulated is in the column labelled .output. column dA gives the area of each box (which is simply \\(dA = dx\\, dy\\)).\nAs the notation \\[\\int_\\text{Blob1} \\rho(x, y) dx dy\\] suggests, to accumulate the results for the individual boxes we just multiply the .output. by dA and sum.\n\nmass <- with(Boxes, sum(.output. * dA))\n\n\n## [1] 67.3\n\nComputing the \\(x\\)-component of the center of mass, \\(\\bar{x}\\), is much the same but now the function being integrated is \\(x \\rho(x,y)\\) instead of just \\(\\rho(x,y)\\):\n\nBoxes2 <- box_set(10*x ~ x + y, Zcalc::Blob1, dx=0.1)\nxbar <- with(Boxes2, sum(.output. * dA)) / mass\n\n\n## [1] -0.1543015\n\nThe \\(y\\) component of the center of mass, \\(\\bar{y}\\) is computed almost identically, but substituting 10*y ~ x & y as the function to be integrated. In the next line, we’ll tell box_set() to do the summation over all the boxes directly, instead of our having to do it with the with(..., sum(.output. * dA)) command.\n\nybar <- box_set(10*y ~ x + y, Zcalc::Blob1, dx=0.1, sum=TRUE) / mass\n\n\n## [1] -0.2371817\n\n\nRecall that the summation over the boxes provides an approximation to the integral. The quality of the approximation depends on the boxes being small enough. It’s responsible to check the result by using smaller box size:\n\nybar <- box_set(10*y ~ x + y, Zcalc::Blob1, dx = 0.01, sum=TRUE) / mass\nybar\n## [1] -0.2323201\nbox_set(10*y ~ x + y, Zcalc::Blob1, dx = 0.001, sum=TRUE) / mass\n## [1] -0.2322872\n\nFrom this, we conclude that a box size dx = 0.01 gives 4 digits precision, but dx = 0.1 was not small enough.\nRepeat the calculation for \\(\\bar{x}\\) to get the same precision: ::: {.cell layout-align=“center” fig.showtext=‘false’}\nxbar  <- box_set(10*x ~ x + y, Zcalc::Blob1, dx = 0.01, sum=TRUE) / mass\n\n\n## [1] -0.1513999\n\n\nThere is more than one way to describe the perimeter of an object, and the manner of integration has to be selected to match the description.\nConsider this shape that might be the design of a panel in a large sculpture. The panel will be cut out of 3mm thick sheet aluminum \\(x\\) and \\(y\\) are given in meters. In order for the panel to be balanced, it will be mounted at its center of mass\n\n\n\n\n\n\nFigure 52.10: A panel to locate center of mass\n\n\n\nThe shape is defined by two functions, \\(f(x)\\) and \\(g(x)\\), one of which sets the top edge and the other the bottom edge. The side edges are defined by the leftmost and rightmost values of \\(x\\). Here, that’s \\(x_\\text{left} = - 1.5\\) and \\(x_\\text{right} = 4.0\\).\nThe area of the object can be found using the integration techniques from Block 3. For the purpose of finding the center of mass, we need to calculate the mass of the object. For 3mm sheet aluminum the density is about 8.1 kg/m2. Here, that’s simply \\[\\text{mass} = \\int_{-1.5}^{4.0} 8.1 \\left[\\strut f(x) - g(x)\\right] dx \\approx 880 \\text{kg}\\ .\\]\nWhat about the center of mass? Because the shape is not described as a set of boxes, as we did earlier in this section, we need a way to perform the accumulation that uses only the information in the functions.\nThe differential \\(8.1 \\left[\\strut f(x) - g(x)\\right] dx\\) gives the mass of each vertical slice of the object, several of which are shown in \\(\\color{magenta}{\\text{magenta}}\\) in ?fig-cm-fun-diff.The tops and bottoms of those slices don’t align exactly with the boundaries of the object. That’s because we’ve drawn them at a finite width so that you can see them. But the actual differentials being accumulated will have negligible width, and so will fit exactly.\n\n\n\n\n\nFigure 52.11: The panel can be divided into vertical slices, a few of which are shown here. The vertical mid-point of each slice is marked with a blue dash. Accumulating the slices’ mid-point coordinates times the slices’ mass, and dividing by the panel’s mass, gives the \\(y\\)-component of the center of mass.\n\n\n\n\nThe horizontal positions of the vertical slices are given by \\(x\\). The \\(x\\)-component of the center of mass of each individual vertical slice will be \\[x \\left[\\strut \\text{top}(x) - \\text{bottom}(x)\\right] dx\\ .\\] The center of mass of the entire object will be the accumulation \\[\\bar{x}= \\frac{1}{\\text{mass}}\\int_{-1.5}^{4.0} x\\ \\text{density} \\left[\\strut \\text{top}(x) - \\text{bottom}(x)\\right] dx \\approx 1.72 \\text{m}\\ .\\]\nFinding the \\(y\\)-component of the center of mass could be done in a similar way, by constructing horizontal slices. However, we would have to calculate the functions \\(\\text{left}(y)\\) and \\(\\text{right}(y)\\) that bound each slice.\nAn easier way is to find the vertical center of each slice. For a slice at position \\(x\\), the vertical center is \\[y_{\\text{mid}}(x) \\equiv\\left[\\strut \\text{top}(x) + \\text{bottom}(x)\\right]/ 2\\ ,\\] the average of the top and bottom positions. (These are marked in \\(\\color{blue}{\\text{blue}}\\) in Figure 52.11.) The \\(y\\)-component of the center of mass is \\[\\begin{eqnarray}\n\\bar{y} &=& \\frac{1}{\\text{mass}} \\int_{-1.5}^{4.0} \\text{density}\\ y_\\text{mid}(x)\\ \\left[\\strut \\text{top}(x) - \\text{bottom}(x)\\right] dx = \\\\\n&=&\\frac{1}{\\text{mass}} \\int_{-1.5}^{4.0} \\text{density}\\ \\frac{\\left[\\strut \\text{top}(x) + \\text{bottom}(x) \\right]}{2}\\ \\left[\\strut \\text{top}(x) - \\text{bottom}(x)\\right] dx =\\\\\n&=&\\frac{1}{\\text{mass}} \\int_{-1.5}^{4.0} \\text{density}\\ \\frac{\\left[\\strut \\text{top}(x)^2 - \\text{bottom}(x)^2 \\right]}{2}\\ \\approx -5.43 \\text{m}\\ .\n\\end{eqnarray}\\]\nThe center of mass, \\((x=1.72, y=-5.43)\\), is plotted as \\(\\color{blue}{\\Large\\mathbf{\\text{+}}}\\) on the object."
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#angular-momentum-and-torque",
    "href": "Manifestations/B4-mechanics.html#angular-momentum-and-torque",
    "title": "52  Mechanics",
    "section": "52.5 Angular momentum and torque",
    "text": "52.5 Angular momentum and torque\nThe relationship between force and momentum is familiar: \\[F = \\partial_t\\, m\\, v =\\ \\underbrace{m \\ \\partial_t\\  v}_\\text{if mass is constant}\\ .\\] Of course, the derivative of velocity with respect to time is also called “acceleration.”\nConsider the following situation. A space probe is being acted on by a constant force, as in Figure 52.12. The mass of the probe is \\(m\\), the thrust from the rocket engine provides the force \\(F\\). Starting from velocity \\(\\partial_t y(t=0)\\) and position \\(y(t=0) = 0\\), the thrust produces an acceleration \\(\\partial_{tt} y(t) = F/m\\). Integrating the acceleration gives the velocity as a function of time \\[\\partial_t y(t) = \\frac{F}{m} t + C\\ .\\]\n\n\n\n\n\n\nFigure 52.12: A space probe accelerating along a linear course. The position at time \\(t\\) can be written as \\(y(t)\\) or as $ heta(t)$.\n\n\n\nThe function \\(y(t)\\) is not the only way to represent where the probe is as a function of \\(t\\). Suppose that the probe is being observed by a telescope which measures the angle \\(\\theta(t)\\) with respect to the equatorial plane. If the distance to the probe is \\(D(t)\\), then the pair \\(\\left(\\strut\\theta(t), D(t)\\right)\\) gives the position of the probe. As \\(y(t)\\) increases, so do \\(\\theta(t)\\) and \\(D(t)\\).\nWe know the laws of motion in terms of \\(y(t)\\). Can we translate these laws to an expression in terms of \\(\\theta(t)\\) and \\(D(t)\\)? That is, can we find the function \\[\\partial_{t} \\theta(t) = {\\Large ?}\\] If we can find the laws of motion in terms of \\(\\theta(t)\\) and \\(D(t)\\), we’ll have a way to describe the motion of spinning bodies.\n\n\n\nThe derivation of \\(\\partial_{t} \\theta(t)\\) will not be obvious, but you’ll be able to see how calculus operations come into play.\nThree points in the diagram describe a right triangle: the probe’s position at \\(t=0\\), the center of the planet, and the probe’s position at time \\(t\\). The length of the horizontal leg of the triangle is \\(D(t=0)\\) which not a function of time, so we’ll drop the unnecessary parentheses and write it as \\(D_0\\). The vertical leg has length \\(y(t)\\), and the hypotenuse has length \\(D(t)\\). The Pythagorean theorem tells us that \\[D(t)^2 = y(t)^2 + D_0^2\\ .\\]\nStep 1: Differentiate both sides with respect to \\(t\\): \\[\\partial_t \\left[\\strut D(t)^2\\right] = \\partial_t \\left[\\strut y(t)^2\\right] \\ . \\] Using the chain rule and the fact that \\(D_0\\) does not depend on \\(t\\), gives \\[2\\, D(t)\\, \\partial_t D(t) = 2\\, y(t)\\ \\partial_t y(t)\\ \\ \\implies\\ \\ \\partial_t y(t) = \\frac{D(t)}{y(t)}\\,\\partial_t D(t)\\ .\\]\nStep 2: Trigonometry allows us to see a relationship among the functions \\(y(t)\\), \\(\\theta(t)\\), and \\(D(t)\\):\n\\[y(t) = D(t) \\sin\\left(\\strut\\theta(t)\\right) \\ .\\] Plugging this form of \\(y(t)\\) into the equation for \\(\\partial_t y(t)\\) in Step 1 produces \\[\\partial_t y(t) = \\frac{1}{\\sin(\\theta(t))} \\partial_t D(t)\\] and \\[D_0 = D(t) \\cos\\left(\\strut\\theta(t)\\right)\\ \\ \\implies\\ \\ D(t) = \\frac{D_0}{\\cos\\left(\\strut\\theta(t)\\right)}\\]\nStep 3: Another fact from trigonometry is that \\[D(t) = D_0/\\cos(\\theta(t))\\ .\\] Differentiating both sides (chain rule again!) with respect to \\(t\\) gives another form for \\(\\partial_t D(t)\\): \\[\\partial_t D(t) = D_0\\, \\partial_t \\left(\\frac{1}{\\cos\\left(\\strut\\theta(t)\\right)}\\right) = D_0 \\frac{\\sin\\left(\\strut\\theta(t)\\right)}{\\cos\\left(\\strut\\theta(t)\\right)^2}\\, \\partial_t \\theta(t)\\]\nStep 4: Combining the results from Steps 1 and 3 gives \\[\\partial_t y(t) =  \\frac{1}{\\sin\\left(\\strut\\theta(t)\\right)}D_0 \\frac{\\sin\\left(\\strut\\theta(t)\\right)}{\\cos\\left(\\strut\\theta(t)\\right)^2}\\, \\partial_t \\theta(t)\\ .\\] Cancelling out the \\(\\sin(\\theta(t))\\) terms and remembering that \\(\\partial_t y(t) = \\frac{F}{m} t\\) gives\n\\[\\frac{F}{m} t = \\frac{D_0}{\\cos\\left(\\strut \\theta(t)\\right)^2}\\, \\partial_t\\theta(t) \\] Multiplying both sides by \\(D_0\\) and recalling that \\(D(t) = D_0/\\cos(\\theta(t))\\) we arrive at \\[\\frac{F D_0}{m} t = \\frac{D_0^2}{\\cos\\left(\\strut \\theta(t)\\right)^2}\\, \\partial_t\\theta(t) = D(t)^2 \\partial_t \\theta(t)\\ . \\]\nAgain re-arranging to find \\(\\partial_t\\, \\theta(t)\\): \\[\\partial_t\\,\\theta(t) = \\frac{F\\, D_0}{m D(t)^2}\\ t\\ .\\]\nTo summarize, we have two equivalent expressions for the dynamics of the space probe:\n\\[\\partial_t y(t) = \\frac{\\overbrace{\\ F}^\\text{force}}{\\underbrace{M}_\\text{mass}} t \\ \\ \\text{and}\\ \\ \\partial_t \\theta(t) = \\frac{\\overbrace{F\\, D_0}^\\text{torque}}{\\underbrace{m D(t)^2}_\\text{moment of inertia}}\\ t\\ .\\] In rectangular \\((x,y)\\) coordinates, the velocity is the accumulation of force divided by mass: the usual statement of Newton’s second law of motion. In the angular coordinates \\((\\theta, D)\\) the angular velocity is the accumulation of torque divided by ***moment of inertia.\nThe angular coordinate representation is helpful when studying the rotation of objects. To illustrate, imagine a different configuration for the system than that in in Figure 52.12 where the space probe was free to accelerate in a straight line. Instead, suppose the rocket is mounted on a carousel, that is a wheel whose axle goes through the center as in Figure 52.13.\n\n\n\n\n\n\nFigure 52.13: The space probe mounted on a rigid wheel that can spin around its center.\n\n\n\nIn the rocket-on-wheel configuration, \\(D(t)\\) is a constant; the rocket stays the same distance from the center. Therefore, the moment of inertia is \\(m D_0^2\\). Following the previous formula, \\[\\partial_t \\theta(t) = \\frac{F D_0}{m D_0^2} t\\] which is easily differentiated to give the angular acceleration \\[\\partial_{tt} \\theta(t) = \\frac{F D_0}{m D_0^2}\\ .\\]\nIn a typical wheel, there is mass density throughout the wheel, not just at distance \\(D_0\\). To find the moment of inertia of such a distributed mass system, break the wheel down into small pieces and find the moment of inertia due to each bit. Then accumulate the pieces’ moments of inertia to find the total moment of inertia:\n\\[\\text{moment of inertia} = \\int_\\text{wheel} \\rho(x,y) \\left(\\strut x^2 + y^2\\right) d \\text{wheel}\\ .\\]\n\nCompute the moment of inertia of Zcalc::Blob1.\nIt’s not enough to say, “compute the moment of inertia.” We also have to specify what is the reference location—the wheel axle in the configuration. We’ll first do the calculation around the center of mass \\((\\bar{x}, \\bar{y})\\) which we computed earlier as xbar and ybar:\n\n# moment of inertia\nbox_set(10*((x - xbar)^2 + (y-ybar)^2)~ x + y, Zcalc::Blob1, dx = 0.01, sum=TRUE) \n## [1] 76.67827"
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#exercises",
    "href": "Manifestations/B4-mechanics.html#exercises",
    "title": "52  Mechanics",
    "section": "52.6 Exercises",
    "text": "52.6 Exercises"
  }
]